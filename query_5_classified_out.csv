eid,doi,pii,pubmed_id,title,subtype,subtypeDescription,creator,afid,affilname,affiliation_city,affiliation_country,author_count,author_names,author_ids,author_afids,coverDate,coverDisplayDate,publicationName,issn,source_id,eIssn,aggregationType,volume,issueIdentifier,article_number,pageRange,description,authkeywords,citedby_count,openaccess,fund_acr,fund_no,fund_sponsor,abstract,include?
2-s2.0-84872723602,10.5755/j01.eee.18.9.2825,,,The LEGO NXT robot-based e-learning environment to teach computer science topics,ar,Article,Burbaite R.,,Kaunas University of Technology,Kaunas,Lithuania,,,,,2012-12-01,2012,Elektronika ir Elektrotechnika,13921215,19900193212,,Journal,18,9,,113-116,,,12,1,,,,"It is difficult to motivate learners to learn abstract Computer Science topics (e.g., data structures, algorithms and programming) with the adequate level of engagement. We present the process of constructing a LEGO robot, called the DRAWBOT (drawing robot), which enables to create the e-learning environment to demonstrate visually the solution of graph-based Computer Science tasks through teaching programming. Our research has confirmed the importance of using robot-based environments for teaching that was known so far in the literature on e-learning. We have extended the known approaches: a) by providing technical characteristics for the process to create the e-learning environment for the real setting; b) by smoothly integrating different phases of the process and considering it into entirety to support the constructivist learning model.

DOI: http://dx.doi.org/10.5755/j01.eee.18.9.2825",SI
2-s2.0-84870861362,10.1080/03043797.2012.725711,,,Embedded C programming: A practical course introducing programmable microprocessors,ar,Article,Laverty D.,,Queen's University Belfast,Belfast,United Kingdom,,,,,2012-12-01,December 2012,European Journal of Engineering Education,03043797,11300153314,14695898,Journal,37,6,,557-574,,,3,0,,,,"This paper presents a new laboratory-based module for embedded systems teaching, which addresses the current lack of consideration for the link between hardware development, software implementation, course content and student evaluation in a laboratory environment. The course introduces second year undergraduate students to the interface between hardware and software and the programming of embedded devices; in this case, the PIC (originally peripheral interface controller, later rebranded programmable intelligent computer) microcontroller. A hardware development board designed for use in the laboratories of this module is presented. Through hands on laboratory experience, students are encouraged to engage with practical problem-solving exercises and develop programming skills across a broad range of scenarios.",NO
2-s2.0-84864477631,10.1016/j.eswa.2012.04.038,S0957417412006355,,Adaptability analysis of genetic network programming with reinforcement learning in dynamically changing environments,ar,Article,Mabu S.,,Waseda University,Tokyo,Japan,,,,,2012-11-15,15 November 2012,Expert Systems with Applications,09574174,24201,,Journal,39,16,,12349-12357,,,10,0,,,,"Genetic network programming (GNP) has been proposed as one of the evolutionary algorithms and extended with reinforcement learning (GNP-RL). The combination of evolution and learning can efficiently evolve programs and the fitness improvement has been confirmed in the simulations of tileworld problems, elevator group supervisory control systems, stock trading models and wall following behavior of Khepera robot. However, its adaptability in testing environments, where the situations dynamically change, has not been analyzed in detail yet. In this paper, the adaptation mechanism in the testing environment is introduced and it is confirmed that GNP-RL can adapt to the environmental changes using a robot simulator WEBOTS, especially when unexperienced sensor troubles suddenly occur. The simulation results show that GNP-RL works well in the testing even if wrong sensor information is given because GNP-RL has a function to automatically change programs using alternative actions. In addition, the analysis on the effects of the parameters of GNP-RL is carried out in both training and testing simulations.

Highlights

► We proposed an adaptive learning mechanism using reinforcement learning. ► The adaptability is examined when some sensors are suddenly broken. ► Faulty sensors are indirectly detected through the changes of Q values. ► The size of Q table is compact, so the quick recovery from troubles is possible.",NO
2-s2.0-84866405210,10.1080/01691864.2012.703167,,,Learning manipulation tasks from human demonstration and 3D shape segmentation,ar,Article,Aleotti J.,,Università di Parma,Parma,Italy,,,,,2012-11-01,1 November 2012,Advanced Robotics,01691864,18003,15685535,Journal,26,16,,1863-1884,,,5,0,,,,"According to neuro-psychology studies, 3D shape segmentation plays an important role in human perception of objects because when an object is perceived for grasping it is first parsed in its constituent parts. This capability is missing in current robot planning systems, which are therefore hindered in their ability to plan part-specific grasps suitable for the current task. In this paper, a novel approach for part-based grasping is presented that combines 3D shape segmentation, programing by human demonstration and manipulation planning. The central advantage over previous approaches is the use of a topological method for shape segmentation enabling both object categorization and robot grasping according to the affordances of an object. Manipulation tasks are demonstrated in a virtual reality environment using a data glove and a motion tracker, and the specific parts of the objects where grasping occurs are learned and encoded in the task description. Tasks are then planned and executed in a robot environment targeting semantically relevant parts for grasping. Planning in the robot environment can be generalized to objects that are similar to the ones used for task demonstration, i.e. objects that belong to the same category. Results obtained in 3D simulation confirm that the proposed approach finds with less effort grasps appropriate for the requested task.",NO
2-s2.0-84868030296,10.5772/50827,,,Combining vision learning and interaction for mobile robot path planning,ar,Article,Bao J.,,Yangzhou University;Southeast University,Yangzhou;Nanjing,China;China,,,,,2012-10-04,4 October 2012,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,9,,104,,,,5,1,,,,"This paper addresses the question of how to make a robot learn natural terrain selectively and use the knowledge to estimate the terrain for planning an optimal path. A scheme which combines vision learning and interaction is proposed. The vision learning module employs an online boosting learning algorithm to constantly receive and learn the terrain samples each of which comprise the visual features extracted from the sub terrain region image and the traversability measured by the onboard Inertia Measurement Unit (IMU). Using this knowledge, the robot could estimate the new terrains and search for the optimal path to travel using the particle swarm optimization method. To overcome the shortcoming that the robot could not understand the intricate environment exactly, the vision interaction method, which complements the robot's capacity of terrain estimation with the human reasoning ability of path correction, is further applied. Experimental results show the effectiveness of the proposed method.",NO
2-s2.0-84867573740,10.1007/s11370-012-0118-y,,,Caesar: An intelligent domestic service robot,ar,Article,Schiffer S.,,Rheinisch-Westfälische Technische Hochschule Aachen,Aachen,Germany,,,,,2012-10-01,October 2012,Intelligent Service Robotics,18612776,9500154152,18612784,Journal,5,4,,259-273,,,34,0,,,,"In this paper we present CAESAR, an intelligent domestic service robot. In domestic settings for service robots complex tasks have to be accomplished. Those tasks benefit from deliberation, from robust action execution and from flexible methods for human–robot interaction that account for qualitative notions used in natural language as well as human fallibility. Our robot CAESAR deploys AI techniques on several levels of its system architecture. On the low-level side, system modules for localization or navigation make, for instance, use of path-planning methods, heuristic search, and Bayesian filters. For face recognition and human–machine interaction, random trees and well-known methods from natural language processing are deployed. For deliberation, we use the robot programming and plan language READYLOG, which was developed for the high-level control of agents and robots; it allows combining programming the behaviour using planning to find a course of action. READYLOG is a variant of the robot programming language Golog. We extended READYLOG to be able to cope with qualitative notions of space frequently used by humans, such as “near” and “far”. This facilitates human–robot interaction by bridging the gap between human natural language and the numerical values needed by the robot. Further, we use READYLOG to increase the flexible interpretation of human commands with decision-theoretic planning. We give an overview of the different methods deployed in CAESAR and show the applicability of a system equipped with these AI techniques in domestic service robotics.",NO
2-s2.0-84859049364,10.1016/j.rcim.2012.02.007,S0736584512000191,,Task-oriented motion planning for multi-arm robotic systems,ar,Article,Basile F.,,Università degli Studi di Salerno,Salerno,Italy,,,,,2012-10-01,October 2012,Robotics and Computer-Integrated Manufacturing,07365845,18080,,Journal,28,5,,569-582,,,57,0,,,,"In this paper a task-oriented motion planning approach for general cooperative multi-robot systems is proposed. In order to derive a meaningful task formulation, a taxonomy of cooperative multi-arm systems of industrial interest is devised. Then, a workpiece-oriented general formulation for cooperative tasks is proposed, where the user is asked to specify the motion of the system only at the workpiece level, while the motion of the single arms in the system is computed via kinematic transformations between the relevant coordinate frames. Based on this task formulation, an instructions set is derived to extend classical programming languages for industrial robots to general multi-robot systems. In order to test the approach, a software environment has been built, composed of an interpreter of the language and the motion planning software.

Highlights

► A taxonomy of cooperative multi-arm systems of industrial interest is devised. ► A workpiece-oriented general formulation for multi-arm cooperative tasks is developed. ► An instructions set is derived to extend robot programming languages to multi-arm systems.",NO
2-s2.0-84865733668,10.1007/978-3-642-32060-6_13,,,Learning visual obstacle detection using color histogram features,ar,Article,Metzler S.,,Universität Bonn,Bonn,Germany,,,,,2012-09-10,2012,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),03029743,25674,16113349,Book Series,7416 LNCS,,,149-161,,,15,0,,,,"Perception of the environment is crucial in terms of successfully playing soccer. Especially the detection of other players improves game play skills, such as obstacle avoidance and path planning. Such information can help refine reactive behavioral strategies, and is conducive to team play capabilities. Robot detection in the RoboCup Standard Platform League is particularly challenging as the Nao robots are limited in computing resources and their appearance is predominantly white in color like the field lines.

This paper describes a vision-based multilevel approach which is integrated into the B-Human Software Framework and evaluated in terms of speed and accuracy. On the basis of color segmented images, a feed-forward neural network is trained to discriminate between robots and non-robots. The presented algorithm initially extracts image regions which potentially depict robots and prepares them for classification. Preparation comprises calculation of color histograms as well as linear interpolation in order to obtain network inputs of a specific size. After classification by the neural network, a position hypothesis is generated.",NO
2-s2.0-84867876487,10.1109/JOE.2012.2205638,,,COLA2: A control architecture for AUVs,ar,Article,Palomeras N.,,Universitat de Girona,Girona,Spain,,,,,2012-08-15,2012,IEEE Journal of Oceanic Engineering,03649059,17277,,Journal,37,4,6263248,695-716,,,59,0,,,,"This paper presents a control architecture for an autonomous underwater vehicle (AUV) named the Component Oriented Layer-based Architecture for Autonomy (COLA2). The proposal implements a component-oriented layer-based control architecture structured in three layers: the reactive layer, the execution layer, and the mission layer. Concerning the reactive layer, to improve the vehicle primitives' adaptability to unknown changing environments, reinforcement learning (RL) techniques have been programmed. Starting from a learned-in-simulation policy, the RL-based primitive cableTracking has been trained to follow an underwater cable in a real experiment inside a water tank using the Ictineu AUV. The execution layer implements a discrete event system (DES) based on Petri nets (PNs). PNs have been used to safely model the primitives' execution flow by means of Petri net building block (PNBBs) that have been designed according to some reachability properties showing that it is possible to compose them preserving these qualities. The mission layer describes the mission phases using a high-level mission control language (MCL), which is automatically compiled into a PN. The MCL presents agreeable properties of simplicity and structured programming. MCL can be used to describe offline imperative missions or to describe planning operators, in charge of solving a particular phase of a mission. If planning operators are defined, an onboard planner will be able to sequence them to achieve the proposed goals. The whole architecture has been validated in a cable tracking mission divided in two main phases. First, the cableTracking primitive of the reactive layer has been trained to follow a cable in a water tank with the Ictineu AUV, one of the research platforms available in the Computer Vision and Robotics Group (VICOROB), University of Girona, Girona, Spain. Second, the whole architecture has been proved in a realistic simulation of a whole cable tracking mission.
(Show More)",NO
2-s2.0-84864475487,10.1177/0278364912438781,,,Learning to place new objects in a scene,ar,Article,Jiang Y.,,Cornell University,Ithaca,United States,,,,,2012-08-01,August 2012,International Journal of Robotics Research,02783649,18050,17413176,Journal,31,9,,1021-1043,,,90,0,,,,"Placing is a necessary skill for a personal robot to have in order to perform tasks such as arranging objects in a disorganized room. The object placements should not only be stable but also be in their semantically preferred placing areas and orientations. This is challenging because an environment can have a large variety of objects and placing areas that may not have been seen by the robot before. In this paper, we propose a learning approach for placing multiple objects in different placing areas in a scene. Given point-clouds of the objects and the scene, we design appropriate features and use a graphical model to encode various properties, such as the stacking of objects, stability, object–area relationship and common placing constraints. The inference in our model is an integer linear program, which we solve efficiently via an linear programming relaxation. We extensively evaluate our approach on 98 objects from 16 categories being placed into 40 areas. Our robotic experiments show a success rate of 98% in placing known objects and 82% in placing new objects stably. We use our method on our robots for performing tasks such as loading several dish-racks, a bookshelf and a fridge with multiple items.",NO
2-s2.0-84861095841,10.1007/s10710-011-9147-0,,,Learning local linear Jacobians for flexible and adaptive robot arm control,ar,Article,Stalph P.,,Eberhard Karls Universität Tübingen,Tubingen,Germany,,,,,2012-06-01,June 2012,Genetic Programming and Evolvable Machines,13892576,24208,,Journal,13,2,,137-157,,,21,1,,,,"Successful planning and control of robots strongly depends on the quality of kinematic models, which define mappings between configuration space (e.g. joint angles) and task space (e.g. Cartesian coordinates of the end effector). Often these models are predefined, in which case, for example, unforeseen bodily changes may result in unpredictable behavior. We are interested in a learning approach that can adapt to such changes—be they due to motor or sensory failures, or also due to the flexible extension of the robot body by, for example, the usage of tools. We focus on learning locally linear forward velocity kinematics models by means of the neuro-evolution approach XCSF. The algorithm learns self-supervised, executing movements autonomously by means of goal-babbling. It preserves actuator redundancies, which can be exploited during movement execution to fulfill current task constraints. For detailed evaluation purposes, we study the performance of XCSF when learning to control an anthropomorphic seven degrees of freedom arm in simulation. We show that XCSF can learn large forward velocity kinematic mappings autonomously and rather independently of the task space representation provided. The resulting mapping is highly suitable to resolve redundancies on the fly during inverse, goal-directed control.",NO
2-s2.0-84862060253,10.1007/978-3-642-29041-1_1,,,Layered programming by demonstration and planning for autonomous robot manipulation,ar,Article,Jäkel R.,,Karlsruher Institut für Technologie,Karlsruhe,Germany,,,,,2012-05-24,2012,Springer Tracts in Advanced Robotics,16107438,4900152703,1610742X,Book Series,80,STAR,,1-57,,,0,0,,,,"We propose a layered system for autonomous planning of complex service robot environment manipulation challenges. Motion planning, logic-based planning and probabilistic mission planning are integrated into a single system and planning models are generated using Programming by [human] Demonstration (PbD). The strength of planning models arises from the flexibility they give the robot in dealing with changing scenes and highly varying sequences of events. This comes at the cost of complex planning model representations and generation, however. Manually engineering very general descriptions covering a large sets of challenges is infeasible as is learning them exclusively by robot self-exploration. Thus, we present PbD for planning models together with generation of parameters from analysis of geometric scene properties to tackle that difficulty. Experimental results show the applicability of these techniques on natural learning and autonomous execution of complex robot manipulation challenges.",NO
2-s2.0-84860883413,10.1007/s00779-011-0404-2,,,Tangible interaction and learning: The case for a hybrid approach,ar,Article,Horn M.,,Northwestern University,Evanston,United States,,,,,2012-04-01,April 2012,Personal and Ubiquitous Computing,16174909,22315,,Journal,16,4,,379-389,,,128,0,,,,"Research involving tangible interaction and children has often focused on how tangibles might support or improve learning compared to more traditional methods. In this paper, we review three of our research studies involving tangible computer programming that have addressed this question in a variety of learning environments with a diverse population of children. Through these studies, we identify situations in which tangible interaction seems to offer advantages for learning; however, we have also identify situations in which tangible interaction proves less useful and an alternative interaction style provides a more appropriate medium for learning. Thus, we advocate for a hybrid approach—one that offers teachers and learners the flexibility to select the most appropriate interaction style to meet the needs of a specific situation.",SI
2-s2.0-84857790586,10.1007/s10846-011-9606-0,,,Reasoning with qualitative positional information for domestic domains in the situation calculus,ar,Article,Schiffer S.,,Rheinisch-Westfälische Technische Hochschule Aachen,Aachen,Germany,,,,,2012-04-01,April 2012,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,66,1-2,,273-300,,,33,0,,,,"In this paper, we present a thorough integration of qualitative representations and reasoning for positional information for domestic service robotics domains into our high-level robot control. In domestic settings for service robots like in the ROBOCUP@HOME competitions, complex tasks such as “get the cup from the kitchen and bring it to the living room” or “find me this and that object in the apartment” have to be accomplished. At these competitions the robots may only be instructed by natural language. As humans use qualitative concepts such as “near” or “far”, the robot needs to cope with them, too. For our domestic robot, we use the robot programming and plan language Readylog, our variant of Golog. In previous work we extended the action language Golog, which was developed for the high-level control of agents and robots, with fuzzy set-based qualitative concepts. We now extend our framework to positional fuzzy fluents with an associated positional context called frames. With that and our underlying reasoning mechanism we can transform qualitative positional information from one context to another to account for changes in context such as the point of view or the scale. We demonstrate how qualitative positional fluents based on a fuzzy set semantics can be deployed in domestic domains and showcase how reasoning with these qualitative notions can seamlessly be applied to a fetch-and-carry task in a ROBOCUP@HOME scenario.",NO
2-s2.0-84856009347,10.1016/j.robot.2011.07.022,S0921889011001552,,A 3D shape segmentation approach for robot grasping by parts,ar,Article,Aleotti J.,,Università di Parma,Parma,Italy,,,,,2012-03-01,March 2012,Robotics and Autonomous Systems,09218890,18079,,Journal,60,3,,358-366,,,31,0,,,,"Neuro-psychological findings have shown that human perception of objects is based on part decomposition. Most objects are made of multiple parts which are likely to be the entities actually involved in grasp affordances. Therefore, automatic object recognition and robot grasping should take advantage from 3D shape segmentation. This paper presents an approach toward planning robot grasps across similar objects by part correspondence. The novelty of the method lies in the topological decomposition of objects that enables high-level semantic grasp planning.

In particular, given a 3D model of an object, the representation is initially segmented by computing its Reeb graph. Then, automatic object recognition and part annotation are performed by applying a shape retrieval algorithm. After the recognition phase, queries are accepted for planning grasps on individual parts of the object. Finally, a robot grasp planner is invoked for finding stable grasps on the selected part of the object. Grasps are evaluated according to a widely used quality measure. Experiments performed in a simulated environment on a reasonably large dataset show the potential of topological segmentation to highlight candidate parts suitable for grasping.

Highlights

► A method for planning robot grasps across similar objects by part correspondence. ► Topological decomposition of objects enables high-level semantic grasp planning. ► Reeb graphs are used for object segmentation and grasping. ► Evaluation of part-based object recognition and grasping by part capabilities.",NO
2-s2.0-84856007818,10.1016/j.robot.2011.07.023,S0921889011001576,,Coupled dynamical system based arm-hand grasping model for learning fast adaptation strategies,ar,Article,Shukla A.,,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,,,,,2012-03-01,March 2012,Robotics and Autonomous Systems,09218890,18079,,Journal,60,3,,424-440,,,39,0,,,,"Performing manipulation tasks interactively in real environments requires a high degree of accuracy and stability. At the same time, when one cannot assume a fully deterministic and static environment, one must endow the robot with the ability to react rapidly to sudden changes in the environment. These considerations make the task of reach and grasp difficult to deal with. We follow a Programming by Demonstration (PbD) approach to the problem and take inspiration from the way humans adapt their reach and grasp motions when perturbed. This is in sharp contrast to previous work in PbD that uses unperturbed motions for training the system and then applies perturbation solely during the testing phase. In this work, we record the kinematics of arm and fingers of human subjects during unperturbed and perturbed reach and grasp motions. In the perturbed demonstrations, the target’s location is changed suddenly after the onset of the motion. Data show a strong coupling between the hand transport and finger motions. We hypothesize that this coupling enables the subject to seamlessly and rapidly adapt the finger motion in coordination with the hand posture. To endow our robot with this competence, we develop a coupled dynamical system based controller, whereby two dynamical systems driving the hand and finger motions are coupled. This offers a compact encoding for reach-to-grasp motions that ensures fast adaptation with zero latency for re-planning. We show in simulation and on the real iCub robot that this coupling ensures smooth and “human-like” motions. We demonstrate the performance of our model under spatial, temporal and grasp type perturbations which show that reaching the target with coordinated hand–arm motion is necessary for the success of the task.

Highlights

► This work concerns handling fast perturbations in reach-to-grasp tasks. ► We studied how humans react under perturbations. ► We found an inherent coupling between hand and arm movements. ► We presented a coupled dynamical system based model which mimics this coupling.",NO
2-s2.0-85087985877,10.1007/s13218-011-0148-1,,,Integration of programming and learning in a control language for autonomous robots,ar,Article,Kirsch A.,,"Fakultät für Informatik, Technische Universität München",Garching bei Munchen,Germany,,,,,2012-02-01,1 February 2012,KI - Kunstliche Intelligenz,09331875,21101017166,16101987,Journal,26,1,,79-82,,,0,0,,,,"Zusammenfassung

Durch den zunehmenden Einsatz von Robotern in Alltagsumgebungen wird die Fähigkeit sich durch Lernen an dynamische Umgebungen anzupassen immer wichtiger. Die Robot Learning Language (RoLL) schafft die Grundlage für eine nahtlose Integration von Lernen in Robotersteuerungsprogramme. Sie enthält Konstrukte zum Definieren und automatischen Sammeln von Erfahrungsdaten sowie zum Definieren und Ausführen von Lernproblemen. Durch ihre Modularität kann RoLL mit verschiedenen Lernalgorithmen verwendet werden.",NO
2-s2.0-84857498771,10.1007/s10015-011-0996-7,,,An educational tool for interactive parallel and distributed processing,ar,Article,Pagliarini L.,,Technical University of Denmark;Accademia di belli arti-Macerata,Lyngby;Macerata,Denmark;Italy,,,,,2012-02-01,February 2012,Artificial Life and Robotics,14335298,144653,16147456,Journal,16,4,,441-447,,,1,0,,,,"In this article we try to describe how the modular interactive tiles system (MITS) can be a valuable tool for introducing students to interactive parallel and distributed processing programming. This is done by providing a handson educational tool that allows a change in the representation of abstract problems related to designing interactive parallel and distributed systems. Indeed, the MITS seems to bring a series of goals into education, such as parallel programming, distributedness, communication protocols, master dependency, software behavioral models, adaptive interactivity, feedback, connectivity, topology, island modeling, and user and multi-user interaction which can rarely be found in other tools. Finally, we introduce the system of modular interactive tiles as a tool for easy, fast, and flexible hands-on exploration of these issues, and through examples we show how to implement interactive parallel and distributed processing with different behavioral software models such as open loop, randomness-based, rule-based, user interaction-based, and AI- and ALife-based software.",NO
2-s2.0-84857030116,10.1109/TE.2011.2155066,,,Localization of mobile robots using an extended kalman filter in a lEGO NXT,ar,Article,Pinto M.,,Universidade do Porto,Porto,Portugal,,,,,2012-02-01,February 2012,IEEE Transactions on Education,00189359,17344,,Journal,55,1,5782966,135-144,,,37,0,,,,"The inspiration for this paper comes from a successful experiment conducted with students in the “Mobile Robots” course in the fifth year of the integrated Master's program in the Department of Electrical and Computer Engineering, Faculty of Engineering, University of Porto (FEUP), Porto, Portugal. One of the topics in this Mobile Robots course is “ Localization of Mobile Robots using the Extended Kalman Filter in a LEGO NXT,” which gives the students the opportunity to study the concepts of localization. This experiment comes within the framework of teaching localization concepts in mobile robotics and focuses primarily on explaining the Kalman filter concept. It involves a specific tool developed by the authors and based on LEGO NXT technology. The work presented here could be a helpful guide for teaching concepts related to localization in mobile robotics to ensure adequate understanding of the concept and of the use of the extended Kalman filter (EKF). The LegoFeup robot described here was built using a LEGO Mindstorms NXT and tested both in simulation and in real scenarios. Based on the results obtained, the authors concluded that the developed tool is effective in motivating students. The implementation of the tool, the structure of the Mobile Robots course, and the criteria for student assessment are described in this paper.",NO
2-s2.0-84855246435,10.1016/j.robot.2011.11.009,S0921889011002120,,A two-tiered global path planning strategy for limited memory mobile robots,ar,Article,Chand P.,,University of the South Pacific;Victoria University of Wellington,Suva;Wellington,Fiji;New Zealand,,,,,2012-02-01,February 2012,Robotics and Autonomous Systems,09218890,18079,,Journal,60,2,,309-321,,,13,0,,,,"Multi-robot systems have inherent advantages such as the ability to allocate and redistribute tasks across the team of robots. For multi-robot tasks such as exploration of large environments, some of the available robots may only possess simple embedded controllers with limited memory capacity. However, in some situations these limited robots may be required to perform global path planning to navigate beyond localised regions of the large environment. Global path planning can be problematic for the limited memory robots if they are unable to store the entire map in their local memory. Hence, this paper presents and evaluates a two-tiered path planning technique to permit global path planning. A set of local maps describing the global map is searched using a two-tiered A∗ algorithm that executes entirely on the limited memory robots. Planning time, data communication and path length are evaluated for various combinations of local and global maps. Employing smaller local map sizes in large global maps is capable of yielding superior or comparable execution times to non-memory constrained planning.",NO
2-s2.0-84864646058,10.1109/TE.2012.2182998,,,A middleware platform for providing mobile and embedded computing instruction to software engineering students,ar,Article,Mattmann C.,,University of Southern California;Jet Propulsion Laboratory,Los Angeles;Pasadena,United States;United States,,,,,2012-01-27,2012,IEEE Transactions on Education,00189359,17344,,Journal,55,3,6140611,425-435,,,3,0,,,,"As embedded software systems have grown in number, complexity, and importance in the modern world, a corresponding need to teach computer science students how to effectively engineer such systems has arisen. Embedded software systems, such as those that control cell phones, aircraft, and medical equipment, are subject to requirements and constraints that are significantly different from those encountered in the standard desktop computing environment. For example, embedded systems must frequently address challenges that arise from severe resource restrictions (e.g., low memory and network bandwidth), heterogeneous hardware platforms, and safety-critical operations. Software architecture has been shown to be an effective means for coping with such issues, yet traditional courses on embedded software development rarely focus on software architectural abstractions. Instead, they have concentrated on lower-level issues such as programming languages and hardware interfaces. Since 2005 at the University of Southern California, Los Angeles, a unique course has been developed that affords students the opportunity to gain experience and insights on developing software architectures for embedded systems. At the heart of the course is a middleware platform, Prism-MW, that helps students use software architectural principles to construct embedded systems and understand the important challenges of the embedded systems domain. This paper describes this course through the explanation and evaluation of four years of class projects, weaving together the course, the middleware platform, and the relationship of each to three key pedagogical goals that drove the formulation of the course curriculum.",NO
2-s2.0-84898802347,10.1109/TE.2012.2190071,,,Algorithmic Bricks: A tangible robot programming tool for elementary school students,ar,Article,Kwon D.,,Korea University,Seoul,South Korea,,,,,2012-01-01,November 2012,IEEE Transactions on Education,00189359,17344,,Journal,55,4,,474-479,,,24,0,,,,"Tangible programming tools enable children to easily learn the programming process, previously considered to be difficult for them. While various tangible programming tools have been developed, there is still a lack of available tools to help students experience the general programming process. This study therefore developed a tool called Algorithmic Bricks (A-Bricks), to improve the programming language experience by considering and utilizing characteristics of procedural language. Specifically, elements such as sequence, repetition, condition, function, and parameter were used to develop A-Bricks. In addition, this study observed the benefits of A-Bricks and confirmed its potential as a tangible educational programming tool by comparing and analyzing elementary school students using A-Bricks to control groups using Scratch.",SI
2-s2.0-84875981743,10.18848/1835-9795/cgp/v04i01/40322,,,Analytical learning through robotics and the internet,ar,Article,Yuventi J.,,Stanford University,Palo Alto,United States,,,,,2012-01-01,2012,Ubiquitous Learning,18359795,21100236814,,Journal,4,1,,29-42,,,0,0,,,,"Learning computer programming or migrating to a new programming language is often perceived as being difficult. This is partially because the traditional methods of teaching focus more on the memorization of syntax rather than understanding and developing algorithms. Additionally, the traditional tools used to teach programming do little to retain students’ attention or increase confidence in their skills. Building upon previous attempts at innovative computer programming strategies to create an environment that engages the student, this paper presents a method of learning programming through the use of robotics and the Internet. The concept revolves around separating language and function, focusing on the application of analytical thinking toward creating algorithms. The Internet is used to provide ubiquity in learning; creating an easily accessible platform that potentially reduces the cost of learning. This method can provide students with a greater understanding of the logic involved in programming than other approaches. This understanding should make it easier to develop unique/complex software or transition to a new programming language. The direction taken in this paper is governed by the notion that programming helps to develop analytical thinking. The method introduced is not meant solely for computer science students, but also the greater technical audience.",NO
2-s2.0-84868027343,10.1007/s12369-012-0162-y,,,Learning of Planning Models for Dexterous Manipulation Based on Human Demonstrations,ar,Article,Jäkel R.,,Karlsruher Institut für Technologie,Karlsruhe,Germany,,,,,2012-01-01,November 2012,International Journal of Social Robotics,18754791,19500157063,18754805,Journal,4,4,,437-448,,,11,0,,,,"In the human environment service robots have to be able to manipulate autonomously a large variety of objects in a workspace restricted by collisions with obstacles, self-collisions and task constraints. Planning enables the robot system to generalize predefined or learned manipulation knowledge to new environments. For dexterous manipulation tasks the manual definition of planning models is time-consuming and error-prone. In this work, planning models for dexterous tasks are learned based on multiple human demonstrations using a general feature space including automatically generated contact constraints, which are automatically relaxed to consider the correspondence problem. In order to execute the learned planning model with different objects, the contact location is transformed to given object geometry using morphing. The initial, overspecialized planning model is generalized using a previously described, parallelized optimization algorithm with the goal to find a maximal subset of task constraints, which admits a solution to a set of test problems. Experiments on two different, dexterous tasks show the applicability of the learning approach to dexterous manipulation tasks.",NO
2-s2.0-84866429369,10.7227/IJEEE.49.3.6,,,Overcoming the challenges of porting OpenCV to TI's embedded ARM + DSP platforms,ar,Article,Coombs J.,,Texas Instruments,Dallas,United States,,,,,2012-01-01,July 2012,International Journal of Electrical Engineering and Education,00207209,17966,,Journal,49,3,,260-274,,,4,0,,,,"The growing performance and decreasing price of embedded processors are opening many doors, for both developers in the industry and in academia. However, the complexities of these systems can create serious developmental bottlenecks. Sophisticated software packages such as OpenCV can assist in both the functional development and educational aspects of these otherwise complex applications; such tools lend themselves very well to use by the academic community, in particular in providing examples of algorithm implementation. However the task of migrating this software to embedded platforms poses its own challenges. This paper will review how to mitigate some of these issues, including C++ implementation, memory constraints, floating-point support, and opportunities to maximise performance using vendor-optimised libraries and integrated accelerators or co-processors. Finally, we will introduce a new effort by Texas Instruments to optimise vision systems by running OpenCV on the C6000™ digital signal processor architecture. Benchmarks will show the advantage of using the DSP by comparing the performance of a DSP+ARM® system-on-chip (SoC) processor against an ARM-only device.",NO
2-s2.0-84866359455,10.7227/IJEEE.49.3.3,,,Development of brushless d.c. motor drive system for teaching purposes using various PWM control techniques,ar,Article,Tadrist N.,,Université des Sciences et de la Technologie Houari Boumediene,Algiers,Algeria,,,,,2012-01-01,July 2012,International Journal of Electrical Engineering and Education,00207209,17966,,Journal,49,3,,210-231,,,6,0,,,,"In this paper, a test bench was developed for teaching purposes to enhance power electronics and real time control of a brushless d.c. motor. Particular emphasis was placed on PWM techniques and theoretical signal generation using a MATLAB/Simulink environment and experimentally with a DSP programming kit. First, a model was developed in MATLAB/Simulink derived from electrical and mechanical equations for the 120° mode. The control strategies implemented involved two PWM techniques, namely soft and hard switching. The system was built in such a way that students are able to carry out modelling and confirm their results through the test bench using these techniques. The approach used has been effective in generating student satisfaction. Improvements in student learning are evident with regard to the drive control applications, either as a variable speed drive or in embedded systems.",NO
2-s2.0-84865132439,10.14198/jopha.2012.6.1.06,,,Learning in real robots from environment interaction,ar,Article,Quintía P.,,Universidad de Santiago de Compostela,Santiago de Compostela,Spain,,,,,2012-01-01,2012,Journal of Physical Agents,18880258,17300154721,,Journal,6,1,,43-51,,,1,1,,,,"This article describes a proposal to achieve fast robot learning from its interaction with the environment. Our proposal will be suitable for continuous learning procedures as it tries to limit the instability that appears every time the robot encounters a new situation it had not seen before. On the other hand, the user will not have to establish a degree of exploration (usual in reinforcement learning) and that would prevent continual learning procedures. Our proposal will use an ensemble of learners able to combine dynamic programming and reinforcement learning to predict when a robot will make a mistake. This information will be used to dynamically evolve a set of control policies that determine the robot actions.",NO
2-s2.0-84864425216,10.1299/kikaic.78.2450,,,Development of in-situ robot motion modification method by hand-guiding instruction,ar,Article,Tsusaka Y.,,,,,,,,,2012-01-01,2012,"Nihon Kikai Gakkai Ronbunshu, C Hen/Transactions of the Japan Society of Mechanical Engineers, Part C",03875024,110132,,Journal,78,791,,2450-2461,,,0,1,,,,"抄録

Future robotic systems intended to be used for domestic housekeeping or elderly care should flexibly adapt to the environment which is uncertain and may fluctuate. However, the current robot systems for industrial domain can operate only in the limited environment (well arranged and very little uncertainty) and require the special knowledge such as teaching-pendant and robot programming of the robot motion instructors. Obviously such requirements are not appropriate for home-use robots. This paper proposes a new method for in-situ robot motion modification by Hand-Guiding instruction. With the proposed method, a human demonstrator can intuitively modify the robot motion during its operation to adapt to environmental changes. Some daily domestic tasks are actually tried by using a lightweight pneumatic robot arm and the experimental results show the effectiveness of the proposed method.",NO
2-s2.0-84863575484,10.1145/2065327.2065335,,,"Architectural robotics, inevitably",ar,Article,Gross M.,,Carnegie Mellon University,Pittsburgh,United States,,,,,2012-01-01,January 2012,Interactions,10725520,4000148705,15583449,Trade Journal,19,1,,28-33,,,16,0,,,,,NO
2-s2.0-84863022806,10.1007/s10489-010-0257-9,,,A new approach to simultaneous localization and map building with implicit model learning using neuro evolutionary optimization,ar,Article,Kang J.G.,,Pohang University of Science and Technology,Pohang,South Korea,,,,,2012-01-01,January 2012,Applied Intelligence,0924669X,23674,,Journal,36,1,,242-269,,,21,0,,,,"This paper presents Neuro-Evolutionary Optimization SLAM (NeoSLAM) a novel approach to SLAM that uses a neural network (NN) to autonomously learn both a nonlinear motion model and the noise statistics of measurement data. The NN is trained using evolutionary optimization to learn the residual error of the motion model, which is then added to the odometry data to obtain the full motion model estimate. Stochastic optimization is used, to accommodate any kind of cost function. Prediction and correction are performed simultaneously within our neural framework, which implicitly integrates the motion and sensor models. An evolutionary programming (EP) algorithm is used to progressively refine the neural model until it generates a trajectory that is most consistent with the actual sensor measurements. During this learning process, NeoSLAM does not require any prior knowledge of motion or sensor models and shows consistently good performance regardless of the robot and the sensor noise type. Furthermore, NeoSLAM does not require the data association step at loop closing which is crucial in most other SLAM algorithms, but can still generate an accurate map. Experiments in various complex environments with widely-varying types of noise show that the learning capability of NeoSLAM ensures performance that is consistently less sensitive to noise and more accurate than that of other SLAM methods.",NO
2-s2.0-84861023809,10.7227/IJEEE.49.3.5,,,An approach to motion control applications based on advanced programmable devices,ar,Article,Rodríguez-Reséndiz J.,,Universidad Autónoma de Querétaro,Queretaro,Mexico,,,,,2012-01-01,July 2012,International Journal of Electrical Engineering and Education,00207209,17966,,Journal,49,3,,243-259,,,5,0,,,,"In this article a methodology for constructing a simple servo loop for motion control applications which is suitable for educational applications is presented. The entire hardware implementation is demonstrated, focusing on a microcontroller-based (μC) servo amplifier and a field programmable gate array-digital signal processor (FPGA-DSP) motion controller. A novel hybrid architecture-based digital stage is featured providing a low-cost servo drive and a high performance controller, which can be used as a basis for an industrial application. Communication between the computer and the controller is exploited in this project in order to perform a simultaneous adaptive servo tuning. The USB protocol has been put into operation in the user front-end because a high speed sampling frequency is required for the PC to acquire position feedback signals. A software interface is developed using educational software, enabling features not only limited to a motion profile but also the supervisory control and data acquisition (SCADA) topology of the system. A classical proportional-integral-derivative controller (PID) is programmed on a DSP in order to ensure a proper tracking of the reference at both low and high speeds in a d.c. motor. Furthermore, certain blocks are embedded on an FPGA. As a result, three of the most important technologies in signal processing are featured, permitting engineering students to understand several concepts covered in theoretical courses.",NO
2-s2.0-84855432288,10.1007/s10846-011-9568-2,,,Path planning strategies for UAVS in 3D environments,ar,Article,De Filippis L.,,Politecnico di Torino,Turin,Italy,,,,,2012-01-01,January 2012,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,65,1-4,,247-264,,,121,0,,,,"The graph-search algorithms developed between 60s and 80s were widely used in many fields, from robotics to video games. The A* algorithm shall be mentioned between some of the most important solutions explicitly oriented to motion-robotics, improving the logic of graph search with heuristic principles inside the loop. Nevertheless, one of the most important drawbacks of the A* algorithm resides in the heading constraints connected with the grid characteristics. Different solutions were developed in the last years to cope with this problem, based on post-processing algorithms or on improvements of the graph-search algorithm itself. A very important one is Theta* that refines the graph search allowing to obtain paths with “any” heading. In the last two years, the Flight Mechanics Research Group of Politecnico di Torino studied and implemented different path planning algorithms. A Matlab based planning tool was developed, collecting four separate approaches: geometric predefined trajectories, manual waypoint definition, automatic waypoint distribution (i.e. optimizing camera payload capabilities) and a comprehensive A*-based algorithm used to generate paths, minimizing risk of collision with orographic obstacles. The tool named PCube exploits Digital Elevation Maps (DEMs) to assess the risk maps and it can be used to generate waypoint sequences for UAVs autopilots. In order to improve the A*-based algorithm, the solution is extended to tri-dimensional environments implementing a more effective graph search (based on Theta*). In this paper the application of basic Theta* to tri-dimensional path planning will be presented. Particularly, the algorithm is applied to orographic obstacles and in urban environments, to evaluate the solution for different kinds of obstacles. Finally, a comparison with the A* algorithm will be introduced as a metric of the algorithm performances.",NO
2-s2.0-84889605432,10.1080/08993408.2013.847152,,,Mindstorms robots and the application of cognitive load theory in introductory programming,ar,Article,Mason R.,,School of Business and Tourism,Lismore,Australia,,,,,2013-12-01,December 2013,Computer Science Education,08993408,19700201422,17445175,Journal,23,4,,296-314,,,13,0,,,,"This paper reports on a series of introductory programming workshops, initially targeting female high school students, which utilised Lego Mindstorms robots. Cognitive load theory (CLT) was applied to the instructional design of the workshops, and a controlled experiment was also conducted investigating aspects of the interface. Results indicated that a truncated interface led to better learning by novice programmers as measured by test performance by participants, as well as enhanced shifts in self-efficacy and lowered perception of difficulty. There was also a transfer effect to another programming environment (Alice). It is argued that the results indicate that for novice programmers, the mere presence on-screen of additional (redundant) entities acts as a form of tacit distraction, thus impeding learning. The utility of CLT to analyse, design and deliver aspects of computer programming environments and instructional materials is discussed.",SI
2-s2.0-84889598013,10.1080/08993408.2013.847226,,,Robotics for computer scientists: what's the big idea?,ar,Article,Touretzky D.,,Carnegie Mellon University,Pittsburgh,United States,,,,,2013-12-01,December 2013,Computer Science Education,08993408,19700201422,17445175,Journal,23,4,,349-367,,,8,0,,,,"Modern robots, like today’s smartphones, are complex devices with intricate software systems. Introductory robot programming courses must evolve to reflect this reality, by teaching students to make use of the sophisticated tools their robots provide rather than reimplementing basic algorithms. This paper focuses on teaching with Tekkotsu, an open source robot application development framework designed specifically for education. But, the curriculum described here can also be taught using ROS, the Robot Operating System that is now widely used for robotics research.",SI
2-s2.0-84887778878,10.1109/TE.2013.2255877,,,Game-console-based projects for learning the computer input/output subsystem,ar,Article,Larraza-Mendiluze E.,,Universidad del Pais Vasco,Leioa,Spain,,,,,2013-11-21,2013,IEEE Transactions on Education,00189359,17344,,Journal,56,4,6502274,453-458,,,8,0,,,,"The input/output (I/O) subsystem is an important topic within computer architecture (CA) because it determines how the computer interacts with its environment. For this reason, computer scientists and engineers must understand how the computer manages this interaction, which is usually taught in introductory CA courses. Of course, there are many different styles of teaching, ranging from purely theoretical to completely practical. The CA course considered in this paper has already applied a practical approach for some time. For the I/O subsystem, students must be able to describe what polling and interrupts are and handle them through low-level programming. However, programming at this level in operating system (OS)-driven computers is not possible without being familiar with the kernel and drivers, which is not usually the case for students in an introductory course. Fortunately, there are many bare and specialized embedded systems around that are not OS-driven. In this proposal, the Nintendo DS (NDS) console was used in a classroom setting. It proved to be an appropriate infrastructure for developing attractive and engaging projects and was useful in providing a better understanding of the mechanisms related to the I/O subsystem. At the same time, the teaching methods were altered to make the transition from classical, passive, lecture-based classes to an active project-based learning (PBL) approach. It has been a very rewarding experience to see students learning to control the NDS devices on their own. In addition to describing the implementation of the proposed changes in two subsequent school years, this paper also presents some data and conclusions.",NO
2-s2.0-84887154791,10.5302/J.ICROS.2013.13.8011,,,A user interface for vision sensor based indirect teaching of a robotic manipulator,ar,Article,Kim T.,,University of Science and Technology (UST),Daejeon,South Korea,,,,,2013-11-12,2013,"Journal of Institute of Control, Robotics and Systems",19765622,21100201073,,Journal,19,10,,921-927,,,0,1,,,,"This paper presents a user interface for vision based indirect teaching of a robotic manipulator with Kinect and IMU (Inertial Measurement Unit) sensors. The user interface system is designed to control the manipulator more easily in joint space, Cartesian space and tool frame. We use the skeleton data of the user from Kinect and Wrist-mounted IMU sensors to calculate the user's joint angles and wrist movement for robot control. The interface system proposed in this paper allows the user to teach the manipulator without a pre-programming process. This will improve the teaching time of the robot and eventually enable increased productivity. Simulation and experimental results are presented to verify the performance of the robot control and interface system.",NO
2-s2.0-84887824644,10.1007/s00170-013-5034-6,,,Autonomous seam acquisition and tracking system for multi-pass welding based on vision sensor,ar,Article,Gu W.P.,,Nanchang Hangkong University,Nanchang,China,,,,,2013-10-01,October 2013,International Journal of Advanced Manufacturing Technology,02683768,20428,14333015,Journal,69,1-4,,451-460,,,69,0,,,,"Automatic welding technology is a solution to increase welding productivity and improve welding quality, especially in thick plate welding. In order to obtain high-quality multi-pass welds, it is necessary to maintain a stable welding bead in each pass. In the multi-pass welding, it is difficult to obtain a stable weld bead by using a traditional teaching and playback arc welding robot. To overcome these traditional limitations, an automatic welding tracking system of arc welding robot is proposed for multi-pass welding. The developed system includes an image acquisition module, an image processing module, a tracking control unit, and their software interfaces. The vision sensor, which includes a CCD camera, is mounted on the welding torch. In order to minimize the inevitable misalignment between the center line of welding seam and the welding torch for each welding pass, a robust algorithm of welding image processing is proposed, which was proved to be suitable for the root pass, filling passes, and the cap passes. In order to accurately track the welding seam, a Fuzzy-P controller is designed to control the arc welding robot to adjust the torch. The Microsoft Visual C++6.0 software is used to develop the application programs and user interface. The welding experiments are carried out to verify the validity of the multi-pass welding tracking system.",NO
2-s2.0-84882996117,10.7227/IJEEE.50.3.4,972020P647T31786,,An autonomous line-following robot project as a training tool for project work,ar,Article,Apsley J.,,The University of Manchester,Manchester,United Kingdom,,,,,2013-07-01,1 July 2013,International Journal of Electrical Engineering and Education,00207209,17966,20504578,Journal,50,3,,239-246,,,6,0,,,,"Project work forms a major part of final year BEng and MEng degree courses, with most of the assessment marks allocated for the final report. Traditional classroom teaching does not promote the independent learning required in running a project, or writing a research report. An autonomous line-following robot challenge has been introduced as a second-year group project, as a training tool in project management, planning and technical writing, in order to prepare students for their third- and fourth-year projects. The line-following robot requires students to develop technical skills in circuit design, fabrication, microcontroller programming and control, in the context of a competition that engages their enthusiasm. It provides a platform for the second-year pastoral system, motivating students to meet weekly with tutors in a small-group context. This paper evaluates the effectiveness of the project in meeting learning objectives, and identifies challenges relating to resources and assessment.",NO
2-s2.0-84878266260,10.1016/j.robot.2012.08.001,S0921889012001182,,End-user programming architecture facilitates the uptake of robots in social therapies,ar,Article,Barakova E.,,Technische Universiteit Eindhoven,Eindhoven,Netherlands,,,,,2013-07-01,July 2013,Robotics and Autonomous Systems,09218890,18079,,Journal,61,7,,704-713,,,50,0,,,,"This paper proposes an architecture that makes programming of robot behavior of an arbitrary complexity possible for end-users and shows the technical solutions in a way that is easy to understand and generalize to different situations. It aims to facilitate the uptake and actual use of robot technologies in therapies for training social skills to autistic children. However, the framework is easy to generalize for an arbitrary human–robot interaction application, where users with no technical background need to program robots, i.e. in various assistive robotics applications. We identified the main needs of end-user programming of robots as a basic prerequisite for the uptake of robots in assistive applications. These are reusability, modularity, affordances for natural interaction and the ease of use. After reviewing the shortcomings of the existing architectures, we developed an initial architecture according to these principles and embedded it in a robot platform. Further, we used a co-creation process to develop and concretize the architecture to facilitate solutions and create affordances for robot specialists and therapists. Several pilot tests showed that different user groups, including therapists with general computer skills and adolescents with autism could make simple training or general behavioral scenarios within 1 h, by connecting existing behavioral blocks and by typing textual robot commands for fine-tuning the behaviors. In addition, this paper explains the basic concepts behind the TiViPE based robot control platform, and gives guidelines for choosing the robot programming tool and designing end-user platforms for robots.

Highlights

► Programming architecture to help end-users create interactive scenarios is proposed. ► Complex programming concepts are explained for non-programmers. ► Iterative co-creation process leads to robot scenarios for training autistic children. ► Using TiViPE therapists can create interactive robot behaviors within 1 h. ► The architecture facilitates creation, and sharing of robot training scenarios.",SI
2-s2.0-84878386088,10.5772/53992,,,Towards behavior control for evolutionary robot based on RL with ENN,ar,Article,Yang J.,,Hefei University of Technology;Changhzou Key Laboratory of Software Technology and Applications,Hefei;,China;China,,,,,2013-06-05,2013,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,10,,157,,,,2,1,,,,"This paper proposes a behavior-switching control strategy of an evolutionary robot based on Artificial Neural Network (ANN) and genetic algorithm (GA). This method is able not only to construct the reinforcement learning models for autonomous robots and evolutionary robot modules that control behaviors and reinforcement learning environments, and but also to perform the behavior-switching control and obstacle avoidance of an evolutionary robot in the unpredictable environments with the static and moving obstacles by combining ANN and GA.

The experimental results have demonstrated that our method can perform the decision-making strategy and parameter setup optimization of ANN and GA by learning and can effectively escape from a trap of local minima, avoid motion deadlock status of humanoid soccer robotic agents, and reduce the oscillation of the planned trajectory among the multiple obstacles by crossover and mutation. We have successfully applied some results of the proposed algorithm to our simulation humanoid robotic soccer team CIT3D which won the 1st prize of RoboCup Championship and ChinaOpen2010 and the 2nd place of the official RoboCup World Championship on 5-11, July 2011 in Istanbul, Turkey.

In comparison with the conventional behavior network and the adaptive behavior method, our algorithm simplified the genetic encoding complexity, improved the convergence rate ρ and the network performance.",NO
2-s2.0-84876815936,10.1109/TLA.2013.6502866,,,Actions towards the application of intelligent systems in computer education,ar,Article,Diaz L.,,Universidad Nacional de Córdoba,Cordoba,Argentina,,,,,2013-05-02,2013,IEEE Latin America Transactions,15480992,19700181218,,Journal,11,1,6502866,591-595,,,4,0,,,,"In this work we present two courses of action as part of a research project which is focused in the use of intelligent tutoring systems and robots to improve the learning process of programming for the engineering field. The first method we use is the application of neural networks to the prediction of academic performance of students of programming and, on the other hand, we are developing practical activities based in robot programming for the same student universe as a motivational tool. These actions are the first steps to a learning strategy based on feedback and motivation, by applying intelligent systems in the process of teaching and learning programming applied to engineering field.",SI
2-s2.0-84875892345,10.1016/j.neunet.2012.09.015,S0893608012002560,23098753,Intrinsically motivated action-outcome learning and goal-based action recall: A system-level bio-constrained computational model,ar,Article,Baldassarre G.,,"Istituto Di Scienze E Tecnologie Della Cognizione, Rome",Rome,Italy,,,,,2013-05-01,May 2013,Neural Networks,08936080,24804,18792782,Journal,41,,,168-187,,,40,0,,,,"Reinforcement (trial-and-error) learning in animals is driven by a multitude of processes. Most animals have evolved several sophisticated systems of ‘extrinsic motivations’ (EMs) that guide them to acquire behaviours allowing them to maintain their bodies, defend against threat, and reproduce. Animals have also evolved various systems of ‘intrinsic motivations’ (IMs) that allow them to acquire actions in the absence of extrinsic rewards. These actions are used later to pursue such rewards when they become available. Intrinsic motivations have been studied in Psychology for many decades and their biological substrates are now being elucidated by neuroscientists. In the last two decades, investigators in computational modelling, robotics and machine learning have proposed various mechanisms that capture certain aspects of IMs. However, we still lack models of IMs that attempt to integrate all key aspects of intrinsically motivated learning and behaviour while taking into account the relevant neurobiological constraints. This paper proposes a bio-constrained system-level model that contributes a major step towards this integration. The model focusses on three processes related to IMs and on the neural mechanisms underlying them: (a) the acquisition of action–outcome associations (internal models of the agent-environment interaction) driven by phasic dopamine signals caused by sudden, unexpected changes in the environment; (b) the transient focussing of visual gaze and actions on salient portions of the environment; (c) the subsequent recall of actions to pursue extrinsic rewards based on goal-directed reactivation of the representations of their outcomes. The tests of the model, including a series of selective lesions, show how the focussing processes lead to a faster learning of action–outcome associations, and how these associations can be recruited for accomplishing goal-directed behaviours. The model, together with the background knowledge reviewed in the paper, represents a framework that can be used to guide the design and interpretation of empirical experiments on IMs, and to computationally validate and further develop theories on them.",NO
2-s2.0-84882956902,10.7227/IJEEE.50.2.4,F753PKJ236837523,,A project-based strategy for teaching robotics using NI's embedded-FPGA platform,ar,Article,Mysorewala M.,,King Fahd University of Petroleum and Minerals,Dhahran,Saudi Arabia,,,,,2013-04-01,1 April 2013,International Journal of Electrical Engineering and Education,00207209,17966,20504578,Journal,50,2,,139-156,,,8,0,,,,"This paper discusses our project-based teaching and learning approach to infuse robotics education into our Control and Instrumentation programme at the KFUPM university. In the last two years, various practical projects were assigned to students either as course projects or as capstone design projects in the area of control engineering using the National Instruments (NI) embedded robotic platform. The assigned projects focus on designing and equipping the robotic platform with environment-sensing (light, temperature and sound) capabilities, control operations for path planning and obstacle avoidance. Using the NI platform as a test bed for our teaching approach has resulted in the design and implementation of a successful prototype that enables students to experiment with various sensing, control and communication techniques on this platform, thus turning it into an intelligent mobile robot capable of implementing complex and computationally demanding control and estimation algorithms. Finally, the survey we conducted to assess the educational content, and value to students, of our proposed approach shows that our strategy has been so far fruitful and gives us ample encouragement to pursue it and develop it further.",NO
2-s2.0-84877876489,10.1007/s10514-013-9324-5,,,A new paradigm for open robotics research and education with the C++ OOML,ar,Article,Valero-Gómez A.,,Universidad Carlos III de Madrid,Madrid,Spain,,,,,2013-04-01,April 2013,Autonomous Robots,09295593,18016,,Journal,34,3,,233-249,,,1,0,,,,"For many years robotics has been benefited from the open source community. Software community projects like Player, Stage, Gazebo, ROS, or OpenCV are present in most robotic applications. In recent years this trend has also been initiated among electronic and mechanical developments (open hardware). The Arduino development platform is a good example of a successful hardware project with a great community of developers and users around it. The apparition of personal 3D printers is bringing the open source philosophy to the fabrication of physical things as well. This new technology is in need of new designing tools to take advantage of it. In this paper we are presenting the C++ Object Oriented Mechanics Library (OOML), a tool to design mechanical components, taking into account the needs and requirements of these emerging technologies. These designs can be easily shared, reused, and modified. The OOML brings together the advantages of (1) modelling things through code, (2) the object oriented programming paradigm, and (3) the power of C++. In the OOML, mechanical parts are described as geometrical combinations of basic primitives. Once a part is defined, fabrication files can be generated in order to print, or mechanize it. Models could also be used for simulation, visualization, structural analysis, etc.",NO
2-s2.0-84877874382,10.1007/s10514-013-9323-6,,,ROS open-source audio recognizer: ROAR environmental sound detection tools for robot programming,ar,Article,Romano J.M.,,Rethink Robotics,Boston,United States,,,,,2013-04-01,April 2013,Autonomous Robots,09295593,18016,,Journal,34,3,,207-215,,,10,0,,,,"Advances in audio recognition have enabled the real-world success of a wide variety of interactive voice systems over the last two decades. More recently, these same techniques have shown promise in recognizing non-speech audio events. Sounds are ubiquitous in real-world manipulation, such as the click of a button, the crash of an object being knocked over, and the whine of activation from an electric power tool. Surprisingly, very few autonomous robots leverage audio feedback to improve their performance. Modern audio recognition techniques exist that are capable of learning and recognizing real-world sounds, but few implementations exist that are easily incorporated into modern robotic programming frameworks. This paper presents a new software library known as the ROS Open-source Audio Recognizer (ROAR). ROAR provides a complete set of end-to-end tools for online supervised learning of new audio events, feature extraction, automatic one-class Support Vector Machine model tuning, and real-time audio event detection. Through implementation on a Barrett WAM arm, we show that combining the contextual information of the manipulation action with a set of learned audio events yields significant improvements in robotic task-completion rates.",NO
2-s2.0-84878499446,10.1007/s10489-012-0339-y,,,Similarity measuring strategy of image patterns based on fuzzy entropy and energy variations in intelligent robot's manipulative task,ar,Article,Son C.,,Dankook University,Seoul,South Korea,,,,,2013-03-01,March 2013,Applied Intelligence,0924669X,23674,,Journal,38,2,,131-145,,,5,0,,,,"A similarity measuring strategy of image patterns based on fuzzy entropy and energy variations, using an intelligent robot’s part macro-assembly (part-bringing) as an example, is presented. A part macro-assembly, locating various shaped assembly holes (targets) in a workspace corresponding to shapes of parts and then bringing a part to a corresponding target for the purpose of part mating despite existing obstalces, is introduced. This is accomplished by cooperating a neural network system with a fuzzy optimal control. Fuzzy entropy and energy functions, which are useful measures of variability and information in terms of uncertainty, are introduced to measure its overall performance of task execution related to the part-bringing task. An interrelation among learning, fuzzy entropy, and energy variations used as a measuring tool for a degree of similarity of image patterns is described. Through variations of fuzzy entropy and energy, a degree of similarity between input and desired output image patterns of neural network can be measured. The proposed technique is not only a useful tool to measure a degree of similarity between image patterns, but applicable to a wide range of robotic tasks including motion planning, manufacturing, maneuvering around workspace, and part mating with various shaped parts and targets.",NO
2-s2.0-84897482407,10.1080/15391523.2013.10782614,,,"Let's dance the ""Robot Hokey-Pokey!"": Children's programming approaches and achievement throughout early cognitive development",ar,Article,Flannery L.,,Tufts University,Medford,United States,,,,,2013-01-01,2013,Journal of Research on Technology in Education,15391523,21100301445,19450818,Journal,46,1,,81-101,,,36,0,,,,"Young learners today generate, express, and interact with sophisticated ideas using a range of digital tools to explore interactive stories, animations, computer games, and robotics. In recent years, new developmentally appropriate robotics kits have been entering early childhood classrooms. This paper presents a retrospective analysis of one study within a design-based robotics research program. We examine how patterns of cognition throughout early childhood relate to programming approaches and achievement in a robotics context. The findings lay a foundation for applying cognitive developmental theory to early technology education and inform the evaluation of the study’s programming and robotics technologies and curriculum.",SI
2-s2.0-84888415230,10.18848/1832-3669/cgp/v08i06/56350,,,Technology-centred teaching methods to introduce programming and robotic concepts,ar,Article,Collier G.,,Kingston University,Kingston Upon Thames,United Kingdom,,,,,2013-01-01,2013,"International Journal of Technology, Knowledge and Society",,19900189254,18323669,Conference Proceeding,8,6,,121-129,,,4,0,,,,"Teaching engineering concepts using a combination of software and hardware is always well received by students. In the first year, engineering undergraduates are introduced to a range of concepts from electrical, electronic and software engineering. They operate in an environment with different levels of interest, background knowledge and motivation. Thus it is essential to create a hands-on course unifying the concepts and demonstrating the application of the theoretical concepts taught in the lectures. This paper describes a first-hand experience of programming a microcontroller system to groups of first year undergraduate engineering students, which can be difficult unless a fun and engaging environment is provided. In this paper a first year teaching course is presented, taking students from introduction to graphical programming environment and microcontroller architecture to creating a programme using real sensors and actuators mounted on a robot, to perform a set of tasks.",SI
2-s2.0-84883044296,10.12785/IJCDS/020204,,,"Task based interdisciplinary E-commerce course with UML sequence diagrams, algorithm transformations and spatial circuits to boost learning information security concepts",ar,Article,Herath A.,,University of Bahrain,Sakhir,Bahrain,,,,,2013-01-01,2013,International Journal of Computing and Digital Systems,,21100890383,2210142X,Journal,2,2,,79-87,,,2,1,,,,"This paper describes a task based active learning module developed with projects to help students understand secure protocols, algorithms and modeling web applications to prevent attacks. We have been developing and continuously improving cyber security courses with methods for introducing important concepts for computing majors for more than a decade. Sequence diagrams (step by step diagram) , symbolic representations, and spatial circuit derivation from equations and algorithms are introduced to students to alleviate difficulties in mastering cryptographic algorithms. UML Sequence diagrams represent progression of events with time. Spatial circuits illustrate the transformation of equations and high level programming language constructs into special purpose hardware. These course materials can also be used in computer architecture or embedded systems courses to help students understand and develop special purpose circuitry.",NO
2-s2.0-84878210399,10.1080/02533839.2012.730249,,,Intention deduction from demonstrated trajectory for tool-handling task,ar,Article,Chan H.Y.,,National Chiao Tung University,Hsinchu,Taiwan,,,,,2013-01-01,2013,"Journal of the Chinese Institute of Engineers, Transactions of the Chinese Institute of Engineers,Series A",02533839,15157,21587299,Journal,36,2,,190-201,,,0,0,,,,"When the robot comes to a home-like environment, its programming becomes very demanding. The concept of learning by demonstration is thus introduced, which may remove the load of detailed analysis and programming from the user. Following this concept, in this article, we propose a novel approach for the robot to deduce the intention of the demonstrator from the trajectories during task execution. We focus on the tool-handling task, which is common in the home environment, but complicated for analysis. The proposed approach does not pre-define motions or put constraints on motion speed, while allowing the event order to be altered and allowing for the presence of redundant operations during the demonstration. We apply the concept of cross-validation to locate the portions of the trajectory that correspond to delicate and skillful maneuvering, and apply an algorithm based on dynamic programming previously developed to search for the most probable intention. In experiments, we applied the proposed approach for two different kinds of tasks, the pouring and coffee-making tasks, with the number of objects and their locations varied during demonstrations. To further investigate our method's scalability and generality, we also performed intensive analysis on the parameters involved in the tasks.",NO
2-s2.0-84877736661,10.1541/ieejeiss.133.856,,,Two-stage reinforcement learning on credit branch genetic network programming for mobile robots,ar,Article,Sendari S.,,Universitas Negeri Malang;Waseda University,Malang;Tokyo,Indonesia;Japan,,,,,2013-01-01,2013,"IEEJ Transactions on Electronics, Information and Systems",03854221,3300147412,13488155,Journal,133,4,,856-863,,,1,0,,,,"This paper proposes Two-Stage Reinforcement Learning on Credit Branch Genetic Network Programming named GNP-TSRL-CB for mobile robots. The proposed method uses 2 kinds of Q-tables for sub node selection and credit branch selection, which has advantages of (1) determining an alternative function by using sub node selection and (2) skipping useless functions by using credit branch selection. It is clarified from simulation results that the adaptability mechanism of the proposed method can improve the performance compared with the conventional methods when the individuals of GNP-TSRL-CB are implemented in the dynamic environments like the sudden changes occur.",NO
2-s2.0-84877583142,10.1109/TE.2012.2208194,,,The use of video-gaming devices as a motivation for learning embedded systems programming,ar,Article,Gonzalez J.,,Universidad de Granada,Granada,Spain,,,,,2013-01-01,2013,IEEE Transactions on Education,00189359,17344,,Journal,56,2,6248186,199-207,,,10,0,,,,"As embedded systems are becoming prevalent in everyday life, many universities are incorporating embedded systems-related courses in their undergraduate curricula. However, it is not easy to motivate students in such courses since they conceive of embedded systems as bizarre computing elements, different from the personal computers with which they are familiar. This problem has been overcome at the University of Granada, Spain, by taking advantage of the connection many students have with video games.",NO
2-s2.0-84874578555,10.1108/03684921311310594,,,Soft-computing based navigation approach for a bi-steerable mobile robot,ar,Article,Azouaoui O.,,Centre de Développement des Technologies Avancées,Algiers,Algeria,,,,,2013-01-01,February 2013,Kybernetes,0368492X,12981,,Journal,42,2,,241-267,,,4,0,,,,"Purpose

The purpose of this paper is to present an implementation of a soft‐computing (SC) based navigation approach on a bi‐steerable mobile robot, Robucar. This approach must provide Robucar with capability to acquire the obstacle avoidance, target localization, decision‐making and action behaviors after learning and adaptation. This approach uses three neural networks (NN) and fuzzy logic (FL) controller to achieve the desired task. The NNs corresponding to the obstacle avoidance and target localization are trained using the back‐propagation algorithm and the last one is based on the reinforcement learning paradigm while the FL controller uses the Mamdani search and match algorithm. Simulation and experimental results are presented, showing the effectiveness of the overall navigation control system.

Design/methodology/approach

In this paper, an interesting navigation approach is applied to a car‐like robot, Robucar, with addition of an action behavior to deal with the generation of smooth motions. Indeed, this approach is based on four basic behaviors; three of them are fused under a neural paradigm using Gradient Back‐Propagation (GBP) and reinforcement learning (RL) algorithms and the last behavior uses a FL controller. It uses a set of suggested rules to describe the control policy to achieve the action behavior.

Findings

In the implemented SC‐based navigation, the intelligent behaviors necessary to the navigation are acquired by learning using GBP algorithm and adaptation using FL. The proposed approach provides Robucar with more autonomy, intelligence and real‐time processing capabilities. Indeed, the proposed NNs and FLC are able to remedy problems of analytical approaches, missing or incorrect environment knowledge and uncertainties which can lead to undesirable effects as the rough velocity changes. The simulation and experimental results display the ability of the proposed SC‐based navigation approach to provide Robucar with capability to intelligently navigate in a priori unknown environment, illustrating the robustness and adaptation capabilities of the approach.

Research limitations/implications

This work can be extended to consider mobile obstacles with a velocity higher than the velocity of the robot.

Originality/value

This paper presents a learning approach to navigating a bi‐steerable mobile robot in an unknown environment using GBP and RL paradigms.",NO
2-s2.0-84873412593,10.1109/TE.2012.2213822,,,Integrating mobile robotics and vision with undergraduate computer science,ar,Article,Cielniak G.,,University of Lincoln,Lincoln,United Kingdom,,,,,2013-01-01,2013,IEEE Transactions on Education,00189359,17344,,Journal,56,1,6294470,48-53,,,14,0,,,,"This paper describes the integration of robotics education into an undergraduate Computer Science curriculum. The proposed approach delivers mobile robotics as well as covering the closely related field of Computer Vision and is directly linked to the research conducted at the authors' institution. The paper describes the most relevant details of the module content and assessment strategy, paying particular attention to the practical sessions using Rovio mobile robots. The specific choices are discussed that were made with regard to the mobile platform, software libraries, and lab environment. The paper also presents a detailed qualitative and quantitative analysis of student results, including the correlation between student engagement and performance, and discusses the outcomes of this experience.",NO
2-s2.0-84872563213,10.1007/s12369-012-0167-6,,,Learning Macro Actions from Instructional Videos Through Integration of Multiple Modalities,ar,Article,Johnson D.O.,,University of Missouri-Kansas City,Kansas City,United States,,,,,2013-01-01,January 2013,International Journal of Social Robotics,18754791,19500157063,18754805,Journal,5,1,,53-73,,,1,0,,,,"We propose an architecture for a system that will “watch and listen to” an instructional video of a human performing a task and translate the audio and video information into a task for a robot to perform. This enables the use of readily available instructional videos from the Internet to train robots to perform tasks instead of programming them. We implemented an operational prototype based on the architecture and showed it could “watch and listen to” two instructional videos on how to clean golf clubs and translate the audio and video information from the instructional video into tasks for a robot to perform. The key contributions of this architecture are: integration of multiple modalities using trees and pruning with filters; task decomposition into macro-tasks composed of parameterized task-primitives and other macro-tasks, where the task-primitive parameters are an action (e.g., dip, clean, dry) taken on an object (e.g., golf club) using a tool (e.g., pail of water, brush, towel); and context, for determining missing and implied task-primitive parameter values, as a set of canonical task-primitive parameter values with a confidence score based on the number of times the parameter value was detected in the video and audio information and how long ago it was detected.",NO
2-s2.0-84872333655,10.1007/s11370-012-0128-9,,,A robot learning from demonstration framework to perform force-based manipulation tasks,ar,Article,Rozo L.,,Universitat Politècnica de Catalunya,Barcelona,Spain,,,,,2013-01-01,January 2013,Intelligent Service Robotics,18612776,9500154152,18612784,Journal,6,1,,33-51,,,92,0,,,,"This paper proposes an end-to-end learning from demonstration framework for teaching force-based manipulation tasks to robots. The strengths of this work are manyfold. First, we deal with the problem of learning through force perceptions exclusively. Second, we propose to exploit haptic feedback both as a means for improving teacher demonstrations and as a human–robot interaction tool, establishing a bidirectional communication channel between the teacher and the robot, in contrast to the works using kinesthetic teaching. Third, we address the well-known what to imitate? problem from a different point of view, based on the mutual information between perceptions and actions. Lastly, the teacher’s demonstrations are encoded using a Hidden Markov Model, and the robot execution phase is developed by implementing a modified version of Gaussian Mixture Regression that uses implicit temporal information from the probabilistic model, needed when tackling tasks with ambiguous perceptions. Experimental results show that the robot is able to learn and reproduce two different manipulation tasks, with a performance comparable to the teacher’s one.",NO
2-s2.0-84869099801,10.1016/j.actaastro.2012.09.006,S0094576512003633,,Collaborative gaming and competition for CS-STEM education using SPHERES Zero Robotics,ar,Article,Nag S.,,Massachusetts Institute of Technology,Cambridge,United States,,,,,2013-01-01,2013,Acta Astronautica,00945765,12372,,Journal,83,,,145-174,,,25,0,,,,"There is widespread investment of resources in the fields of Computer Science, Science, Technology, Engineering, Mathematics (CS-STEM) education to improve STEM interests and skills. This paper addresses the goal of revolutionizing student education using collaborative gaming and competition, both in virtual simulation environments and on real hardware in space. The concept is demonstrated using the SPHERES Zero Robotics (ZR) Program which is a robotics programming competition. The robots are miniature satellites called SPHERES—an experimental test bed developed by the MIT SSL on the International Space Station (ISS) to test navigation, formation flight and control algorithms in microgravity. The participants compete to win a technically challenging game by programming their strategies into the SPHERES satellites, completely from a web browser. The programs are demonstrated in simulation, on ground hardware and then in a final competition when an astronaut runs the student software aboard the ISS. ZR had a pilot event in 2009 with 10 High School (HS) students, a nationwide pilot tournament in 2010 with over 200 HS students from 19 US states, a summer tournament in 2010 with ∼150 middle school students and an open-registration tournament in 2011 with over 1000 HS students from USA and Europe. The influence of collaboration was investigated by (1) building new web infrastructure and an Integrated Development Environment where intensive inter-participant collaboration is possible, (2) designing and programming a game to solve a relevant formation flight problem, collaborative in nature—and (3) structuring a tournament such that inter-team collaboration is mandated. This paper introduces the ZR web tools, assesses the educational value delivered by the program using space and games and evaluates the utility of collaborative gaming within this framework. There were three types of collaborations as variables—within matches (to achieve game objectives), inter-team alliances and unstructured communication on online forums. Simulation competition scores, website usage statistics and post-competition surveys are used to evaluate educational impact and the effect of collaboration.

Highlights

► We have developed a revolutionary robotics programming tournament for STEM education. ► The robots are autonomous nanosatellites that operate on the ISS with the help of astronauts. ► All games can be played by programming using online tools, to be finally run on flight hardware. ► We have introduced several methods of inter-participant collaboration to enhance education. ► The concept of education using collaborative gaming is proven with preliminary results.",SI
2-s2.0-84919710909,10.1109/TAMD.2014.2359912,,,Learning from demonstration in robots using the shared circuits model,ar,Article,Suleman K.,,National University of Computer and Emerging Sciences Islamabad,Islamabad,Pakistan,,,,,2014-12-01,1 December 2014,IEEE Transactions on Autonomous Mental Development,19430604,19700177024,,Journal,6,4,6914535,244-258,,,2,0,,,,"Learning from demonstration presents an alternative method for programming robots for different nontrivial behaviors. Various techniques that address learning from demonstration in robots have been proposed but those do not scale up well. Thus there is a need to discover novel solutions to this problem. Given that the basic idea for such learning comes from nature in the form of imitation in few animals, it makes perfect sense to take advantage of the rigorous study of imitative learning available in relevant natural sciences. In this work a solution for robot learning from a relatively recent theory from natural sciences called the Shared Circuits Model, is sought. Shared Circuits Model theory is a comprehensive, multidiscipline representative theory. It is a modern synthesis that brings together different theories that explain imitation and other related social functions originating from various sciences. This paper attempts to import the shared circuits model to robotics for learning from demonstration. Specifically it: (1) expresses shared circuits model in a software design nomenclature; (2) heuristically extends the basic specification of Shared Circuits Model to implement a working imitative learning system; (3) applies the extended model on mobile robot navigation in a simulated indoor environment; and (4) attempts to validate the shared circuits model theory in the context of imitative learning. Results show that an extremely simple implementation of a theoretically sound theory, the shared circuits model, offers a realistic solution for robot learning from demonstration of nontrivial tasks.",NO
2-s2.0-84911429217,10.1002/cae.21555,,,Arp@: Remote experiences with real embedded systems,ar,Article,Vilajosana X.,,Universitat Oberta de Catalunya,Barcelona,Spain,,,,,2014-12-01,1 December 2014,Computer Applications in Engineering Education,10613773,18156,10990542,Journal,22,4,,639-648,,,1,0,,,,"The emergence of the Internet of Things increases the demand on embedded computer systems, which in turn requires the availability of specialized engineers in the near future. Several universities commenced embedded-systems programming courses to complement students' skills by introducing specific firmware development techniques. Hands-on labs with real hardware interaction is restricted to the time students are in the laboratory whilst virtual-laboratories provide more flexibility at the caveat that students do not improve hardware manipulation skills as they cannot physically inter-actuate with real devices. We argue that students' abilities can be increased by providing them with a sensor board with reduced computation and communication capabilities to work with at home. Students increase the time spent manipulating the device; moreover, their motivation is also increased as they can put their effort on developments of their interest. The article presents the experience carried out at the virtual-course of Embedded-Systems at the UOC. The developed technology, the methodology, and the feedback from students are presented here, and corroborate the benefits of the chosen methodology.© 2012 Wiley Periodicals, Inc. Comput Appl Eng Educ 22:639–648, 2014; View this article online at wileyonlinelibrary.com/journal/cae; DOI 10.1002/cae.21555",NO
2-s2.0-85073048299,10.1142/S1793351X14400091,,,A Semantic++ MapReduce Parallel Programming Model,ar,Article,Zhang G.,,Tsinghua University;Institute of Automation Chinese Academy of Sciences,Beijing;Beijing,China;China,,,,,2014-09-01,1 September 2014,International Journal of Semantic Computing,1793351X,21100872796,17937108,Journal,8,3,,279-299,,,0,0,,,,"Big data is playing a more and more important role in every area such as medical health, internet finance, culture and education etc. How to process these big data efficiently is a huge challenge. MapReduce is a good parallel programming language to process big data. However, it has lots of shortcomings. For example, it cannot process complex computing. It cannot suit real-time computing. In order to overcome these shortcomings of MapReduce and its variants, in this paper, we propose a Semantic++ MapReduce parallel programming model. This study includes the following parts. (1) Semantic++ MapReduce parallel programming model. It includes physical framework of semantic++ MapReduce parallel programming model and logic framework of semantic++ MapReduce parallel programming model; (2) Semantic++ extraction and management method for big data; (3) Semantic++ MapReduce parallel programming computing framework. It includes semantic++ map, semantic++ reduce and semantic++ shuffle; (4) Semantic++ MapReduce for multi-data centers. It includes basic framework of semantic++ MapReduce for multi-data centers and semantic++ MapReduce application framework for multi-data centers; (5) A Case Study of semantic++ MapReduce across multi-data centers.",NO
2-s2.0-84926278159,10.1007/s11721-014-0096-0,,,Stigmergic algorithms for multiple minimalistic robots on an RFID floor,ar,Article,Khaliq A.,,Örebro Universitet,Orebro,Sweden,,,,,2014-09-01,1 September 2014,Swarm Intelligence,19353812,11700154734,19353820,Journal,8,3,,199-225,,,17,0,,,,"Stigmergy is a powerful principle in nature, which has been shown to have interesting applications to robotic systems. By leveraging the ability to store information in the environment, robots with minimal sensing, memory, and computational capabilities can solve complex problems like global path planning. In this paper, we discuss the use of stigmergy in minimalist multi-robot systems, in which robots do not need to use any internal model, long-range sensing, or position awareness. We illustrate our discussion with three case studies: building a globally optimal navigation map, building a gradient map of a sensed feature, and updating the above maps dynamically. All case studies have been implemented in a real environment with multiple ePuck robots, using a floor with 1,500 embedded radio frequency identification tags as the stigmergic medium. Results collected from tens of hours of real experiments and thousands of simulated runs demonstrate the effectiveness of our approach.",NO
2-s2.0-84907686381,10.1007/s11786-014-0202-0,,,VIBes: A Visualizer for Intervals and Boxes,ar,Article,Drevelle V.,,"Laboratoire des Sciences et Techniques de l'Information, de la Communication et de la Connaissance (Lab-Sticc)",Brest,France,,,,,2014-09-01,1 September 2014,Mathematics in Computer Science,16618270,10900153313,16618289,Journal,8,3-4,,563-572,,,5,0,,,,"VIBes is an Open Source scientific visualization system that aims at providing people working with interval methods an easy way to display results (boxes, pavings), without worrying about graphical user interface programming. It provides drawing functions accessible from multiple programming languages, without complex installation and library dependencies. VIBes is made of a visualization program and an application programming interface for popular programming languages (currently C++ and MATLAB, more are planned). It is designed for instant setup in any project and has a very short learning curve, which makes it a good visualization tool for teaching labs and tutorials. The communication between programs and VIBes goes through named-pipe or files and consists in human-readable messages. Very simple drawing functions are provided, and the VIBes viewer features navigating inside drawings and exporting images. This paper presents the main concepts driving the design of VIBes, and its software architecture. Two short programs displaying the results of a set-inversion problem and the display of projected 3-D data are provided, and future development directions are detailed.",NO
2-s2.0-84906536970,10.1080/01969722.2014.945310,,,A study for the application of automated planning to mobile assistive robots,ar,Article,Brea J.,,Universidad Carlos III de Madrid,Madrid,Spain,,,,,2014-08-18,18 August 2014,Cybernetics and Systems,01969722,12931,10876553,Journal,45,6,,512-529,,,0,0,,,,"In recent years, Automated Planning (AP) has experienced important advances. In this study we apply such advances to the field of Mobile Assistive Robots (MAR). In particular, we propose the use of AP to implement the deliberative step between observation and action execution in MAR. First, we analyze the requirements that allow a MAR to plan navigation and manipulation actions in near real time. The intention is to build the foundation for a planning module within the Simultaneous User Learning and TAsk executioN (SULTAN) architecture, allowing a MAR to perform Daily Life Activities (DLA) in humanlike environments. Second, we apply AP techniques in fully observable, deterministic and static simulated environments with a single MAR. In addition, we analyze and compare the best available satisficing automated planners. The selected planners participate in several experiments to obtain plans for a Planning Domain Definition Language (PDDL) based on the Tidybot domain. Finally, in order to know how competitive the selected planners are, we compare the experimental results in detail.",NO
2-s2.0-84907728580,10.1080/08993408.2014.963362,,,The effectiveness of simulated robots for supporting the learning of introductory programming: a multi-case case study,ar,Article,Major L.,,University of Cambridge,Cambridge,United Kingdom,,,,,2014-07-03,june - september 2014,Computer Science Education,08993408,19700201422,17445175,Journal,24,2-3,,193-228,,,6,0,,,,"This work investigates the effectiveness of simulated robots as tools to support the learning of programming. After the completion of a systematic review and exploratory research, a multi-case case study was undertaken. A simulator, named Kebot, was developed and used to run four 10-hour programming workshops. Twenty-three student participants (aged 16–18) in addition to 23 pre-service, and 3 in-service, teachers took part. The effectiveness of this intervention was determined by considering opinions, attitudes, and motivation as well as by analysing students’ programming performance. Pre- and post-questionnaires, in- and post-workshop exercises, and interviews were used. Participants enjoyed learning using the simulator and believed the approach to be valuable and engaging. The performance of students indicates that the simulator aids learning as most completed tasks to a satisfactory standard. Evidence suggests robot simulators can offer an effective means of introducing programming. Recommendations to support the development of other simulators are provided.",NO
2-s2.0-84894050292,10.1007/s10514-013-9339-y,,,Socially guided intrinsic motivation for robot learning of motor skills,ar,Article,Nguyen S.M.,,INRIA Institut National de Recherche en Informatique et en Automatique,Le Chesnay,France,,,,,2014-03-01,March 2014,Autonomous Robots,09295593,18016,,Journal,36,3,,273-294,,,37,0,,,,"This paper presents a technical approach to robot learning of motor skills which combines active intrinsically motivated learning with imitation learning. Our algorithmic architecture, called SGIM-D, allows efficient learning of high-dimensional continuous sensorimotor inverse models in robots, and in particular learns distributions of parameterised motor policies that solve a corresponding distribution of parameterised goals/tasks. This is made possible by the technical integration of imitation learning techniques within an algorithm for learning inverse models that relies on active goal babbling. After reviewing social learning and intrinsic motivation approaches to action learning, we describe the general framework of our algorithm, before detailing its architecture. In an experiment where a robot arm has to learn to use a flexible fishing line, we illustrate that SGIM-D efficiently combines the advantages of social learning and intrinsic motivation and benefits from human demonstration properties to learn how to produce varied outcomes in the environment, while developing more precise control policies in large spaces.",NO
2-s2.0-84897490466,10.5772/58249,,,LEGO-based robotics in higher education: 15 years of student creativity,ar,Article,Danahy E.,,Tufts University,Medford,United States,,,,,2014-02-26,26 February 2014,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,11,1,27,,,,55,1,,,,"Our goal in this article is to reflect on the role LEGO robotics has played in college engineering education over the last 15 years, starting with the introduction of the RCX in 1998 and ending with the introduction of the EV3 in 2013. By combining a modular computer programming language with a modular building platform, LEGO Education has allowed students (of all ages) to become active leaders in their own education as they build everything from animals for a robotic zoo to robots that play children's games. Most importantly, it allows all students to develop different solutions to the same problem to provide a learning community. We look first at how the recent developments in the learning sciences can help in promoting student learning in robotics. We then share four case studies of successful college-level implementations that build on these developments.",SI
2-s2.0-84892414586,10.5755/j01.eee.20.1.6169,,,Reflections on using robots and visual programming environments for project-based teaching,ar,Article,Plauska I.,,Kaunas University of Technology,Kaunas,Lithuania,,,,,2014-01-20,2014,Elektronika ir Elektrotechnika,13921215,19900193212,,Journal,20,1,,71-74,,,5,1,,,,"Visual programming languages provide a more natural approach to specifying software/hardware systems with complex behaviour such as robots. They are especially important in education because they do not require formal knowledge of programming language syntax and are attractive to users. We present an analysis and comparison of two visual programming environments, Lego NXT-G and Microsoft Visual Programming Language, based on the cognitive and usability requirements, evaluate their application in robotics-based Computer Science education, identify main problems and propose solutions for using visual programming languages in the Internet-of-Things domain.

DOI: http://dx.doi.org/10.5755/j01.eee.20.1.6169",SI
2-s2.0-84995579611,10.3389/fnbot.2013.00025,,,Curiosity driven reinforcement learning for motion planning on humanoids,ar,Article,Frank M.,,Scuola Universitaria Professionale della Svizzera Italiana;IDSIA Dalle Molle Institute for Artificial Intelligence;Università della Svizzera italiana,Manno;Viganello;Lugano,Switzerland;Switzerland;Switzerland,,,,,2014-01-01,2014,Frontiers in Neurorobotics,,21100199837,16625218,Journal,7,JAN,25,,,,36,1,,,,"Most previous work on artificial curiosity (AC) and intrinsic motivation focuses on basic concepts and theory. Experimental results are generally limited to toy scenarios, such as navigation in a simulated maze, or control of a simple mechanical system with one or two degrees of freedom. To study AC in a more realistic setting, we embody a curious agent in the complex iCub humanoid robot. Our novel reinforcement learning (RL) framework consists of a state-of-the-art, low-level, reactive control layer, which controls the iCub while respecting constraints, and a high-level curious agent, which explores the iCub's state-action space through information gain maximization, learning a world model from experience, controlling the actual iCub hardware in real-time. To the best of our knowledge, this is the first ever embodied, curious agent for real-time motion planning on a humanoid. We demonstrate that it can learn compact Markov models to represent large regions of the iCub's configuration space, and that the iCub explores intelligently, showing interest in its physical constraints as well as in objects it finds in its environment.",NO
2-s2.0-84928238603,10.1142/S0219843614500236,,,Finding curvilinear path features in a layered learning paradigm for humanoid robot using monocular vision,ar,Article,Manoochehri H.,,University of Isfahan,Isfahan,Iran,,,,,2014-01-01,25 September 2014,International Journal of Humanoid Robotics,02198436,4700152208,,Journal,11,3,1450023,,,,1,0,,,,"In this paper, a method to find curvilinear path features is proposed. These features are defined as centers and radiuses of circles that best fit to the curvature parts of the curvilinear path. In our previous research, we proposed a hierarchical layered paradigm for humanoid robot to learn how to walk in the curvilinear path. This model consists of four layers and each one has a specific purpose and is responsible to provide some feedbacks for the lower layer. In this study, we focus on the first layer which is high level decision unit responsible to provide some feedbacks and parameters for the lower layer using robot sensory inputs. The ultimate goal is that robot learn to walk in the curvilinear path and to reach this goal, the first step is to find robot position in the environment. In this work, Monte Carlo localization method is used for robot localization. Then we used artificial potential field to generate a path between robot and a goal. Finally, we proposed an algorithm that search the circles that best fit to the curvature parts of the path. Finding these features would help the learning process for lower layers in the learning model. We used robot camera as the only sensor to identify landmarks and obstacles for robot localization, path planning and finding curvilinear path features.",NO
2-s2.0-84911446431,10.1177/0013164414520629,,,Learning Computerese: The Role of Second Language Learning Aptitude in Technology Acceptance,ar,Article,Warner J.A.,,Sam Houston State University,Huntsville,United States,,,,,2014-01-01,24 December 2014,Educational and Psychological Measurement,00131644,13563,15523888,Journal,74,6,,991-1017,,,6,0,,,,"This article introduces a new construct coined as Computer User Learning Aptitude (CULA). To establish construct validity, CULA is embedded in a nomological network that extends the technology acceptance model (TAM). Specifically, CULA is posited to affect perceived usefulness and perceived ease of use, the two underlying TAM constructs. Furthermore, we examine several antecedents of CULA by relying on the second language learning literature. These include computer anxiety, tolerance of ambiguity, and risk taking. Conceptualization of CULA is based on the observation that computer systems use language as communication between the computer and the user, making system usage significantly dependent on the ability of the individual to learn the language. We posit that learning to communicate with computer technology is akin to learning a second language, that is, a language learned after the first language(s) or native language(s), and is referred to as computerese. The proposed construct, CULA, measures the aptitude of an individual to learn computerese, and it is specified as a second-order variable. It includes measures of three critical facets of computerese pertaining to general hardware/software, programming, and the Internet. Significant relationships are found between computer anxiety, tolerance of ambiguity, and taking risk with CULA, as well as between CULA and TAM constructs.",NO
2-s2.0-84905582683,10.1109/TFUZZ.2013.2279535,,,Generalized Markov models for real-time modeling of continuous systems,ar,Article,Filev D.,,Ford Motor Company,Dearborn,United States,,,,,2014-01-01,August 2014,IEEE Transactions on Fuzzy Systems,10636706,24242,,Journal,22,4,6588289,983-998,,,40,0,,,,"This paper presents a modeling framework based on finite-state space Markov chains (MCs) and fuzzy subsets to represent signals that vary in a continuous range. Our special attention to this extension of finite-state space MC modeling is motivated by numerous opportunities in applying MC models to represent physical variables in automotive and aerospace systems and, subsequently, using these models for fault detection, estimation, prediction, stochastic dynamic programming, and stochastic model predictive control. Our generalized MC modeling framework synergistically combines the notion of transition probabilities with information granulation based on fuzzy partitioning. As compared with the case of more familiar interval partitioning, the transition probabilities in our model are defined for transitions between fuzzy subsets rather than intervals/rectangular cells. Our framework is first introduced for scalar-valued signals and then extended to vector-valued signals. A real-time capable recursive algorithm for learning transition probabilities from measured signal data is derived. Formulas that characterize the possibility distribution of the next signal value and predict the next signal value are given. It is shown that the introduced modeling framework based on MC models defined over fuzzy partitioning inherits all properties and represents a natural extension of MC models defined over interval partitioning, while providing interpolation ability and improved prediction accuracy. In addition, we derive an alternative formulation of the Chapman-Kolmogorov equation that applies to models in possibilistic/fuzzy environment. Examples are given to illustrate the key notions and results based on modeling of the vehicle speed and road grade signals.",NO
2-s2.0-84904745003,10.3389/fnbot.2014.00001,,,A psychology based approach for longitudinal development in cognitive robotics,ar,Article,Law J.,,Aberystwyth University,Aberystwyth,United Kingdom,,,,,2014-01-01,2014,Frontiers in Neurorobotics,,21100199837,16625218,Journal,8,JAN,Article 1,,,,22,1,,,,"A major challenge in robotics is the ability to learn, from novel experiences, new behavior that is useful for achieving new goals and skills. Autonomous systems must be able to learn solely through the environment, thus ruling out a priori task knowledge, tuning, extensive training, or other forms of pre-programming. Learning must also be cumulative and incremental, as complex skills are built on top of primitive skills. Additionally, it must be driven by intrinsic motivation because formative experience is gained through autonomous activity, even in the absence of extrinsic goals or tasks. This paper presents an approach to these issues through robotic implementations inspired by the learning behavior of human infants. We describe an approach to developmental learning and present results from a demonstration of longitudinal development on an iCub humanoid robot. The results cover the rapid emergence of staged behavior, the role of constraints in development, the effect of bootstrapping between stages, and the use of a schema memory of experiential fragments in learning new skills. The context is a longitudinal experiment in which the robot advanced from uncontrolled motor babbling to skilled hand/eye integrated reaching and basic manipulation of objects. This approach offers promise for further fast and effective sensory-motor learning techniques for robotic learning.",NO
2-s2.0-84904695628,10.1007/978-3-319-08491-6_13,,,Intelligent Sensing and Learning for Assisted Living Applications,ar,Article,Augustyniak P.,,AGH University of Science and Technology,Krakow MP,Poland,,,,,2014-01-01,July 2014,Advances in Intelligent Systems and Computing,21945357,5100152904,,Book Series,300,,,155-166,,,1,0,,,,"Achievements of today telemedicine and surveillance techniques offer exciting possibilities for developing intelligent assisted living systems for elderly or disabled. This chapter presents an universal sketch of multimodal health monitoring systems complying with regard to a paradigm of ubiquitous and personalized medicine. The proposed design combines advantages of context-reprogrammable sensors, flexibility of reconfigurable networks built on the surface of human body or embedded in premise infrastructures and automatic, subject-sensitive decision making based on presumptions and experience represented in artificial intelligence. Considering these key features leads to a concept, technical design and a prototype of a system suitable for majority of human surveillance purposes including home care, hospices, rehabilitation and sport training. The prototype was tested in several experimental setups intended to simulate volunteers’ homes for seamless monitoring with no limit of indoor and outdoor mobility and for recognition of normal, suspected and dangerous events. The results confirm the expected adaptability of the system to human-dependent and environment-specific relations.",NO
2-s2.0-84902830143,10.1108/MMMS-11-2012-0019,,,Real time algorithm implemented in Altera's FPGA for a newly designed mobile robot: Autonomous navigation and parallel parking,ar,Article,Abdelmoula C.,,Ecole Nationale d'Ingénieurs de Sfax,Sfax,Tunisia,,,,,2014-01-01,2014,Multidiscipline Modeling in Materials and Structures,15736105,7100153127,15736113,Journal,10,1,17112943,75-93,,,4,0,,,,"Purpose

The purpose of this paper is to propose a generic platform for a robotic mobile system, seeking to obtain a support tool for under-graduation and graduation activities. Another objective was to gather knowledge in the mobile robotic area in order to provide practical solutions for industrial problems.

Design/methodology/approach

The proposed new integrated platform would serve as didactic material for many disciplines, shown to be an ideal platform to teach DC motor drives, stepper motor and motion-control systems. To reach this objective, the ability of the robot to plan its motion autonomously is of vital importance. The control of a mobile robot in dynamic and unstructured environments typically requires efficient processing of data/information to ensure precise navigation and many other applications. Path planning is also one common method of auto-navigation. After the computation of the shortest path, mobile robot can navigate safely and without occlusion.

Findings

The developed platform is an integrated system for intelligent software middleware to coordinate many activities in the field of electric drives, robotics, autonomous systems and artificial intelligence.

Originality/value

As a result of the study, this paper contributed to research in the industrial development, principally in the fields of industrial robotics and also in different application purposes such as entertainment, personal use, welfare, education, rehabilitation, etc.",NO
2-s2.0-84902477022,10.3991/ijoe.v10i4.3270,,,Online laboratory sessions in system design with DSPs using the R-DSP lab,ar,Article,Kalantzopoulos A.,,University of Patras,Rio,Greece,,,,,2014-01-01,2014,International Journal of Online Engineering,18681646,20000195073,18612121,Journal,10,4,,4-12,,,13,1,,,,"The education of students in the design of DSP (Digital Signal Processor) based systems is achieved through courses including lectures and laboratory sessions. Traditionally, the laboratory sessions take place in the hands-on laboratories and the physical presence of both students and instructors is required. This paper presents the online conduction of the System Design with DSPs postgraduate course's laboratory sessions utilizing the R-DSP Lab (Remote Digital Signal Processors Laboratory). This interactive RL (Remote Laboratory) allows the students to verify their DSP applications which are written by them in C and/or assembly programming language without time and place restrictions. It also supports the remote control of the available laboratory equipment through an internet accessible and user-friendly control environment. However, the most important feature of the R-DSP Lab which is proposed in this paper, is the remote control of student's DSP applications through GUIs (Graphical User Interfaces) developed by them. This feature is demonstrated through an example concerning the implementation and verification processes of a real-time DTMF (Dual Tone Multi Frequency) encoder/decoder. In this example the DSP application is remotely controlled through a LabVIEW based GUI developed by the students following the instructions of the corresponding laboratory session. The assessment and evaluation of both the System Design with DSPs laboratory sessions and the R-DSP Lab are also discussed in this paper.",NO
2-s2.0-84902464144,10.1108/IJICC-05-2013-0028,,,Chaotic artificial bee colony approach to step planning of maintaining balance for quadruped robot,ar,Article,Luo Q.,,Beihang University,Beijing,China,,,,,2014-01-01,June 2014,International Journal of Intelligent Computing and Cybernetics,1756378X,19700182406,17563798,Journal,7,2,,175-191,,,4,0,,,,"Purpose

Artificial bee colony (ABC) algorithm is a relatively new optimization method inspired by the herd behavior of honey bees, which shows quite intelligence. The purpose of this paper is to propose an improved ABC optimization algorithm based on chaos theory for solving the push recovery problem of a quadruped robot, which can tune the controller parameters based on its search mechanism. ADAMS simulation environment is adopted to implement the proposed scheme for the quadruped robot.

Design/methodology/approach

Maintaining balance is a rather complicated global optimum problem for a quadruped robot which is about seeking a foot contact point prevents itself from falling down. To ensure the stability of the intelligent robot control system, the intelligent optimization method is employed. The proposed chaotic artificial bee colony (CABC) algorithm is based on basic ABC, and a chaotic mechanism is used to help the algorithm to jump out of the local optimum as well as finding the optimal parameters. The implementation procedure of our proposed chaotic ABC approach is described in detail.

Findings

The proposed CABC method is applied to a quadruped robot in ADAMS simulator. Using the CABC to implement, the quadruped robot can work smoothly under the interference. A comparison among the basic ABC and CABC is made. Experimental results verify a better trajectory tracking response can be achieved by the proposed CABC method after control parameters training.

Practical implications

The proposed CABC algorithm can be easily applied to practice and can steer the robot during walking, which will considerably increase the autonomy of the robot.

Originality/value

The proposed CABC approach is interesting for the optimization of a control scheme for quadruped robot. A parameter training methodology, using the presented intelligent algorithm is proposed to increase the learning capability. The experimental results verify the system stabilization, favorable performance and no chattering phenomena can be achieved by using the proposed CABC algorithm. And, the proposed CABC methodology can be easily extended to other applications.",NO
2-s2.0-84902193781,10.1016/j.robot.2014.04.005,S0921889014000797,,Learning object deformation models for robot motion planning,ar,Article,Frank B.,,Universität Freiburg,Freiburg im Breisgau,Germany,,,,,2014-01-01,August 2014,Robotics and Autonomous Systems,09218890,18079,,Journal,62,8,,1153-1174,,,19,0,,,,"Highlights

•

We present a planning system for robots in environments with deformable objects.

•

A manipulation robot determines the deformation parameters of real objects.

•

We consider the costs of object deformations by finite element simulations.

•

The deformation costs are modeled using Gaussian processes for efficient planning.

•

Application to wheeled and manipulation robots operating in real environments.
In this paper, we address the problem of robot navigation in environments with deformable objects. The aim is to include the costs of object deformations when planning the robot’s motions and trade them off against the travel costs. We present our recently developed robotic system that is able to acquire deformation models of real objects. The robot determines the elasticity parameters by physical interaction with the object and by establishing a relation between the applied forces and the resulting surface deformations. The learned deformation models can then be used to perform physically realistic finite element simulations. This allows the planner to evaluate robot trajectories and to predict the costs of object deformations. Since finite element simulations are time-consuming, we furthermore present an approach to approximate object-specific deformation cost functions by means of Gaussian process regression. We present two real-world applications of our motion planner for a wheeled robot and a manipulation robot. As we demonstrate in real-world experiments, our system is able to estimate appropriate deformation parameters of real objects that can be used to predict future deformations. We show that our deformation cost approximation improves the efficiency of the planner by several orders of magnitude.",NO
2-s2.0-84901258359,10.1109/MCOM.2014.6815911,,,Software-defined radio: A new paradigm for integrated curriculum delivery,ar,Article,Bilén S.G.,,"University of Michigan, Ann Arbor",Ann Arbor,United States,,,,,2014-01-01,May 2014,IEEE Communications Magazine,01636804,17249,,Journal,52,5,6815911,184-193,,,28,0,,,,"Software-defined radio is a rapidly developing field that is driving the development of and innovation in communications technology, and promises to significantly impact all communications sectors. Entities developing these SDR systems require a trained workforce that has been prepared with the mindset, knowledge, skills, and tools required to address both the system (breadth) and technical (depth) aspects of SDR systems. Developing SDRs necessarily involves a collection of disciplines including, but not limited to, electromagnetics, radio-frequency engineering, communications, digital signal processing, embedded systems, computer programming, and systems engineering. Whereas electrical engineering and computer science and engineering curricula at the university level may include courses in all of these areas, a student's typical curriculum does not; nor does it usually involve the integration of all these topics. However, SDR can be employed as an integrative construct that facilitates systems thinking and cross-domain learning via peers. In this article, we present several significant educational efforts across six U.S. universities that have developed integrated curricula in SDR, most including a significant laboratory component.",NO
2-s2.0-84896305250,10.5755/j01.itc.43.1.3715,,,Refactoring of heterogeneous meta-program into k-stage meta-program,ar,Article,Štuikys V.,,Kaunas University of Technology,Kaunas,Lithuania,,,,,2014-01-01,2014,Information Technology and Control,1392124X,19700174611,,Journal,43,1,,14-27,,,4,0,,,,"The paper presents: (1) a graph-based theoretical background to refactoring a correct heterogeneous meta-program into its k-stage representation; (2) the refactoring method; (3) refactoring experiments with tasks taken from different domains, including real world tasks, such as meta-programs to teach Computer Science (CS) topics using educational robots. Refactoring meta-programs by staging enables to flexibly adapt them to the different context of use. To do that (semi-)automatically, we use the contextual information as a priority relation (e.g. highest, lowest, etc.) introduced within the meta-program specification. We implement the refactoring method using the so-called activating/de-activating label (index) to change the role of meta-language constructs at different stages. The contribution of the paper is: (1) applying the known (in programming) staging concept to heterogeneous meta-programming; (2) a theoretical background, properties and the method to solve tasks of this kind of refactoring.

DOI: http://dx.doi.org/10.5755/j01.itc.43.1.3715",NO
2-s2.0-84891371919,10.1007/s10994-013-5352-9,,,Plane-based object categorisation using relational learning,ar,Article,Farid R.,,UNSW Sydney,Sydney,Australia,,,,,2014-01-01,January 2014,Machine Learning,08856125,24775,15730565,Journal,94,1,,3-23,,,12,0,,,,"We use Inductive Logic Programming (ILP) to learn classifiers for generic object recognition from point clouds, as generated by 3D cameras, such as the Kinect. Each point cloud is segmented into planar surfaces. Each subset of planes that represents an object is labelled and predicates describing those planes and their relationships are used for learning. Our claim is that a relational description for classes of 3D objects can be built for robust object categorisation in real robotic application. To test the hypothesis, labelled sets of planes from 3D point clouds gathered during the RoboCup Rescue Robot competition are used as positive and negative examples for an ILP system. The robustness of the results is evaluated by 10-fold cross validation. In addition, common household objects that have curved surfaces are used for evaluation and comparison against a well-known non-relational classifier. The results show that ILP can be successfully applied to recognise objects encountered by a robot especially in an urban search and rescue environment.",NO
2-s2.0-84940614866,10.1016/j.neucom.2014.09.092,S0925231215005676,,A hierarchical path planning approach based on A<sup>*</sup> and least-squares policy iteration for mobile robots,ar,Article,Zuo L.,,National University of Defense Technology,Changsha,China,,,,,2015-12-25,25 December 2015,Neurocomputing,09252312,24807,18728286,Journal,170,,,257-266,,,42,0,,,,"In this paper, we propose a novel hierarchical path planning approach for mobile robot navigation in complex environments. The proposed approach has a two-level structure. In the first level, the A⁎ algorithm based on grids is used to find a geometric path quickly and several path points are selected as subgoals for the next level. In the second level, an approximate policy iteration algorithm called least-squares policy iteration (LSPI) is used to learn a near-optimal local planning policy that can generate smooth trajectories under kinematic constraints of the robot. Using this near-optimal local planning policy, the mobile robot can find an optimized path by sequentially approaching the subgoals obtained in the first level. One advantage of the proposed approach is that the kinematic characteristics of the mobile robot can be incorporated into the LSPI-based path optimization procedure. The second advantage is that the LSPI-based local path optimizer uses an approximate policy iteration algorithm which has been proven to be data-efficient and stable. The training of the local path optimizer can use sample experiences collected randomly from any reasonable sampling distribution. Furthermore, the LSPI-based local path optimizer has the ability of dealing with uncertainties in the environment. For unknown obstacles, it just needs to replan the path in the second level rather than the whole planner. Simulations for path planning in various types of environments have been carried out and the results demonstrate the effectiveness of the proposed approach.",NO
2-s2.0-85013133538,10.1186/s40648-014-0025-4,,,View-based teaching/playback for robotic manipulation,ar,Article,Maeda Y.,,Yokohama National University,Yokohama,Japan,,,,,2015-12-01,1 December 2015,ROBOMECH Journal,,21100853738,21974225,Journal,2,1,2,,,,10,1,,,,"In this paper, we study a new method for robot programming: view-based teaching/playback. The motivation of its development is to achieve more robustness against changes of task conditions than conventional teaching/playback without losing its general versatility. For proof of concept, the method was implemented and tested on a virtual environment.

The method is composed of two parts: teaching phase and playback phase. In the teaching phase, a human operator commands a robot to achieve a manipulation task. All the movements of the robot are recorded. All the images of the teaching scenes are also recorded by a camera. Then, a mapping from the recorded images to the movements is obtained as an artificial neural network. In the playback phase, the motion of the robot is determined by the output of the neural network calculated from scene images.

We applied this view-based teaching/playback to pick-and-place and pushing by a robot hand with eight degrees of freedom in the virtual environment. Human demonstrated manipulation was successfully reproduced by the robot hand with our proposed method. Moreover, manipulation of the object from some initial positions that are not identical to those in the demonstrations was also successfully achieved with our method.",NO
2-s2.0-84960805981,10.1109/JSYST.2014.2374334,,,Autonomous Construction of Multiple Structures Using Learning Automata: Description and Experimental Validation,ar,Article,Barros Dos Santos S.R.,,Instituto Tecnologico de Aeronautica,Sao Jose dos Campos,Brazil,,,,,2015-12-01,December 2015,IEEE Systems Journal,19328184,11300153734,19379234,Journal,9,4,7018006,1376-1387,,,23,0,,,,"In this paper, we develop an adaptive scheme based on reinforcement learning (RL) for planning the construction tasks using a quadrotor. Moreover, an autonomous construction system to assemble user-specified 3-D structures is proposed. Nowadays, complex construction tasks using mobile robots are characterized by three fundamental problems: assembly planning, motion planning, and path tracking control. The high-level plan to perform the construction task consists of assembly mode algorithms that are derived offline in a simulation environment through learning and heuristic search. A promising approach to design and optimize the path tracking controllers for a quadrotor as well as the attitude controllers using RL is presented. This paper describes a comprehensive validation framework that enables an aerial robot to build structures in a robust and safe manner. The experimental trials for building the 3-D structures using the designed high-level plans and path tracking controllers have provided encouraging results.",NO
2-s2.0-84953359131,10.1007/s10846-015-0178-2,,,Robotic Ubiquitous Cognitive Ecology for Smart Homes,ar,Article,Amato G.,,Istituto di Scienza e Tecnologie dell'Informazione A. Faedo,Pisa,Italy,,,,,2015-12-01,1 December 2015,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,80,,,57-81,,,30,0,,,,"Robotic ecologies are networks of heterogeneous robotic devices pervasively embedded in everyday environments, where they cooperate to perform complex tasks. While their potential makes them increasingly popular, one fundamental problem is how to make them both autonomous and adaptive, so as to reduce the amount of preparation, pre-programming and human supervision that they require in real world applications. The project RUBICON develops learning solutions which yield cheaper, adaptive and efficient coordination of robotic ecologies. The approach we pursue builds upon a unique combination of methods from cognitive robotics, machine learning, planning and agent-based control, and wireless sensor networks. This paper illustrates the innovations advanced by RUBICON in each of these fronts before describing how the resulting techniques have been integrated and applied to a proof of concept smart home scenario. The resulting system is able to provide useful services and pro-actively assist the users in their activities. RUBICON learns through an incremental and progressive approach driven by the feedback received from its own activities and from the user, while also self-organizing the manner in which it uses available sensors, actuators and other functional components in the process. This paper summarises some of the lessons learned by adopting such an approach and outlines promising directions for future work.",NO
2-s2.0-84953348846,10.1007/s10846-015-0219-x,,,Gesture-Based Extraction of Robot Skill Parameters for Intuitive Robot Programming,ar,Article,Pedersen M.,,Aalborg University,Aalborg,Denmark,,,,,2015-12-01,1 December 2015,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,80,,,149-163,,,14,0,,,,"Despite a lot of research in the field, only very little experience exists with Teaching by Demonstration (TbD) in actual industrial use cases. In the factory of the future, it is necessary to rapidly reprogram flexible mobile manipulators to perform new tasks, when the need arises, for which a working system capable of TbD would be ideal. Contrary to current TbD approaches, that generally aim to recognize both action and where it is applied, we propose a division of labor, where the operator manually specifies the action the robot should perform, while gestures are used for specifying the relevant action parameter (e.g. on which object to apply the action). Using this two-step method has the advantages that there is no uncertainty of which action the robot will perform, it takes into account that the environment changes, so objects do not need to be at predefined locations, and the parameter specification is possible even for inexperienced users. Experiments with 24 people in 3 different environments verify that it is indeed intuitive, even for a robotics novice, to program a mobile manipulator using this method.",NO
2-s2.0-85046969953,10.1080/14484846.2015.1093218,,,A new hybrid intelligent path planner for mobile robot navigation based on adaptive neuro-fuzzy inference system,ar,Article,Mohanty P.,,National Institute of Technology Rourkela,Rourkela,India,,,,,2015-11-17,17 November 2015,Australian Journal of Mechanical Engineering,14484846,12100157246,,Journal,13,3,,195-207,,,8,0,,,,"In this paper, a new intelligent motion planning approach to mobile robot navigation is addressed. Adaptive neuro-fuzzy inference system (ANFIS) is a well-known hybrid neuro-fuzzy structure for modelling the engineering system. It has also taken the advantages of both learning ability of neural network and the reasoning ability of the fuzzy inference system. In this navigational model, different sensor-extracted information, such as front obstacle distance, right obstacle distance, left obstacle distance, heading angle, left wheel velocity and right wheel velocity, are given input to the ANFIS controller and output from the controller is steering angle for the robot. Based on the output information, the robot moves safely in an unstructured environment populated by variety of static obstacles. Using ANFIS tool box, the obtained mean of squared error for the training dataset in the current paper is 0.0021. Finally, the simulation results are verified with real-time experimental results using Khepra-III mobile robot to show the feasibility and effectiveness of the proposed navigational algorithm.",NO
2-s2.0-84947020821,10.1080/10494820.2013.815220,,,Creation of an integrated environment to supply e-learning platforms with Office Automation features,ar,Article,Palumbo E.,,Politecnico di Torino,Turin,Italy,,,,,2015-11-02,2 November 2015,Interactive Learning Environments,10494820,145681,17445191,Journal,23,6,,766-777,,,3,0,,,,"Over the last years great efforts have been made within the University environment to implement e-learning technologies in the standard educational practice. These learning technologies distribute online educational multimedia contents through technological platforms. Even though specific e-learning tools for technical disciplines were already available on the Internet, in our opinion more general tools, typically involving calculations, plots or diagrams, through the use of spreadsheets or graphical applications, were still needed to provide a more flexible and multi-purpose integrated environment. Therefore, we developed an integrated system to supply e-learning platforms with almost the same functionalities offered by standalone Office Automation applications. Modular object-oriented dynamic learning environment (MOODLE) and OpenOffice.org were selected to deal with any problem originating from the software and to smooth over the users' learning curve. Furthermore, MOODLE is a modular platform and offers an extensive application programming interface for coding in a simple and effective manner. The implementation of the work required the employment of Java and Asynchronous JavaScript and Extensible Markup Language technologies and included the creation of a Java Applet to be embedded in the web pages of the new MOODLE modules. Students could thus be offered a single working environment for handling “traditional” material and performing practical activities. The students' feedback on this new integrated system was very positive and proved the effectiveness of our work.",NO
2-s2.0-85087950299,10.1007/s13218-015-0386-8,,,Statistical Relational Artificial Intelligence: From Distributions through Actions to Optimization,ar,Article,Kersting K.,,Technische Universität Dortmund,Dortmund,Germany,,,,,2015-11-01,1 November 2015,KI - Kunstliche Intelligenz,09331875,21101017166,16101987,Journal,29,4,,363-368,,,0,0,,,,"Statistical Relational AI—the science and engineering of making intelligent machines acting in noisy worlds composed of objects and relations among the objects—is currently motivating a lot of new AI research and has tremendous theoretical and practical implications. Theoretically, combining logic and probability in a unified representation and building general-purpose reasoning tools for it has been the dream of AI, dating back to the late 1980s. Practically, successful statistical relational AI tools enable new applications in several large, complex real-world domains including those involving big data, natural text, social networks, the web, medicine and robotics, among others. Such domains are often characterized by rich relational structure and large amounts of uncertainty. Logic helps to faithfully model the former while probability helps to effectively manage the latter. Our intention here is to give a brief (and necessarily incomplete) overview and invitation to the emerging field of Statistical Relational AI from the perspective of acting optimally and learning to act.",NO
2-s2.0-84944186687,10.1115/1.4031089,,,The MechProcessor: Helping Novices Design Printable Mechanisms Across Different Printers,ar,Article,Fuge M.,,A. James Clark School of Engineering,College Park,United States,,,,,2015-11-01,1 November 2015,"Journal of Mechanical Design, Transactions of the ASME",10500472,20979,,Journal,137,11,111707,,,,11,0,,,,"Additive manufacturing (AM), or 3D-printing, sits at the heart of the Maker Movement—the growing desire for wider-ranges of people to design physical objects. However, most users that wish to design functional moving devices face a prohibitive barrier-to-entry: they need fluency in a computer-aided design (CAD) package. This limits most people to being merely consumers, rather than designers or makers. To solve this problem, we combine advances in mechanism synthesis, computer languages, and design for AM to create a computational framework, the MechProcessor, which allows novices to produce 3D-printable, moving mechanisms of varying complexity using simple and extendable interfaces. The paper describes how we use hierarchical cascading configuration languages, breadth-first search, and mixed-integer linear programming (MILP) for mechanism synthesis, along with a nested, printable test-case to detect and resolve the AM constraints needed to ensure the devices can be 3D printed. We provide physical case studies and an open-source library of code and mechanisms that enable others to easily extend the MechProcessor framework. This encourages new research, commercial, and educational directions, including new types of customized printable robotics, business models for customer-driven design, and STEM education initiatives that involve nontechnical audiences in mechanical design. By promoting novice interaction in complex design and fabrication of movable components, we can move society closer to the true promise of the Maker Movement: turning consumers into designers.",NO
2-s2.0-84945129053,10.1088/1748-3190/10/5/055002,,26352901,Texture recognition and localization in amorphous robotic skin,ar,Article,Hughes D.,,University of Colorado Boulder,Boulder,United States,,,,,2015-09-09,9 September 2015,Bioinspiration and Biomimetics,17483182,4700152290,17483190,Journal,10,5,055002,,,,33,0,,,,"We present a soft robotic skin that can recognize and localize texture using a distributed set of sensors and computational elements that are inspired by the Pacinian corpuscle, the fast adapting, uniformly spaced mechanoreceptor with a wide receptive field, which is responsive to vibrations due to rubbing or slip on the skin. Tactile sensing and texture recognition is important for controlled manipulation of objects and navigating in one's environment. Yet, providing robotic systems or prosthetic devices with such capability at high density and bandwidth remains challenging. Each sensor node in the presented skin is created by collocating computational elements with individual microphones. These nodes are networked in a lattice and embedded in EcoFlex rubber, forming an amorphous medium. Unlike existing skins consisting of passive sensor arrays that feed into a central computer, our approach allows for detecting, conditioning and processing of tactile signals in-skin, facilitating the use of high-bandwidth signals, such as vibration, and allowing nodes to respond only to signals of interest. Communication between nodes allows the skin to localize the source of a stimulus, such as rubbing or slip, in a decentralized manner. Signal processing by individual nodes allows the skin to estimate the material touched. Combining these two capabilities, the skin is able to convert high-bandwidth, spatiotemporal information into low-bandwidth, event-driven information. Unlike taxel-based sensing arrays, this amorphous approach greatly reduces the computational load on the central robotic system. We describe the design, analysis, construction, instrumentation and programming of the robotic skin. We demonstrate that a 2.8 square meter skin with 10 sensing nodes is capable of localizing stimulus to within 2 centimeters, and that an individual sensing node can identify 15 textures with an accuracy of 71%. Finally, we discuss how such a skin could be used for full-body sensing in existing robots, augment existing sensing modalities, and how this material may be useful in robotic grasping tasks.",NO
2-s2.0-84937523610,10.1007/s10514-015-9435-2,,,Adaptation of manipulation skills in physical contact with the environment to reference force profiles,ar,Article,Abu-Dakka F.J.,,Jozef Stefan Institute,Ljubljana,Slovenia,,,,,2015-08-23,23 August 2015,Autonomous Robots,09295593,18016,15737527,Journal,39,2,,199-217,,,58,0,,,,"We propose a new methodology for learning and adaption of manipulation skills that involve physical contact with the environment. Pure position control is unsuitable for such tasks because even small errors in the desired trajectory can cause significant deviations from the desired forces and torques. The proposed algorithm takes a reference Cartesian trajectory and force/torque profile as input and adapts the movement so that the resulting forces and torques match the reference profiles. The learning algorithm is based on dynamic movement primitives and quaternion representation of orientation, which provide a mathematical machinery for efficient and stable adaptation. Experimentally we show that the robot’s performance can be significantly improved within a few iteration steps, compensating for vision and other errors that might arise during the execution of the task. We also show that our methodology is suitable both for robots with admittance and for robots with impedance control.",NO
2-s2.0-84994518923,10.5772/61087,,,Affordance Learning Based on Subtask's Optimal Strategy,ar,Article,Min H.,,South China University of Technology,Guangzhou,China,,,,,2015-08-20,20 August 2015,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,12,8,111,,,,5,1,,,,"Affordances define the relationships between the robot and environment, in terms of actions that the robot is able to perform. Prior work is mainly about predicting the possibility of a reactive action, and the object's affordance is invariable. However, in the domain of dynamic programming, a robot's task could often be decomposed into several subtasks, and each subtask could limit the search space. As a result, the robot only needs to replan its sub-strategy when an unexpected situation happens, and an object's affordance might change over time depending on the robot's state and current subtask. In this paper, we propose a novel affordance model linking the subtask, object, robot state and optimal action. An affordance represents the first action of the optimal strategy under the current subtask when detecting an object, and its influence is promoted from a primitive action to the subtask strategy. Furthermore, hierarchical reinforcement learning and state abstraction mechanism are introduced to learn the task graph and reduce state space. In the navigation experiment, the robot equipped with a camera could learn the objects' crucial characteristics, and gain their affordances in different subtasks.",NO
2-s2.0-85027916652,10.1109/TRO.2015.2441511,,,Extending the Applicability of POMDP Solutions to Robotic Tasks,ar,Article,Grady D.,,Google LLC;Rice University,Mountain View;Houston,United States;United States,,,,,2015-08-01,1 August 2015,IEEE Transactions on Robotics,15523098,95101,,Journal,31,4,7131561,948-961,,,15,0,,,,"Partially observable Markov decision processes (POMDPs) are used in many robotic task classes from soccer to household chores. Determining an approximately optimal action policy for POMDPs is PSPACE-complete, and the exponential growth of computation time prohibits solving large tasks. This paper describes two techniques to extend the range of robotic tasks that can be solved using a POMDP. Our first technique reduces the motion constraints of a robot and, then, uses state-of-the-art robotic motion planning techniques to respect the true motion constraints at runtime. We then propose a novel task decomposition that can be applied to some indoor robotic tasks. This decomposition transforms a long time horizon task into a set of shorter tasks. We empirically demonstrate the performance gain provided by these two techniques through simulated execution in a variety of environments. Comparing a direct formulation of a POMDP to solving our proposed reductions, we conclude that the techniques proposed in this paper can provide significant enhancement to current POMDP solution techniques, extending the POMDP instances that can be solved to include large continuous-state robotic tasks.",NO
2-s2.0-84957961553,10.1007/s10798-014-9287-7,,,"“I want my robot to look for food”: Comparing Kindergartner’s programming comprehension using tangible, graphic, and hybrid user interfaces",ar,Article,Strawhacker A.,,Tufts University,Medford,United States,,,,,2015-08-01,1 August 2015,International Journal of Technology and Design Education,09577572,21389,15731804,Journal,25,3,,293-319,,,58,0,,,,"In recent years, educational robotics has become an increasingly popular research area. However, limited studies have focused on differentiated learning outcomes based on type of programming interface. This study aims to explore how successfully young children master foundational programming concepts based on the robotics user interface (tangible, graphical, hybrid) taught in their curriculum. Thirty-five Kindergarten students participated in a 9-week robotics curriculum using the LEGO WeDo robotics construction kit and the Creative Hybrid Environment for Robotic Programming (CHERP) programming language. A mixed methods data collection approach was employed, including qualitative observational data from the classrooms, as well as quantitative mid- and post-test assessments of students’ programming knowledge using CHERP. The findings show little association between user interface and programming comprehension, although there may be an order-affect when introducing user interfaces. Implications for best practices when introducing programming in early childhood settings are discussed.",SI
2-s2.0-84946219634,10.1109/RITA.2015.2452692,,,MODEBOTS: Environment for Programming Robots for Children between the Ages of 4 and 6,ar,Article,Ramirez-Benavides K.,,Universidad de Costa Rica,San Jose,Costa Rica,,,,,2015-08-01,1 August 2015,Revista Iberoamericana de Tecnologias del Aprendizaje,,19700201532,19328540,Journal,10,3,7155494,152-159,,,6,0,,,,"Learning how to program in early age helps children to develop some capabilities as logical thinking, problem solving, and creativity. Incorporating robotics in programming children can help to learn in a concrete and funny way, collaborating with each other. The research project presented in this paper describes the first prototype that implements a programming environment for robots using mobile devices, for children in early childhood-4 to 6 years old. This prototype is fully functional and allows Bluetooth communication one by one. We expect that our research will contribute to human-computer interface field, providing a new nontraditional interface to support the learning process of programming in preschoolers.",SI
2-s2.0-84938965400,10.1007/s10994-014-5471-y,,,Meta-interpretive learning of higher-order dyadic datalog: predicate invention revisited,ar,Article,Muggleton S.H.,,Imperial College London,London,United Kingdom,,,,,2015-07-27,27 July 2015,Machine Learning,08856125,24775,15730565,Journal,100,1,,49-73,,,86,1,,,,"Since the late 1990s predicate invention has been under-explored within inductive logic programming due to difficulties in formulating efficient search mechanisms. However, a recent paper demonstrated that both predicate invention and the learning of recursion can be efficiently implemented for regular and context-free grammars, by way of metalogical substitutions with respect to a modified Prolog meta-interpreter which acts as the learning engine. New predicate symbols are introduced as constants representing existentially quantified higher-order variables. The approach demonstrates that predicate invention can be treated as a form of higher-order logical reasoning. In this paper we generalise the approach of meta-interpretive learning (MIL) to that of learning higher-order dyadic datalog programs. We show that with an infinite signature the higher-order dyadic datalog class H^2_2 has universal Turing expressivity though H^2_2 is decidable given a finite signature. Additionally we show that Knuth–Bendix ordering of the hypothesis space together with logarithmic clause bounding allows our MIL implementation Metagol_{D} to PAC-learn minimal cardinality H^2_2 definitions. This result is consistent with our experiments which indicate that Metagol_{D} efficiently learns compact H^2_2 definitions involving predicate invention for learning robotic strategies, the East–West train challenge and NELL. Additionally higher-order concepts were learned in the NELL language learning domain. The Metagol code and datasets described in this paper have been made publicly available on a website to allow reproduction of results in this paper.",NO
2-s2.0-84933498327,10.1109/TAMD.2015.2427233,,,"Structural bootstrapping-A novel, generative mechanism for faster and more efficient acquisition of action-knowledge",ar,Article,Worgotter F.,,Bernstein Center for Computational Neuroscience Göttingen,Gottingen,Germany,,,,,2015-06-01,1 June 2015,IEEE Transactions on Autonomous Mental Development,19430604,19700177024,,Journal,7,2,7096939,140-154,,,13,0,,,,"Humans, but also robots, learn to improve their behavior. Without existing knowledge, learning either needs to be explorative and, thus, slow or-to be more efficient-it needs to rely on supervision, which may not always be available. However, once some knowledge base exists an agent can make use of it to improve learning efficiency and speed. This happens for our children at the age of around three when they very quickly begin to assimilate new information by making guided guesses how this fits to their prior knowledge. This is a very efficient generative learning mechanism in the sense that the existing knowledge is generalized into as-yet unexplored, novel domains. So far generative learning has not been employed for robots and robot learning remains to be a slow and tedious process. The goal of the current study is to devise for the first time a general framework for a generative process that will improve learning and which can be applied at all different levels of the robot's cognitive architecture. To this end, we introduce the concept of structural bootstrapping-borrowed and modified from child language acquisition-to define a probabilistic process that uses existing knowledge together with new observations to supplement our robot's data-base with missing information about planning-, object-, as well as, action-relevant entities. In a kitchen scenario, we use the example of making batter by pouring and mixing two components and show that the agent can efficiently acquire new knowledge about planning operators, objects as well as required motor pattern for stirring by structural bootstrapping. Some benchmarks are shown, too, that demonstrate how structural bootstrapping improves performance.",NO
2-s2.0-84926395738,10.1109/TRO.2015.2409912,,,Task-Based Robot Grasp Planning Using Probabilistic Inference,ar,Article,Song D.,,The Royal Institute of Technology (KTH),Stockholm,Sweden,,,,,2015-06-01,June 2015,IEEE Transactions on Robotics,15523098,95101,,Journal,31,3,7078848,546-561,,,35,1,,,,"Grasping and manipulating everyday objects in a goal-directed manner is an important ability of a service robot. The robot needs to reason about task requirements and ground these in the sensorimotor information. Grasping and interaction with objects are challenging in real-world scenarios, where sensorimotor uncertainty is prevalent. This paper presents a probabilistic framework for the representation and modeling of robot-grasping tasks. The framework consists of Gaussian mixture models for generic data discretization, and discrete Bayesian networks for encoding the probabilistic relations among various task-relevant variables, including object and action features as well as task constraints. We evaluate the framework using a grasp database generated in a simulated environment including a human and two robot hand models. The generative modeling approach allows the prediction of grasping tasks given uncertain sensory data, as well as object and grasp selection in a task-oriented manner. Furthermore, the graphical model framework provides insights into dependencies between variables and features relevant for object grasping.",NO
2-s2.0-84932598723,10.5772/60093,,,Understanding human hand gestures for learning robot pick-and-place tasks,ar,Article,Lin H.I.,,National Taipei University of Technology,Taipei,Taiwan,,,,,2015-05-06,6 May 2015,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,12,,49,,,,10,1,,,,"Programming robots by human demonstration is an intuitive approach, especially by gestures. Because robot pick-and-place tasks are widely used in industrial factories, this paper proposes a framework to learn robot pick-and-place tasks by understanding human hand gestures. The proposed framework is composed of the module of gesture recognition and the module of robot behaviour control. For the module of gesture recognition, transport empty (TE), transport loaded (TL), grasp (G), and release (RL) from Gilbreth's therbligs are the hand gestures to be recognized. A convolution neural network (CNN) is adopted to recognize these gestures from a camera image. To achieve the robust performance, the skin model by a Gaussian mixture model (GMM) is used to filter out non-skin colours of an image, and the calibration of position and orientation is applied to obtain the neutral hand pose before the training and testing of the CNN. For the module of robot behaviour control, the corresponding robot motion primitives to TE, TL, G, and RL, respectively, are implemented in the robot. To manage the primitives in the robot system, a behaviour-based programming platform based on the Extensible Agent Behavior Specification Language (XABSL) is adopted. Because the XABSL provides the flexibility and re-usability of the robot primitives, the hand motion sequence from the module of gesture recognition can be easily used in the XABSL programming platform to implement the robot pick-and-place tasks. The experimental evaluation of seven subjects performing seven hand gestures showed that the average recognition rate was 95.96%. Moreover, by the XABSL programming platform, the experiment showed the cube-stacking task was easily programmed by human demonstration.",NO
2-s2.0-84929346516,10.3390/s150510399,,,Analyzing systemC designs: SystemC analysis approaches for varying applications,ar,Article,Stoppe J.,,German Research Center for Artificial Intelligence (DFKI),Kaiserslautern,Germany,,,,,2015-05-04,4 May 2015,Sensors (Switzerland),14248220,130124,,Journal,15,5,,10399-10421,,,6,1,,,,"The complexity of hardware designs is still increasing according to Moore’s law. With embedded systems being more and more intertwined and working together not only with each other, but also with their environments as cyber physical systems (CPSs), more streamlined development workflows are employed to handle the increasing complexity during a system’s design phase. SystemC is a C++ library for the design of hardware/software systems, enabling the designer to quickly prototype, e.g., a distributed CPS without having to decide about particular implementation details (such as whether to implement a feature in hardware or in software) early in the design process. Thereby, this approach reduces the initial implementation’s complexity by offering an abstract layer with which to build a working prototype. However, as SystemC is based on C++, analyzing designs becomes a difficult task due to the complex language features that are available to the designer. Several fundamentally different approaches for analyzing SystemC designs have been suggested. This work illustrates several different SystemC analysis approaches, including their specific advantages and shortcomings, allowing designers to pick the right tools to assist them with a specific problem during the design of a system using SystemC. View Full-Text",NO
2-s2.0-84930670420,10.1109/TLA.2015.7111976,,,A tutorial on the CVX system for modeling and solving convex optimization problems,ar,Article,Guimarães D.,,Instituto Nacional de Telecomunicações,Santa Rita do Sapucai,Brazil,,,,,2015-05-01,1 May 2015,IEEE Latin America Transactions,15480992,19700181218,,Journal,13,5,7111976,1228-1257,,,17,0,,,,"In many areas of knowledge, situations in which we have to model and solve optimization problems are recurrent. Among the mathematical theories that support the solution of such problems, convex optimization unveiled to be an important tool. This is mainly due to the existence of algorithms whose computational solution has matured a lot in terms of speed of solution and reliability during the past few years. In this context, it deserves attention the CVX, a system for modeling and solving convex optimization problems. CVX uses the disciplined convex programming concept, which is a set of conventions or rules that permits the verification of convexity and automatic conversion of the problem instance into forms directly handled by the embedded solvers. This tutorial presents CVX in a didactic manner whose objective is to facilitate the learning about using the tool along with disciplined convex programming. Besides a number of examples, the tutorial also provides some applications, their corresponding CVX codes, the numerical solutions and discussions.",NO
2-s2.0-84929061405,10.1007/s10270-013-0325-9,,,VPML: an approach to detect design patterns of MOF-based modeling languages,ar,Article,Elaasar M.,,IBM Canada Ltd.,Markham,Canada,,,,,2015-05-01,1 May 2015,Software and Systems Modeling,16191366,144641,16191374,Journal,14,2,,735-764,,,5,0,,,,"A design pattern is a recurring and well-understood design fragment. In a model-driven engineering methodology, detecting occurrences of design patterns supports the activities of model comprehension and maintenance. With the recent explosion of domain-specific modeling languages, each with its own syntax and semantics, there has been a corresponding explosion in approaches to detecting design patterns that are so much tailored to those many languages that they are difficult to reuse. This makes developing generic analysis tools extremely hard. Such a generic tool is however desirable to reduce the learning curve for pattern designers as they specify patterns for different languages used to model different aspects of a system. In this paper, we propose a unified approach to detecting design patterns of MOF-based modeling languages. MOF is increasingly used to define modeling languages, including UML and BPMN. In our approach, a pattern is modeled with a Visual Pattern Modeling Language and mapped to a corresponding QVT-Relations transformation. Such a transformation runs over an input model where pattern occurrences are to be detected and reports those occurrences in a result model. The approach is prototyped on Eclipse and validated in two large case studies that involve detecting design patterns—specifically a subset of GoF patterns in a UML model and a subset of Control Flow patterns in a BPMN model. Results show that the approach is adequate for modeling complex design patterns for MOF-based modeling languages and detecting their occurrences with high accuracy and performance.",NO
2-s2.0-84939651743,10.1007/s11858-014-0623-x,,,Accumulation of experience in a vast number of cases: enactivism as a fit framework for the study of spatial reasoning in mathematics education,ar,Article,Khan S.,,University of Calgary,Calgary,Canada,,,,,2015-04-01,April 2015,ZDM Mathematics Education,18639690,21100217601,18639704,Journal,47,2,,269-279,,,14,0,,,,"As we witness a push toward studying spatial reasoning as a principal component of mathematical competency and instruction in the twenty first century, we argue that enactivism, with its strong and explicit foci on the coupling of organism and environment, action as cognition, and sensory motor coordination provides an inclusive, expansive, apt, and fit framework. We illustrate the fit of enactivism as a theory of learning with data from an ongoing research project involving teachers and elementary-aged children’s engagement in the design and assembly of motorized robots. We offer that spatial reasoning with its considerations of physical context, the dynamics of a body moving through space, sensorimotor coordination, and cognition, appears different from other conceptual competencies in mathematics. Specifically, we argue that learner engagements with diverse types of informationally ‘dense’ visuo-spatial interfaces (e.g., blueprints, programming icons, blocks, maps), as in the research study, afford some of the necessary experiences with/in a vast number of cases described by Varela et al. (1991) that enable the development of other mathematical competencies.",NO
2-s2.0-84919363429,10.1016/j.eswa.2014.10.053,S0957417414006940,,Bio-inspired approach to learning robot motion trajectories and visual control commands,ar,Article,Mitić M.,,University of Belgrade,Belgrade,Serbia,,,,,2015-04-01,1 April 2015,Expert Systems with Applications,09574174,24201,,Journal,42,5,,2624-2637,,,17,0,,,,"Highlights

•

We propose a robust bio-inspired learning control approach (BILCA) for mobile robots.

•

Novel approach treats the robot trajectory learning and visual homing problems.

•

First paper to integrate metaheuristic algorithm and trajectory learning problem in robots.

•

First paper to integrate metaheuristic technique and visual homing strategy in robots.

•

Various simulations and a real world experiment confirm applicability and usefulness of BILCA.
In this paper, a novel bio-inspired learning control approach (BILCA) for mobile robots based on Learning from Demonstration (LfD), Firefly Algorithm (FA), and homography between current and target camera view is developed. BILCA consists of two steps: (i) first step in which the actuator commands are learned using FA and demonstrations of desired behavior, and (ii) second step in which the obtained wheel commands are evaluated through the real world experiment. Two different problems are considered in this study: trajectory reproduction, and generation of visual control commands for correction of robot orientation. Developed simulations are used to evaluate BILCA in the domain of learning actuator commands for reproduction of different complex trajectories. Results show that the bigger firefly swarms produce better results in terms of accuracy in the final mobile robot pose, and that the desired trajectory is reproduced with minimal error in final control iteration. Likewise, simulations prove that the FA outperforms other metaheuristic techniques. Experiment conducted on a real mobile robot in indoor environment unifies two considered problems within a single transportation task. Depending of the feature position in the image plane, the homography controller for forward motion or the BILCA based controller for robot orientation correction is employed. Experimental results show the applicability and effectiveness of the developed intelligent approach in real world conditions.",NO
2-s2.0-84925600225,10.1080/01691864.2014.964314,,,Humanoid robot imitation through continuous goal-directed actions: An evolutionary approach,ar,Article,Morante S.,,Universidad Carlos III de Madrid,Madrid,Spain,,,,,2015-03-04,4 March 2015,Advanced Robotics,01691864,18003,15685535,Journal,29,5,,303-314,,,7,0,,,,"Humanoids can learn motor skills through the programming by demonstration framework, which allows matching the kinematic movements of a robot with those of a human. Continuous goal-directed actions (CGDA) is a framework that can complement the paradigm of robot imitation. Instead of kinematic parameters, its encoding is centered on the changes an action produces on object features. The features can be any measurable characteristic of the object such as color, area, etc. The execution of actions encoded as CGDA allows a robot-configuration independent achievement of tasks, avoiding the correspondence problem. By tracking object features during action execution, we create a trajectory in an n-dimensional feature space that represents object temporal states, allowing generalization, recognition, and execution of action effects on the environment. Experiments have been performed, using a humanoid robot in a simulated environment. Evolutionary computation was used for joint parameter calculation of a humanoid robot. The objective is to generate a motor trajectory which leads to a feature trajectory equal to the objective one. In one of the experiments, the robot performs a spatial trajectory based on spatial object features. In a new experiment, the robot paints a wall by following a color feature encoding.",NO
2-s2.0-84921941296,10.1177/0278364914554471,,,Learning grounded finite-state representations from unstructured demonstrations,ar,Article,Niekum S.,,The Robotics Institute;University of Massachusetts Amherst,Pittsburgh;Amherst MA,United States;United States,,,,,2015-03-03,3 March 2015,International Journal of Robotics Research,02783649,18050,17413176,Journal,34,2,,131-157,,,100,0,,,,"Robots exhibit flexible behavior largely in proportion to their degree of knowledge about the world. Such knowledge is often meticulously hand-coded for a narrow class of tasks, limiting the scope of possible robot competencies. Thus, the primary limiting factor of robot capabilities is often not the physical attributes of the robot, but the limited time and skill of expert programmers. One way to deal with the vast number of situations and environments that robots face outside the laboratory is to provide users with simple methods for programming robots that do not require the skill of an expert. For this reason, learning from demonstration (LfD) has become a popular alternative to traditional robot programming methods, aiming to provide a natural mechanism for quickly teaching robots. By simply showing a robot how to perform a task, users can easily demonstrate new tasks as needed, without any special knowledge about the robot. Unfortunately, LfD often yields little knowledge about the world, and thus lacks robust generalization capabilities, especially for complex, multi-step tasks. We present a series of algorithms that draw from recent advances in Bayesian non-parametric statistics and control theory to automatically detect and leverage repeated structure at multiple levels of abstraction in demonstration data. The discovery of repeated structure provides critical insights into task invariants, features of importance, high-level task structure, and appropriate skills for the task. This culminates in the discovery of a finite-state representation of the task, composed of grounded skills that are flexible and reusable, providing robust generalization and transfer in complex, multi-step robotic tasks. These algorithms are tested and evaluated using a PR2 mobile manipulator, showing success on several complex real-world tasks, such as furniture assembly.",NO
2-s2.0-84922835770,10.1007/s00500-014-1299-4,,,Knowledge-driven path planning for mobile robots: relative state tree,ar,Article,Chen Y.,,Wuhan University of Science and Technology,Wuhan,China,,,,,2015-03-01,March 2014,Soft Computing,14327643,28554,14337479,Journal,19,3,,763-773,,,8,0,,,,"Path planning is important in the field of mobile robot. However, traditional path planning techniques optimize the navigation path solely based on the models of the robot and the environments. Owing to the time-varying environment, the robot is expected to launch the replanning procedure in real-time continuously. It is slow and wastes computing resources for repeated decisions. In this study, a new perspective is adopted which utilizes a knowledge-driven approach for path planning. The concept of relative state tree is proposed to develop an incremental learning method based on a path planning knowledge base. The knowledge library, which stores a collection of the mappings from environmental information to robot decisions, can be established by offline or online learnings. As the robot plans online, its movement is guided by the optimal decision that is retrieved from the library based on the information which matches mostly the current environment. A large number of simulations are executed to verify the proposed method. When comparing to k-d tree, this novel method has shown to use smaller storage space and have higher efficiency.",NO
2-s2.0-84921792031,10.1016/j.engappai.2014.11.004,S0952197614002760,,Planning robot manipulation to clean planar surfaces,ar,Article,Martínez D.,,CSIC-UPC - Instituto de Robotica e Informatica Industrial (IRII),Barcelona,Spain,,,,,2015-03-01,1 March 2015,Engineering Applications of Artificial Intelligence,09521976,24182,,Journal,39,,,23-32,,,27,0,,,,"This paper presents a new approach to plan high-level manipulation actions for cleaning surfaces in household environments, like removing dirt from a table using a rag. Dragging actions can change the distribution of dirt in an unpredictable manner, and thus the planning becomes challenging. We propose to define the problem using explicitly uncertain actions, and then plan the most effective sequence of actions in terms of time. However, some issues have to be tackled to plan efficiently with stochastic actions. States become hard to predict after executing a few actions, so replanning every few actions with newer perceptions gives the best results, and the trade-off between planning time and plan quality is also important. Finally a learner is integrated to provide adaptation to changes, such as different rag grasps, robots, or cleaning surfaces.

We demonstrate experimentally, using two different robot platforms, that planning is more advantageous than simple reactive strategies for accomplishing complex tasks, while still providing a similar performance for easy tasks. We also performed experiments where the rag grasp was changed, and thus the behaviour of the dragging actions, showing that the learning capabilities allow the robot to double its performance with a new rag grasp after a few cleaning iterations.",NO
2-s2.0-84926643194,10.7641/CTA.2015.40630,,,Improved geometrical learning planning for service robot in dynamic environment,ar,Article,Chen Y.J.,,Hunan University,Changsha,China,,,,,2015-02-01,1 February 2015,Kongzhi Lilun Yu Yingyong/Control Theory and Applications,10008152,12585,,Journal,32,2,,162-168,,,2,0,,,,"To deal with the collision avoidance and target arrival for service robot when working, we propose an improved geometrical learning-based planning algorithm. Based on the geometrical learning planning algorithm, the nonholonomic constraint of mobile robot is firstly introduced to obtain higher planning feasibility. Secondly, the influence of obstacle is modified by making the detected obstacles effective only in the known area so as to reduce the influence of unknown area on path generation. Then, in order to improve the poor convergence performance of the geometrical learning planning algorithm when the robot gets close to the target, the random select point method is modified by considering the target as the first selected point when the target appears in the detected area. Moreover, an adaptive velocity moving strategy is designed to ensure the good convergence ability and high efficiency of planning. Finally, the simulation and experimental results show that the improved geometrical learning has higher planning efficiency and better convergence ability than the traditional ones.",NO
2-s2.0-85027945436,10.1016/j.rcim.2014.08.013,S073658451400074X,,On-line knowledge acquisition and enhancement in robotic assembly tasks,ar,Article,Navarro-Gonzalez J.L.,,Center for Research and Advanced Studies of the National Polytechnic Institute (Cinvestav),Saltillo,Mexico,,,,,2015-01-01,June 2015,Robotics and Computer-Integrated Manufacturing,07365845,18080,,Journal,33,,,78-89,,,20,0,,,,"Highlights

•

A novel multimodal assembly controller (MAC) was designed having minimal assembly information (−Z assembly direction).

•

It was demonstrated that knowledge can be refined when other different matting pair are assembled without the need to acquire another primitive knowledge base (PKB).

•

The robot learns a new assembly and improves its skills from experience observed by a reduced number of patterns, lower compliant forces and shorter assembly trajectories.

•

The MAC demonstrated that can be used in non-structured environments for the kitting process with uncertainties (in position and geometry) for both, the kits and the pegs.
Industrial robots are reliable machines for manufacturing tasks such as welding, panting, assembly, palletizing or kitting operations. They are traditionally programmed by an operator using a teach pendant in a point-to-point scheme with limited sensing capabilities such as industrial vision systems and force/torque sensing. The use of these sensing capabilities is associated to the particular robot controller, operative systems and programming language. Today, robots can react to environment changes specific to their task domain but are still unable to learn skills to effectively use their current knowledge. The need for such a skill in unstructured environments where knowledge can be acquired and enhanced is desirable so that robots can effectively interact in multimodal real-world scenarios.

In this article we present a multimodal assembly controller (MAC) approach to embed and effectively enhance knowledge into industrial robots working in multimodal manufacturing scenarios such as assembly during kitting operations with varying shapes and tolerances. During learning, the robot uses its vision and force capabilities resembling a human operator carrying out the same operation. The approach consists of using a MAC based on the Fuzzy ARTMAP artificial neural network in conjunction with a knowledge base. The robot starts the operation having limited initial knowledge about what task it has to accomplish. During the operation, the robot learns the skill for recognising assembly parts and how to assemble them. The skill acquisition is evaluated by counting the steps to complete the assembly, length of the followed assembly path and compliant behaviour. The performance improves with time so that the robot becomes an expert demonstrated by the assembly of a kit with different part geometries. The kit is unknown by the robot at the beginning of the operation; therefore, the kit type, location and orientation are unknown as well as the parts to be assembled since they are randomly fed by a conveyor belt.",NO
2-s2.0-84956878218,10.1155/2015/597956,,,Genetic Scheduling and Reinforcement Learning in Multirobot Systems for Intelligent Warehouses,ar,Article,Dou J.,,Nanjing University,Nanjing,China,,,,,2015-01-01,2015,Mathematical Problems in Engineering,1024123X,13082,15635147,Journal,2015,,597956,,,,15,1,,,,"A new hybrid solution is presented to improve the efficiency of intelligent warehouses with multirobot systems, where the genetic algorithm (GA) based task scheduling is combined with reinforcement learning (RL) based path planning for mobile robots. Reinforcement learning is an effective approach to search for a collision-free path in unknown dynamic environments. Genetic algorithm is a simple but splendid evolutionary search method that provides very good solutions for task allocation. In order to achieve higher efficiency of the intelligent warehouse system, we design a new solution by combining these two techniques and provide an effective and alternative way compared with other state-of-the-art methods. Simulation results demonstrate the effectiveness of the proposed approach regarding the optimization of travel time and overall efficiency of the intelligent warehouse system.",NO
2-s2.0-84948416590,10.1017/S1471068415000174,S1471068415000174,,A logic programming approach to predict effective compiler settings for embedded software,ar,Article,Blackmore C.,,University of Bristol,Bristol,United Kingdom,,,,,2015-01-01,3 September 2015,Theory and Practice of Logic Programming,14710684,28424,14753081,Journal,15,4-5,,481-494,,,3,0,,,,"This paper introduces a new logic-based method for optimising the selection of compiler flags on embedded architectures. In particular, we use Inductive Logic Programming (ILP) to learn logical rules that relate effective compiler flags to specific program features. Unlike earlier work, we aim to infer human-readable rules and we seek to develop a relational first-order approach which automatically discovers relevant features rather than relying on a vector of predetermined attributes. To this end we generated a data set by measuring execution times of 60 benchmarks on an embedded system development board and we developed an ILP prototype which outperforms the current state-of-the-art learning approach in 34 of the 60 benchmarks. Finally, we combined the strengths of the current state of the art and our ILP method in a hybrid approach which reduced execution times by an average of 8% and up to 50% in some cases.",NO
2-s2.0-84944673528,10.1007/s00779-014-0774-3,,,Evaluating children performance with graphical and tangible robot programming tools,ar,Article,Sapounidis T.,,Aristotle University of Thessaloniki,Thessaloniki,Greece,,,,,2015-01-01,1 January 2015,Personal and Ubiquitous Computing,16174909,22315,,Journal,19,1,,225-237,,,39,0,,,,"This paper presents a cross-age study exploring children’s performance on robot introductory programming activities with one tangible and one isomorphic graphical system. Both subsystems are parts of an innovative system, namely the PROTEAS kit. The tangible subsystem consists of cube-shaped blocks that represent simple and more advanced programming structures. Users may interconnect the cubic-shaped commands and so create the robot programming code. The graphical subsystem presents onscreen an isomorphic to the tangible programming space. Children (N = 109) of five different aged groups were let to interact in pairs with the two operationally equivalent programming subsystems with the scope to program a NXT Lego robot. Three variables associated with children performance upon tasks and four variables related with performance during free interaction were studied. Data analysis based on computer logs and video recordings showed that children produced fewer errors, made more effective debugging and younger children in particular needed less time to accomplish the robot programming tasks with the tangible subsystem. Moreover, during free interaction, elder children were more engaged, created more complicated programs and explored different commands and parameters more actively in the tangible case. Finally, interpretation of the findings is provided and the advantages of tangible user interfaces in children’s introductory programming are discussed.",SI
2-s2.0-84943525294,10.5875/ausmt.v5i3.979,,,A collaborative authoring workspace and script-based control platform for heterogeneous robots,ar,Article,Lin J.,,Shih Hsin University,Taipei,Taiwan,,,,,2015-01-01,2015,International Journal of Automation and Smart Technology,,21100327713,22239766,Journal,5,3,,163-171,,,0,1,,,,,NO
2-s2.0-84942929471,10.1142/S021968671550016X,,,Teach Less Robotic System for Deburring Workpieces of Various Shapes,ar,Article,Leo Princely F.,,National Institute of Technology Tiruchirappalli,Tiruchirappalli,India,,,,,2015-01-01,1 December 2015,Journal of Advanced Manufacturing Systems,02196867,27676,,Journal,14,4,,247-257,,,4,0,,,,"In the case of conventional industrial robot systems, operators have to write robot-language programs for each type of workpiece. This is an onerous task, especially when each workpiece has a different shape. In this paper, a teaching-less robot system for the finishing of two-dimensional workpieces of various shapes and thicknesses using computer vision is proposed. The robot system does not require shape information for the workpiece to be included in the CAD data or to be input by the operator. Each workpiece shape is acquired by segmenting edges into straight lines and circular arcs from the image data of the workpiece. The robot-language program for each workpiece is generated automatically from the workpiece shape data and finishing condition data. The effectiveness of the proposed method is verified by experiments using a newly developed robot system. This method provides a compact and inexpensive finishing robot system which reduces the programming timing.",NO
2-s2.0-84941034110,10.1016/j.engappai.2015.07.004,S0952197615001517,,A cognitive robotic ecology approach to self-configuring and evolving AAL systems,ar,Article,Dragone M.,,Trinity College Dublin,Dublin,Ireland,,,,,2015-01-01,1 October 2015,Engineering Applications of Artificial Intelligence,09521976,24182,,Journal,45,,,269-280,,,18,0,,,,"Robotic ecologies are systems made out of several robotic devices, including mobile robots, wireless sensors and effectors embedded in everyday environments, where they cooperate to achieve complex tasks. This paper demonstrates how endowing robotic ecologies with information processing algorithms such as perception, learning, planning, and novelty detection can make these systems able to deliver modular, flexible, manageable and dependable Ambient Assisted Living (AAL) solutions. Specifically, we show how the integrated and self-organising cognitive solutions implemented within the EU project RUBICON (Robotic UBIquitous Cognitive Network) can reduce the need of costly pre-programming and maintenance of robotic ecologies. We illustrate how these solutions can be harnessed to (i) deliver a range of assistive services by coordinating the sensing & acting capabilities of heterogeneous devices, (ii) adapt and tune the overall behaviour of the ecology to the preferences and behaviour of its inhabitants, and also (iii) deal with novel events, due to the occurrence of new user׳s activities and changing user׳s habits.",NO
2-s2.0-84940105529,10.1177/0278364915581505,,,Temporal logic motion control using actor-critic methods,ar,Article,Wang J.,,Boston University,Boston,United States,,,,,2015-01-01,27 September 2015,International Journal of Robotics Research,02783649,18050,17413176,Journal,34,10,,1329-1344,,,17,0,,,,"This paper considers the problem of deploying a robot from a specification given as a temporal logic statement about some properties satisfied by the regions of a large, partitioned environment. We assume that the robot has noisy sensors and actuators and model its motion through the regions of the environment as a Markov decision process (MDP). The robot control problem becomes finding the control policy which maximizes the probability of satisfying the temporal logic task on the MDP. For a large environment, obtaining transition probabilities for each state–action pair, as well as solving the necessary optimization problem for the optimal policy, are computationally intensive. To address these issues, we propose an approximate dynamic programming framework based on a least-squares temporal difference learning method of the actor–critic type. This framework operates on sample paths of the robot and optimizes a randomized control policy with respect to a small set of parameters. The transition probabilities are obtained only when needed. Simulations confirm that convergence of the parameters translates to an approximately optimal policy.",NO
2-s2.0-84938563589,10.14257/ijmue.2015.10.7.30,,,Mobile robot path planning based on improved Q learning algorithm,ar,Article,Peng J.,,Hechi University,Guangxi,China,,,,,2015-01-01,1 July 2015,International Journal of Multimedia and Ubiquitous Engineering,19750080,21100197523,,Journal,10,7,,285-294,,,2,1,,,,,NO
2-s2.0-84937513040,10.1016/j.robot.2015.04.003,S0921889015000858,,The Q-learning obstacle avoidance algorithm based on EKF-SLAM for NAO autonomous walking under unknown environments,ar,Article,Wen S.,,Yanshan University,Qinhuangdao,China,,,,,2015-01-01,1 October 2015,Robotics and Autonomous Systems,09218890,18079,,Journal,72,,,29-36,,,28,0,,,,"Highlights

•

An integration of EKF-SLAM and Q-learning algorithm for navigation is presented.

•

The clustering algorithm is applied on laser sensor data at one observation.

•

FOPI is designed to minimize the motion deviation during NAO’s walking.

•

The simulations and experiments prove the proposed method is valid.
The two important problems of SLAM and Path planning are often addressed independently. However, both are essential to achieve successfully autonomous navigation. In this paper, we aim to integrate the two attributes for application on a humanoid robot. The SLAM problem is solved with the EKF-SLAM algorithm whereas the path planning problem is tackled via Q-learning. The proposed algorithm is implemented on a NAO equipped with a laser head. In order to differentiate different landmarks at one observation, we applied clustering algorithm on laser sensor data. A Fractional Order PI controller (FOPI) is also designed to minimize the motion deviation inherent in during NAO’s walking behavior. The algorithm is tested in an indoor environment to assess its performance. We suggest that the new design can be reliably used for autonomous walking in an unknown environment.",NO
2-s2.0-84930158786,10.1145/2699697,,,aToucan: An automated framework to derive UML analysis models from use case models,ar,Article,Yue T.,,Universitetet i Oslo,Oslo,Norway,,,,,2015-01-01,1 May 2015,ACM Transactions on Software Engineering and Methodology,1049331X,18121,15577392,Journal,24,3,13,,,,58,0,,,,"The transition from an informal requirements specification in natural language to a structured, precise specification is an important challenge in practice. It is particularly so for object-oriented methods, defined in the context of the OMG's Model Driven Architecture (MDA), where a key step is to transition from a use case model to an analysis model. However, providing automated support for this transition is challenging, mostly because, in practice, requirements are expressed in natural language and are much less structured than other kinds of development artifacts. Such an automated transformation would enable at least the generation of an initial, likely incomplete, analysis model and enable automated traceability from requirements to code, through various intermediate models. In this article, we propose a method and a tool called aToucan, building on existing work, to automatically generate a UML analysis model comprising class, sequence and activity diagrams from a use case model and to automatically establish traceability links between model elements of the use case model and the generated analysis model. Note that our goal is to save effort through automated support, not to replace human abstraction and decision making.

Seven (six) case studies were performed to compare class (sequence) diagrams generated by aToucan to the ones created by experts, Masters students, and trained, fourth-year undergraduate students. Results show that aToucan performs well regarding consistency (e.g., 88% class diagram consistency) and completeness (e.g., 80% class completeness) when comparing generated class diagrams with reference class diagrams created by experts and Masters students. Similarly, sequence diagrams automatically generated by aToucan are highly consistent with the ones devised by experts and are also rather complete, for instance, 91% and 97% message consistency and completeness, respectively. Further, statistical tests show that aToucan significantly outperforms fourth-year engineering students in this respect, thus demonstrating the value of automation. We also conducted two industrial case studies demonstrating the applicability of aToucan in two different industrial domains. Results showed that the vast majority of model elements generated by aToucan are correct and that therefore, in practice, such models would be good initial models to refine and augment so as to converge towards to correct and complete analysis models. A performance analysis shows that the execution time of aToucan (when generating class and sequence diagrams) is dependent on the number of simple sentences contained in the use case model and remains within a range of a few minutes. Five different software system descriptions (18 use cases altogether) were performed to evaluate the generation of activity diagrams. Results show that aToucan can generate 100% complete and correct control flow information of activity diagrams and on average 85% data flAow information completeness. Moreover, we show that aToucan outperforms three commercial tools in terms of activity diagram generation.",NO
2-s2.0-84924736512,10.1177/0278364914557874,,,Robot navigation in dense human crowds: Statistical models and experimental studies of human-robot cooperation,ar,Article,Trautman P.,,"Matrix Research, Inc.",Dayton,United States,,,,,2015-01-01,15 March 2015,International Journal of Robotics Research,02783649,18050,17413176,Journal,34,3,,335-356,,,115,0,,,,"We consider the problem of navigating a mobile robot through dense human crowds. We begin by exploring a fundamental impediment to classical motion planning algorithms called the “freezing robot problem”: once the environment surpasses a certain level of dynamic complexity, the planner decides that all forward paths are unsafe, and the robot freezes in place (or performs unnecessary maneuvers) to avoid collisions. We argue that this problem can be avoided if the robot anticipates human cooperation, and accordingly we develop interacting Gaussian processes, a prediction density that captures cooperative collision avoidance, and a “multiple goal” extension that models the goal-driven nature of human decision making. We validate this model with an empirical study of robot navigation in dense human crowds (488 runs), specifically testing how cooperation models effect navigation performance. The multiple goal interacting Gaussian processes algorithm performs comparably with human teleoperators in crowd densities nearing 0.8 humans/m2, while a state-of-the-art non-cooperative planner exhibits unsafe behavior more than three times as often as the multiple goal extension, and twice as often as the basic interacting Gaussian process approach. Furthermore, a reactive planner based on the widely used dynamic window approach proves insufficient for crowd densities above 0.55 people/m2. We also show that our non-cooperative planner or our reactive planner capture the salient characteristics of nearly any dynamic navigation algorithm. Based on these experimental results and theoretical observations, we conclude that a cooperation model is critical for safe and efficient robot navigation in dense human crowds.",NO
2-s2.0-84923788173,10.3969/j.issn.1002-6819.2015.01.009,,,Design of test platform for robot flexible grasping and grasping force tracking impedance control,ar,Article,Wang X.,,Qilu University of Technology,Jinan,China,,,,,2015-01-01,1 January 2015,Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering,10026819,62499,,Journal,31,1,,58-63,,,24,0,,,,,NO
2-s2.0-84922799118,10.1016/j.neucom.2014.05.080,S0925231214012855,,"A basic Growing Functional Modules ""artificial brain""",ar,Article,Leboeuf-Pasquier J.,,Universidad de Guadalajara,Guadalajara,Mexico,,,,,2015-01-01,2015,Neurocomputing,09252312,24807,18728286,Journal,151,P1,,55-61,,,1,0,,,,"The purpose of this paper is to exhibit the internal process of the Growing Functional Modules (GFM) controllers. These learning based controllers are graphically designed by the user, interconnecting four kinds of components: Global Goals, Acting Modules, Sensing Modules and Sensations. Global Goals specify the intrinsic motivations, Acting and Sensing Modules develop their respective functionalities while Sensations provide the controlled system׳s feedback. GFM Controllers engage in a learning process to satisfy the specified motivations while interacting with the environment and thus can be considered as artificial brains. The traditional systems programming task is replaced by a design phase that consists in graphically configuring and interconnecting the GFM components. This paper gives a description of the aforementioned components and of their specific roles in the learning based control process. The behavior of the controller and its components is exemplified with the characterization of a simple control application.",NO
2-s2.0-84922569750,10.1016/j.compedu.2015.01.006,S0360131515000317,,CALEE: A computer-assisted learning system for embedded OS laboratory exercises,ar,Article,Chu E.,,National Yunlin University of Science and Technology,Douliou,Taiwan,,,,,2015-01-01,May 2015,Computers and Education,03601315,17645,,Journal,84,,,36-48,,,16,0,,,,"Highlights

•

A computer assisted learning system named CALEE is proposed to help students to complete hands-on assignments.

•

CALEE includes a self-learning assistant and a collaborative learning website.

•

A series of embedded operating system laboratory exercises is proposed.

•

CALEE can enhance students' learning motivation and speed up learning curve.

•

CALEE can reduce teaching load.
With the popularity of embedded systems and the consequently rising demand in the job market for professionals well-versed in them, embedded operating systems (EOSs) have become one of the core courses in computer science studies across the world. The objective of EOS courses is to develop students' ability to port, modify, and customize an embedded operating system through a series of laboratory exercises. However, our teaching experience has revealed that beginners require a considerable amount of time to familiarize themselves with the development environment and the relevant processes, such as operating in a command line interface, setting environment variables, and kernel configurations. Furthermore, students need to constantly handle compiler error messages, malfunctions of the target EOS, and incompatibility issues related to development tools. These problems may frustrate and discourage students. A common strategy to address this problem is to dedicate more hours to teaching or to hire more teaching assistants to help students progress. However, none of these methods is suitable for institutions with limited resources. Therefore, in this paper, we develop a computer-assisted learning system called the Computer-assisted Learning Environment (CALEE) to assist students with their assignments and thus motivate them. CALEE consists of two parts: a self-learning assistant (SLAT) and a collaborative learning website (CLW). SLAT is a software application that provides a set of useful functions to help students perform EOS laboratory exercises, whereas the collaborative learning website seeks to encourage greater interaction among students. Our experiments show that CALEE expedites learning, improves students' motivation, and reduces the teaching load.",NO
2-s2.0-84921787489,10.1016/j.rcim.2014.08.012,S0736584514000738,,"Design, programming and orchestration of heterogeneous manufacturing systems through VR-powered remote collaboration",ar,Article,Galambos P.,,Obuda University;Magyar Tudomanyos Akademia,Budapest;Budapest,Hungary;Hungary,,,,,2015-01-01,June 2015,Robotics and Computer-Integrated Manufacturing,07365845,18080,,Journal,33,,,68-77,,,52,0,,,,"Highlights

•

The paper identifies the synergies of recent advances in Future Internet and ICT.

•

Surveys the need of high-fidelity virtual collaboration for industrial robotics.

•

Introduces the VirCA platform as a remote collaboration and orchestration framework.

•

Shows the integration of ontologies and CogInfoCom methods into industrial setups.

•

Presents use case examples of knowledge-driven automation scenarios based on VirCA.
Modern manufacturing systems are often composed of a variety of highly customized units and specifically designed manufacturing cells. Optimization of assembly and training of staff requires a series of demo installations and excessive use of costly operational resources. In some cases, components are located at different sites, making the orchestration of the whole system even more difficult.

Virtual Reality (VR) collaboration environments offer a solution by enabling high fidelity testing and training of complex manufacturing systems. On the other hand, such platforms are difficult to implement in an engineering perspective, as they are required to provide reliable, standard interfaces towards both robotic components and human operators.

The VirCA (Virtual Collaboration Arena) platform is a software framework that supports various means of collaboration through the use of 3D augmented/virtual reality as a communication medium. VirCA offers functions for the high-level interoperability of heterogeneous components in a wide range of domains, spanning from research & development, through remote education to orchestration and management of industrial processes in manufacturing applications. This paper provides an overview of the industrial requirements behind high-fidelity virtual collaboration and demonstrates how the VirCA platform meets these requirements. Use cases are provided to illustrate the usability of the platform.",NO
2-s2.0-84908428493,10.1016/j.asoc.2014.09.021,S1568494614004748,,Learning fuzzy controllers in mobile robotics with embedded preprocessing,ar,Article,Rodríguez-Fdez I.,,Universidad de Santiago de Compostela,Santiago de Compostela,Spain,,,,,2015-01-01,January 2015,Applied Soft Computing Journal,15684946,18136,,Journal,26,,,123-142,,,9,0,,,,"Highlights

•

An algorithm which is able to learn controllers with embedded preprocessing for mobile robotics is presented.

•

Quantified Fuzzy Propositions, a model able to summarize the low-level input data, are used.

•

The algorithm was tested with the wall-following behavior both in simulated and real environments.

•

Results show a better and statistically significant performance of our proposal.

•

The approach was also successfully tested in three real world behaviors.
The automatic design of controllers for mobile robots usually requires two stages. In the first stage, sensorial data are preprocessed or transformed into high level and meaningful values of variables which are usually defined from expert knowledge. In the second stage, a machine learning technique is applied to obtain a controller that maps these high level variables to the control commands that are actually sent to the robot. This paper describes an algorithm that is able to embed the preprocessing stage into the learning stage in order to get controllers directly starting from sensorial raw data with no expert knowledge involved. Due to the high dimensionality of the sensorial data, this approach uses Quantified Fuzzy Rules (QFRs), that are able to transform low-level input variables into high-level input variables, reducing the dimensionality through summarization. The proposed learning algorithm, called Iterative Quantified Fuzzy Rule Learning (IQFRL), is based on genetic programming. IQFRL is able to learn rules with different structures, and can manage linguistic variables with multiple granularities. The algorithm has been tested with the implementation of the wall-following behavior both in several realistic simulated environments with different complexity and on a Pioneer 3-AT robot in two real environments. Results have been compared with several well-known learning algorithms combined with different data preprocessing techniques, showing that IQFRL exhibits a better and statistically significant performance. Moreover, three real world applications for which IQFRL plays a central role are also presented: path and object tracking with static and moving obstacles avoidance.

Graphical abstract

Download : Download full-size image",NO
2-s2.0-85011961527,10.1109/MCS.2016.2602090,,,Measurable Augmented Reality for Prototyping Cyberphysical Systems: A Robotics Platform to Aid the Hardware Prototyping and Performance Testing of Algorithms,ar,Article,Omidshafiei S.,,Massachusetts Institute of Technology,Cambridge,United States,,,,,2016-12-01,December 2016,IEEE Control Systems,1066033X,21100239264,,Journal,36,6,7740990,65-87,,,11,0,,,,"Planning, control, perception, and learning are current research challenges in multirobot systems. The transition dynamics of the robots may be unknown or stochastic, making it difficult to select the best action each robot must take at a given time. The observation model, a function of the robots' sensor systems, may be noisy or partial, meaning that deterministic knowledge of the team's state is often impossible to attain. Moreover, the actions each robot can take may have an associated success rate and/or a probabilistic completion time. Robots designed for real-world applications require careful consideration of such sources of uncertainty, regardless of the control scheme or planning or learning algorithms used for a specific problem. Understanding the underlying mechanisms of planning algorithms can be challenging due to the latent variables they often operate on. When performance testing such algorithms on hardware, the simultaneous use of the debugging and visualization tools available on a workstation can be difficult. This transition from experimentation to implementation becomes especially challenging when the experiments need to replicate some feature of the software tool set in hardware, such as simulation of visually complex environments. This article details a robotics prototyping platform, called measurable augmented reality for prototyping cyberphysical systems (MAR-CPS), that directly addresses this problem, allowing for the real-time visualization of latent state information to aid hardware prototyping and performance testing of algorithms.",NO
2-s2.0-85006279499,10.1109/TCDS.2016.2614992,,,Affordance Research in Developmental Robotics: A Survey,ar,Article,Min H.,,South China University of Technology,Guangzhou,China,,,,,2016-12-01,December 2016,IEEE Transactions on Cognitive and Developmental Systems,23798920,21100784665,23798939,Journal,8,4,7582380,237-255,,,52,0,,,,"Affordances capture the relationships between a robot and the environment in terms of the actions that the robot is able to perform. The notable characteristic of affordance-based perception is that an object is perceived by what it affords (e.g., graspable and rollable), instead of identities (e.g., name, color, and shape). Affordances play an important role in basic robot capabilities such as recognition, planning, and prediction. The key challenges in affordance research are: (1) how to automatically discover the distinctive features that specify an affordance in an online and incremental manner and (2) how to generalize these features to novel environments. This survey provides an entry point for interested researchers, including: (1) a general overview; (2) classification and critical analysis of existing work; (3) discussion of how affordances are useful in developmental robotics; (4) some open questions about how to use the affordance concept; and (5) a few promising research directions.",NO
2-s2.0-84999808941,10.1109/TSMC.2016.2531656,,,Interactive Teachable Cognitive Agents: Smart Building Blocks for Multiagent Systems,ar,Article,Subagdja B.,,Nanyang Technological University,Singapore City,Singapore,,,,,2016-12-01,December 2016,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",21682216,12952,21682232,Journal,46,12,7434068,1724-1735,,,9,0,,,,"Developing a complex intelligent system by abstracting their behaviors, functionalities, and reasoning mechanisms can be tedious and time consuming. In this paper, we present a framework for developing an application or software system based on smart autonomous components that collaborate with the developer or user to realize the entire system. Inspired by teachable approaches and programming-by-demonstration methods in robotics and end-user development, we treat intelligent agents as teachable components that make up the system to be built. Each agent serves different functionalities and may have prebuilt operations to accomplish its own design objectives. However, each agent may also be equipped with in-built social-cognitive traits to interact with the user or other agents in order to adapt its own operations, objectives, and relationships with others. The results of adaptation can be in the form of groups or multiagent systems as new aggregated components. This approach is made to tackle the difficulties in completely programming the entire system by allowing the user to teach the components toward the desired behaviors in the situated context of the application. We exemplify this novel method with cases in the domains of human-like agents in virtual environment and agents for in-house caregiving.",NO
2-s2.0-84988493689,10.1016/j.artint.2016.07.004,S0004370216300819,,"A synthesis of automated planning and reinforcement learning for efficient, robust decision-making",ar,Article,Leonetti M.,,The University of Texas at Austin;University of Leeds,Austin;Leeds,United States;United Kingdom,,,,,2016-12-01,1 December 2016,Artificial Intelligence,00043702,23675,,Journal,241,,,103-130,,,36,1,,,,"Automated planning and reinforcement learning are characterized by complementary views on decision making: the former relies on previous knowledge and computation, while the latter on interaction with the world, and experience. Planning allows robots to carry out different tasks in the same domain, without the need to acquire knowledge about each one of them, but relies strongly on the accuracy of the model. Reinforcement learning, on the other hand, does not require previous knowledge, and allows robots to robustly adapt to the environment, but often necessitates an infeasible amount of experience. We present Domain Approximation for Reinforcement LearnING (DARLING), a method that takes advantage of planning to constrain the behavior of the agent to reasonable choices, and of reinforcement learning to adapt to the environment, and increase the reliability of the decision making process. We demonstrate the effectiveness of the proposed method on a service robot, carrying out a variety of tasks in an office building. We find that when the robot makes decisions by planning alone on a given model it often fails, and when it makes decisions by reinforcement learning alone it often cannot complete its tasks in a reasonable amount of time. When employing DARLING, even when seeded with the same model that was used for planning alone, however, the robot can quickly learn a behavior to carry out all the tasks, improves over time, and adapts to the environment as it changes.",NO
2-s2.0-84962518373,10.1109/TCYB.2015.2498760,,,An Efficient Fine-to-Coarse Wayfinding Strategy for Robot Navigation in Regionalized Environments,ar,Article,Zhong C.,,East China University of Science and Technology,Shanghai,China,,,,,2016-12-01,December 2016,IEEE Transactions on Cybernetics,21682267,21100274221,,Journal,46,12,7428910,3157-3170,,,4,0,,,,"This paper proposes an efficient wayfinding strategy for robot navigation in regionalized environments by designing a regionalized spatial knowledge model (RSK model) and a region-based wayfinding algorithm, i.e., a fine-to-coarse A* (FTC-A*) search algorithm. First, the RSK model, which imitates the representation of environments in the human brain, is presented to describe the search environments. The environments that are divided into regions are represented by a hierarchical nested structure where small regions are grouped together to form superordinate regions. Second, on the basis of the RSK model, an FTC-A* search algorithm is developed to plan the fine-to-coarse route. By making a fine planning to robot surroundings in vicinity, but a coarse planning to that at the distance, the FTC-A* algorithm can effectively reduce computational complexity, so as to enhance the efficiency of route search, and meanwhile makes robots to react quickly to user's commands, especially in large-scale environments. Finally, four exhaustive simulations and a physical experiment have been carried out to illustrate the feasibility and effectiveness of the proposed wayfinding strategy.",NO
2-s2.0-84976316418,10.1007/s00165-016-0382-2,,,Model checking learning agent systems using Promela with embedded C code and abstraction,ar,Article,Kirwan R.,,University of Glasgow,Glasgow,United Kingdom,,,,,2016-11-01,1 November 2016,Formal Aspects of Computing,09345043,24980,1433299X,Journal,28,6,,1027-1056,,,1,1,,,,"As autonomous systems become more prevalent, methods for their verification will become more widely used. Model checking is a formal verification technique that can help ensure the safety of autonomous systems, but in most cases it cannot be applied by novices, or in its straight “off-the-shelf” form. In order to be more widely applicable it is crucial that more sophisticated techniques are used, and are presented in a way that is reproducible by engineers and verifiers alike. In this paper we demonstrate in detail two techniques that are used to increase the power of model checking using the model checker SPIN. The first of these is the use of embedded C code within Promela specifications, in order to accurately reflect robot movement. The second is to use abstraction together with a simulation relation to allow us to verify multiple environments simultaneously. We apply these techniques to a fairly simple system in which a robot moves about a fixed circular environment and learns to avoid obstacles. The learning algorithm is inspired by the way that insects learn to avoid obstacles in response to pain signals received from their antennae. Crucially, we prove that our abstraction is sound for our example system—a step that is often omitted but is vital if formal verification is to be widely accepted as a useful and meaningful approach.",NO
2-s2.0-84945242984,10.1007/s00530-015-0488-z,,,Object interaction and task programming by demonstration in visuo-haptic augmented reality,ar,Article,Aleotti J.,,Università di Parma,Parma,Italy,,,,,2016-11-01,1 November 2016,Multimedia Systems,09424962,25626,,Journal,22,6,,675-691,,,6,0,,,,"A visuo-haptic augmented reality system is presented for object manipulation and task learning from human demonstration. The proposed system consists of a desktop augmented reality setup where users operate a haptic device for object interaction. Users of the haptic device are not co-located with the environment where real objects are present. A three degrees of freedom haptic device, providing force feedback, is adopted for object interaction by pushing, selection, translation and rotation. The system also supports physics-based animation of rigid bodies. Virtual objects are simulated in a physically plausible manner and seem to coexist with real objects in the augmented reality space. Algorithms for calibration, object recognition, registration and haptic rendering have been developed. Automatic model-based object recognition and registration are performed from 3D range data acquired by a moving laser scanner mounted on a robot arm. Several experiments have been performed to evaluate the augmented reality system in both single-user and collaborative tasks. Moreover, the potential of the system for programming robot manipulation tasks by demonstration is investigated. Experiments show that a precedence graph, encoding the sequential structure of the task, can be successfully extracted from multiple user demonstrations and that the learned task can be executed by a robot system.",NO
2-s2.0-84993981965,10.2200/S00728ED1V01Y201608DCS051,,,Embedded Systems Design with the Texas Instruments MSP432 32-bit Processor,ar,Article,Dang D.,,Texas Instruments,Dallas,United States,,,,,2016-10-26,26 October 2016,Synthesis Lectures on Digital Circuits and Systems,19323166,5000158709,19323174,Book Series,51,,,1-574,,,1,0,,,,"This book provides a thorough introduction to the Texas Instruments MPS432™ microcontroller. The MPS432 is a 32-bit processor with the ARM Cortex M4F architecture and a built-in floating point unit. At the core, the MSP432 features a 32-bit ARM Cortex-M4F CPU, a RISC-architecture processing unit that includes a built-in DSP engine and a floating point unit. As an extension of the ultra-low-power MSP microcontroller family, the MSP432 features ultra-low power consumption and integrated digital and analog hardware peripherals. The MSP432 is a new member to the MSP family. It provides for a seamless transition to applications requiring 32-bit processing at an operating frequency of up to 48 MHz. The processor may be programmed at a variety of levels with different programming languages including the user-friendly Energia rapid prototyping platform, in assembly language, and in C. A number of C programming options are also available to developers, starting with register-level access code where developers can directly configure the device's registers, to Driver Library, which provides a standardized set of application program interfaces (APIs) that enable software developers to quickly manipulate various peripherals available on the device. Even higher abstraction layers are also available, such as the extremely user-friendly Energia platform, that enables even beginners to quickly prototype an application on MSP432. The MSP432 LaunchPad is supported by a host of technical data, application notes, training modules, and software examples. All are encapsulated inside one handy package called MSPWare, available as both a stand-alone download package as well as on the TI Cloud development site: dev.ti.com The features of the MSP432 may be extended with a full line of BoosterPack plug-in modules. The MSP432 is also supported by a variety of third party modular sensors and software compiler companies. In the back, a thorough introduction to the MPS432 line of microcontrollers, programming techniques, and interface concepts are provided along with considerable tutorial information with many illustrated examples. Each chapter provides laboratory exercises to apply what has been presented in the chapter. The book is intended for an upper level undergraduate course in microcontrollers or mechatronics but may also be used as a reference for capstone design projects. Practicing engineers already familiar with another microcontroller, who require a quick tutorial on the microcontroller, will also find this book very useful. Finally, middle school and high school students will find the MSP432 highly approachable via the Energia rapid prototyping system.

Table of Contents: Preface / Acknowledgments / Introduction to Microcontrollers and the MSP432 / A Brief Introduction to Programming / MSP432 Operating Parameters and Interfacing / MSP432 Memory System / MSP432 Power Systems / Time-Related Systems / Resets and Interrupts / Analog Peripherals / Communication Systems / MSP432 System Integrity / System Level Design / Authors' Biographies / Index",NO
2-s2.0-84992602677,10.1177/1729881416664078,,,Planning with ants,ar,Article,Viseras A.,,Deutsches Zentrum fur Luft- Und Raumfahrt, Cologne,Germany,,,,,2016-10-07,7 October 2016,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,13,5,,1-16,,,16,1,,,,"Rapidly exploring random trees (RRTs) have been proven to be efficient for planning in environments populated with obstacles. These methods perform a uniform sampling of the state space, which is needed to guarantee the algorithm’s completeness but does not necessarily lead to the most efficient solution. In previous works it has been shown that the use of heuristics to modify the sampling strategy could incur an improvement in the algorithm performance. However, these heuristics only apply to solve the shortest path-planning problem. Here we propose a framework that allows us to incorporate arbitrary heuristics to modify the sampling strategy according to the user requirements. This framework is based on ‘learning from experience’. Specifically, we introduce a utility function that takes the contribution of the samples to the tree construction into account; sampling at locations of increased utility then becomes more frequent. The idea is realized by introducing an ant colony optimization concept in the RRT/RRT* algorithm and defining a novel utility function that permits trading off exploitation versus exploration of the state space. We also extend the algorithm to allow an anytime implementation. The scheme is validated with three scenarios: one populated with multiple rectangular obstacles, one consisting of a single narrow passage and a maze-like environment. We evaluate its performance in terms of the cost and time to find the first path, and in terms of the evolution of the path quality with the number of iterations. It is shown that the proposed algorithm greatly outperforms state-of-the-art RRT and RRT* algorithms.",NO
2-s2.0-84964270642,10.1007/s10489-016-0788-9,,,XCS-based reinforcement learning algorithm for motion planning of a spherical mobile robot,ar,Article,Roozegar M.,,Université McGill,Montreal,Canada,,,,,2016-10-01,1 October 2016,Applied Intelligence,0924669X,23674,15737497,Journal,45,3,,736-746,,,16,0,,,,"A Reinforcement Learning (RL) algorithm based on eXtended Classifier System (XCS) is used to navigate a spherical robot. Traditional motion planning strategies rely on pre-planned optimal trajectories and feedback control techniques. The proposed learning agent approach enjoys a direct model-free methodology that enables the robot to function in dynamic and/or partially observable environments. The agent uses a set of guard-action rules that determines the motion inputs at each step. Using a number of control inputs (actions) and the developed RL scheme, the agent learns to make near-optimal moves in response to the incoming position/orientation signals. The proposed method employs an improved variant of the XCS as its learning agent. Results of several simulated experiments for the spherical robot show that this approach is capable of planning a near-optimal path to a predefined target from any given position/orientation.",NO
2-s2.0-84944541766,10.1007/s10514-015-9502-8,,,Human–robot planning and learning for marine data collection,ar,Article,Somers T.,,Oregon State University,Corvallis,United States,,,,,2016-10-01,1 October 2016,Autonomous Robots,09295593,18016,15737527,Journal,40,7,,1123-1137,,,16,0,,,,We propose an integrated learning and planning framework that leverages knowledge from a human user along with prior information about the environment to generate trajectories for scientific data collection in marine environments. The proposed framework combines principles from probabilistic planning with nonparametric uncertainty modeling to refine trajectories for execution by autonomous vehicles. These trajectories are informed by a utility function learned from the human operator’s implicit preferences using a modified coactive learning algorithm. The resulting techniques allow for user-specified trajectories to be modified for reduced risk of collision and increased reliability. We test our approach in two marine monitoring domains and show that the proposed framework mimics human-planned trajectories while also reducing the risk of operation. This work provides insight into the tools necessary for combining human input with vehicle navigation to provide persistent autonomy.,NO
2-s2.0-85008394491,10.1016/j.neucom.2016.05.057,S0925231216304945,,A hybrid improved PSO-DV algorithm for multi-robot path planning in a clutter environment,ar,Article,Das P.,,VSS University of Technology,Sambalpur,India,,,,,2016-09-26,26 September 2016,Neurocomputing,09252312,24807,18728286,Journal,207,,,735-753,,,65,0,,,,"This paper proposed a novel approach to determine the optimal trajectory of the path for multi-robots in a clutter environment using hybridization of improved particle swarm optimization (IPSO) with differentially perturbed velocity (DV) algorithm. The objective of the algorithm is to minimize the maximum path length that corresponds to minimize the arrival time of all the robots to their respective destination in the environment. The robots on the team make independent decisions, coordinate, and cooperate with each other to determine the next positions from their current position in the world map using proposed hybrid IPSO-DV. The proposed scheme adjusts the velocity of the robots by incorporating a vector differential operator inherited from Differential Evolution (DE) in IPSO. Finally the analytical and experimental results of the multi-robot path planning have been compared to those obtained by IPSO-DV, IPSO, DE in a similar environment. Simulation and khepera environment results are compared with those obtained by IPSO-DV to ensure the integrity of the algorithm. The results obtained from Simulation as well as Khepera environment reveal that, the proposed IPSO-DV performs better than IPSO and DE with respect to optimal trajectory path length and arrival time.",NO
2-s2.0-85054201401,10.3390/robotics5030012,,,IDC Robocon: A transnational teaming competition for project-based design education in undergraduate robotics,ar,Article,Tan N.,,National University of Singapore,Singapore City,Singapore,,,,,2016-09-01,1 September 2016,Robotics,,21100833833,22186581,Journal,5,3,12,,,,7,1,,,,"This paper presents a robot design competition called ‘IDC Robocon’ as an effective tool for engineering education. The International Design Contest (IDC) Robocon competition has several benefits in creating a meaningful design experience for undergraduate engineering students and includes an international flavour as participants of the competition hail from all around the world. The problem posed to the contestants is to design, build and test mobile robots that are capable of accomplishing a task. A primary goal of the competition is to provide undergraduates with a meaningful design experience with an emphasis on mechanical design, electronic circuits and programming. It is hoped that by placing the emphasis on the design, the course will encourage more undergraduates to go into the field of engineering design. This paper presents the latest 2015 IDC Robocon (the 26th edition) in detail and discusses course of events and results in terms of the educational experience. In this competition, a simulated space problem of cleaning the debris from orbit is proposed for the latest IDC Robocon competition. Teams, comprising of students from multiple countries work together to develop robotic systems to compete with each other in collecting the foam balls and delivering them to the rotating the holder. View Full-Text",NO
2-s2.0-85028619966,10.1016/j.robot.2016.06.012,S0921889016303542,,Automatic discovery of relational concepts by an incremental graph-based representation,ar,Article,Tenorio-González A.,,Instituto Nacional de Astrofisica Optica y Electronica,Puebla,Mexico,,,,,2016-09-01,September 2016,Robotics and Autonomous Systems,09218890,18079,,Journal,83,,,1-14,,,2,0,,,,"Highlights

•

We designed a method to learn relational concepts from a graph-based representation.

•

Our method is designed to discover common/useful concepts of an environment.

•

Our method can be used by an autonomous agent like a robot.

•

Our method learned common concepts in three domains (polygons/furniture/floors).

•

Independent human users validated the common concepts learned by our method.
Automatic discovery of concepts has been an elusive area in machine learning. In this paper, we describe a system, called ADC, that automatically discovers concepts in a robotics domain, performing predicate invention. Unlike traditional approaches of concept discovery, our approach automatically finds and collects instances of potential relational concepts. An agent, using ADC, creates an incremental graph-based representation with the information it gathers while exploring its environment, from which common sub-graphs are identified. The subgraphs discovered are instances of potential relational concepts which are induced with Inductive Logic Programming and predicate invention. Several concepts can be induced concurrently and the learned concepts can form arbitrarily hierarchies. The approach was tested for learning concepts of polygons, furniture, and floors of buildings with a simulated robot and compared with concepts suggested by users.",NO
2-s2.0-84991220046,10.1007/s10846-016-0371-y,,,Experience-Based Planning Domains: an Integrated Learning and Deliberation Approach for Intelligent Robots: Robot Task Learning from Human Instructions,ar,Article,Mokhtari V.,,Instituto de Engenharia Electrónica e Telemática de Aveiro,Aveiro,Portugal,,,,,2016-09-01,1 September 2016,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,83,3-4,,463-483,,,8,0,,,,"Deliberation and learning are required to endow a robot with the capabilities for acquiring knowledge, performing a variety of tasks and interactions, and adapting to open-ended environments. This paper presents the notion of experience-based planning domains (EBPDs) for task level learning and planning in robotics. EBPDs provide methods for a robot to: (i) obtain robot activity experiences from the robot’s performance in a dynamic environment; (ii) conceptualize each experience producing an activity schema; and (iii) exploit the learned activity schemata to make plans in similar situations. Experiences are episodic descriptions of plan-based robot activities including environment perception, sequences of applied actions and achieved tasks. The conceptualization approach integrates different techniques including deductive generalization, abstraction, goal inference and feature extraction. A high-level task planner was developed to find a solution for a task by following an activity schema. The proposed approach is illustrated and evaluated in a restaurant environment where a service robot learns how to carry out complex tasks.",NO
2-s2.0-84962541336,10.1080/0951192X.2015.1130251,,,Human–robot interaction review and challenges on task planning and programming,ar,Article,Tsarouchi P.,,University of Patras,Rio,Greece,,,,,2016-08-02,2 August 2016,International Journal of Computer Integrated Manufacturing,0951192X,18198,13623052,Journal,29,8,,916-931,,,185,0,,,,"The wide interest of research and industry in the human–robot interaction (HRI) related topics is proportional to the increased productivity and flexibility of the production lines, as it combines human and robot capabilities. This paper presents a review of recent research and progress on HRI, related to task planning/coordination and programming with emphasis on the manufacturing/production environment. Human–robot task allocation and scheduling, metrics for HRI, as well as the social aspects are reviewed. The role of digital human modelling systems for human–robot task planning related issues is also discussed. The process of learning by demonstration as well as the instructive systems is reviewed, focussing mainly on programming through visual guidance and imitation, voice commands and haptic interaction. The aspect of physical HRI as well as the safety related issues are also discussed. Additionally, a survey on multimodal communication frameworks is presented. Challenges encountered and directions for future research are discussed.",NO
2-s2.0-84979935488,10.3390/s16081195,,,Applying high-speed vision sensing to an industrial robot for high-performance position regulation under uncertainties,ar,Article,Huang S.,,The University of Tokyo,Tokyo,Japan,,,,,2016-07-29,29 July 2016,Sensors (Switzerland),14248220,130124,,Journal,16,8,1195,,,,11,1,,,,"It is traditionally difficult to implement fast and accurate position regulation on an industrial robot in the presence of uncertainties. The uncertain factors can be attributed either to the industrial robot itself (e.g., a mismatch of dynamics, mechanical defects such as backlash, etc.) or to the external environment (e.g., calibration errors, misalignment or perturbations of a workpiece, etc.). This paper proposes a systematic approach to implement high-performance position regulation under uncertainties on a general industrial robot (referred to as the main robot) with minimal or no manual teaching. The method is based on a coarse-to-fine strategy that involves configuring an add-on module for the main robot’s end effector. The add-on module consists of a 1000 Hz vision sensor and a high-speed actuator to compensate for accumulated uncertainties. The main robot only focuses on fast and coarse motion, with its trajectories automatically planned by image information from a static low-cost camera. Fast and accurate peg-and-hole alignment in one dimension was implemented as an application scenario by using a commercial parallel-link robot and an add-on compensation module with one degree of freedom (DoF). Experimental results yielded an almost 100% success rate for fast peg-in-hole manipulation (with regulation accuracy at about 0.1 mm) when the workpiece was randomly placed. View Full-Text",NO
2-s2.0-84984614280,10.3969/j.issn.1004-132X.2016.14.003,,,Research on robot control technology for finishing cut process of aluminum alloy hubs,ar,Article,Yang Z.,,Chongqing University,Chongqing,China,,,,,2016-07-25,25 July 2016,Zhongguo Jixie Gongcheng/China Mechanical Engineering,1004132X,22181,,Journal,27,14,,1857-1862,,,0,0,,,,"A robot control technology that integrated teaching programming method with off-line programming method was proposed to complete the finishing cut of hubs by comparing the merits and demerits of these two methods,based on analyzing the structure of aluminum alloy wheel hubs and the requirements of finishing cut.The off-line programing was achieved by using Pieper method to complete robot inverse kinematics solution,according to the point’s informations of hub surface tool path and robot kinematic equations.The research shows that the robot control technology integrated teaching and off-line programming method satisfies the finishing cut requirements,and greatly en-hance the efficiency of hub finishing cut.",NO
2-s2.0-85008195206,10.3772/j.issn.1002-0470.2016.07.007,,,Workspace and machining trajectory analyses under a belt grinding robot's grinding of curved surface workpieces,ar,Article,Li D.,,Hubei University of Science and Technology;Beihang University,Xianning;Beijing,China;China,,,,,2016-07-01,1 July 2016,Gaojishu Tongxin/Chinese High Technology Letters,10020470,16121,,Journal,26,7,,667-676,,,0,0,,,,"The robot belt grinding was studied to overcome traditional grinding ’ s shortcomings such as creating harsh working environment and increasing labor-intensity. A 3P3R belt grinding robot was designed for curved surface workpiece grinding. The robot kinematics and workspace were analyzed, and then the roughly reachable workspace of this robot was obtained by using the numerical analysis method. By modeling the surface point of the workpiece to be machined, the reachability simulation analysis was carried out on the processing of machining surface points by the Monte Carlo method, and the robot posture and the processing trajectory were obtained while all the surface points to be grinded were closest to the Grinding wheel. The analysis of this approach can be used to judge whether this robot can machine the curved surface workpiece or not, and can provide guidance to specific workpieces’ ma-chining teaching programing, while providing a way of off-line programming.",NO
2-s2.0-85001950354,10.1016/j.riai.2016.05.004,S1697791216300061,,Advanced Rapid Control Prototyping system on engineering education for multidisciplinary student groups,ar,Article,Caballero A.F.,,Universidad Carlos III de Madrid,Madrid,Spain,,,,,2016-07-01,1 July 2016,RIAI - Revista Iberoamericana de Automatica e Informatica Industrial,16977912,5300152203,16977920,Journal,13,3,,350-362,,,8,1,,,,"Con el objetivo de alcanzar resultados satisfactorios en la enseñanza y puesta en práctica de cursos semestrales de ingeniería de control, en los que la presencia de alumnos de distintas disciplinas es más que notoria, se torna necesario recurrir a altos niveles de abstracción en la programación de los sistemas de control. Este alto nivel de abstracción procede del uso de un sistema de prototipado rápido para control de carácter avanzado, que permite recurrir a funcionalidades que no habían sido previstas en ningún entorno de prototipado rápido para control disponible con anterioridad. El carácter avanzado del sistema brinda soluciones desde el más alto nivel de abstracción, el denominado diseño basado en modelos, para las intricadas relaciones necesarias entre la ingeniería de control y la informática en tiempo real, permitiendo que los alumnos puedan centrar su esfuerzo en el desarrollo del algoritmo de control, la identificación de sistemas y el modelado de plantas físicas en lugar de preocuparse por las tediosas tareas de gestión y configuración a bajo nivel de la arquitectura hardware que están empleando. Gracias a este alto nivel de abstracción, que cubre el espectro abarcado por funcionalidades de muy bajo nivel y funcionalidades de muy alto nivel, el manejo del sistema propuesto se encuentra al alcance de audiencias multidisciplinares. El sistema avanzado de prototipado rápido para control se está empleando para cursos semestrales así como en multitud de Tesis de Máster y Doctorales.",NO
2-s2.0-84975506485,10.1145/2928270,,,COBAYN: Compiler autotuning framework using Bayesian networks,ar,Article,Ashouri A.H.,,DEIB,Milan,Italy,,,,,2016-06-01,June 2016,ACM Transactions on Architecture and Code Optimization,15443566,12100154406,15443973,Journal,13,2,21,,,,41,1,,,,"The variety of today’s architectures forces programmers to spend a great deal of time porting and tuning application codes across different platforms. Compilers themselves need additional tuning, which has considerable complexity as the standard optimization levels, usually designed for the average case and the specific target architecture, often fail to bring the best results.

This article proposes COBAYN: Compiler autotuning framework using BAYesian Networks, an approach for a compiler autotuning methodology using machine learning to speed up application performance and to reduce the cost of the compiler optimization phases. The proposed framework is based on the application characterization done dynamically by using independent microarchitecture features and Bayesian networks. The article also presents an evaluation based on using static analysis and hybrid feature collection approaches. In addition, the article compares Bayesian networks with respect to several state-of-the-art machine-learning models.

Experiments were carried out on an ARM embedded platform and GCC compiler by considering two benchmark suites with 39 applications. The set of compiler configurations, selected by the model (less than 7% of the search space), demonstrated an application performance speedup of up to 4.6 × on Polybench (1.85 × on average) and 3.1 × on cBench (1.54 × on average) with respect to standard optimization levels. Moreover, the comparison of the proposed technique with (i) random iterative compilation, (ii) machine learning--based iterative compilation, and (iii) noniterative predictive modeling techniques shows, on average, 1.2 × , 1.37 × , and 1.48 × speedup, respectively. Finally, the proposed method demonstrates 4 × and 3 × speedup, respectively, on cBench and Polybench in terms of exploration efficiency given the same quality of the solutions generated by the random iterative compilation model.",NO
2-s2.0-84971668369,10.1002/cta.2159,,,Development of numerical linear algebra algorithms in dynamic fixed-point format: A case study of Lanczos tridiagonalization,ar,Article,Pradhan T.,,Indian Institute of Technology Kharagpur,Kharagpur,India,,,,,2016-06-01,1 June 2016,International Journal of Circuit Theory and Applications,00989886,17963,1097007X,Journal,44,6,,1222-1262,,,3,0,,,,,NO
2-s2.0-84968928092,10.1109/MRA.2016.2533002,,,Teaching Introductory Robotics Programming: Learning to Program with National Instruments' LabVIEW,ar,Article,Bower T.,,Kansas State University Polytechnic Campus,Salina,United States,,,,,2016-06-01,June 2016,IEEE Robotics and Automation Magazine,10709932,18027,,Journal,23,2,7469301,67-73,,,7,0,,,,"This article considers strategies for teaching beginning students how to program mobile robots for autonomous operation. Many high school and beginning undergraduate students desire to learn about robotics, but they may lack the required knowledge. Experiences from an undergraduate course are described to illustrate the robot, its programming environment, software design, and algorithms, which faculty can use to guide beginning students from a place of no prior experience to writing impressive, autonomous mobile-robot programs. Autonomous algorithms that perform well and are appropriate for beginning students, including a new wall-following algorithm, are reviewed.",SI
2-s2.0-84964262606,10.1007/s10994-016-5558-8,,,Probabilistic logic programming for hybrid relational domains,ar,Article,Nitti D.,,KU Leuven,3000 Leuven,Belgium,,,,,2016-06-01,1 June 2016,Machine Learning,08856125,24775,15730565,Journal,103,3,,407-449,,,20,1,,,,"We introduce a probabilistic language and an efficient inference algorithm based on distributional clauses for static and dynamic inference in hybrid relational domains. Static inference is based on sampling, where the samples represent (partial) worlds (with discrete and continuous variables). Furthermore, we use backward reasoning to determine which facts should be included in the partial worlds. For filtering in dynamic models we combine the static inference algorithm with particle filters and guarantee that the previous partial samples can be safely forgotten, a condition that does not hold in most logical filtering frameworks. Experiments show that the proposed framework can outperform classic sampling methods for static and dynamic inference and that it is promising for robotics and vision applications. In addition, it provides the correct results in domains in which most probabilistic programming languages fail.",NO
2-s2.0-84955454062,10.1016/j.swevo.2015.10.011,S2210650215001005,,A hybridization of an improved particle swarm optimization and gravitational search algorithm for multi-robot path planning,ar,Article,Das P.K.,,VSS University of Technology,Sambalpur,India,,,,,2016-06-01,June 2016,Swarm and Evolutionary Computation,22106502,19900192513,,Journal,28,,,14-28,,,138,0,,,,"This paper proposed a new methodology to determine the optimal trajectory of the path for multi-robot in a clutter environment using hybridization of improved particle swarm optimization (IPSO) with an improved gravitational search algorithm (IGSA). The proposed approach embedded the social essence of IPSO with motion mechanism of IGSA. The proposed hybridization IPSO–IGSA maintain the efficient balance between exploration and exploitation because of adopting co-evolutionary techniques to update the IGSA acceleration and particle positions with IPSO velocity simultaneously. The objective of the algorithm is to minimize the maximum path length that corresponds to minimize the arrival time of all robots to their respective destination in the environment. The robot on the team make independent decisions, coordinate, and cooperate with each other to determine the next positions from their current position in the world map using proposed hybrid IPSO–IGSA. Finally the analytical and experimental results of the multi-robot path planning were compared to those obtained by IPSO–IGSA, IPSO, IGSA in a similar environment. The Simulation and the Khepera environment result show outperforms of IPSO–IGSA as compared with IPSO and IGSA with respect to optimize the path length from predefine initial position to designation position ,energy optimization in the terms of number of turn and arrival time.",NO
2-s2.0-84949644531,10.1016/j.rcim.2015.11.002,S073658451500126X,,Accurate sensorless lead-through programming for lightweight robots in structured environments,ar,Article,Ragaglia M.,,Politecnico di Milano,Milan,Italy,,,,,2016-06-01,1 June 2016,Robotics and Computer-Integrated Manufacturing,07365845,18080,,Journal,39,,,9-21,,,28,0,,,,"Highlights

•

Estimation of the most likely direction of robot TCP positional/orientational displacement.

•

Accurate tracking whilst maintaining safety with respect to workspace obstacles.
Nowadays, programming an industrial manipulator is a complex and time-consuming activity, and this prevents industrial robots from being massively used in companies characterized by high production flexibility and rapidly changing products. The introduction of sensor-based lead-through programming approaches (where the operator manually guides the robot to teach new positions), instead, allows to increase the speed and reduce the complexity of the programming phase, yielding an effective solution to enhance flexibility. Nevertheless, some drawbacks arise, like for instance lack of accuracy, need to ensure the human operator safety, and need for force/torque sensors (the standard devices adopted for lead-through programming) that are expensive, fragile and difficult to integrate in the robot controller.

This paper presents a novel approach to lead-through robot programming. The proposed strategy does not rely on dedicated hardware since torques due to operator's forces are estimated using a model-based observer fed with joint position, joint velocity and motor current measures. On the basis of this information, the external forces applied to the manipulator are reconstructed. A voting system identifies the largest Cartesian component of the force/torque applied to the manipulator in order to obtain accurate lead-through programming via admittance control. Finally an optimization stage is introduced in order to track the joint position displacements computed by the admittance filter as much as possible, while enforcing obstacle avoidance constraints, actuation bounds and Tool Centre Point (TCP) operational space velocity limits. The proposed approach has been implemented and experimentally tested on an ABB dual-arm concept robot FRIDA.",NO
2-s2.0-85000195459,10.1080/00207721.2014.945982,,,Attention control learning in the decision space using state estimation,ar,Article,Gharaee Z.,,K. N. Toosi University of Technology,Tehran,Iran,,,,,2016-05-18,18 May 2016,International Journal of Systems Science,00207721,12419,14645319,Journal,47,7,,1659-1674,,,6,0,,,,"The main goal of this paper is modelling attention while using it in efficient path planning of mobile robots. The key challenge in concurrently aiming these two goals is how to make an optimal, or near-optimal, decision in spite of time and processing power limitations, which inherently exist in a typical multi-sensor real-world robotic application. To efficiently recognise the environment under these two limitations, attention of an intelligent agent is controlled by employing the reinforcement learning framework. We propose an estimation method using estimated mixture-of-experts task and attention learning in perceptual space. An agent learns how to employ its sensory resources, and when to stop observing, by estimating its perceptual space. In this paper, static estimation of the state space in a learning task problem, which is examined in the WebotsTM simulator, is performed. Simulation results show that a robot learns how to achieve an optimal policy with a controlled cost by estimating the state space instead of continually updating sensory information.",NO
2-s2.0-84965006493,10.1145/2837614.2843895,,,Programming the world of uncertain things (keynote),ar,Article,McKinley K.,,Microsoft Research,Redmond,United States,,,,,2016-04-08,8 April 2016,ACM SIGPLAN Notices,15232867,19700185000,,Journal,51,1,,1-2,,,1,0,,,,"Computing has entered the era of uncertain data, in which hardware and software generate and reason about estimates. Applications use estimates from sensors, machine learning, big data, humans, and approximate hardware and software. Unfortunately, developers face pervasive correctness, programmability, and optimization problems due to estimates. Most programming languages unfortunately make these problems worse. We propose a new programming abstraction called Uncertain<T> embedded into languages, such as C#, C++, Java, Python, and JavaScript. Applications that consume estimates use familiar discrete operations for their estimates; overloaded conditional operators specify hypothesis tests and applications use them control false positives and negatives; and new compositional operators express domain knowledge. By carefully restricting the expressiveness, the runtime automatically implements correct statistical reasoning at conditionals, relieving developers of the need to implement or deeply understand statistics. We demonstrate substantial programmability, correctness, and efficiency benefits of this programming model for GPS sensor navigation, approximate computing, machine learning, and xBox.",NO
2-s2.0-85035096133,10.1145/2872362.2872380,,,Lifting assembly to intermediate representation: A novel approach leveraging compilers,ar,Article,Hasabnis N.,,Intel Corporation,Santa Clara,United States,,,,,2016-04-01,April 2016,ACM SIGPLAN Notices,15232867,19700185000,,Journal,51,4,,311-324,,,4,1,,,,"Translating low-level machine instructions into higher-level intermediate language (IL) is one of the central steps in many binary analysis and instrumentation systems. Existing systems build such translators manually. As a result, it takes a great deal of effort to support new architectures. Even for widely deployed architectures, full instruction sets may not be modeled, e.g., mature systems such as Valgrind still lack support for AVX, FMA4 and SSE4.1 for x86 processors. To overcome these difficulties, we propose a novel approach that leverages knowledge about instruction set semantics that is already embedded into modern compilers such as GCC. In particular, we present a learning-based approach for automating the translation of assembly instructions to a compiler's architecture-neutral IL. We present an experimental evaluation that demonstrates the ability of our approach to easily support many architectures (x86, ARM and AVR), including their advanced instruction sets. Our implementation is available as open-source software.",NO
2-s2.0-84978033484,10.1007/s11370-015-0193-y,,,Efficient terrain coverage for deploying wireless sensor nodes on multi-robot system,ar,Article,Arezoumand R.,,Universiti Putra Malaysia,Serdang,Malaysia,,,,,2016-04-01,1 April 2016,Intelligent Service Robotics,18612776,9500154152,18612784,Journal,9,2,,163-175,,,8,0,,,,Coverage and connectivity are the two main functionalities of wireless sensor network. Stochastic node deployment or random deployment almost always cause hole in sensing coverage and cause redundant nodes in area. In the other hand precise deployment of nodes in large area is very time consuming and even impossible in hazardous environment. One of solution for this problem is using mobile robots with concern on exploration algorithm for mobile robot. In this work an autonomous deployment method for wireless sensor nodes is proposed via multi-robot system which robots are considered as node carrier. Developing an exploration algorithm based on spanning tree is the main contribution and this exploration algorithm is performing fast localization of sensor nodes in energy efficient manner. Employing multi-robot system and path planning with spanning tree algorithm is a strategy for speeding up sensor nodes deployment. A novel improvement of this technique in deployment of nodes is having obstacle avoidance mechanism without concern on shape and size of obstacle. The results show using spanning tree exploration along with multi-robot system helps to have fast deployment behind efficiency in energy.,NO
2-s2.0-84962745974,10.1108/IR-05-2015-0103,,,User-friendly task level programming based on an online walk-through teaching approach,ar,Article,Brunete A.,,Universidad Politécnica de Madrid,Madrid,Spain,,,,,2016-03-21,21 March 2016,Industrial Robot,0143991X,18047,,Journal,43,2,,153-163,,,12,0,,,,"Purpose

This paper aims to propose a new technique for programming robotized machining tasks based on intuitive human–machine interaction. This will enable operators to create robot programs for small-batch production in a fast and easy way, reducing the required time to accomplish the programming tasks.

Design/methodology/approach

This technique makes use of online walk-through path guidance using an external force/torque sensor, and simple and intuitive visual programming, by a demonstration method and symbolic task-level programming.

Findings

Thanks to this technique, the operator can easily program robots without learning every robot-specific language and can design new tasks for industrial robots based on manual guidance.

Originality/value

The main contribution of the paper is a new procedure to program machining tasks based on manual guidance (walk-through teaching method) and user-friendly visual programming. Up to now, the acquisition of paths and the task programming were done in separate steps and in separate machines. The authors propose a procedure for using a tablet as the only user interface to acquire paths and to make a program to use this path for machining tasks.",NO
2-s2.0-84963575208,10.13700/j.bh.1001-5965.2015.0218,,,Vision guide based teaching programming for industrial robot,ar,Article,Ni Z.,,Beihang University,Beijing,China,,,,,2016-03-01,1 March 2016,Beijing Hangkong Hangtian Daxue Xuebao/Journal of Beijing University of Aeronautics and Astronautics,10015965,13747,,Journal,42,3,,562-568,,,3,0,,,,,NO
2-s2.0-84960090392,10.1002/cae.21707,,,Implementing fuzzy logic to simulate a process of inference on sensory stimuli of deaf people in an e-learning environment,ar,Article,Dos Santos Guimarães R.,,Instituto Tecnologico de Aeronautica,Sao Jose dos Campos,Brazil,,,,,2016-03-01,1 March 2016,Computer Applications in Engineering Education,10613773,18156,10990542,Journal,24,2,,320-330,,,5,0,,,,"A novel approach to education aimed at deaf students, based on computing that performs individualized instruction on the domain of programming languages is presented. This approach is fully implemented and evaluated in an educational application model, called model of Mental Architecture Digitized—AMD. In particular, performs user modeling by dynamically identifying and updating a student's knowledge level of all the concepts of the domain knowledge. The concept of AMD is based on fuzzy cognitive maps (FCMs) that are used to represent the dependences among the domain concepts. AMD uses fuzzy sets to represent a student's knowledge level as a subset of the domain knowledge. Thus, it combines fuzzy theory with the overlay model. Moreover, it employs a novel inference mechanism that dynamically updates user stereotypes using fuzzy sets. It should be noted that the overlay model and stereotypes constitute two widely used methods for user modeling. The gain from this novel combination is significant as a student level of knowledge is represented in a more realistic way by automatically modeling the learning or forgetting process of a student with respect to the FCMs and thus, the system can provide individualized adaptive advice. The transmission and retention of knowledge rests on the cognitive faculty of the concepts linked to it. The repeatability of your applications builds a solid foundation for Education, according to behavioral standards set. This cognitive ability to infer on what we observe and perceive, regarded as intrinsic human beings, does not depend of their physical capacity. © 2015 Wiley Periodicals, Inc. Comput Appl Eng Educ 24:320–330, 2016; View this article online at wileyonlinelibrary.com/journal/cae; DOI 10.1002/cae.21707",NO
2-s2.0-84959207717,10.1007/s10489-015-0660-3,,,Altruistic coordination for multi-robot cooperative pathfinding,ar,Article,Wei C.,,Delft University of Technology,Delft,Netherlands,,,,,2016-03-01,1 March 2016,Applied Intelligence,0924669X,23674,15737497,Journal,44,2,,269-281,,,9,0,,,,"When multiple robots perform tasks in a shared workspace, they might be confronted with the risk of blocking each other’s ways, which will lead to conflicts or interference among them. Planning collision-free paths for all the robots is a challenge for a multi-robot system, which is also known as the multi-robot cooperative pathfinding problem in which each robot has to navigate from its starting location to the destination while keeping avoiding stationary obstacles as well as the other robots. In this paper, we present a novel fully decentralized approach to this problem. Our approach allows robots to make real-time responses to dynamic environments and can resolve a set of benchmark deadlock situations subject to complex spatial constraints in a shared workspace by means of altruistic coordination. Specifically, when confronted with congested situations, each robot can employ waiting, moving-forwards, dodging, retreating and turning-head strategies to make local adjustments. Most importantly, each robot only needs to coordinate and communicate with the others that are located within its coordinated network in our approach, which can reduce communication overhead in fully decentralized multi-robot systems. In addition, experimental results also show that our proposed approach provides an efficient and competitive solution to this problem.",NO
2-s2.0-84957038800,10.1017/S0263574714001611,S0263574714001611,,Socially aware path planning for mobile robots,ar,Article,Kodagoda S.,,University of Technology Sydney,Sydney,Australia,,,,,2016-03-01,1 March 2016,Robotica,02635747,18078,14698668,Journal,34,3,,513-526,,,2,0,,,,"Human–robot interaction is an emerging area of research where a robot may need to be working in human-populated environments. Human trajectories are generally not random and can belong to gross patterns. Knowledge about these patterns can be learned through observation. In this paper, we address the problem of a robot's social awareness by learning human motion patterns and integrating them in path planning. The gross motion patterns are learned using a novel Sampled Hidden Markov Model, which allows the integration of partial observations in dynamic model building. This model is used in the modified A* path planning algorithm to achieve socially aware trajectories. Novelty of the proposed method is that it can be used on a mobile robot for simultaneous online learning and path planning. The experiments carried out in an office environment show that the paths can be planned seamlessly, avoiding personal spaces of occupants.",NO
2-s2.0-84949639522,10.1002/asmb.2145,,,A random forest application to contact-state classification for robot programming by human demonstration,ar,Article,Cabras S.,,Università degli Studi di Cagliari;Universidad Carlos III de Madrid,Cagliari;Madrid,Italy;Spain,,,,,2016-03-01,1 March 2016,Applied Stochastic Models in Business and Industry,15241904,25195,15264025,Journal,32,2,,209-227,,,2,0,,,,,NO
2-s2.0-84955716563,10.1007/s11554-013-0353-2,,,Accelerating embedded image processing for real time: a case study,ar,Article,Pedre S.,,Universidad de Buenos Aires,Buenos Aires,Argentina,,,,,2016-02-01,1 February 2016,Journal of Real-Time Image Processing,18618200,4900152415,,Journal,11,2,,349-374,,,13,0,,,,"Many image processing applications need real-time performance, while having restrictions of size, weight and power consumption. Common solutions, including hardware/software co-designs, are based on Field Programmable Gate Arrays (FPGAs). Their main drawback is long development time. In this work, a co-design methodology for processor-centric embedded systems with hardware acceleration using FPGAs is proposed. The goal of this methodology is to achieve real-time embedded solutions, using hardware acceleration, but achieving development time similar to that of software projects. Well established methodologies, techniques and languages from the software domain—such as Object-Oriented Paradigm design, Unified Modelling Language, and multithreading programming—are applied; and semiautomatic C-to-HDL translation tools and methods are used and compared. The methodology is applied to achieve an embedded implementation of a global vision algorithm for the localization of multiple robots in an e-learning robotic laboratory. The algorithm is specifically developed to work reliably 24/7 and to detect the robot’s positions and headings even in the presence of partial occlusions and varying lighting conditions expectable in a normal classroom. The co-designed implementation of this algorithm processes 1,600 × 1,200 pixel images at a rate of 32 fps with an estimated energy consumption of 17 mJ per frame. It achieves a 16× acceleration and 92 % energy saving, which compares favorably with the most optimized embedded software solutions. This case study shows the usefulness of the proposed methodology for embedded real-time image processing applications.",NO
2-s2.0-84954383441,10.1007/s10798-015-9304-5,,,Robotics in the early childhood classroom: learning outcomes from an 8-week robotics curriculum in pre-kindergarten through second grade,ar,Article,Sullivan A.,,Tufts University,Medford,United States,,,,,2016-02-01,1 February 2016,International Journal of Technology and Design Education,09577572,21389,15731804,Journal,26,1,,3-20,,,131,0,,,,"In recent years there has been an increasing focus on the missing “T” of technology and “E” of engineering in early childhood STEM (science, technology, engineering, mathematics) curricula. Robotics offers a playful and tangible way for children to engage with both T and E concepts during their foundational early childhood years. This study looks at N = 60 children in pre-kindergarten through second grade who completed an 8-week robotics curriculum in their classrooms using the KIWI robotics kit combined with a tangible programming language. Children were assessed on their knowledge of foundational robotics and programming concepts upon completion of the curriculum. Results show that beginning in pre-kindergarten, children were able to master basic robotics and programming skills, while the older children were able to master increasingly complex concepts using the same robotics kit in the same amount of time. Implications for developmentally appropriate design of technology, as well as structure and pace of robotics curricula for young children are addressed.",SI
2-s2.0-84955240057,10.1108/IR-05-2015-0092,,,The design of an intelligent soccer-playing robot,ar,Article,Xiong D.,,National University of Defense Technology,Changsha,China,,,,,2016-01-18,18 January 2016,Industrial Robot,0143991X,18047,,Journal,43,1,,91-102,,,12,0,,,,"Purpose

The purpose of this paper is to design intelligent robots operating in such dynamic environments like the RoboCup Middle-Size League (MSL). In the RoboCup MSL, two teams of five autonomous robots play on an 18- × 12-m field. Equipped with sensors and on-board computers, each robot should be able to perceive the environment, make decision and control itself to play the soccer game autonomously.

Design/methodology/approach

This paper presents the design of our soccer robots, participating in RoboCup MSL. The mechanical platform, electrical architecture and software framework are discussed separately. The mechanical platform is designed modularly, so easy maintainability is achieved; the electronic architecture is built on industrial standards using PC-based control technique, which results in high robustness and reliability during the intensive and fierce MSL games; the software is developed upon the open-source Robot Operating System (ROS); thus, the advantages of ROS such as modularity, portability and expansibility are inherited.

Findings

Based on this paper and the open-source hardware and software, the MSL robots can be re-developed easily to participate in the RoboCup MSL. The robots can also be used in other research and education fields, especially for multi-robot systems and distributed artificial intelligence. Furthermore, the main designing ideas proposed in the paper, i.e. using a modular mechanical structure, an industrial electronic system and ROS-based software, provide a common solution for designing general intelligent robots.

Originality/value

The methodology of the intelligent robot design for highly competitive and dynamic RoboCup MSL environments is proposed.",NO
2-s2.0-85012235767,10.1109/ACCESS.2016.2587805,,,Advanced LMS Integration of SCORM Web Laboratories,ar,Article,Ruano I.,,Universidad de Jaén,Jaen,Spain,,,,,2016-01-01,2016,IEEE Access,,21100374601,21693536,Journal,4,,7506221,6352-6363,,,10,1,,,,"E-learning and its hybrid counterpart-B-learning-have become standard tools in higher education. The development of information and communications technologies (ICTs) and their application to education has made this possible. Among ICT technologies, the learning management system (LMS) has been the most important development. Teaching labs have also undergone a technological evolution, enabling them to be used online while interacting closely with LMSs. This paper presents a set of procedures that ease the integration of Java and JavaScript laboratories with LMSs in order to obtain adaptive learning contents, which are presented customized to students based on their likes and results. It describes innovative tools implemented by us as a Java package, a JavaScript library, and associated resources that achieve an advanced Lab-LMS integration in a shared content object reference model (SCORM) environment. These resources simplify communications between the elements of an SCORM content package, including the embedded Web laboratory, and the LMS where they are hosted. This paper describes the tools, procedures, and discusses its possibilities and advantages, and shows the results of several use cases of Web Labs delivered to undergraduate engineering students at University of Jaén that prove the validity of the proposal obtaining adapted learning and good results.",NO
2-s2.0-85010874847,10.5370/JEET.2016.11.1.215,,,Trajectory tracking control of a real redundant manipulator of the SCARA type,ar,Article,Urrea C.,,Universidad de Santiago de Chile,Santiago,Chile,,,,,2016-01-01,January 2016,Journal of Electrical Engineering and Technology,19750102,17200154707,20937423,Journal,11,1,,215-226,,,10,1,,,,"Modeling, control and implementation of a real redundant robot with five Degrees Freedom (DOF) of the SCARA (Selective Compliant Assembly Robot Arm) manipulator type is presented. Through geometric methods and structural and functional considerations, the inverse kinematics for redundant robot can be obtained. By means of a modification of the classical sliding mode control law through a hyperbolic function, we get a new algorithm which enables reducing the chattering effect of the real actuators, which together with the learning and adaptive controllers, is applied to the model and to the real robot. A simulation environment including the actuator dynamics is elaborated. A 5 DOF robot, a communication interface and a signal conditioning circuit are designed and implemented for feedback. Three control laws are executed in: a simulation structure (together with the dynamic model of the SCARA type redundant manipulator and the actuator dynamics) and a real redundant manipulator of the SCARA type carried out using MatLab/Simulink programming tools. The results, obtained through simulation and implementation, were represented by comparative curves and RMS indices of the joint errors, and they showed that the redundant manipulator, both in the simulation and the implementation, followed the test trajectory with less pronounced maximum errors using the adaptive controller than the other controllers, with more homogeneous motions of the manipulator.",NO
2-s2.0-85006136272,10.1155/2016/1714350,,,A Mobile Application That Allows Children in the Early Childhood to Program Robots,ar,Article,Ramírez-Benavides K.,,Universidad de Costa Rica,San Jose,Costa Rica,,,,,2016-01-01,2016,Mobile Information Systems,1574017X,19700174653,1875905X,Journal,2016,,1714350,,,,7,1,,,,"Children born in the Information Age are digital natives; this characteristic should be exploited to improve the learning process through the use of technology. This paper addresses the design, construction, and evaluation process of TITIBOTS, a programming assistance tool for mobile devices that allows children in the early childhood to create programs and execute them using robots. We present the results of using TITIBOTS in different scenarios with children between 4 and 6 years old. The insight obtained in the development and evaluation of the tool could be useful when creating applications for children in the early childhood. The results were promising; children liked the application and were willing to continue using it to program robots to solve specific tasks, developing the skills of the 21st century.",SI
2-s2.0-85005950446,10.1007/978-3-319-49130-1_17,,,Boosting the development of ASP-based applications in mobile and general scenarios,ar,Article,Calimeri F.,,Università della Calabria;DLVSystem Srl,Rende;Rende,Italy;Italy,,,,,2016-01-01,2016,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),03029743,25674,16113349,Book Series,10037 LNAI,,,223-236,,,0,0,,,,"Answer Set Programming (ASP) is a well-established declarative programming paradigm in close relationship with other formalisms such as Satisfiability Modulo Theories, Constraint Handling Rules, FO(.) (First-Order logic extensions), Planning Domain Definition Language and many others; it became widely used in AI and recognized as a powerful tool for knowledge representation and reasoning, especially for its high expressiveness and the ability to deal also with incomplete knowledge. In the latest years, the community produced significant theoretical results and a number of robust and efficient implementations; this has been moving the focus from a strict theoretical scope to more practical aspects, and ASP has been increasingly employed in a number of different domains and for the development of industrial-level and enterprise applications. Although different development tools have been released, there is still a lack of proper means for an effective, large-scale applicability of ASP, especially in the mobile setting. In this work we show a general framework for integrating ASP reasoners into external systems and its use for designing and implementing ASP-based applications to different extents. In particular, we illustrate the integration of the ASP system DLV on the Android platform, and a full-native ASP-based mobile app for helping players of a live game of checkers.",NO
2-s2.0-85002616406,10.5772/62180,,,The local definability of robotic largescale knowledge based on splitting,ar,Article,Wu M.,,Huzhou University;Guizhou University,Huzhou;Guiyang,China;China,,,,,2016-01-01,2016,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,13,1,62180,,,,0,1,,,,"In order to reduce the computational tasks in robots with large-scale and complex knowledge, several methods of robotic knowledge localization have been proposed over the past decades. Logic is an important and useful tool for complex robotic reasoning, action planning, learning and verification. This paper uses propositional atoms in logic to describe the affecting factors of robotic large-scale knowledge. Definability in logic reasoning shows that truths of some propositional atoms are decided by other propositional atoms. Definability technology is an important method to eliminate inessential propositional atoms in robotic large-scale and complex knowledge, so the computational tasks in robotic knowledge can be completed faster. On the other hand, by applying the splitting technique, the knowledge base can be equivalently divided into a number of sub-knowledge bases, without sharing any propositional atoms with others. In this paper, we show that the inessential propositional atoms can be decided faster by the local definability technology based on the splitting method, first formed in local belief revision by Parikh in 1999. Hence, the decision-making in robotic large-scale and complex knowledge is more effective.",NO
2-s2.0-85000352295,10.1541/ieejfms.136.759,,,Microcontroller laboratory in the TekBots® hands-on engineering program at the electrical engineering of FIT,ar,Article,Tsujino T.,,Fukuoka Institute of Technology,Fukuoka,Japan,,,,,2016-01-01,2016,IEEJ Transactions on Fundamentals and Materials,03854205,3300147408,13475533,Journal,136,12,,759-771,,,0,0,,,,"抄録

Today's engineering students benefit from an educational program that integrates their knowledge so that they can better solve engineering problems and become natural innovators. The TekBots Platforms for Learning™ (TekBots® PFL) developed at the School of Electrical Engineering and Computer Science (EECS) of Oregon State University (OSU) in the United States have integrated a curriculum into a coherent whole while providing an environment for innovation. The TekBots, which are an automobile robot and a platform for learning created for electrical and computer engineering students, have been designed to assist teaching many practical engineering skills; innovation, design, knowledge integration, and the “real” problem solutions of “real” systems. With the hands-on TekBots, the students can experience the real meaning to many of the seemingly ambiguous topics presented in lecture. The department of Electrical Engineering at Fukuoka Institute of Technology (FIT) has introduced this TekBots PFL to improve its engineering curriculum and has developed the TekBots course program used at FIT in a small scale. The program has been built by four subjects; Freshmen Laboratory for Electrical Engineering, C Programming, Mechatronics I and II. A TekBots project “TekBots Global Vision System” for a graduation thesis has also been carried out. Since two subjects, the Freshmen Laboratory for Electrical Engineering and the C Programming, have already been reported in our previous paper, this paper treats the results of implementation on the Mechatronics I and II. The Mechatronics I and II courses are hands-on laboratories for learning PWM programming and interrupt processing respectively. A microcontroller unit (MCU) is used to control the TekBots instead of the analog board used in previous courses. Intermediate student surveys for the Mechatronics I were carried out during term. It is shown that the surveys are not only useful for communication between students and faculty but also beneficial to an improvement of the TekBots course.",NO
2-s2.0-84982976003,10.5302/J.ICROS.2016.16.0102,,,Intuitive programming of dual-arm robot tasks using kinesthetic teaching method,ar,Article,Kim P.K.,,Korea Institute of Industrial Technology;Seoul National University,Cheonan;Seoul,South Korea;South Korea,,,,,2016-01-01,2016,"Journal of Institute of Control, Robotics and Systems",19765622,21100201073,,Journal,22,8,,656-664,,,4,1,,,,"While anthropomorphic robots are gaining interest, dual-arm robots are widely used in the industrial environment. Many methods exist in order to implement bimanual tasks by dual-arm robot. However, kinesthetic teaching is used in this paper. This paper suggests three different kinesthetic teaching methods that can implement most of the human task by the robot. The three kinesthetic teaching methods are joint level, task level, and contact level teaching. The task introduced in this paper is box packing, which is a popular and complex task in industrial environment. The task is programmed into the dual-arm robot by utilizing the suggested kinesthetic teaching method, and this paper claims that most tasks can be implemented by using the suggesting kinesthetic teaching methods.",NO
2-s2.0-84981537965,10.1504/EJIE.2016.078142,,,Automated robotic assembly line design with unavailability periods and tool changes,ar,Article,Gultekin H.,,TOBB University of Economics and Technology,Ankara,Turkey,,,,,2016-01-01,2016,European Journal of Industrial Engineering,17515254,11200153401,17515262,Journal,10,4,,499-526,,,6,0,,,,"We focus on an assembly line design problem of a fully automated robotic spot-welding line. Different from existing studies, we take the prescheduled unavailability periods, such as lunch and tea breaks, into account in order to reflect a more realistic production environment. This problem includes allocating operations to the stations and satisfying the demand and cycle time within a desired interval for each model to be produced. We also ensure that assignability, precedence, and tool life constraints are met. Furthermore, the existing studies in the literature overlook the limited lives of the tools that are used for production. Tool replacement decisions not only affect the tooling cost, but also the production rate. Therefore, we determine the number of stations and allocate the operations into the stations in such a way that tool change periods coincide with the unavailability periods to eliminate tool change related line stoppages in a mixed model robotic assembly line. We provide a mathematical formulation, propose a two-stage local search algorithm and test the performances of these methods using different problem instances with varying parameters. [Received 12 November 2012; Revised 8 February 2016; Accepted 18 February 2016[",NO
2-s2.0-84981276184,10.3233/THC-161140,,26835733,LEGO Mindstorms NXT for elderly and visually impaired people in need: A platform,ar,Article,Al-Halhouli A.,,German Jordanian University,Amman,Jordan,,,,,2016-01-01,2016,Technology and Health Care,09287329,19644,,Journal,24,4,,579-585,,,5,0,,,,"This paper presents the employment of LEGO Mindstorms NXT robotics as core component of low cost multidisciplinary platform for assisting elderly and visually impaired people. LEGO Mindstorms system offers a plug-and-play programmable robotics toolkit, incorporating construction guides, microcontrollers and sensors, all connected via a comprehensive programming language. It facilitates, without special training and at low cost, the use of such device for interpersonal communication and for handling multiple tasks required for elderly and visually impaired people in-need. The research project provides a model for larger-scale implementation, tackling the issues of creating additional functions in order to assist people in-need. The new functions were built and programmed using MATLAB through a user friendly Graphical User Interface (GUI). Power consumption problem, besides the integration of WiFi connection has been resolved, incorporating GPS application on smart phones enhanced the guiding and tracking functions. We believe that developing and expanding the system to encompass a range of applications beyond the initial design schematics to ease conducting a limited number of pre-described protocols. However, the beneficiaries for the proposed research would be limited to elderly people who require assistance within their household as assistive-robot to facilitate a low-cost solution for a highly demanding health circumstance.",SI
2-s2.0-84973538508,10.20965/jrm.2016.p0017,,,Collision avoidance using contact information with multiple objects by multi-leg robot,ar,Article,Takubo T.,,Osaka City University,Osaka,Japan,,,,,2016-01-01,2016,Journal of Robotics and Mechatronics,09153942,21100197345,18838049,Journal,28,1,,17-30,,,2,0,,,,"In robotics, a walking through motion is complex because of the presence of multipoint contact objects in the working environment of a robot. To simplify the walking through motion of a robot, a virtual impedance field is implemented to the contact points of the robot and an object so that the robot avoids the object passively. The traveling direction of the robot is altered by a virtual repulsive force obtained from the position of the estimated obstacle and the virtual impedance field. The resulting action depends on the parameter of virtual impedance coefficients. Because a combination of parameters includes many things, reinforcement learning is employed to obtain an optimal motion. The optimization of the multipoint contact walking through motion of a robot is finally achieved by evaluating the walking motion while encountering complex obstacles in a dynamic simulator. The motion is implemented on a hexapod robot, and the results demonstrate the effectiveness of the proposed method.",NO
2-s2.0-84963744746,10.1108/AA-11-2015-108,,,A novel path planning method for biomimetic robot based on deep learning,ar,Article,Lu Y.,,Heilongjiang Bayi Agricultural University,Mishan,China,,,,,2016-01-01,2016,Assembly Automation,01445154,24904,,Journal,36,2,,186-191,,,11,0,,,,"Purpose

This paper aims to design a multi-layer convolutional neural network (CNN) to solve biomimetic robot path planning problem.

Design/methodology/approach

At first, the convolution kernel with different scales can be obtained by using the sparse auto encoder training algorithm; the parameter of the hidden layer is a series of convolutional kernel, and the authors use these kernels to extract first-layer features. Then, the authors get the second-layer features through the max-pooling operators, which improve the invariance of the features. Finally, the authors use fully connected layers of neural networks to accomplish the path planning task.

Findings

The NAO biomimetic robot respond quickly and correctly to the dynamic environment. The simulation experiments show that the deep neural network outperforms in dynamic and static environment than the conventional method.

Originality/value

A new method of deep learning based biomimetic robot path planning is proposed. The authors designed a multi-layer CNN which includes max-pooling layer and convolutional kernel. Then, the first and second layers features can be extracted by these kernels. Finally, the authors use the sparse auto encoder training algorithm to train the CNN so as to accomplish the path planning task of NAO robot.",NO
2-s2.0-84953353836,10.1007/s10514-015-9442-3,,,Spatial adaption of robot trajectories based on laplacian trajectory editing,ar,Article,Nierhoff T.,,Technical University of Munich,Munich,Germany,,,,,2016-01-01,1 January 2016,Autonomous Robots,09295593,18016,15737527,Journal,40,1,,159-173,,,5,0,,,,"Assuming that a robot trajectory is given from a high-level planning or learning mechanism, it needs to be adapted to react to dynamic environment changes. In this article we propose a novel approach to deform trajectories while keeping their local shape similar, which is based on the discrete Laplace–Beltrami operator. The approach can be readily extended and covers multiple deformation techniques including fixed waypoints that must be passed, positional constraints for collision avoidance or a cooperative manipulation scheme for the coordination of multiple robots. Due to its low computational complexity it allows for real-time trajectory deformation both on local and global scale and online adaptation to changed environmental constraints. Simulations illustrate the straightforward combination of the proposed approach with other established trajectory-related methods like artificial potential fields or prioritized inverse kinematics. Experiments with the HRP-4 humanoid successfully demonstrate the applicability in complex daily-life tasks.",NO
2-s2.0-84952980187,10.1007/s11370-015-0181-2,,,Optimization of humanoid’s motions under multiple constraints in vehicle ingress task,ar,Article,Sohn K.,,"University of Nevada, Las Vegas",Las Vegas,United States,,,,,2016-01-01,1 January 2016,Intelligent Service Robotics,18612776,9500154152,18612784,Journal,9,1,,31-48,,,3,0,,,,"This paper presents an approach on whole-body motion optimization for a humanoid robot to enter a ground vehicle. Motion capture system (mocap) was used to plan an initial suboptimal motion. Reinforcement learning was then implemented to optimize the trajectories with respect to kinematic and torque limits at the both body and the joint level. The cost functions in the body level calculated a robot’s static balancing ability, collisions and validity of the end-effector movement. Balancing and collision checks were computed from kinematic models of the robot and the vehicle model. Energy consumption such as torque limit obedience was checked at the joint level. Energy cost was approximated as joint torque, measured from a dynamic model. Various penalties such as joint angle and velocity limits were also computed in the joint level. Physical limits of each joint ensured both spatial and temporal smoothness of the generated trajectories. Finally, experimental evaluations of the presented approach were demonstrated through simulation and physical platforms in a real environment.",NO
2-s2.0-85032438005,10.1016/j.compag.2017.10.009,S016816991730621X,,Porcine automation: Robotic abdomen cutting trajectory planning using machine vision techniques based on global optimization algorithm,ar,Article,Liu Y.,,Dalian University of Technology,Dalian,China,,,,,2017-12-01,December 2017,Computers and Electronics in Agriculture,01681699,30441,,Journal,143,,,193-200,,,5,0,,,,"Highlights

•

The proposed method relates to biosignature, algorithms, machine vision and robotics.

•

For this experiment, GA is better in comparing kinds of optimization algorithms.

•

The results are significant to the theoretical researches and practical applications.
The purpose of this paper is to provide details on implementation of accurate and intelligent automation solution for porcine abdomen cutting while a pig is hung up by rear legs. The system developed utilized a 6-DOF industrial manipulators, customized tools, 2D camera and PC. Eye-to-hand calibrations built coordinate transformation relations of units in Cartesian space. The porcine abdomen curve was identified and fitted into quintic spline curve from image. Under cavum peritonaei constrains, optimal sectional trajectory was planned based on genetic algorithm (GA) by comparing several kinds of optimization algorithms. The results of experimental replications show that the system was successful both in following the varied position carcass and cutting open abdominal cavity without haslet damage. The system can enhance the quality, hygienic standard and efficiency of the process.",NO
2-s2.0-85018249048,10.1016/j.rcim.2017.04.010,S0736584515301447,,Human-robot collaboration while sharing production activities in dynamic environment: SPADER system,ar,Article,Meziane R.,,Université du Québec à Chicoutimi,Chicoutimi,Canada,,,,,2017-12-01,1 December 2017,Robotics and Computer-Integrated Manufacturing,07365845,18080,,Journal,48,,,243-253,,,26,1,,,,"Highlights

•

A safe trajectory generation in dynamic environments.

•

The evaluation of human motion.

•

A strategy adapted for industrial robot already installed in the production line.

•

The system is based on neural network in order to create the waypoints required for dynamic obstacles avoidance.

•

Finally, a quintic polynomial function is used in order to smooth motion and least-square is computed for an optimal trajectory.
Interactive robot doing collaborative work in hybrid work cell need adaptive trajectory planning strategy. Indeed, systems must be able to generate their own trajectories without colliding with dynamic obstacles like humans and assembly components moving inside the robot workspace. The aim of this paper is to improve collision-free motion planning in dynamic environment in order to insure human safety during collaborative tasks such as sharing production activities between human and robot. Our system proposes a trajectory generating method for an industrial manipulator in a shared workspace. A neural network using a supervised learning is applied to create the waypoints required for dynamic obstacles avoidance. These points are linked with a quintic polynomial function for smooth motion which is optimized using least-square to compute an optimal trajectory. Moreover, the evaluation of human motion forms has been taken into consideration in the proposed strategy. According to the results, the proposed approach is an effective solution for trajectories generation in a dynamic environment like a hybrid workspace.",NO
2-s2.0-85040860192,10.1166/asl.2017.10252,,,Early childhood educational robotic system (C-Block): A design methodology,ar,Article,Mariappan M.,,Universiti Malaysia Sabah,Kota Kinabalu,Malaysia,,,,,2017-11-01,November 2017,Advanced Science Letters,19366612,19700181106,19367317,Journal,23,11,,11206-11210,,,0,0,,,,"Critical thinking is important in developing creative and innovative minds. Project-based learning (PBL) curriculum is introduced for students to allow active participation which involves scientific inquiry and application of mathematics in the context of technological designing or problem-solving. Programmable Tangible Blocks Robotic System for Early Childhood Education (C-Block) is proposed as a tool for children aged 4 to 7 to engage in PBL activity. C-Block is a kit which comprises of instruction blocks, programming mat and a mobile robot. This paper is aimed to describe the design methodology of the C-Block kits. The first prototype of the programming mat was fabricated and the results is discussed.",SI
2-s2.0-85034596603,10.1016/j.compag.2017.11.023,S016816991730827X,,Development of a prototype robot and fast path-planning algorithm for static laser weeding,ar,Article,Xiong Y.,,Harper Adams University,Shropshire,United Kingdom,,,,,2017-11-01,November 2017,Computers and Electronics in Agriculture,01681699,30441,,Journal,142,,,494-503,,,25,0,,,,"Highlights

•

Developed a prototype laser weeding robot equipped with dual-gimbal laser pointers.

•

Two image processing algorithms were used to classify weeds and crops.

•

Proposed an efficient fast path-planning method for travelling-salesman problem.

•

Established a model for optimal segmentation size and target quantity.

•

Test showed the weeding mean positional error was 1.97 mm with 97% hit rate.
To demonstrate the feasibility and improve the implementation of laser weeding, a prototype robot was built and equipped with machine vision and gimbal mounted laser pointers. The robot consisted of a mobile platform modified from a small commercial quad bike, a camera to detect the crop and weeds and two steerable gimbals controlling the laser pointers. Visible-one laser pointers were used to simulate the powerful laser trajectories. A colour segmentation algorithm was utilised to extract plants from the soil background; size estimation was used to differentiate crop from weeds; and an erosion and dilation algorithm was developed to separate objects that were touching. Conversely, another algorithm, which utilised shape descriptors, was able to distinguish plant species in non-touching status regardless of area difference. Next, in order to reduce route length and run time, a new path-planning algorithm for static weeding was proposed and tested. It was demonstrated to be more efficient especially when addressing a higher density of weeds. A model was then established to determine the optimal segmentation size, based on the route length for treatment. It was found that the segmentation algorithm has the potential to be widely used in fast path-planning for the travelling-salesman problem. Finally, performance tests in the indoor environments showed that the weeding mean positional error was 1.97 mm, with a 0.88 mm standard deviation. Another test indicated that with a laser traversal speed of 30 mm/s and a dwell time of 0.64 s per weed, it had a hit rate of 97%.",NO
2-s2.0-85020823138,10.1016/j.patrec.2017.06.003,S016786551730199X,,Learning robot tasks with loops from experiences to enhance robot adaptability,ar,Article,Mokhtari V.,,Instituto de Engenharia Electrónica e Telemática de Aveiro,Aveiro,Portugal,,,,,2017-11-01,1 November 2017,Pattern Recognition Letters,01678655,24825,,Journal,99,,,57-66,,,4,0,,,,"Highlights

•

A unified framework of experience-based planning domains (EBPDs).

•

A one-shot learning technique for robot task learning based on robot’s experiences.

•

A method to detect repetition of actions in a task demonstration.

•

A method to adapt and extend a task knowledge to new contexts.
Learning robot task models with loops helps to increase both the applicability and the compactness of task knowledge. In the framework of Experience-Based Planning Domains (EBPDs), previously formalized by the authors, an approach was developed for learning and exploiting high-level robot task models (the so-called activity schemata) with loops. The paper focuses on the development of: (i) a method—Contiguous Non-overlapping Longest Common Subsequence (CNLCS)—based on the Longest Common Prefix (LCP) array for detecting loops of actions in a robot experience; and (ii) an abstract planner to instanciate a learned task model with loops for solving particular instances of the same task with varying numbers of objects. Demonstrations of this system in both real and simulated environments prove its potentialities.",NO
2-s2.0-85044304242,10.1109/TLT.2016.2627565,,,Web environment for programming and control of a mobile robot in a remote laboratory,ar,Article,Dos Santos Lopes M.S.,,State University of Southwest Bahia (UESB),Salvador,Brazil,,,,,2017-10-01,October-December 2017,IEEE Transactions on Learning Technologies,19391382,19700167026,,Journal,10,4,,526-531,,,13,0,,,,"Remote robotics laboratories have been successfully used for engineering education. However, few of them use mobile robots to to teach computer science. This article describes a mobile robot Control and Programming Environment (CPE) and its pedagogical applications. The system comprises a remote laboratory for robotics, an online programming tool, and a virtual learning environment. It allows experiments with a mobile robot to be carried out, tested and validated remotely, using a simple graphic interface via web browser, without additional software installation on the user's computer. Students can control and manipulate the robot with simple commands without worrying about hardware details or use C/C++ programming language to develop complex programs. The robot has been built with inexpensive components and has sensors that enable its use in several experiments. CPE can be used in contextualized teaching in various subjects of computer science, both in class and at distance. A practical application of the whole system using CPE, introducing programming concepts, is also described in this paper. The initial assessment of the environment as an educational tool shows high levels of interest among our students, an improvement in their academic scores, and potential for application in the context of computing education, when properly introduced as a learning tool.",SI
2-s2.0-85028932070,10.1142/S0218488517500295,,,FML-based Dynamic Assessment Agent for Human-Machine Cooperative System on Game of Go,ar,Article,Lee C.,,National University of Tainan Taiwan,Tainan,Taiwan,,,,,2017-10-01,1 October 2017,"International Journal of Uncertainty, Fuzziness and Knowlege-Based Systems",02184885,24326,,Journal,25,5,,677-705,,,9,0,,,,"In this paper, we demonstrate the application of Fuzzy Markup Language (FML) to construct an FML-based Dynamic Assessment Agent (FDAA), and we present an FML-based Human–Machine Cooperative System (FHMCS) for the game of Go. The proposed FDAA comprises an intelligent decision-making and learning mechanism, an intelligent game bot, a proximal development agent, and an intelligent agent. The intelligent game bot is based on the open-source code of Facebook’s Darkforest, and it features a representational state transfer application programming interface mechanism. The proximal development agent contains a dynamic assessment mechanism, a GoSocket mechanism, and an FML engine with a fuzzy knowledge base and rule base. The intelligent agent contains a GoSocket engine and a summarization agent that is based on the estimated win rate, real-time simulation number, and matching degree of predicted moves. Additionally, the FML for player performance evaluation and linguistic descriptions for game results commentary are presented. We experimentally verify and validate the performance of the FDAA and variants of the FHMCS by testing five games in 2016 and 60 games of Google’s Master Go, a new version of the AlphaGo program, in January 2017. The experimental results demonstrate that the proposed FDAA can work effectively for Go applications.",NO
2-s2.0-85028458074,10.1109/TASE.2017.2731371,,,Toward Socially Aware Robot Navigation in Dynamic and Crowded Environments: A Proactive Social Motion Model,ar,Article,Truong X.,,Le Quy Don Technical University;UNIVERSITI BRUNEI DARUSSALAM,Hanoi;Bandar Seri Begawan,Viet Nam;Brunei Darussalam,,,,,2017-10-01,October 2017,IEEE Transactions on Automation Science and Engineering,15455955,17340,,Journal,14,4,8011466,1743-1760,,,57,0,,,,"Safe and social navigation is the key to deploying a mobile service robot in a human-centered environment. Widespread acceptability of mobile service robots in daily life is hindered by robot's inability to navigate in crowded and dynamic human environments in a socially acceptable way that would guarantee human safety and comfort. In this paper, we propose an effective proactive social motion model (PSMM) that enables a mobile service robot to navigate safely and socially in crowded and dynamic environments. The proposed method considers not only human states (position, orientation, motion, field of view, and hand poses) relative to the robot but also social interactive information about human-object and human group interactions. This allows development of the PSMM that consists of elements of an extended social force model and a hybrid reciprocal velocity obstacle technique. The PSMM is then combined with a path planning technique to generate a motion planning system that drives a mobile robot in a socially acceptable manner and produces respectful and polite behaviors akin to human movements. Note to Practitioners-In this paper, we validated the effectiveness and feasibility of the proposed proactive social motion model (PSMM) through both simulation and real-world experiments under the newly proposed human comfortable safety indices. To do that, we first implemented the entire navigation system using the open-source robot operating system. We then installed it in a simulated robot model and conducted experiments in a simulated shopping mall-like environment to verify its effectiveness. We also installed the proposed algorithm on our mobile robot platform and conducted experiments in our office-like laboratory environment. Our results show that the developed socially aware navigation framework allows a mobile robot to navigate safely, socially, and proactively while guaranteeing human safety and comfort in crowded and dynamic environments. In this paper, we exami...
(Show More)",NO
2-s2.0-85026454177,10.1007/s10758-017-9328-x,,,Introducing Computational Thinking to Young Learners: Practicing Computational Perspectives Through Embodiment in Mathematics Education,ar,Article,Sung W.,,Columbia University,New York,United States,,,,,2017-10-01,1 October 2017,"Technology, Knowledge and Learning",22111662,19700200832,22111670,Journal,22,3,,443-463,,,29,0,,,,"A science, technology, engineering, and mathematics-influenced classroom requires learning activities that provide hands-on experiences with technological tools to encourage problem-solving skills (Brophy et al. in J Eng Educ 97(3):369–387, 2008; Matarić et al. in AAAI spring symposium on robots and robot venues: resources for AI education, pp 99–102, 2007). The study aimed to bring computational thinking, an applicable skill set in computer science, into existing mathematics and programming education in elementary classrooms. An essential component of computational thinking is the ability to think like a computer scientist when confronted with a problem (Grover and Pea in Educ Res 42(1):38–43. doi:10.3102/0013189X12463051, 2013). Computational perspectives (Berland and Wilensky in J Sci Educ Technol 24(5):628–647. doi:10.1007/s10956-015-9552-x, 2015) refer to the frame of reference programmers or computer scientists adopt when approaching a problem. The study examined the effects of taking computational perspectives through various degrees of embodied activities (i.e., full vs. low) on students’ achievement in mathematics and programming. The study employed a 2 (full vs. low embodiment) × 2 (with vs. without computational perspective taking) factorial condition to evaluate four learning conditions from a combination of embodiment and computational perspective-taking practice. The results from this experimental study (N = 66 kindergarten and first graders) suggest that full-embody activities combined with the practice of computational perspective-taking in solving mathematics problem improved mathematics understanding and programming skills as demonstrated in Scrath Jr. among novice young learners. Moreover, the practice of using a computational perspective significantly improved students’ understanding of core programming concepts regardless of the level of embodiment. The article includes recommendations for how to make the computational thinking process more concrete and relevant within the context of a standard curriculum, particularly mathematics.",NO
2-s2.0-85011706654,10.1109/TCYB.2017.2653800,,28166513,Improving the Critic Learning for Event-Based Nonlinear H<inf>∞</inf> Control Design,ar,Article,Wang D.,,University of Chinese Academy of Sciences;Institute of Automation Chinese Academy of Sciences,Beijing;Beijing,China;China,,,,,2017-10-01,October 2017,IEEE Transactions on Cybernetics,21682267,21100274221,,Journal,47,10,7836355,3417-3428,,,41,1,,,,"In this paper, we aim at improving the critic learning criterion to cope with the event-based nonlinear H ∞ state feedback control design. First of all, the H ∞ control problem is regarded as a two-player zero-sum game and the adaptive critic mechanism is used to achieve the minimax optimization under event-based environment. Then, based on an improved updating rule, the event-based optimal control law and the time-based worst-case disturbance law are obtained approximately by training a single critic neural network. The initial stabilizing control is no longer required during the implementation process of the new algorithm. Next, the closed-loop system is formulated as an impulsive model and its stability issue is handled by incorporating the improved learning criterion. The infamous Zeno behavior of the present event-based design is also avoided through theoretical analysis on the lower bound of the minimal intersample time. Finally, the applications to an aircraft dynamics and a robot arm plant are carried out to verify the efficient performance of the present novel design method.",NO
2-s2.0-85018273240,10.1002/cae.21828,,,Robot kinematics made easy using RoboAnalyzer software,ar,Article,Othayoth R.,,Johns Hopkins University,Baltimore,United States,,,,,2017-09-01,September 2017,Computer Applications in Engineering Education,10613773,18156,10990542,Journal,25,5,,669-680,,,18,0,,,,"RoboAnalyzer is a software based on 3D model of robots. It was developed primarily for teaching and learning of robot mechanics, although it is robust enough for the use by researchers as well. The motive behind the development of RoboAnalyzer was mainly to help teachers and students get started with teaching/learning of robotics using template-based skeleton models or CAD models of serial robots. This minimizes the time otherwise spent on modeling, programming, and simulating the robots from scratch. In this article, we focus on the visualization of the Denavit Hartenberg (DH) parameters used to define a robot's architecture, and the modeling of the robot's input-output motion characteristics, that is, robot kinematics, using them. The advantages of using RoboAnalyzer to overcome several challenges of learning robotics in a classroom environment are also discussed.",NO
2-s2.0-85006954122,10.1109/TCYB.2016.2633318,,27992357,"Evolutionary Metric-Learning-Based Recognition Algorithm for Online Isolated Persian/Arabic Characters, Reconstructed Using Inertial Pen Signals",ar,Article,Sepahvand M.,,Razi University,Kermanshah,Iran,,,,,2017-09-01,September 2017,IEEE Transactions on Cybernetics,21682267,21100274221,,Journal,47,9,7782360,2872-2884,,,16,0,,,,"The development of sensors with the microelectromechanical systems technology expedites the emergence of new tools for human-computer interaction, such as inertial pens. These pens, which are used as writing tools, do not depend on a specific embedded hardware, and thus, they are inexpensive. Most of the available inertial pen character recognition approaches use the low-level features of inertial signals. This paper introduces a Persian/Arabic handwriting character recognition system for inertial-sensor-equipped pens. First, the motion trajectory of the inertial pen is reconstructed to estimate the position signals by using the theory of inertial navigation systems. The position signals are then used to extract high-level geometrical features. A new metric learning technique is then adopted to enhance the accuracy of character classification. To this end, a characteristic function is calculated for each character using a genetic programming algorithm. These functions form a metric kernel classifying all the characters. The experimental results show that the performance of the proposed method is superior to that of one of the state-of-the-art works in terms of recognizing Persian/Arabic handwriting characters.",NO
2-s2.0-85025170322,10.1021/acssynbio.6b00304,,28051850,BioBlocks: Programming Protocols in Biology Made Easier,ar,Article,Gupta V.,,Universidad Politécnica de Madrid,Madrid,Spain,,,,,2017-07-21,21 July 2017,ACS Synthetic Biology,,21100218506,21615063,Journal,6,7,,1230-1232,,,8,0,,,,"The methods to execute biological experiments are evolving. Affordable fluid handling robots and on-demand biology enterprises are making automating entire experiments a reality. Automation offers the benefit of high-throughput experimentation, rapid prototyping, and improved reproducibility of results. However, learning to automate and codify experiments is a difficult task as it requires programming expertise. Here, we present a web-based visual development environment called BioBlocks for describing experimental protocols in biology. It is based on Google’s Blockly and Scratch, and requires little or no experience in computer programming to automate the execution of experiments. The experiments can be specified, saved, modified, and shared between multiple users in an easy manner. BioBlocks is open-source and can be customized to execute protocols on local robotic platforms or remotely, that is, in the cloud. It aims to serve as a de facto open standard for programming protocols in Biology.",NO
2-s2.0-85011101723,10.1016/j.jpdc.2016.12.028,S0743731517300060,,SAUCE: A web application for interactive teaching and learning of parallel programming,ar,Article,Hundt C.,,Johannes Gutenberg-Universität Mainz,Mainz,Germany,,,,,2017-07-01,1 July 2017,Journal of Parallel and Distributed Computing,07437315,25621,,Journal,105,,,163-173,,,10,0,,,,"Highlights

•

A web application for the automated assessment of parallel programs is introduced.

•

Interactive programming exercises for the teaching of parallel programming are discussed.

•

C++11 multi-threading, OpenMP, MPI and CUDA support are demonstrated.

•

Black box testing can be used to validate code in terms of correctness and performance.

•

Short feedback loops increase the quality of submitted source code.
Prevalent hardware trends towards parallel architectures and algorithms create a growing demand for graduate students familiar with the programming of concurrent software. However, learning parallel programming is challenging due to complex communication and memory access patterns as well as the avoidance of common pitfalls such as dead-locks and race conditions. Hence, the learning process has to be supported by adequate software solutions in order to enable future computer scientists and engineers to write robust and efficient code. This paper discusses a selection of well-known parallel algorithms based on C++11 threads, OpenMP, MPI, and CUDA that can be interactively embedded in an HPC or parallel computing lecture using a unified framework for the automated evaluation of source code—namely the “System for AUtomated Code Evaluation” (SAUCE). SAUCE is free software licensed under AGPL-3.0 and can be downloaded at https://github.com/moschlar/SAUCE free of charge.",NO
2-s2.0-85021634555,10.1177/0278364917691112,,,Structured learning for spoken language understanding in human-robot interaction,ar,Article,Bastianelli E.,,"Università degli Studi di Roma ""Tor Vergata""",Rome,Italy,,,,,2017-06-01,June 2017,International Journal of Robotics Research,02783649,18050,17413176,Journal,36,5-7,,,,,4,0,,,,"Robots are slowly becoming a part of everyday life, being marketed for commercial applications such as telepresence, cleaning or entertainment. Thus, the ability to interact via natural language with non-expert users is becoming a key requirement. Even if user utterances can be efficiently recognized and transcribed by automatic speech recognition systems, several issues arise in translating them into suitable robotic actions and most of the existing solutions are strictly related to a specific scenario. In this paper, we present an approach to the design of natural language interfaces for human robot interaction, to translate spoken commands into computational structures that enable the robot to execute the intended request. The proposed solution is achieved by combining a general theory of language semantics, i.e. frame semantics, with state-of-the-art methods for robust spoken language understanding, based on structured learning algorithms. The adopted data driven paradigm allows the development of a fully functional natural language processing chain, that can be initialized by re-using available linguistic tools and resources. In addition, it can be also specialized by providing small sets of examples representative of a target newer domain. A systematic benchmarking resource, in terms of a rich and multi-layered spoken corpus has also been created and it has been used to evaluate the natural language processing chain. Our results show that our processing chain, trained with generic resources, provides a solid baseline for command understanding in a service robot domain. Moreover, when domain-dependent resources are provided to the system, the accuracy of the achieved interpretation always improves.",NO
2-s2.0-85015659483,10.1007/s11633-016-0983-5,,,Reactive navigation of underwater mobile robot using ANFIS approach in a manifold manner,ar,Article,Kundu S.,,National Institute of Technology Rourkela,Rourkela,India,,,,,2017-06-01,1 June 2017,International Journal of Automation and Computing,14768186,5200152703,17518520,Journal,14,3,,307-320,,,12,0,,,,Learning and self-adaptation ability is highly required to be integrated in path planning algorithm for underwater robot during navigation through an unspecified underwater environment. High frequency oscillations during underwater motion are responsible for nonlinearities in dynamic behavior of underwater robot as well as uncertainties in hydrodynamic coefficients. Reactive behaviors of underwater robot are designed considering the position and orientation of both target and nearest obstacle from robot’s current position. Human like reasoning power and approximation based learning skill of neural based adaptive fuzzy inference system (ANFIS) has been found to be effective for underwater multivariable motion control. More than one ANFIS models are used here for achieving goal and obstacle avoidance while avoiding local minima situation in both horizontal and vertical plane of three dimensional workspace. An error gradient approach based on input-output training patterns for learning purpose has been promoted to spawn trajectory of underwater robot optimizing path length as well as time taken. The simulation and experimental results endorse sturdiness and viability of the proposed method in comparison with other navigational methodologies to negotiate with hectic conditions during motion of underwater mobile robot.,NO
2-s2.0-85014423231,10.1016/j.compedu.2017.03.001,S0360131517300490,,Assessing elementary students’ computational thinking in everyday reasoning and robotics programming,ar,Article,Chen G.,,University of Miami,Coral Gables,United States,,,,,2017-06-01,1 June 2017,Computers and Education,03601315,17645,,Journal,109,,,162-175,,,133,1,,,,"Highlights

•

Assess computational thinking (CT) in ways that are independent of platform.

•

Assess fifth graders' CT in both everyday and programming settings.

•

Psychometric analysis of the instrument shows high quality.
Based on a framework of computational thinking (CT) adapted from Computer Science Teacher Association's standards, an instrument was developed to assess fifth grade students' CT. The items were contextualized in two types of CT application (coding in robotics and reasoning of everyday events). The instrument was administered as a pre and post measure in an elementary school where a new humanoid robotics curriculum was adopted by their fifth grade. Results show that the instrument has good psychometric properties and has the potential to reveal student learning challenges and growth in terms of CT.",SI
2-s2.0-84980006497,10.1007/s10514-016-9601-1,,,Robot life-long task learning from human demonstrations: a Bayesian approach,ar,Article,Koenig N.,,Open Source Robotics Foundation,Mountain View,United States,,,,,2017-06-01,1 June 2017,Autonomous Robots,09295593,18016,15737527,Journal,41,5,,1173-1188,,,18,0,,,,"Programming a robot to act intelligently is a challenging endeavor beyond the skill level of most people. Trained roboticists generally program robots for a single purpose. Enabling robots to be programmed by non-experts and to perform multiple tasks are both open challenges in robotics. This paper presents a framework that allows life-long robot task learning from demonstrations. To make that possible, the paper introduces a task representation based on influence diagrams, and a method to transfer knowledge between similar tasks. A novel approach to influence diagram learning is presented along with a demonstration method that allows non-experts to teach tasks to the robot in an intuitive manner. The results from three user studies validate that the approach enables both a simulated and a physical robot to learn complex tasks from a variety of teachers, refining those tasks during on-line performance, successfully completing the tasks in different environments, and transferring knowledge from one task to another.",NO
2-s2.0-84928556182,10.1016/j.artint.2015.04.004,S0004370215000661,,Efficient interactive decision-making framework for robotic applications,ar,Article,Agostini A.,,Bernstein Center for Computational Neuroscience Göttingen,Gottingen,Germany,,,,,2017-06-01,1 June 2017,Artificial Intelligence,00043702,23675,,Journal,247,,,187-212,,,19,1,,,,"The inclusion of robots in our society is imminent, such as service robots. Robots are now capable of reliably manipulating objects in our daily lives but only when combined with artificial intelligence (AI) techniques for planning and decision-making, which allow a machine to determine how a task can be completed successfully. To perform decision making, AI planning methods use a set of planning operators to code the state changes in the environment produced by a robotic action. Given a specific goal, the planner then searches for the best sequence of planning operators, i.e., the best plan that leads through the state space to satisfy the goal. In principle, planning operators can be hand-coded, but this is impractical for applications that involve many possible state transitions. An alternative is to learn them automatically from experience, which is most efficient when there is a human teacher. In this study, we propose a simple and efficient decision-making framework for this purpose. The robot executes its plan in a step-wise manner and any planning impasse produced by missing operators is resolved online by asking a human teacher for the next action to execute. Based on the observed state transitions, this approach rapidly generates the missing operators by evaluating the relevance of several cause–effect alternatives in parallel using a probability estimate, which compensates for the high uncertainty that is inherent when learning from a small number of samples. We evaluated the validity of our approach in simulated and real environments, where it was benchmarked against previous methods. Humans learn in the same incremental manner, so we consider that our approach may be a better alternative to existing learning paradigms, which require offline learning, a significant amount of previous knowledge, or a large number of samples.",NO
2-s2.0-84920577661,10.1016/j.artint.2014.11.009,S0004370214001416,,Automated aerial suspended cargo delivery through reinforcement learning,ar,Article,Faust A.,,The University of New Mexico,Albuquerque,United States,,,,,2017-06-01,1 June 2017,Artificial Intelligence,00043702,23675,,Journal,247,,,381-398,,,66,1,,,,"Cargo-bearing unmanned aerial vehicles (UAVs) have tremendous potential to assist humans by delivering food, medicine, and other supplies. For time-critical cargo delivery tasks, UAVs need to be able to quickly navigate their environments and deliver suspended payloads with bounded load displacement. As a constraint balancing task for joint UAV-suspended load system dynamics, this task poses a challenge. This article presents a reinforcement learning approach for aerial cargo delivery tasks in environments with static obstacles. We first learn a minimal residual oscillations task policy in obstacle-free environments using a specifically designed feature vector for value function approximation that allows generalization beyond the training domain. The method works in continuous state and discrete action spaces. Since planning for aerial cargo requires very large action space (over 106 actions) that is impractical for learning, we define formal conditions for a class of robotics problems where learning can occur in a simplified problem space and successfully transfer to a broader problem space. Exploiting these guarantees and relying on the discrete action space, we learn the swing-free policy in a subspace several orders of magnitude smaller, and later develop a method for swing-free trajectory planning along a path. As an extension to tasks in environments with static obstacles where the load displacement needs to be bounded throughout the trajectory, sampling-based motion planning generates collision-free paths. Next, a reinforcement learning agent transforms these paths into trajectories that maintain the bound on the load displacement while following the collision-free path in a timely manner. We verify the approach both in simulation and in experiments on a quadrotor with suspended load and verify the method's safety and feasibility through a demonstration where a quadrotor delivers an open container of liquid to a human subject. The contributions of this work are two-fold. First, this article presents a solution to a challenging, and vital problem of planning a constraint-balancing task for an inherently unstable non-linear system in the presence of obstacles. Second, AI and robotics researchers can both benefit from the provided theoretical guarantees of system stability on a class of constraint-balancing tasks that occur in very large action spaces.",NO
2-s2.0-85028763348,10.1109/RITA.2017.2697739,,,Introduction to Robotics: Importance of a Summer Camp as a Recruiting Tool for Future University Students,ar,Article,Balaguer Alvarez I.J.,,Universidad de Puerto Rico en Aguadilla,Aguadilla,Puerto Rico,,,,,2017-05-01,May 2017,Revista Iberoamericana de Tecnologias del Aprendizaje,,19700201532,19328540,Journal,12,2,7913578,71-75,,,8,0,,,,"This paper describes a robotics summer camp that was held at the University of Puerto Rico at Aguadilla Campus (UPR-Aguadilla) during the summer of 2015. This camp gave high school students the opportunity to collaborate with their peers, in a university setting, in the building and programing of robots. The main contribution of this paper is the evaluation of the camp's influence on student enrollment at the UPR-Aguadilla. The impact was evaluated by using pre- and post-test surveys that included content and interest questions. In addition, the pre- and the post-test surveys included questions on whether or not the camp influenced student enrollment at the UPR-Aguadilla. The camp survey results suggest that attendance to the camp had a significant effect on the enrollment of participating students at the UPR-Aguadilla.",SI
2-s2.0-85027054261,10.1145/3025013,,,Teaching programming in secondary education through embodied computing platforms: Robotics and wearables,ar,Article,Merkouris A.,,Ionian Panepistimion,49100 Corfu,Greece,,,,,2017-05-01,May 2017,ACM Transactions on Computing Education,,19700183047,19466226,Journal,17,2,9,,,,26,0,,,,"Pedagogy has emphasized that physical representations and tangible interactive objects benefit learning especially for young students. There are many tangible hardware platforms for introducing computer programming to children, but there is limited comparative evaluation of them in the context of a formal classroom. In this work, we explore the benefits of learning to code for tangible computers, such as robots and wearable computers, in comparison to programming for the desktop computer. For this purpose, 36 students participated in a within-groups study that involved three types of target computer platform tangibility: (1) desktop, (2) wearable, and (3) robotic. We employed similar blocks-based visual programming environments, and we measured emotional engagement, attitudes, and computer programming performance. We found that students were more engaged by and had a higher intention of learning programming with the robotic rather than the desktop computer. Furthermore, tangible computing platforms, either robot or wearable, did not affect the students’ performance in learning basic computational concepts (e.g., sequence, repeat, and decision). Our findings suggest that computer programming should be introduced through multiple target platforms (e.g., robots, smartphones, wearables) to engage children.",SI
2-s2.0-85020041140,10.1177/1729881417703930,,,Manipulator motion planning using flexible obstacle avoidance based on model learning,ar,Article,Wei Z.,,Shanghai Jiao Tong University,Shanghai,China,,,,,2017-05-01,May 2017,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,14,3,,,,,7,1,,,,"Traditional manipulator motion planning methods aim to find collision-free paths. But in highly cluttered environments, it is hard to find available solutions. We present a novel motion planning strategy which integrates the sampling-based path planning algorithm with the flexible obstacle avoidance approach for finding the efficient path through changing poses of movable obstacles. Following the resulting path, the manipulator can push the obstacles away and move to the target simultaneously. For dealing with the safety issue of the interaction between manipulator and obstacles, a learning-based motion modeling method is proposed for motion prediction of the obstacles being pushed by manipulator, and then the trained models are utilized in the motion planning. The results from both simulations and real robot experiments show that the proposed method can generate efficient paths which cannot be solved by traditional method.",NO
2-s2.0-85015400447,10.1016/j.cmpb.2017.03.010,S0169260716312895,28391814,Antibiogramj: A tool for analysing images from disk diffusion tests,ar,Article,Alonso C.,,Universidad de La Rioja,Logrono,Spain,,,,,2017-05-01,1 May 2017,Computer Methods and Programs in Biomedicine,01692607,23604,18727565,Journal,143,,,159-169,,,13,0,,,,"Highlights

•

AntibiogramJ determines, measures and categorises inhibition zones of antibiograms.

•

AntibiogramJ deals with images captured with any device that incorporates a camera.

•

AntibiogramJ is user-friendly, open-source, guides users, learns, and stores results.

•

AntibiogramJ provides the benefits of automated readers but without any investment.
Background and objectives

Disk diffusion testing, known as antibiogram, is widely applied in microbiology to determine the antimicrobial susceptibility of microorganisms. The measurement of the diameter of the zone of growth inhibition of microorganisms around the antimicrobial disks in the antibiogram is frequently performed manually by specialists using a ruler. This is a time-consuming and error-prone task that might be simplified using automated or semi-automated inhibition zone readers. However, most readers are usually expensive instruments with embedded software that require significant changes in laboratory design and workflow.

Methods

Based on the workflow employed by specialists to determine the antimicrobial susceptibility of microorganisms, we have designed a software tool that, from images of disk diffusion tests, semi-automatises the process. Standard computer vision techniques are employed to achieve such an automatisation.

Results

We present AntibiogramJ, a user-friendly and open-source software tool to semi-automatically determine, measure and categorise inhibition zones of images from disk diffusion tests. AntibiogramJ is implemented in Java and deals with images captured with any device that incorporates a camera, including digital cameras and mobile phones. The fully automatic procedure of AntibiogramJ for measuring inhibition zones achieves an overall agreement of 87% with an expert microbiologist; moreover, AntibiogramJ includes features to easily detect when the automatic reading is not correct and fix it manually to obtain the correct result.

Conclusions

AntibiogramJ is a user-friendly, platform-independent, open-source, and free tool that, up to the best of our knowledge, is the most complete software tool for antibiogram analysis without requiring any investment in new equipment or changes in the laboratory.",NO
2-s2.0-85007360285,10.1016/j.neucom.2016.08.108,S0925231216313856,,Path planning of multi-agent systems in unknown environment with neural kernel smoothing and reinforcement learning,ar,Article,Cruz D.L.,,Instituto Politécnico Nacional,Mexico City,Mexico,,,,,2017-04-12,12 April 2017,Neurocomputing,09252312,24807,18728286,Journal,233,,,34-42,,,31,0,,,,"Path planning is a basic task of robot navigation, especially for autonomous robots. It is more complex and difficult for multi-agent systems. The popular reinforcement learning method cannot solve the path planning problem directly in unknown environment.

In this paper, the classical multi-agent reinforcement learning algorithm is modified such that it does not need the unvisited state. The neural networks and kernel smoothing techniques are applied to approximate greedy actions by estimating the unknown environment. Experimental and simulation results show that the proposed algorithms can generate paths in unknown environment for multiple agents.",NO
2-s2.0-85041961530,10.1109/LRA.2017.2653850,,,Guiding Trajectory Optimization by Demonstrated Distributions,ar,Article,Osa T.,,Technische Universität Darmstadt,Darmstadt,Germany,,,,,2017-04-01,April 2017,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,2,2,7819469,819-826,,,22,0,,,,"Trajectory optimization is an essential tool for motion planning under multiple constraints of robotic manipulators. Optimization-based methods can explicitly optimize a trajectory by leveraging prior knowledge of the system and have been used in various applications such as collision avoidance. However, these methods often require a hand-coded cost function in order to achieve the desired behavior. Specifying such cost function for a complex desired behavior, e.g., disentangling a rope, is a nontrivial task that is often even infeasible. Learning from demonstration (LfD) methods offer an alternative way to program robot motion. LfD methods are less dependent on analytical models and instead learn the behavior of experts implicitly from the demonstrated trajectories. However, the problem of adapting the demonstrations to new situations, e.g., avoiding newly introduced obstacles, has not been fully investigated in the literature. In this letter, we present a motion planning framework that combines the advantages of optimization-based and demonstration-based methods. We learn a distribution of trajectories demonstrated by human experts and use it to guide the trajectory optimization process. The resulting trajectory maintains the demonstrated behaviors, which are essential to performing the task successfully, while adapting the trajectory to avoid obstacles. In simulated experiments and with a real robotic system, we verify that our approach optimizes the trajectory to avoid obstacles and encodes the demonstrated behavior in the resulting trajectory.",NO
2-s2.0-85013380311,10.1016/j.engappai.2017.02.010,S0952197617300337,,3Dana: A path planning algorithm for surface robotics,ar,Article,Muñoz P.,,Universidad de Alcalá,Alcala de Henares,Spain,,,,,2017-04-01,1 April 2017,Engineering Applications of Artificial Intelligence,09521976,24182,,Journal,60,,,175-192,,,13,0,,,,"Autonomous navigation is a research topic that has received considerable attention in robotics. Generally, it is a two step process: (i) generate a global route to the goal and (ii) local motion of the robot along the route. The focus of this paper is on the first part of the process. Some common techniques used are based on heuristic search algorithms that obtain (sub)optimal paths by usually exploiting a rather simplistic terrain representation. Then, the paths generated hardly take into account relevant terrain features, which leads to potentially unsafe paths in realistic environments. This paper presents two contributions: a mathematical formulation for any DTM that can be used by heuristic search algorithms, and a path planning algorithm that generates candidate paths that are safer than the ones obtained by previous approaches. This algorithm, called 3Dana, considers different parameters to maximize the path quality: the maximum slope allowed by the robot and the heading changes during the path. These constraints allow discarding infeasible paths while minimizing the heading changes. To demonstrate the effectiveness of the algorithm proposed, we present results for different scenarios, which include an evaluation of the algorithm in real Mars DTMs.",NO
2-s2.0-85010726015,10.1007/s11370-017-0217-x,,,Path planning of modular robots on various terrains using Q-learning versus optimization algorithms,ar,Article,Haghzad Klidbary S.,,Sharif University of Technology,Tehran,Iran,,,,,2017-04-01,1 April 2017,Intelligent Service Robotics,18612776,9500154152,18612784,Journal,10,2,,121-136,,,12,0,,,,"Self-reconfigurable modular robots (SRMRs) have recently attracted considerable attention because of their numerous potential applications in the real world. In this paper, we draw a comprehensive comparison among five different algorithms in path planning of a novel SRMR system called ACMoD through an environment comprised of various terrains in a static condition. The contribution of this work is that the reconfiguration ability of ACMoD has been taken into account. This consideration, though raises new algorithmic challenges, equips the robot with new capability to pass difficult terrains rather than bypassing them, and consequently the robot can achieve better performance in terms of traversal time and energy consumption. In this work, four different optimization algorithms, including Adaptive Genetic Algorithm, Elitist Ant System, Dijkstra and Dynamic Weighting A*, along with a well-known reinforcement learning algorithm called Q-Learning, are proposed to solve this path planning problem. The outputs of these algorithms are the optimal path through the environment and the associated configuration on each segment of the path. The challenges involved in mapping the path planning problem to each algorithm are discussed in full details. Eventually, all algorithms are compared in terms of the quality of their solutions and convergence rate.",NO
2-s2.0-84976504418,10.1007/s10514-016-9588-7,,,An incremental nonparametric Bayesian clustering-based traversable region detection method,ar,Article,Lee H.,,Korea Advanced Institute of Science and Technology,Daejeon,South Korea,,,,,2017-04-01,1 April 2017,Autonomous Robots,09295593,18016,15737527,Journal,41,4,,795-810,,,5,0,,,,"Navigation capability in complex and unknown outdoor environments is one of the major requirements for an autonomous vehicle and a robot that perform tasks such as a military mission or planetary exploration. Robust traversability estimation in unknown environments would allow the vehicle or the robot to devise control and planning strategies to maximize their effectiveness. In this study, we present a self-supervised on-line learning architecture to estimate the traversability in complex and unknown outdoor environments. The proposed approach builds a model by clustering appearance data using the newly proposed incremental nonparametric Bayesian clustering algorithm. The clusters are then classified as being either traversable or non-traversable. Because our approach effectively groups unknown regions with similar properties, while the vehicle is in motion without human intervention, the vehicle can be deployed to new environments by automatically adapting to changing environmental conditions. We demonstrate the performance of the proposed clustering algorithm through intensive experiments using synthetic and real data and evaluate the viability of the traversability estimation using real data sets collected in outdoor environment.",NO
2-s2.0-85017269987,10.1145/3014586,,,Configurable detection of SDC-causing errors in programs,ar,Article,Lu Q.,,The University of British Columbia,Vancouver,Canada,,,,,2017-03-01,March 2017,ACM Transactions on Embedded Computing Systems,15399087,10300153313,15583465,Journal,16,3,88,,,,9,0,,,,"Silent Data Corruption (SDC) is a serious reliability issue in many domains, including embedded systems. However, current protection techniques are brittle and do not allow programmers to trade off performance for SDC coverage. Further, many require tens of thousands of fault-injection experiments, which are highly time- and resource-intensive. In this article, we propose two empirical models, SDCTune and SDCAuto, to predict the SDC proneness of a program’s data. Both models are based on static and dynamic features of the program alone and do not require fault injections to be performed. The main difference between them is that SDCTune requires manual tuning while SDCAuto is completely automated, using machine-learning algorithms.

We then develop an algorithm using both models to selectively protect the most SDC-prone data in the program subject to a given performance overhead bound. Our results show that both models are accurate at predicting the relative SDC rate of an application compared to fault injection, for a fraction of the time taken. Further, in terms of efficiency of detection (i.e., ratio of SDC coverage provided to performance overhead), our technique outperforms full duplication by a factor of 0.78x to 1.65x with the SDCTune model and 0.62x to 0.96x with SDCAuto model.",NO
2-s2.0-85015231495,10.1109/TLA.2017.7867603,,,CardBot-Assistive Technology for Visually Impaired in Educational Robotics: Experiments and Results,ar,Article,Barros R.P.,,Universidade Federal do Rio Grande do Norte,Natal,Brazil,,,,,2017-03-01,March 2017,IEEE Latin America Transactions,15480992,19700181218,,Journal,15,3,7867603,517-527,,,6,0,,,,"We proposes an educational assistive methodology aiming to provide the access to educational robotics activities to students with visual impairments or low vision. As an approach to soften the main issues related to this challenging problem, we introduce a low cost, assistive technology, called CardBot 2.0. Basically, this model for teaching-learning is composed by a programming environment, a mobile application, and several geometric cards, each of them representing a specific action that is recognized by the application with a tag. So, the student can program the robot by selecting and organizing geometric cards on the surface of a board or on a table. Also a contribution of this work being part of the solution, the professor can create new cards and register the respective actions and tags. This allows the professor to add new actions for the robot or even to create a new language. We validated our approach by performing experimental classes for students with different visual impairments and ages, and for students without impairment, with an analysis of the results, qualitative.",SI
2-s2.0-85015222515,10.1109/TIP.2017.2654165,,28103555,Robust Head-Pose Estimation Based on Partially-Latent Mixture of Linear Regressions,ar,Article,Drouard V.,,INRIA Institut National de Recherche en Informatique et en Automatique,Le Chesnay,France,,,,,2017-03-01,March 2017,IEEE Transactions on Image Processing,10577149,25534,,Journal,26,3,7819497,1428-1440,,,42,0,,,,"Head-pose estimation has many applications, such as social event analysis, human-robot and human-computer interaction, driving assistance, and so forth. Head-pose estimation is challenging, because it must cope with changing illumination conditions, variabilities in face orientation and in appearance, partial occlusions of facial landmarks, as well as bounding-box-to-face alignment errors. We propose to use a mixture of linear regressions with partially-latent output. This regression method learns to map high-dimensional feature vectors (extracted from bounding boxes of faces) onto the joint space of head-pose angles and bounding-box shifts, such that they are robustly predicted in the presence of unobservable phenomena. We describe in detail the mapping method that combines the merits of unsupervised manifold learning techniques and of mixtures of regressions. We validate our method with three publicly available data sets and we thoroughly benchmark four variants of the proposed algorithm with several state-of-the-art head-pose estimation methods.",NO
2-s2.0-85014156989,10.1145/3043950,,,Teaching physical computing in family workshops,ar,Article,Von Wangenheim C.,,Universidade Federal de Santa Catarina,Florianopolis,Brazil,,,,,2017-03-01,March 2017,ACM Inroads,21532184,19700201136,21532192,Trade Journal,8,1,,48-51,,,2,0,,,,"Family workshops in which children together with a parent learn basic physical computing concepts and programming have proven very successful in popularizing computing in Santa Catarina/Brazil. During the hands-on workshops, participants learn step-by-step how to “give life” to an interactive superhero robot through a simple, lowcost, platform-independent, reliable, and stable strategy integrating a microcontroller, a few hardware parts and block-based visual programming languages. The results of several of these family workshops in Santa Catarina indicate that the workshops enable the learning of basic computing concepts (specifically programming) besides providing additional benefits through the involvement of the families.",SI
2-s2.0-85013649120,10.1109/MRA.2016.2636372,,,Bringing Robotics to Formal Education: The Thymio Open-Source Hardware Robot,ar,Article,Mondada F.,,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,,,,,2017-03-01,March 2017,IEEE Robotics and Automation Magazine,10709932,18027,,Journal,24,1,7859350,77-85,,,53,0,,,,"Mobile robots are valuable tools for education because of both the enthusiasm they raise and the multidisciplinary nature of robotics technology. Mobile robots give access to a wide range of fields, such as complex mechanics, sensors, wireless transmission, mathematics, and computer science. However, despite their potential as educational tools, robots are still not as widespread in schools as they could be. In this article, we identify five key reasons: lack of diversity, high cost, noninclusive design, lack of educational material, and lack of stability over time. Then, we describe our answers to these problems, as we implemented them in the Thymio project: a mature mass-produced open-hardware robot, at a low price, with a multiage and gender-neutral feature set, and with a design promoting creativity, facilitating learning, and providing a wide range of interaction possibilities from built-in behaviors to text programming, passing through different visual programming environments. We highlight some neglected key issues that differentiate open-source hardware from open-source software, for instance the legal uncertainty of designing open hardware using professional computer-aided design (CAD) tools and the difficulty to distribute the development. Our solution to these being to increase the awareness of CAD editors to open-source hardware and to provide a two-layer development model for hardware.",SI
2-s2.0-85012158593,10.5370/JEET.2017.12.2.890,,,Collision prediction based genetic network programming-reinforcement learning for mobile robot navigation in unknown dynamic environments,ar,Article,Findi A.H.M.,,University of Technology- Iraq,Baghdad,Iraq,,,,,2017-03-01,March 2017,Journal of Electrical Engineering and Technology,19750102,17200154707,20937423,Journal,12,2,,890-903,,,6,1,,,,"The problem of determining a smooth and collision-free path with maximum possible speed for a Mobile Robot (MR) which is chasing a moving target in a dynamic environment is addressed in this paper. Genetic Network Programming with Reinforcement Learning (GNP-RL) has several important features over other evolutionary algorithms such as it combines offline and online learning on the one hand, and it combines diversified and intensified search on the other hand, but it was used in solving the problem of MR navigation in static environment only. This paper presents GNP-RL based on predicting collision positions as a first attempt to apply it for MR navigation in dynamic environment. The combination between features of the proposed collision prediction and that of GNP-RL provides safe navigation (effective obstacle avoidance) in dynamic environment, smooth movement, and reducing the obstacle avoidance latency time. Simulation in dynamic environment is used to evaluate the performance of collision prediction based GNP-RL compared with that of two state-of-the art navigation approaches, namely, Q-Learning (QL) and Artificial Potential Field (APF). The simulation results show that the proposed GNP-RL outperforms both QL and APF in terms of smooth movement and safer navigation. In addition, it outperforms APF in terms of preserving maximum possible speed during obstacle avoidance.",NO
2-s2.0-85012012609,10.1016/j.compag.2017.01.008,S016816991630494X,,Weed detecting robot in sugarcane fields using fuzzy real time classifier,ar,Article,Sujaritha M.,,"Sri Krishna College of Engineering and Technology, Coimbatore",Coimbatore,India,,,,,2017-03-01,1 March 2017,Computers and Electronics in Agriculture,01681699,30441,,Journal,134,,,160-171,,,44,0,,,,"Highlights

•

An image classification system is designed by extracting internal leaf textures.

•

A novel fuzzy real-time classifier is developed to automatically classify weed and crop in sugarcane fields.

•

Morphological operators are used to capture the morphological pattern of the crop and weed.

•

A robot carrying Raspberry PI board, camera, motors and power system has been fabricated and tested.

•

The hardware identifies the sugarcane crop from 9 different weed species with 92.9% accuracy.
The objective of this research work is to propose a weed detecting robotic model for sugarcane fields that uses a fuzzy real time classifier on leaf textures. The differentiation between weed and crop and weed removal are the two challenging tasks for the farmers especially in the Indian sugarcane cultivation scenario. The automatic weed detection and removal becomes a vital task for improving the cost effectiveness and efficiency of the agricultural processes. The detection of weeds by the robotic model employs a Raspberry Pi based control system placed in a moving vehicle. An automated image classification system has been designed which extracts leaf textures and employs a fuzzy real-time classification technique. Morphological operators are applied to extract circular leaf patterns in different scales from the leaf images. An optimal set of features have been identified for the characterization of crops and weeds in sugarcane fields. A weed detecting robotic prototype is designed and developed using a Raspberry Pi micro controller and suitable input output subsystems such as cameras, small light sources and motors with power systems. The prototype’s control incorporates the weed detection mechanism using a Raspbian operating system support and python programming. The designed robotic prototype correctly identifies the sugarcane crop among nine different weed species. The system detects weeds with 92.9% accuracy over a processing time of 0.02 s.",NO
2-s2.0-85017623690,10.11975/j.issn.1002-6819.2017.z1.012,,,Path tracking algorithm of vehicles based on fuzzy hyperbolic tangent model,ar,Article,Yang J.,,University of Science and Technology Beijing,Beijing,China,,,,,2017-02-01,1 February 2017,Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering,10026819,62499,,Journal,33,,,78-84,,,2,0,,,,,NO
2-s2.0-85014834735,10.1109/TIE.2016.2613507,,,Episodic Memory-Based Robotic Planning under Uncertainty,ar,Article,Liu D.,,Harbin Institute of Technology;Dalian University of Technology,Harbin;Dalian,China;China,,,,,2017-02-01,February 2017,IEEE Transactions on Industrial Electronics,02780046,26053,,Journal,64,2,7576685,1762-1772,,,11,0,,,,"This paper presents a robotic behavior planning method under uncertainty based on biology-inspired episodic memory. Adaptive behavior planning, prediction and reasoning are achieved between tasks, environment, and threats. Through building a novel episode model and introducing the activation and stimulation mechanism of state neurons, the framework of an episodic memory-driving Markov decision process (EM-MDP) is proposed for incremental self-learning of robotic experience and cognitive behavior planning. Two main challenges in robot behavior control under uncertainty are addressed: high computational complexity and perceptual aliasing. The approach for robotic global planning and behaviors sequence prediction based on the EM-MDP is developed utilizing neuron synaptic potential. A local behavioral planning method based on risk function and feasible paths is employed to achieve path optimization and behavior reasoning under the condition of imperfect memory. Robot can evaluate the past events sequence, predict the current state, and plan the desired behaviors. The proposed method is evaluated in several real-life environments for a mobile robot system. The robot system is able to successfully produce solutions in general scenarios under uncertainty.",NO
2-s2.0-84982168607,10.1007/s10846-016-0408-2,,,An Optimization Based Approach for Relative Localization and Relative Tracking Control in Multi-Robot Systems,ar,Article,Mehrez M.,,Memorial University of Newfoundland,St John's,Canada,,,,,2017-02-01,1 February 2017,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,85,2,,385-408,,,15,0,,,,"In this paper, an optimization based method is used for relative localization and relative trajectory tracking control in Multi-Robot Systems (MRS’s). In this framework, one or more robots are located and commanded to follow time varying trajectories with respect to another (possibly moving) robot reference frame. Such systems are suitable for a considerable number of applications, e.g. patrolling missions, searching operations, perimeter surveillance, and area coverage. Here, the nonlinear and constrained motion and measurement models in an MRS are incorporated to achieve an accurate state estimation algorithm based on nonlinear Moving Horizon Estimation (MHE) and a tracking control method based on Nonlinear Model Predictive Control (NMPC). In order to fulfill the real-time requirements, a fast and efficient algorithm based on a Real Time Iteration (RTI) scheme and automatic C-code generation, is adopted. Numerical simulations are conducted to: first, compare the performance of MHE against the traditional estimator used for relative localization, i.e. extended Kalman filter (EKF); second, evaluate the utilized relative localization and tracking control algorithm when applied to a team of multiple robots; finally, laboratory experiments are performed, for real-time performance evaluation. The conducted simulations validated the adopted algorithm and the experiments demonstrated its practical applicability.",NO
2-s2.0-85070645527,10.30630/joiv.1.4.56,,,Specific language for robot trajectory generation,ar,Article,Yankov K.,,Trakia University,Stara Zagora,Bulgaria,,,,,2017-01-01,2017,International Journal on Informatics Visualization,,21101033322,25499904,Journal,1,4,,157-164,,,1,1,,,,"In this paper, a programming language for describing trajectories of the Mover 4 educational robot is discussed. The goal is to overcome the limitations of the programming tools provided by the manufacturer. Object-oriented structures of trajectories in the joint space and three-dimensional space are formulated. The model of the trajectory in the joint space is represented by the value of the joint, its velocity and acceleration, and the inertial tensor of the configuration from the respective joint to the end-effector. The inertia tensor is necessary to calculate joint forces and moments. A point from the trajectory in three-dimensional space is defined by the Cartesian coordinates of the end-effector, its orientation with the Euler angles and its velocity. Language offers spatial primitives to describe trajectories formed by segments, circle arcs, and cubic splines. Each primitive has a method of generating intermediate points. The language will allow the study of kinematic and dynamic capabilities in tracking trajectories.",NO
2-s2.0-85057755759,10.1109/LRA.2016.2588584,,,Teaching Robots Generalizable Hierarchical Tasks Through Natural Language Instruction,ar,Article,Suddrey G.,,Queensland University of Technology,Brisbane,Australia,,,,,2017-01-01,January 2017,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,2,1,7506292,201-208,,,5,0,,,,"Natural language provides a convenient means of communicating information, and as such, is an ideal medium for enabling nonexpert users to teach robots novel tasks. However, in order to take advantage of natural language, a series of challenges must first be overcome. These challenges include the need to a) generalize learnt tasks to novel scenarios without retraining, b) resolve problems encountered during task execution, and c) derive implicit information from knowledge about the domain. To solve these challenges, this paper presents a novel approach to learning complex hierarchical tasks through natural language instruction, which not only allows learnt tasks to be generalized to novel situations without the need for retraining, but also enables an agent to derive implicit information from domain knowledge. Additionally, the approach presented in this paper enables the agent to infer task properties, such as preconditions and effects, directly from the explanation of the task flow. The authors validate the approach by demonstrating an implementation of the algorithms both on a simulated agent, as well as a Baxter robot. In each case, the agent is provided with a small set of primitive tasks for manipulating its workspace. From these primitives, the authors demonstrate the ability to teach the agent increasing complex tasks, including tasks of table cleaning, solely through natural language instructions.",NO
2-s2.0-85045318262,10.3923/jeasci.2017.2927.2934,,,Learning method of WeDo+scratch based on programming for non-programing major,ar,Article,Choi S.,,Incheon National University,Incheon,South Korea,,,,,2017-01-01,2017,Journal of Engineering and Applied Sciences,1816949X,21100231100,18187803,Journal,12,11,,2927-2934,,,0,0,,,,"For boosting computational thinking skills, the need of SW education has been becoming conspicuous recently and algorithm-based programing education has been conducted. However, new learners, who have never learned programing before, find difficulties understanding the basic syntax and the logic of computer languages in the process of acquiring programming techniques and also find difficulties making out algorithm and converting it into computer language code. These difficulties are due to limited time for acquisition of the techniques. In this study, an education method to draw interest from new learners into programming and develop algorithm thinking skills using the basic syntax of programing and to develop abilities to solve problems that arise in programing shall be introduced. This education makes the concept of SW education easier to approach by interlocking the concept of WeDo constructionism-based robotics built with LEGO Model blocks and scratch-based programing of more effective programing education method to learn and use the basic programing concept through prerequisite.",SI
2-s2.0-85029852256,10.1016/j.promfg.2017.07.230,S2351978917304389,,How to Deploy a Wire with a Robotic Platform: Learning from Human Visual Demonstrations,ar,Article,Stival F.,,Università degli Studi di Padova,Padua,Italy,,,,,2017-01-01,2017,Procedia Manufacturing,,21100792109,23519789,Journal,11,,,224-232,,,1,1,,,,"In this paper, we address the problem of deploying a wire along a specific path selected by an unskilled user. The robot has to learn the selected path and pass a wire through the peg table by using the same tool. The main contribution regards the hybrid use of Cartesian positions provided by a learning procedure and joint positions obtained by inverse kinematics and motion planning. Some constraints are introduced to deal with non-rigid material without breaks or knots. We took into account a series of metrics to evaluate the robot learning capabilities, all of them over performed the targets.",NO
2-s2.0-85028778247,10.1109/ACCESS.2017.2706943,,,A Branch History Directed Heuristic Search for Effective Binary Level Dynamic Symbolic Execution,ar,Article,Hu Y.,,Dalian University of Technology,Dalian,China,,,,,2017-01-01,2017,IEEE Access,,21100374601,21693536,Journal,5,,7932069,8752-8762,,,2,1,,,,"Heuristic search is an important part of modern dynamic symbolic execution (DSE) tools, as heuristic search can be used to effectively explore the large program input space. Searching task remains one of several research challenges due to the fact that the input space grows exponentially with the increase of program size, and different programs may have very different structures. The challenge is compounded in a cyber-physical system or cloud-based Internet of Things environment. In this paper, we propose a novel heuristic search algorithm, which analyzes the program execution history and uses the refined history information to inform the search. This paper is based on the observation that the branch and input history generated during dynamic symbolic execution can help memorize the explored input space, and infer the partial structure of the program. With a summarized branch history, the proposed heuristic search makes informed (and better) decisions about which input area to search next for better efficiency. To evaluate the search algorithm, we implement the core DSE engine, integrated with modules to perform execution history collection and analysis. To make our method practical, we incorporate taint analysis and constraint solving statistics to guide the search algorithm. Experimental results demonstrate that with the rich history information, the new search algorithm can explore the input space more effectively, thus resulting in detecting software defects faster.",NO
2-s2.0-85021826626,10.3966/199115592017062803019,,,Application of two modified autonomous development algorithms in robot obstacle avoidance,ar,Article,Ren H.,,North China University of Science and Technology,Tangshan,China,,,,,2017-01-01,2017,Journal of Computers (Taiwan),19911599,21100228316,2312993X,Journal,28,3,,235-250,,,1,0,,,,234-249,NO
2-s2.0-85021142017,10.1166/asl.2017.7714,,,C programming: Relevant exercises for engineering students using bloom’s taxonomy,ar,Article,Abdul Rahman T.,,Universiti Teknologi MARA,Shah Alam,Malaysia,,,,,2017-01-01,2017,Advanced Science Letters,19366612,19700181106,19367317,Journal,23,4,,2667-2670,,,0,0,,,,"A program is a set of instructions that tell the computers how to accomplish a given task. C is one of the highlevel programming languages that is mostly used for system programming to write embedded system software that interact with hardware. Past assessments and random interviews showed that students from Foundation Engineering Program, Universiti Teknologi MARA, Malaysia face some difficulties in learning the concept of C programming. Therefore, this study was conducted to help the students in learning C programming. The objective of this paper is to frame out a set of C programming exercise using blooms taxonomy that suite with the students’ level. A quantitative research was carried out where by as many as 105 students were involved in answering questionnaires and creating their own set of questions on a specific chapter given. From the set of questions created by the students, it showed that most of the questions fall under the first four levels of bloom’s taxonomy which is remember, understanding, application and analysis. Thus, a set of exercise was framed out by implementing Bloom’s Taxonomy that accord with the student’s level. The new set of exercise was then answered by 82 students and their performance was evaluated to see whether the exercises are relevant to their level or not. Findings revealed that 75% of the scores fall above the first quartile (score = 59.64) which means the set of exercises is relevant to the students’ level because most of them were able to answer the exercises.",NO
2-s2.0-85017144209,10.1155/2017/1850678,,,Escaping Depressions in LRTS Based on Incremental Refinement of Encoded Quad-Trees,ar,Article,Hu Y.,,National University of Defense Technology,Changsha,China,,,,,2017-01-01,2017,Mathematical Problems in Engineering,1024123X,13082,15635147,Journal,2017,,1850678,,,,0,1,,,,"In the context of robot navigation, game AI, and so on, real-time search is extensively used to undertake motion planning. Though it satisfies the requirement of quick response to users’ commands and environmental changes, learning real-time search (LRTS) suffers from the heuristic depressions where agents behave irrationally. There have introduced several effective solutions, such as state abstractions. This paper combines LRTS and encoded quad-tree abstraction which represent the search space in multiresolutions. When exploring the environments, agents are enabled to locally repair the quad-tree models and incrementally refine the spatial cognition. By virtue of the idea of state aggregation and heuristic generalization, our EQ LRTS (encoded quad-tree based LRTS) possesses the ability of quickly escaping from heuristic depressions with less state revisitations. Experiments and analysis show that (a) our encoding principle for quad-trees is a much more memory-efficient method than other data structures expressing quad-trees, (b) EQ LRTS differs a lot in several characteristics from classical PR LRTS which represent the space and refine the paths hierarchically, and (c) EQ LRTS substantially reduces the planning amount and curtails heuristic updates compared with LRTS on uniform cells.",NO
2-s2.0-85015794799,10.1007/978-3-319-55553-9_15,,,The combined use of lego mindstorms NXT and app inventor for teaching novice programmers,ar,Article,Papadakis S.,,University of Crete,Rethymnon,Greece,,,,,2017-01-01,2017,Advances in Intelligent Systems and Computing,21945357,5100152904,,Book Series,560,,,193-204,,,24,0,,,,"Both in Greece and abroad, students in school and in introductory computer science courses perceive programming as a difficult task. Introductory programming courses are often disappointing both for students and for teachers. One of the major factors to which these difficulties in learning programming has been attributed is the traditional approach to teaching the fundamentals of programming, which is unable to provide students with an interesting and richly stimulating environment through which problems and concepts are the subject of investigation in a creative and enjoyable way. In contrast, several studies claim that teachings robotics is suitable to students regardless of age and background and is a way of encouraging learning. This paper presents an alternative use of robotic Lego Mindstorms constructions and the visual programming environment App Inventor for teaching programming with the goal of understanding basic programming structures.",SI
2-s2.0-85015779509,10.1007/978-3-319-55553-9_14,,,The use of robotics in introductory programming for elementary students,ar,Article,Athanasiou L.,,University of Ioannina,Ioannina,Greece,,,,,2017-01-01,2017,Advances in Intelligent Systems and Computing,21945357,5100152904,,Book Series,560,,,183-192,,,2,0,,,,"Studies have shown that teaching programming to students is often a difficult task. The programming language itself is not as much a challenge as the concepts and structures, which define it. This paper explores the use of educational robotics to introduce basic programming concepts through meaningful teaching and learning activities with the hands-on use of bee-bots. The results from an empirical study show that students can successfully develop algorithmic thinking and programming skills based on their knowledge acquired by the bee-bots. Thanks to the tactile interaction with robots, students developed their creativity and imagination as built systems with Lego WeDo, all the while enjoying the course through teamwork activities.",SI
2-s2.0-85015777229,10.1007/978-3-319-55553-9_7,,,Educational robotics and STEM education in primary education: A pilot study using the H&amp;S electronic systems platform,ar,Article,Stergiopoulou M.,,University of Patras,Rio,Greece,,,,,2017-01-01,2017,Advances in Intelligent Systems and Computing,21945357,5100152904,,Book Series,560,,,88-103,,,2,0,,,,"In this paper an attempt is made to utilize educational robotics applications in Primary Education in order to teach basic principles of Automatic Control Systems and Programming. For this purpose, the robotic package H&S Electronic Systems was used in the frame of the STEM education approach. According to the latter, emphasis is given to the connection of the four subjects, Science, Technology, Engineering and Mathematics (STEM). Educational robotics can be proven to be an important tool to achieve these goals, but also to develop students’ motivation to participate in an active way in learning. Within this work the students are asked to work in groups to design, develop and implement their programs to control the behavior of their robotic constructions, following specially designed worksheets. This work, finally, aims to investigate and highlight educational benefits emerging from the data analysis of students’ work.",SI
2-s2.0-85015775218,10.1007/978-3-319-55553-9_17,,,Learning programming with educational robotics: Towards an integrated approach,ar,Article,Xenos M.,,National and Kapodistrian University of Athens,Athens,Greece,,,,,2017-01-01,2017,Advances in Intelligent Systems and Computing,21945357,5100152904,,Book Series,560,,,215-222,,,1,0,,,,"Despite the fact that it has been a few years since robotics entered the school and offered new learning opportunities, educational robotics usually is offered in the context of extra-curricular activity (e.g. a “club”) which addresses a limited number of students and participation is based on student personal interest. In this paper we explore the potential of ER when it is integrated in the typical school curriculum. In the study we report here, we integrated ER in the computer science curriculum and all students of a 9th grade class engaged with robotics activities. The rationale underlying the study is that robotics can be used as a medium to motivate students in engaging with programming and support them to negotiate real life problems. Analysis of the data collected, indicate that ER when integrated with the computer science curriculum, can create a rich learning environment where programming is contextualized and students are highly motivated to engage and negotiate important STEM concepts.",SI
2-s2.0-85015760348,10.1007/978-3-319-55553-9_22,,,Programming constructs in curriculum for educational robotics at lower secondary school,ar,Article,Veselovská M.,,Univerzita Komenského v Bratislave,Bratislava,Slovakia,,,,,2017-01-01,2017,Advances in Intelligent Systems and Computing,21945357,5100152904,,Book Series,560,,,242-245,,,0,0,,,,"In this article we present programming constructs taught to lower secondary school pupils in the context of educational robotics curriculum. It consists of eleven activities with robotic kit LEGO WeDo. Students develop many important skills, such as problem solving skills, programming skills, design and ICT competencies. The development of this curriculum was a part of our dissertation research. The students were in 5th and 6th grade (10–12 years old), studying the school subject Informatics. We used qualitative methods of data collection and data analysis. In this article we present programming constructs such as count loop, conditions, variables and parameters that most of the pupils in our classes acquired. These constructs were based on analysis of programming environment for robotic kit LEGO WeDo.",SI
2-s2.0-85015747010,10.1007/978-3-319-55553-9_13,,,Assessment of lower secondary school pupils’ work at educational robotics classes,ar,Article,Veselovská M.,,Univerzita Komenského v Bratislave,Bratislava,Slovakia,,,,,2017-01-01,2017,Advances in Intelligent Systems and Computing,21945357,5100152904,,Book Series,560,,,170-179,,,0,0,,,,"This paper presents our proposal for assessment of lower secondary pupils working with educational robotics LEGO WeDo, using the curriculum we have designed. The curriculum consisted of eleven activities with complex methodical materials that the teachers can incorporate into their ordinary classes. Teachers can use this curriculum within compulsory subject Informatics and therefore it was necessary to create a way to assess pupils’ work. We have created evaluation through rubrics, because working with robotic kits encompasses several aspects. The assessment focuses on three main aspects: (a) the construction of the robotic model, (b) program to control it and (c) the presentation of mentioned program. In this paper we also describe the concrete example of assessment of pupils’ work using our rubrics.",SI
2-s2.0-85015743306,10.1007/978-3-319-55553-9_2,,,Primary level young makers programming &amp; making electronics with snap4arduino,ar,Article,Pina A.,,Universidad Pública de Navarra,Pamplona,Spain,,,,,2017-01-01,2017,Advances in Intelligent Systems and Computing,21945357,5100152904,,Book Series,560,,,20-33,,,3,0,,,,"The main goal of this study is to show that young makers (8–12 years old) are able to start programming & making electronics with Snap4Arduino, and that this is a way to have (already trained) Makers for secondary level education. We have performed a feasibility study of the Snap4Arduino as an educational tool for elementary school students. The study has been conducted as part of a certified course carried out by the Pamplona’s Planetarium where different skills such as learning to learn or sense of initiative and entrepreneurship were evaluated through a PrBL project based learning methodology. Cooperative learning was achieved focusing on teamwork attitude and behavior.",SI
2-s2.0-85014543344,10.1177/0959651816677198,,,A real-time immune planning algorithm incorporating a specific immune mechanism for multi-robots in complex environments,ar,Article,Yuan M.,,Jiangsu University of Science and Technology,Zhenjiang,China,,,,,2017-01-01,1 January 2017,Proceedings of the Institution of Mechanical Engineers. Part I: Journal of Systems and Control Engineering,09596518,20409,20413041,Journal,231,1,,29-42,,,1,0,,,,"To solve the real-time path planning of multi-robots in complex environments, a new immune planning algorithm incorporating a specific immune mechanism is presented. In the immune planning algorithm incorporating a specific immune mechanism, a new coding format for an antibody is first defined according to the impact of the obstacle distribution on the obstacle avoidance behaviors of multi-robots. Then, a new robot immune dynamic model for antibody selection is designed in terms of different impacts of obstacles and targets on robot behaviors. Finally, aiming at the local minimum problem in complex environments and inspired by the specific immune mechanism, a series of appropriate avoidance behaviors are selected through the calculation of a specific immune mechanism to help robots walk out of local minima. In addition, to solve deadlock situations, a learning strategy for the antibody concentration is presented. Compared with four related immune planning algorithms—an improved artificial potential field, a rapidly exploring random tree algorithm, a D* algorithm and a A* algorithm—the simulation results in four static environments show that the paths planned by immune planning algorithm incorporating a specific immune mechanism are the shortest and the path smoothness is generally the highest, which shows its strong planning capability in multi-obstacle environments. The simulation result in a dynamic environment with local minima shows that the immune planning algorithm incorporating a specific immune mechanism has strong planning ability in dynamic obstacle avoidance and in escaping from local minima. Additionally, an experiment in a multi-robot environment shows that two robots can not only avoid static obstacles but also avoid dynamic obstacles, which further supports the validity of the proposed immune planning algorithm incorporating a specific immune mechanism for multi-robots in real environments.",NO
2-s2.0-85010720990,10.1109/TLA.2017.7827886,,,Development of an automotive scanner for educational application,ar,Article,Camara Chaves J.,,SENAI CIMATEC,Salvador,Brazil,,,,,2017-01-01,January 2017,IEEE Latin America Transactions,15480992,19700181218,,Journal,15,1,7827886,40-47,,,1,0,,,,"This paper deals with the strategy for development of an automotive scanner software for educational application, supplying the gaps created by the shortcomings of automotive electronics embedded systems diagnosis scanners market with respect to use in the classroom. The application of electronic diagnostic devices has become essential in view of the rapid development and growth of electronic embedded systems in automobiles, combined with increasing specialization necessary for professionals working in the maintenance segment and automotive repair. Using a low cost cable interface controller and application protocols established by the Society of Automotive Engineers (SAE), a Java PC application was developed. It allows the teacher to perform fault simulations without the need to modify parts or systems in the vehicle that is being used in class, ensuring greater productivity and safety in their classes.",NO
2-s2.0-85010390722,10.1016/j.envsoft.2017.01.004,S1364815217300221,,A modernized version of a 1D soil vegetation atmosphere transfer model for improving its future use in land surface interactions studies,ar,Article,Anagnostopoulos V.,,National Technical University of Athens;INFOCOSMOS,Athens;Athens,Greece;Greece,,,,,2017-01-01,2017,Environmental Modelling and Software,13648152,23295,,Journal,90,,,147-156,,,9,0,,,,"Highlights

•

Application Programming Interface (API) is now provided to execute SimSphere.

•

A Service Oriented Architecture with Web Service interface added to SimSphere.

•

SimSphere becomes now suitable for HPC use.

•

Developments vital in its future use as standalone tool and for its synergy with EO data.
SimSphere is a land biosphere model that provides a mathematical representation of vertical ‘views’ of the physical mechanisms controlling Earth's energy and mass transfers in the soil/vegetation/atmosphere continuum. Herein, we present recent advancements introduced to SimSphere code, aiming at making its use more integrated to the automation of processes within High Performance Computing (HPC) that allows using the model at large scale. In particular, a new interface to the model is presented, so-called “SimSphere-SOA” which forms a command line land biosphere tool, a Web Service interface and a parameters verification facade that offers a standardised environment for specification execution and result retrieval of a typical model simulation based on Service Oriented Architecture (SOA). SimSphere-SOA library can now execute various simulations in parallel. This allows exploitation of the tool in a simple and efficient way in comparison to the currently distributed approach. In SimSphere-SOA, an Application Programming Interface (API) is also provided to execute simulations that can be publicly consumed. Finally this API is exported as a Web Service for remotely executing simulations through web based tools. This way a simulation by the model can be executed efficiently and subsequently the model simulation outputs may be used in any kind of relevant analysis required.

The use of these new functionalities offered by SimSphere-SOA is also demonstrated using a “real world” simulation configuration file. The inclusion of those new functions in SimSphere are of considerable importance in the light of the model's expanding use worldwide as an educational and research tool.",NO
2-s2.0-85006271509,10.1016/j.knosys.2016.10.023,S0950705116304178,,TextX: A Python tool for Domain-Specific Languages implementation,ar,Article,Dejanović I.,,University of Novi Sad,21000 Novi Sad,Serbia,,,,,2017-01-01,1 January 2017,Knowledge-Based Systems,09507051,24772,,Journal,115,,,1-4,,,13,0,,,,"TextX is a meta-language and a tool for building Domain-Specific Languages in Python. It’s built on top of the Arpeggio PEG parser and takes away the burden of converting parse trees to abstract representations from language designers.

From a single grammar description, textX constructs Arpeggio parser and a meta-model in run-time. The meta-model contains all the information about the language and a set of Python classes inferred from grammar rules. The parser will parse programs/models written in the new language and construct Python object graph a.k.a. the model conforming to the meta-model.

The textX tool has support for error reporting, debugging, and meta-model and model visualization. It is used in industrial environments and teaching Domain-Specific Languages course at the Faculty of Technical Sciences in Novi Sad.

It is a free and open-source software available at GitHub under the MIT license.",NO
2-s2.0-85003674335,10.1016/j.sysarc.2016.06.006,S1383762116300649,,Precise contention-aware performance prediction on virtualized multicore system,ar,Article,Cheng Y.,,Zhejiang University,Hangzhou,China,,,,,2017-01-01,1 January 2017,Journal of Systems Architecture,13837621,12398,,Journal,72,,,42-50,,,9,0,,,,"Highlights

•

Virtualized multicore contention - aware performance prediction model.

•

Virtual machine contention sensitivity and intensity features collection.

•

Quantify the precise levels of performance degradation between VMs.
Multicore systems are widely deployed in both the embedded and the high end computing infrastructures. However, traditional virtualization systems can not effectively isolate shared micro architectural resources among virtual machines (VMs) running on multicore systems. CPU and memory intensive VMs contending for these resources will lead to serious performance interference, which makes virtualization systems less efficient and VM performance less stable. In this paper, we propose a contention-aware performance prediction model on the virtualized multicore systems to quantify the performance degradation of VMs. First, we identify the performance interference factors and design synthetic micro-benchmarks to obtain VM’s contention sensitivity and intensity features that are correlated with VM performance degradation. Second, based on the contention features, we build VM performance prediction model using machine learning techniques to quantify the precise levels of performance degradation. The proposed model can be used to optimize VM performance on multicore systems. Our experimental results show that the performance prediction model achieves high accuracy and the mean absolute error is 2.83%.",NO
2-s2.0-85001950358,10.1016/j.asoc.2016.11.036,S1568494616306056,,Learned Action SLAM: Sharing SLAM through learned path planning information between heterogeneous robotic platforms,ar,Article,Williams H.,,Victoria University of Wellington,Wellington,New Zealand,,,,,2017-01-01,1 January 2017,Applied Soft Computing Journal,15684946,18136,,Journal,50,,,313-326,,,6,0,,,,"Currently when path planning is used in SLAM it is to benefit SLAM only, with no mutual benefit for path planning. Furthermore, SLAM algorithms are generally implemented and modified for individual heterogeneous robotic platforms without autonomous means of sharing navigation information. This limits the ability for robot platforms to share navigation information and can require heterogeneous robot platforms to generate individual maps within the same environment. This paper introduces Learned Action SLAM, which for the first time autonomously combines path-planning with SLAM such that heterogeneous robots can share learnt knowledge through Learning Classifier Systems (LCS). This is in contrast to Active SLAM, where path-planning is used to benefit SLAM only. Results from testing LA-SLAM on robots in the real world have shown; promise for use on teams of robots with various sensor morphologies, implications for scaling to associated domains, and ability to share maps taken from less capable to more advanced robots.",NO
2-s2.0-84950255908,10.1007/s10514-015-9528-y,,,Learning potential functions from human demonstrations with encapsulated dynamic and compliant behaviors,ar,Article,Khansari-Zadeh S.M.,,Stanford University,Palo Alto,United States,,,,,2017-01-01,1 January 2017,Autonomous Robots,09295593,18016,15737527,Journal,41,1,,45-69,,,32,0,,,,"We consider the problem of devising a unified control policy capable of regulating both the robot motion and its physical interaction with the environment. We formulate this control policy by a non-parametric potential function and a dissipative field, which both can be learned from human demonstrations. We show that the robot motion and its stiffness behaviors can be encapsulated by the potential function’s gradient and curvature, respectively. The dissipative field can also be used to model desired damping behavior throughout the motion, hence generating motions that follows the same velocity profile as the demonstrations. The proposed controller can be realized as a unification approach between “realtime motion generation” and “variable impedance control”, with the advantages that it has guaranteed stability as well as does not rely on following a reference trajectory. Our approach, called unified motion and variable impedance control (UMIC), is completely time-invariant and can be learned from a few demonstrations via solving two (convex) constrained quadratic optimization problems. We validate UMIC on a library of 30 human handwriting motions and on a set of experiments on 7-DoF KUKA light weight robot.",NO
2-s2.0-85062037298,10.13245/j.hust.181214,,,Path planning for robots based on deep reinforcement learning by depth constraint,ar,Article,Wang K.,,Harbin Institute of Technology,Harbin,China,,,,,2018-12-23,23 December 2018,Huazhong Keji Daxue Xuebao (Ziran Kexue Ban)/Journal of Huazhong University of Science and Technology (Natural Science Edition),16714512,22382,,Journal,46,12,,77-82,,,2,0,,,,,NO
2-s2.0-85062013159,10.13245/j.hust.181212,,,Robot path planning algorithm based on reinforcement learning,ar,Article,Zhang F.,,Harbin Institute of Technology,Harbin,China,,,,,2018-12-23,23 December 2018,Huazhong Keji Daxue Xuebao (Ziran Kexue Ban)/Journal of Huazhong University of Science and Technology (Natural Science Edition),16714512,22382,,Journal,46,12,,65-70,,,12,0,,,,,NO
2-s2.0-85058018578,10.1108/IR-06-2018-0120,,,Application of mixed reality in robot manipulator programming,ar,Article,Neves J.,,"University of Coimbra, Centre for Mechanical Engineering, Materials and Processes",Coimbra,Portugal,,,,,2018-12-07,7 Dec 2018,Industrial Robot,0143991X,18047,,Journal,45,6,,784-793,,,14,0,,,,"Purpose

Mixed reality is expanding in the industrial market and several companies in various fields are adapting this set of technologies for various purposes, such as optimizing processes, improving the programming tasks and promoting the interactivity of their products with the users, or even improving teaching or training. Robotics is another area that can benefit from these recent technologies. In fact, most of the current and futuristic robotic applications, namely, the areas related to advanced manufacturing tasks (e.g. additive-manufacturing, collaborative robotics, etc.), require new technics to actually perceive the result of several actions, including programming tasks, anticipate trajectories, visualize the motion and related information, interface with programmers and users and several other human–machine interfaces. Consequently, this paper aims to explain a new concept of human–machine interfaces aiming to improve the interaction between advanced users and industrial robotic work cells.

Design/methodology/approach

The presented concept uses two different applications (apps) developed to explore the advanced features of the Microsoft HoloLens device. The objectives of the project reported in this paper are to optimize robot paths, just by allowing the advanced user to adjust the selected path through the mixed reality environment, and create new paths, just by allowing the advanced user to insert points in the mixed reality environment, correct them as needed, connect them using a certain type of motion, parametrize them (in terms of velocity, motion precision, etc.) and command them to the robot controller.

Findings

The solutions demonstrated in this paper show how mixed reality can be used to allow users, with limited programming experience, to fully use the robotics fields. They also show clearly that the integration of the mixed reality technology in the current robot systems will be a turning point in reducing the complexity for end-users.

Research limitations/implications

There are two challenges in the developed applications. The first relates to the robot tool identification, which is very sensitive to lighting conditions or to very complex robot tools. This can result in positioning errors when the software shows the path in the mixed reality scene. The paper presents solutions to overcome this problem. Another unattended challenge is associated with handling the robot singularities when adjusting or creating new paths. Ongoing work is concentrated in creating mechanisms that prevent the end-user to create paths that contain unreachable points or paths that are not feasible because of bad motion parameters.

Practical implications

This paper demonstrates the utilization of mixed reality device to improve the tasks of programming and commanding manufacturing work cells based on industrial robots [see video in (Pires et al., 2018)]. As the presented devices and robot cells are the basis for Industry 4.0 objectives, this demonstration has a vast field of application in the near future, positively influencing the way complex applications, that require much close cooperation between humans and machines, are thought, planned and built. The paper presents two different applications fully ready to use in industrial environments. These applications are scientific experiments designed to demonstrate the principles and technologies of mixed reality applied to industrial robotics, namely, for improving the programming task.

Social implications

Although the HoloLens device opens outstanding new areas for robot command and programming, it is still expensive and somehow heavy for everyday use. Consequently, this opens an opportunity window to combine these devices with other mobile devices, such as tablets and phones, building applications that take advantage of their combined features.

Originality/value

The paper presents two different applications fully ready to use in industrial environments. These applications are scientific experiments designed to demonstrate the principles and technologies of mixed reality applied to industrial robotics, namely, for improving the programming task. The first application is about path visualization, i.e. enables the user to visualize, in a mixed reality environment, any path preplanned for the robot cell. With this feature, the advanced user can follow the robot path, identify problems, associate any difficulty in the final product with a particular issue in the robot paths, anticipate execution problems with impact on the final product quality, etc. This is particularly important for not only advanced applications, but also for cases where the robot path results from a CAD package (in an offline fashion). The second application consists of a graphical path manipulation procedure that allows the advanced user to create and optimize a robot path. Just by exploring this feature, the end-user can adjust any path obtained from any programming method, using the mixed reality approach to guide (visually) the path manipulation procedure. It can also create a completely new path using a process of graphical insertion of point positions and paths into the mixed reality scene. The ideas and implementations of the paper are original and there is no other example in the literature applied to industrial robot programming.",NO
2-s2.0-85056790641,10.1016/j.swevo.2018.03.014,S2210650217306776,,Synergism of Firefly Algorithm and Q-Learning for Robot Arm Path Planning,ar,Article,Sadhu A.K.,,Jadavpur University,Kolkata,India,,,,,2018-12-01,December 2018,Swarm and Evolutionary Computation,22106502,19900192513,,Journal,43,,,50-68,,,29,0,,,,"Over the past few decades, Firefly Algorithm (FA) has attracted the attention of many researchers by virtue of its capability of solving complex real-world optimization problems. The only factor restricting the efficiency of this FA algorithm is the need of having balanced exploration and exploitation while searching for the global optima in the search-space. This balance can be established by tuning the two inherent control parameters of FA. One is the randomization parameter and another is light absorption coefficient, over iterations, either experimentally or by an automatic adaptive strategy. This paper aims at the later by proposing an improvised FA which involves the Q-learning framework within itself. In this proposed Q-learning induced FA (QFA), the optimal parameter values for each firefly of a population are learnt by the Q-learning strategy during the learning phase and applied thereafter during execution. The proposed algorithm has been simulated on fifteen benchmark functions suggested in the CEC 2015 competition. In addition, the proposed algorithm's superiority is tested by conducting the Friedman test, Iman–Davenport and Bonferroni Dunn test. Moreover, its suitability for application in real-world constrained environments has been examined by employing the algorithm in the path planning of a robotic manipulator amidst various obstacles. To avoid obstacles one mechanism is designed for the robot-arm. The results, obtained from both simulation and real-world experiment, confirm the superiority of the proposed QFA over other contender algorithms in terms of solution quality as well as run-time complexity.",NO
2-s2.0-85053797358,10.1016/j.robot.2018.08.016,S0921889017307856,,Context-aware 3D object anchoring for mobile robots,ar,Article,Günther M.,,German Research Center for Artificial Intelligence (DFKI),Kaiserslautern,Germany,,,,,2018-12-01,December 2018,Robotics and Autonomous Systems,09218890,18079,,Journal,110,,,12-32,,,5,0,,,,"Highlights

•

Anchoring system keeps track of objects for robot planning, learning and execution.

•

Builds online graph-based 3D world model of objects in the environment.

•

Can integrate arbitrary object recognition method.

•

Exploits context between objects to improve object recognition results.
A world model representing the elements in a robot’s environment needs to maintain a correspondence between the objects being observed and their internal representations, which is known as the anchoring problem. Anchoring is a key aspect for an intelligent robot operation, since it enables high-level functions such as task planning and execution. This work presents an anchoring system that continually integrates new observations from a 3D object recognition algorithm into a probabilistic world model. Our system takes advantage of the contextual relations inherent to human-made spaces in order to improve the classification results of the baseline object recognition system. To achieve that, the system builds a graph-based world model containing the objects in the scene (both in the current and previously perceived observations), which is exploited by a Probabilistic Graphical Model (PGM) in order to leverage contextual information during recognition. The world model also enables the system to exploit information about objects beyond the current field of view of the robot sensors. Most importantly, this is done in an online fashion, overcoming both the disadvantages of single-shot recognition systems (e.g., limited sensor aperture) and offline recognition systems that require prior registration of all frames of a scene (e.g., dynamic scenes, unsuitability for plan-based robot control). We also propose a novel way to include the outcome of local object recognition methods in the PGM, which results in a decrease in the usually high model learning complexity and an increase in the system performance. The system performance has been assessed with a dataset collected by a mobile robot from restaurant-like settings, obtaining positive results for both its data association and object recognition capabilities. The system has been successfully used in the RACE robotic architecture.",NO
2-s2.0-85052873205,10.1186/s40648-018-0120-z,,,Design of robot programming software for the systematic reuse of teaching data including environment model,ar,Article,Hanai R.,,National Institute of Advanced Industrial Science and Technology,Tsukuba,Japan,,,,,2018-12-01,1 December 2018,ROBOMECH Journal,,21100853738,21974225,Journal,5,1,21,,,,1,1,,,,"The motion of the robot to realize assembly work includes the part where the reuse of the motion adjusted for the real objects is effective and the part where automatic generation in the simulator is suitable. In order to smoothly teach such assembly work, teaching software that enables to combine previously used motions and perform overall adjustment of the workflow and integrated environment representation in the simulator is expected. Some teaching tools focus on the function of making robot motion in detail, and it assumes that the adjustment of the whole workflow including system layout using the real work environment. For this reason, the environmental expression is not sufficient for the above purpose. Although offline teaching tools and motion planning tools are rich in the representation of the environment, there are not many studies on a systematic reuse mechanism of motions adjusted in a real environment, including environment representations. In this paper, we present software design to solve this problem and the implementation of it as a plugin for Choreonoid. By an experiment, we confirmed that we can describe a comparatively complicated assembly work with the proposed software.",NO
2-s2.0-85049862755,10.1177/0278364918781001,,,Data-driven planning via imitation learning,ar,Article,Choudhury S.,,Carnegie Mellon University,Pittsburgh,United States,,,,,2018-12-01,1 December 2018,International Journal of Robotics Research,02783649,18050,17413176,Journal,37,13-14,,1632-1672,,,9,1,,,,"Robot planning is the process of selecting a sequence of actions that optimize for a task=specific objective. For instance, the objective for a navigation task would be to find collision-free paths, whereas the objective for an exploration task would be to map unknown areas. The optimal solutions to such tasks are heavily influenced by the implicit structure in the environment, i.e. the configuration of objects in the world. State-of-the-art planning approaches, however, do not exploit this structure, thereby expending valuable effort searching the action space instead of focusing on potentially good actions. In this paper, we address the problem of enabling planners to adapt their search strategies by inferring such good actions in an efficient manner using only the information uncovered by the search up until that time. We formulate this as a problem of sequential decision making under uncertainty where at a given iteration a planning policy must map the state of the search to a planning action. Unfortunately, the training process for such partial-information-based policies is slow to converge and susceptible to poor local minima. Our key insight is that if we could fully observe the underlying world map, we would easily be able to disambiguate between good and bad actions. We hence present a novel data-driven imitation learning framework to efficiently train planning policies by imitating a clairvoyant oracle: an oracle that at train time has full knowledge about the world map and can compute optimal decisions. We leverage the fact that for planning problems, such oracles can be efficiently computed and derive performance guarantees for the learnt policy. We examine two important domains that rely on partial-information-based policies: informative path planning and search-based motion planning. We validate the approach on a spectrum of environments for both problem domains, including experiments on a real UAV, and show that the learnt policy consistently outperforms state-of-the-art algorithms. Our framework is able to train policies that achieve up to 39% more reward than state-of-the art information-gathering heuristics and a 70× speedup as compared with A* on search-based planning problems. Our approach paves the way forward for applying data-driven techniques to other such problem domains under the umbrella of robot planning.",NO
2-s2.0-85034583395,10.1007/s10846-017-0739-7,,,Experience Learning From Basic Patterns for Efficient Robot Navigation in Indoor Environments,ar,Article,Saha O.,,University of Nebraska at Omaha,Omaha,United States,,,,,2018-12-01,1 December 2018,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,92,3-4,,545-564,,,4,0,,,,"In this paper we propose a machine learning technique for real-time robot path planning for an autonomous robot in a planar environment with obstacles where the robot possess no a priori map of its environment. Our main insight in this paper is that a robot’s path planning times can be significantly reduced if it can refer to previous maneuvers it used to avoid obstacles during earlier missions, and adapt that information to avoid obstacles during its current navigation. We propose an online path planning algorithm called LearnerRRT that utilizes a pattern matching technique called Sample Consensus Initial Alignment (SAC-IA) in combination with an experience-based learning technique to adapt obstacle boundary patterns encountered in previous environments to the current scenario followed by corresponding adaptations in the obstacle-avoidance paths. Our proposed algorithm LearnerRRT works as a learning-based reactive path planning technique which enables robots to improve their overall path planning performance by locally improving maneuvers around commonly encountered obstacle patterns by accessing previously accumulated environmental information. We have conducted several experiments in simulations and hardware to verify the performance of the LearnerRRT algorithm and compared it with a state-of-the-art sampling-based planner. LearnerRRT on average takes approximately 10% of the planning time and 14% of the total time taken by the sampling-based planner to solve the same navigation task based on simulation results and takes only 33% of the planning time, 46% of total time and 95% of total distance compared to the sampling-based planner based on our hardware results.",NO
2-s2.0-85056315648,10.3390/s18113818,,30405084,Real evaluations tractability using continuous goal-directed actions in smart city applications,ar,Article,Fernandez-Fernandez R.,,Universidad Carlos III de Madrid,Madrid,Spain,,,,,2018-11-07,7 November 2018,Sensors (Switzerland),14248220,130124,,Journal,18,11,3818,,,,0,1,,,,"One of the most important challenges of Smart City Applications is to adapt the system to interact with non-expert users. Robot imitation frameworks aim to simplify and reduce times of robot programming by allowing users to program directly through action demonstrations. In classical robot imitation frameworks, actions are modelled using joint or Cartesian space trajectories. They accurately describe actions where geometrical characteristics are relevant, such as fixed trajectories from one pose to another. Other features, such as visual ones, are not always well represented with these pure geometrical approaches. Continuous Goal-Directed Actions (CGDA) is an alternative to these conventional methods, as it encodes actions as changes of any selected feature that can be extracted from the environment. As a consequence of this, the robot joint trajectories for execution must be fully computed to comply with this feature-agnostic encoding. This is achieved using Evolutionary Algorithms (EA), which usually requires too many evaluations to perform this evolution step in the actual robot. The current strategies involve performing evaluations in a simulated environment, transferring only the final joint trajectory to the actual robot. Smart City applications involve working in highly dynamic and complex environments, where having a precise model is not always achievable. Our goal is to study the tractability of performing these evaluations directly in a real-world scenario. Two different approaches to reduce the number of evaluations using EA, are proposed and compared. In the first approach, Particle Swarm Optimization (PSO)-based methods have been studied and compared within the CGDA framework: naïve PSO, Fitness Inheritance PSO (FI-PSO), and Adaptive Fuzzy Fitness Granulation with PSO (AFFG-PSO). The second approach studied the introduction of geometrical and velocity constraints within the CGDA framework. The effects of both approaches were analyzed and compared in the “wax” and “paint” actions, two CGDA commonly studied use cases. Results from this paper depict an important reduction in the number of required evaluations. View Full-Text",NO
2-s2.0-85056654313,10.1002/cae.22003,,,Making image and vision effortless: Learning methodology through the quick and easy design of short case studies,ar,Article,Mateo Sanguino T.,,Universidad de Huelva,Huelva,Spain,,,,,2018-11-01,November 2018,Computer Applications in Engineering Education,10613773,18156,10990542,Journal,26,6,,2102-2115,,,2,0,,,,"Learning on machine vision and image processing generally require high-level knowledge on techniques, algorithms and programming skills. The educational process is frequently supported by formal lecture approaches assisted by object lessons or lab activities, and project-based learning methodologies where students engage complex questions, challenges, and problems over a longer period of time. These educational approaches are not effective when applying to learners in robotics study programs or without a programming background where time and motivation are different. To address this concern, this paper presents an educational tool developed to teach the basic principles of machine vision and image processing through the design of short case studies. As the main contribution, the proposed tool allows to shorten the training time required by students—mainly beginners—without the skills in programming and deep understanding of math hidden behind each image operation. This lets to fit theoretical and practical works into short development times. To this end, we conducted an educational experience in robotics subjects with third year students of the computer science and industrial engineering degrees. As a result of this scenario, we statistically compared the teaching and learning issues, the user preferences about the tool and the student academic performance.",NO
2-s2.0-85043388367,10.1111/coin.12166,,,Optimal path planning for mobile robots using oppositional invasive weed optimization,ar,Article,Panda M.R.,,Siksha O Anusandhan (Deemed to be University),Bhubaneswar,India,,,,,2018-11-01,November 2018,Computational Intelligence,08247935,23737,14678640,Journal,34,4,,1072-1100,,,9,0,,,,"A mobile robot is an autonomous agent, capable of planning the path from source to destination in both, a known, or an unknown environment. In this paper, we presented a novel approach to find the optimal trajectory. We have hybridized oppositional-based learning (OBL) with the evolutionary invasive weed optimization (IWO) technique to generate the optimal path for different robot(s). The navigation algorithm considered in this work is intelligent enough to fulfill the objective of minimizing the path length and the time to reach its specified goal. Oppositional IWO (OIWO) algorithm mimics the colonizing behavior of weed and uses the concept of quasi-opposite number, the concept of OBL is to find the shortest path between source and destination of mobile robot(s). An objective function has been formulated that takes care of the optimal target-seeking behavior as well as the obstacle avoidance of the mobile robot. In this technique, OBL considers the current population generated by IWO algorithm and its opposite population simultaneously to get better and faster convergence. The simulation and experimental results prove and validate the effectiveness of developed OIWO path planning algorithm.",NO
2-s2.0-85042863706,10.1109/TII.2018.2800744,,,Integrating different levels of automation: Lessons from winning the amazon robotics challenge 2016,ar,Article,Corbato C.,,TU Delft Robotics Institute,Delft,Netherlands,,,,,2018-11-01,November 2018,IEEE Transactions on Industrial Informatics,15513203,144912,,Journal,14,11,8304784,4916-4926,,,15,1,,,,"This paper describes Team Delft's robot winning the Amazon Robotics Challenge 2016. The competition involves automating pick and place operations in semistructured environments, specifically the shelves in an Amazon warehouse. Team Delft's entry demonstrated that the current robot technology can already address most of the challenges in product handling: object recognition, grasping, motion, or task planning; under broad yet bounded conditions. The system combines an industrial robot arm, 3-D cameras and a custom gripper. The robot's software is based on the robot operating system to implement solutions based on deep learning and other state-of-the-art artificial intelligence techniques, and to integrate them with off-the-shelf components. From the experience developing the robotic system, it was concluded that: 1) the specific task conditions should guide the selection of the solution for each capability required; 2) understanding the characteristics of the individual solutions and the assumptions they embed is critical to integrate a performing system from them; and 3) this characterization can be based on “levels of robot automation.” This paper proposes automation levels based on the usage of information at design or runtime to drive the robot's behavior, and uses them to discuss Team Delft's design solution and the lessons learned from this robot development experience.",NO
2-s2.0-85041835110,10.1007/s11277-018-5479-x,,,ALIC: A Low Overhead Compiler Optimization Prediction Model,ar,Article,Liu H.,,Henan Normal University;State Key Laboratory of Mathematical Engineering and Advanced Computing,Xinxiang;Zhengzhou,China;China,,,,,2018-11-01,1 November 2018,Wireless Personal Communications,09296212,20725,1572834X,Journal,103,1,,809-829,,,3,0,,,,"Iterative compilation based on machine learning can automatically predict the best optimization for the new programs. However, the efficient prediction models often require repetitive training, which leads to a higher training time overheads, and greatly affects the widespread utilization of the technology. The existing approaches in the prediction model construction often use random sample search strategy, which easily lead to data redundancy. In addition, due to the effect of run-time noises, the sample program is subjected to a fixed number of repetitive observations. However, in the case there is very little noises, the repetitive observations will result in a serious waste of iterative compilation time overheads. Therefore, how to effectively collect the optimal prediction model samples and choose the appropriate sample observations number are the key problem of reducing the iterative compilation overheads. We propose a low overheads iterative compilation optimization parameters prediction model ALIC. First, we describe the target programs by static-dynamic features representation based on feature-class relevance, and construct an initial optimization prediction model by the classifier. Then we use a dynamic number of sample observations strategy for each sample. The most profitable sample from the candidate samples set is selected and marked, each mark is equivalent to increase the number of sample observations. Finally, the optimization prediction model is constructed based on the intermediate prediction model that learns candidate samples actively. The experimental results show that when predicting optimization parameters for the new programs on Intel Xeon E5520 and Chinese Shenwei 26010 platforms, the ALIC model generates 1.38× (by ICC14.0 compiler), 1.35× (by GCC5.4 compiler) average performance improvement on the Xeon platform, and 1.42× (by SW compiler) on the Shenwei Platform. In addition, the ALIC model can significantly reduce the iterative compilation training time overheads than the existing approaches.",NO
2-s2.0-85056658695,10.1088/1741-2552/aae186,,30215610,Gumpy: A Python toolbox suitable for hybrid brain-computer interfaces,ar,Article,Tayeb Z.,,"Fakultät für Elektrotechnik und Informationstechnik, Technische Universität München;Technical University of Munich",Munich;Munich,Germany;Germany,,,,,2018-10-10,10 October 2018,Journal of Neural Engineering,17412560,130164,17412552,Journal,15,6,065003,,,,18,0,,,,"Objective. The objective of this work is to present gumpy, a new free and open source Python toolbox designed for hybrid brain–computer interface (BCI). Approach. Gumpy provides state-of-the-art algorithms and includes a rich selection of signal processing methods that have been employed by the BCI community over the last 20 years. In addition, a wide range of classification methods that span from classical machine learning algorithms to deep neural network models are provided. Gumpy can be used for both EEG and EMG biosignal analysis, visualization, real-time streaming and decoding. Results. The usage of the toolbox was demonstrated through two different offline example studies, namely movement prediction from EEG motor imagery, and the decoding of natural grasp movements with the applied finger forces from surface EMG (sEMG) signals. Additionally, gumpy was used for real-time control of a robot arm using steady-state visually evoked potentials (SSVEP) as well as for real-time prosthetic hand control using sEMG. Overall, obtained results with the gumpy toolbox are comparable or better than previously reported results on the same datasets. Significance. Gumpy is a free and open source software, which allows end-users to perform online hybrid BCIs and provides different techniques for processing and decoding of EEG and EMG signals. More importantly, the achieved results reveal that gumpy's deep learning toolbox can match or outperform the state-of-the-art in terms of accuracy. This can therefore enable BCI researchers to develop more robust decoding algorithms using novel techniques and hence chart a route ahead for new BCI improvements.",NO
2-s2.0-85070874404,10.1145/3178903,,,Tradeoffs in neuroevolutionary learning-based real-time robotic task design in the imprecise computation framework,ar,Article,Huang P.,,University of Nebraska at Omaha,Omaha,United States,,,,,2018-10-01,October 2018,ACM Transactions on Cyber-Physical Systems,2378962X,21100935201,23789638,Journal,3,2,14,,,,3,0,,,,"A cyberphysical avatar is a semi-autonomous robot that adjusts to an unstructured environment and performs physical tasks subject to critical timing constraints while under human supervision. This article first realizes a cyberphysical avatar that integrates three key technologies: body-compliant control, neuroevolution, and real-time constraints. Body-compliant control is essential for operator safety, because avatars perform cooperative tasks in close proximity to humans; neuroevolution (NEAT) enables “programming” avatars such that they can be used by non-experts for a large array of tasks, some unforeseen, in an unstructured environment; and real-time constraints are indispensable to provide predictable, bounded-time response in human-avatar interaction. Then, we present a study on the tradeoffs between three design parameters for robotic task systems that must incorporate at least three dimensions: (1) the amount of training effort for robot to perform the task, (2) the time available to complete the task when the command is given, and (3) the quality of the result of the performed task. A tradeoff study in this design space by using the imprecise computation as a framework is to perform a common robotic task, specifically, grasping of unknown objects. The results were validated with a real robot and contribute to the development of a systematic approach for designing robotic task systems that must function in environments like flexible manufacturing systems of the future.",NO
2-s2.0-85063309705,10.1109/LRA.2018.2849568,,,Path planning and micromanipulation using a learned model,ar,Article,Venkatesan V.,,Purdue University,West Lafayette,United States,,,,,2018-10-01,October 2018,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,3,4,,3089-3096,,,8,1,,,,"This letter presents a system for manipulating microscale objects in an obstacle prone environment using push manipulations based on a learned model. The path planning is done using a RRT* search algorithm adapted for this setup and the manipulation is done using a regression model trained on manipulation data collected a priori . This model is used to capture the dynamics of the micropart and its interaction with the environment such as frictional contacts and other uncertainties that are difficult to model explicitly. The push manipulation is done using probes attached to micromanipulators capable of high-resolution movements. The setup is demonstrated through simulations using two manipulators and a LEGO inspired micropart as it is pushed through different trajectories. Experiments include performing push manipulations in the presence of obstacles, with single and multiple manipulators, and demonstrating the use of the system to perform a microassembly task. The major contribution is a working manipulation system for microparts that implicitly models difficult to model aspects like uncertainties in the environment, such as physical phenomena in the microscale like friction, and the contact interactions between microparts.",NO
2-s2.0-85063308594,10.1109/LRA.2018.2856925,,,The Repetition Roadmap for Repetitive Constrained Motion Planning,ar,Article,Lehner P.,,Deutsches Zentrum fur Luft- Und Raumfahrt, Cologne,Germany,,,,,2018-10-01,October 2018,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,3,4,8412538,3884-3891,,,7,0,,,,"We present the Repetition Roadmap, a motion planner that effectively exploits the repetitiveness of a set of tasks with small variations to efficiently compute new motions. The method learns an abstract roadmap of probability distributions for the configuration space of a particular task set from previous solution paths. We show how to construct the Repetition Roadmap by learning a Gaussian mixture model and connecting the distribution components based on the connectivity information of the prior paths. We present an algorithm that exploits the information in the Repetition Roadmap to guide the search for solutions of similar tasks. We illustrate our method in a maze, which explains the construction of the Repetition Roadmap and how the method can generalize over different environments. We show how to apply the Repetition Roadmap to similar constrained manipulation tasks and present our results including significant speedup in computation time when compared to uniform and adaptive sampling.",NO
2-s2.0-85063307225,10.1109/LRA.2018.2856927,,,Efficient Sampling with Q-Learning to Guide Rapidly Exploring Random Trees,ar,Article,Huh J.,,University of Pennsylvania,Philadelphia,United States,,,,,2018-10-01,October 2018,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,3,4,8412544,3868-3875,,,4,0,,,,"This letter presents a novel approach for efficient sampling of Rapidly-exploring Random Trees (RRTs) based upon learning a state-action value function (Q-function). Our sampling method selects the optimal node to extend in the search tree via the learned state value computed from the node feature representation. Our softmax node selection procedure avoids becoming stuck at local minima and maintains the asymptotic completeness property of RRTs. We employ several features in learning the Q-function, including radial basis function (RBF) scoring of collision and collision-free regions in the configuration space. Since this approach allows the RRT to explore efficiently while avoiding obstacles via the Q-function, the RRT planner is continually adapted to the surrounding environment in an online manner. We compare our proposed method with traditional sampling-based planning algorithms in a number of robot arm planning scenarios and demonstrate the utility and effectiveness of our approach.",NO
2-s2.0-85063307055,10.1109/LRA.2018.2854958,,,Sequence-to-Sequence model for trajectory planning of nonprehensile manipulation including contact model,ar,Article,Kutsuzawa K.,,Saitama University,Saitama,Japan,,,,,2018-10-01,October 2018,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,3,4,8410030,3606-3613,,,5,1,,,,"Nonprehensile manipulation is necessary for robots to operate in humans' daily lives. As nonprehensile manipulation should satisfy both kinematics and dynamics requirements simultaneously, it is difficult to manipulate objects along given paths. Previous studies have considered the problems with sequence-to-sequence models, which are neural networks for time-series conversion. However, they did not consider nonlinear contact models, such as friction models. When we train the seq2seq models using end-to-end backpropagation, training losses vanish owing to static friction. In this letter, we realize sequence-to-sequence models for trajectory planning of nonprehensile manipulation including contact models between the robots and target objects. This letter proposes a training curriculum that commences training without contact models to bring the seq2seq models outside of the gradient-vanishing zone. This letter discusses sliding manipulation, which includes a friction model between objects and tools, such as frying pans fixed onto the robots. We validated the proposed curriculum through a simulation. In addition, we observed that the trained seq2seq models could handle parameter fluctuations that did not exist during training.",NO
2-s2.0-85044441207,10.1016/j.rcim.2018.03.008,S0736584516301910,,Skill-based instruction of collaborative robots in industrial settings,ar,Article,Schou C.,,Aalborg University,Aalborg,Denmark,,,,,2018-10-01,October 2018,Robotics and Computer-Integrated Manufacturing,07365845,18080,,Journal,53,,,72-80,,,41,0,,,,"Highlights

•

A skill-based software system that facilitates easy and fast instruction of collaborative robots by inexperienced operators.

•

A system that can facilitate easy integration of existing off-the-shelf components in terms of hardware and software.

•

Multiple successful demonstrations where the adapt- ability, scalability, and reconfigure-ability of the approach are investigated by deploying it in various real industrial settings.
During the past decades, the increasing need for more flexible and agile manufacturing equipment has spawned a growing interest in collaborative robots. Contrary to traditional industrial robots, collaborative robots are intended for operating alongside the production personnel in dynamic or semi-structured human environments. To cope with the environment and workflow of humans, new programming and control methods are needed compared to those of traditional industrial robots. This paper presents a task-level programming software tool allowing robotic novices to program industrial tasks on a collaborative robot. The tool called Skill Based System (SBS) is founded on the concept of robot skills, which are parameterizable and task-related actions of the robot. Task programming is conducted by first sequencing skills followed by an online parameterization performed using kinesthetic teaching. Through several user studies, SBS is found to enable robotic novices to program industrial tasks. SBS has further been deployed and tested in two manufacturing settings demonstrating its applicability in real industrial scenarios.",NO
2-s2.0-85040942552,10.1109/TASE.2017.2783342,,,MASD: A Multimodal Assembly Skill Decoding System for Robot Programming by Demonstration,ar,Article,Wang Y.,,State Key Laboratory of Industrial Control Technology,Hangzhou,China,,,,,2018-10-01,October 2018,IEEE Transactions on Automation Science and Engineering,15455955,17340,,Journal,15,4,8263146,1722-1734,,,9,0,,,,"Programming by demonstration (PBD) transforms the robot programming from the code level to automated interface between robot and human, promoting the flexibility of robotized automation. In this paper, we focus on programming the industrial robot for assembly tasks by parsing the human demonstration into a series of assembly skills and compiling the skill to the robot executables. To achieve this goal, an identification system using multimodal information to recognize the assembly skill, called MASD, is proposed including: 1) an initial learning stage using a hierarchical model to recognize the action by considering the features from action-object effect, gesture, and trajectory and 2) a retrospective thinking stage using a segmentation method to cut the continuous demonstrations into multiple assembly skills optimally. Using MASD, the demonstration of assembly tasks can be explained with high accuracy in real time, driving a hypothesis that a PBD system on the top of MASD can be extended to more realistic assembly tasks beyond pure positional moving and picking. In experiments, the skill identification module is used to recognize the five kinds of assembly skills in demonstrations of both single and multiple assembly skills, and outperforms the comparative action identification methods. Besides integrated with the MASD, the PBD system can generate the program based on the demonstration and successfully enable an ABB industrial robotic arm simulator to assemble a flashlight and a switch, verifying the initial hypothesis. Note to Practitioners-In the conventional robotized automation, the key role of the robot mainly owes to its capacity for repeating a wide variety of tasks with high speed and accuracy in long term, with a cost of days to months of programming for deployment. On the other hand, the new trend of customization brings the new characteristics: production in short cycle and small volume. This irreversible momentum urges the robot to switch from task to t...
(Show More)",NO
2-s2.0-85067572832,10.17851/1983-3652.11.3.317-330,,,Free robotics and the teaching of physics and programming: Developing an electronic music keyboard,ar,Article,Marques de Andrade T.G.,,Universidade Federal da Paraíba,Joao Pessoa,Brazil,,,,,2018-09-01,September 2018,Texto Livre,,21100833036,19833652,Journal,11,3,,317-330,,,0,1,,,,,NO
2-s2.0-85059076455,10.13195/j.kzyjc.2017.0620,,,Mobile robot autonomous path planning method based on intrinsic motivation mechanism,ar,Article,Zhang X.,,Beijing University of Technology,Beijing,China,,,,,2018-09-01,1 September 2018,Kongzhi yu Juece/Control and Decision,10010920,79015,,Journal,33,9,,1605-1611,,,3,0,,,,,NO
2-s2.0-85051405342,10.1109/JPROC.2018.2849003,,,SMC: Satisfiability Modulo Convex Programming,ar,Article,Shoukry Y.,,"A. James Clark School of Engineering;University of California, Los Angeles;University of California, Berkeley",College Park;Los Angeles;Berkeley,United States;United States;United States,,,,,2018-09-01,September 2018,Proceedings of the IEEE,00189219,17915,15582256,Journal,106,9,8428633,1655-1679,,,17,1,,,,"The design of cyber-physical systems (CPSs) requires methods and tools that can efficiently reason about the interaction between discrete models, e.g., representing the behaviors of “cyber” components, and continuous models of physical processes. Boolean methods such as satisfiability (SAT) solving are successful in tackling large combinatorial search problems for the design and verification of hardware and software components. On the other hand, problems in control, communications, signal processing, and machine learning often rely on convex programming as a powerful solution engine. However, despite their strengths, neither approach would work in isolation for CPSs. In this paper, we present a new satisfiability modulo convex programming (SMC) framework that integrates SAT solving and convex optimization to efficiently reason about Boolean and convex constraints at the same time. We exploit the properties of a class of logic formulas over Boolean and nonlinear real predicates, termed monotone satisfiability modulo convex formulas, whose satisfiability can be checked via a finite number of convex programs. Following the lazy satisfiability modulo theory (SMT) paradigm, we develop a new decision procedure for monotone SMC formulas, which coordinates SAT solving and convex programming to provide a satisfying assignment or determine that the formula is unsatisfiable. A key step in our coordination scheme is the efficient generation of succinct infeasibility proofs for inconsistent constraints that can support conflict-driven learning and accelerate the search. We demonstrate our approach on different CPS design problems, including spacecraft docking mission control, robotic motion planning, and secure state estimation. We show that SMC can handle more complex problem instances than state-of-the-art alternative techniques based on SMT solving and mixed integer convex programming.",NO
2-s2.0-85045182549,10.1016/j.ijcci.2018.03.002,S2212868917300351,,Physical computing with plug-and-play toolkits:Key recommendations for collaborative learning implementations,ar,Article,Katterfeldt E.,,Universität Bremen,Bremen,Germany,,,,,2018-09-01,September 2018,International Journal of Child-Computer Interaction,22128689,21100228541,,Journal,17,,,72-82,,,13,0,,,,"Physical computing toolkits have long been used in educational contexts to learn about computational concepts by engaging in the making of interactive projects. This paper presents a comprehensive toolkit that can help educators teach programming with an emphasis on collaboration, and provides suggestions for its effective pedagogical implementation. The toolkit comprises the Talkoo kit with physical computing plug-and-play modules and a visual programming environment. The key suggestions are inspired by the results of the evaluation studies which show that children (aged 14–18 in a sample group of 34 students) are well motivated when working with the toolkit but lack confidence in the kit’s support for collaborative learning. If the intention is to move beyond tools and code in computer education to community and context, thus encouraging computational participation, collaboration should be considered as a key aspect of physical computing activities. Our approach expands the field of programming with physical computing for teenage children with a focus on empowering teachers and students with not only a kit but also its appropriate classroom implementation for collaborative learning.",SI
2-s2.0-85055895243,10.1080/09720529.2018.1526405,,,Sports mental behaviours of college students based on cluster analysis,ar,Article,Li T.,,Henan Institute of Science and Technology;Wonkwang University,Xinxiang;Iksan,China;South Korea,,,,,2018-08-18,18 August 2018,Journal of Discrete Mathematical Sciences and Cryptography,09720529,19700186892,,Journal,21,6,,1299-1304,,,0,0,,,,"To improve the sports mental behaviours of college students is a subject that should be studied for every physical education teacher in colleges. Cluster analysis can classify samples and help the teachers to adopt the hierarchical teaching model to improve the sports mental behaviours. This paper analyses the necessity of cluster analysis of sports mental behaviours of college students and elaborates the concept and methods of cluster analysis. The process of sports mental behaviours classification of college students based on cluster analysis include four steps of indexes selection, data collection, clustering analysis and result analysis. According to the different psychological behaviour of college students, we use cluster analysis to classify the students into class A, class B and class C to use different kinds of teaching methods for different kinds of students. The cluster analysis based on the psychological behaviour of college students has important reference significance for improving the quality of physical education in colleges.",NO
2-s2.0-85035001913,10.1002/rob.21767,,,Data-driven learning and planning for environmental sampling,ar,Article,Ma K.C.,,University of Southern California,Los Angeles,United States,,,,,2018-08-01,August 2018,Journal of Field Robotics,15564959,4700152301,15564967,Journal,35,5,,643-661,,,30,1,,,,"Robots such as autonomous underwater vehicles (AUVs) and autonomous surface vehicles (ASVs) have been used for sensing and monitoring aquatic environments such as oceans and lakes. Environmental sampling is a challenging task because the environmental attributes to be observed can vary both spatially and temporally, and the target environment is usually a large and continuous domain whereas the sampling data are typically sparse and limited. The challenges require that the sampling method must be informative and efficient enough to catch up with the environmental dynamics. In this paper, we present a planning and learning method that enables a sampling robot to perform persistent monitoring tasks by learning and refining a dynamic “data map” that models a spatiotemporal environment attribute such as ocean salinity content. Our environmental sampling framework consists of two components: To maximize the information collected, we propose an informative planning component that efficiently generates sampling waypoints that contain the maximal information; to alleviate the computational bottleneck caused by large-scale data accumulated, we develop a component based on a sparse Gaussian process whose hyperparameters are learned online by taking advantage of only a subset of data that provides the greatest contribution. We validate our method with both simulations running on real ocean data and field trials with an ASV in a lake environment. Our experiments show that the proposed framework is both accurate in learning the environmental data map and efficient in catching up with the dynamic environmental changes.",NO
2-s2.0-85000997254,10.1007/s00521-016-2717-6,,,Chaotic metaheuristic algorithms for learning and reproduction of robot motion trajectories,ar,Article,Mitić M.,,University of Belgrade,Belgrade,Serbia,,,,,2018-08-01,1 August 2018,Neural Computing and Applications,09410643,24800,,Journal,30,4,,1065-1083,,,13,0,,,,"Most of today’s mobile robots operate in controlled environments prone to various unpredictable conditions. Programming or reprogramming of such systems is time-consuming and requires significant efforts by number of experts. One of the solutions to this problem is to enable the robot to learn from human teacher through demonstrations or observations. This paper presents novel approach that integrates Learning from Demonstrations methodology and chaotic bioinspired optimization algorithms for reproduction of desired motion trajectories. Demonstrations of the different trajectories to reproduce are gathered by human teacher while teleoperating the mobile robot in working environment. The learning (optimization) goal is to produce such sequence of mobile robot actuator commands that generate minimal error in the final robot pose. Four different chaotic methods are implemented, namely chaotic Bat Algorithm, chaotic Firefly Algorithm, chaotic Accelerated Particle Swarm Optimization and newly developed chaotic Grey Wolf Optimizer (CGWO). In order to determine the best map for CGWO, this algorithm is tested on ten benchmark problems using ten well-known chaotic maps. Simulations compare aforementioned algorithms in reproduction of two complex motion trajectories with different length and shape. Moreover, these tests include variation of population in swarm and demonstration examples. Real-world experiment on a nonholonomic mobile robot in indoor environment proves the applicability of the proposed approach.",NO
2-s2.0-85050679106,10.2316/Journal.206.2018.4.206-5084,,,Reinforcement learning and ega-based trajectory planning for dual robots,ar,Article,Liu Y.,,Dalian University of Technology,Dalian,China,,,,,2018-07-26,26 July 2018,International Journal of Robotics and Automation,08268185,25482,,Journal,33,4,,367-378,,,3,0,,,,"In robot drilling processes, generating a smooth drilling trajectory is an important issue to guarantee well-drilling performance. This paper proposed a Markov reinforcement learning model and an im- proved genetic algorithm optimization model to solve such problems. Compared with several common global optimization algorithms, the proposed Markov decision process (MDP) surrogated greedy policy is more eﬀective and accurate in dealing such sequential small-scale decision-making problems under uncertainties. The proposed MDP model is used to generate drilling trajectory in Cartesian space, where quintic splines were applied on motion planning of the tool centre point. Inverse kinematics in the joint space is applied to generate a high smooth trajectory. The damped reciprocals method is used to avoid the singularities generated in motion. The minimum- time motion planning has been discussed based on the combination of elitist genetic algorithm (EGA) and inverse kinematics. At the same time, the kinetic constraints of the axes were set during the movement of the robot manipulators. Simulation results for the 6-DOF serial robots also demonstrate good motion performance and the eﬀectiveness on account of EGA.",NO
2-s2.0-85063306812,10.1109/LRA.2018.2800031,,,Vision-Based Online Adaptation of Motion Primitives to Dynamic Surfaces: Application to an Interactive Robotic Wiping Task,ar,Article,Dometios A.C.,,National Technical University of Athens,Athens,Greece,,,,,2018-07-01,July 2018,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,3,3,,1410-1417,,,6,0,,,,"Elderly or disabled people usually need augmented nursing attention both in home and clinical environments, especially to perform bathing activities. The development of an assistive robotic bath system, which constitutes a central motivation of this letter, would increase the independence and safety of this procedure, ameliorating in this way the everyday life for this group of people. In general terms, the main goal of this letter is to enable natural, physical human-robot interaction, involving human-friendly and user-adaptive online robot motion planning and interaction control. For this purpose, we employ imitation learning using a leader-follower framework called coordinate change dynamic movement primitives (CC-DMP), in order to incorporate the expertise of professional carers for bathing sequences. In this letter, we propose a vision-based washing system, combining CC-DMP framework with a perception-based controller, to adapt the motion of robot's end effector on moving and deformable surfaces, such as a human body part. The controller guarantees globally uniformly asymptotic convergence to the leader movement primitive while ensuring avoidance of restricted areas, such as sensitive skin body areas. We experimentally tested our approach on a setup including the humanoid robot ARMAR-III and a Kinect v2 camera. The robot executes motions learned from the publicly available KIT whole-body human motion database, achieving good tracking performance in challenging interactive task scenarios.",NO
2-s2.0-85060317628,10.1109/LRA.2018.2801479,,,A Solution to Time-Varying Markov Decision Processes,ar,Article,Liu L.,,Indiana University Bloomington,Bloomington,United States,,,,,2018-07-01,July 2018,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,3,3,,1631-1638,,,16,1,,,,"We consider a decision-making problem where the environment varies both in space and time. Such problems arise naturally when considering, e.g., the navigation of an underwater robot amidst ocean currents or the navigation of an aerial vehicle in wind. To model such spatiotemporal variation, we extend the standard Markov decision process (MDP) to a new framework called the time-varying Markov decision process (TVMDP). The TVMDP has a time-varying state transition model and transforms the standard MDP that considers only immediate and static uncertainty descriptions of state transitions, to a framework that is able to adapt to future time-varying transition dynamics over some horizon. We show how to solve a TVMDP via a redesign of the MDP value propagation mechanisms by incorporating the introduced dynamics along the temporal dimension. We validate our framework in a marine robotics navigation setting using spatiotemporal ocean data and show that it outperforms prior efforts.",NO
2-s2.0-85055544839,10.13973/j.cnki.robot.180139,,,Personalized Gait Planning Method for the Lower-Limb Rehabilitation Training Robot with the Physiotherapist Interaction,ar,Article,Guo B.,,Henan University of Science and Technology;Henan Provincial Key Laboratory of Robotics and Intelligent Systems,Luoyang;Luoyang,China;China,,,,,2018-07-01,1 July 2018,Jiqiren/Robot,10020446,18056,,Journal,40,4,,,,,1,0,,,,,NO
2-s2.0-85055471712,10.13973/j.cnki.robot.180164,,,Demonstration Programming and Optimization Method of Cooperative Robot Based on Multi-Source Information Fusion,ar,Article,Wang F.,,Faculty of Robot Science and Engineering,Shenyang,China,,,,,2018-07-01,1 July 2018,Jiqiren/Robot,10020446,18056,,Journal,40,4,,551-559,,,2,0,,,,,NO
2-s2.0-85084177795,10.1145/3211332.3211335,,,MakeCode and CODAL: Intuitive and efficient embedded systems programming for education,ar,Article,Devine J.,,Lancaster University,Lancaster,United Kingdom,,,,,2018-06-19,19 June 2018,ACM SIGPLAN Notices,15232867,19700185000,,Journal,53,6,,19-30,,,3,1,,,,"Across the globe, it is now commonplace for educators to engage in the making (design and development) of embedded systems in the classroom to motivate and excite their students. This new domain brings its own set of unique requirements. Historically, embedded systems development requires knowledge of low-level programming languages, local installation of compilation toolchains, device drivers, and applications. For students and educators, these requirements can introduce insurmountable barriers.

We present the motivation, requirements, implementation, and evaluation of a new programming platform that enables novice users to create software for embedded systems. The platform has two major components: 1) Microsoft MakeCode ( www.makecode.com), a web app that encapsulates an entire beginner IDE for microcontrollers; and 2) CODAL, an efficient component-oriented C++ runtime for microcontrollers. We show how MakeCode and CODAL provide an accessible, cross-platform, installation-free programming experience for the BBC micro:bit and other embedded devices.",SI
2-s2.0-85035079318,10.1016/j.eswa.2017.11.011,S0957417417307613,,Towards a common implementation of reinforcement learning for multiple robotic tasks,ar,Article,Martínez-Tenor A.,,Instituto de Investigación Biomédica de Málaga,Malaga,Spain,,,,,2018-06-15,15 June 2018,Expert Systems with Applications,09574174,24201,,Journal,100,,,246-259,,,17,0,,,,"Highlights

•

A value-iteration-based algorithm is effectively applied to multiple robotic tasks.

•

Novel, efficient method improves softmax action selection by structuring the inputs.

•

Resulted RL method improves model-free solutions with minimal task knowledge.

•

Compatible with high-dimensional RL with low computational cost.

•

A new software framework allows us to test and compare diverse RL algorithms.
Mobile robots are increasingly being employed for performing complex tasks in dynamic environments. Those tasks can be either explicitly programmed by an engineer or learned by means of some automatic learning method, which improves the adaptability of the robot and reduces the effort of setting it up. In this sense, reinforcement learning (RL) methods are recognized as a promising tool for a machine to learn autonomously how to do tasks that are specified in a relatively simple manner. However, the dependency between these methods and the particular task to learn is a well-known problem that has strongly restricted practical implementations in robotics so far. Breaking this barrier would have a significant impact on these and other intelligent systems; in particular, having a core method that requires little tuning effort for being applicable to diverse tasks would boost their autonomy in learning and self-adaptation capabilities. In this paper we present such a practical core implementation of RL, which enables the learning process for multiple robotic tasks with minimal per-task tuning or none. Based on value iteration methods, we introduce a novel approach for action selection, called Q-biased softmax regression (QBIASSR), that takes advantage of the structure of the state space by attending the physical variables involved (e.g., distances to obstacles, robot pose, etc.), thus experienced sets of states accelerate the decision-making process of unexplored or rarely-explored states. Intensive experiments with both real and simulated robots, carried out with the software framework also introduced here, show that our implementation is able to learn different robotic tasks without tuning the learning method. They also suggest that the combination of true online SARSA(λ) (TOSL) with QBIASSR can outperform the existing RL core algorithms in low-dimensional robotic tasks. All of these are promising results towards the possibility of learning much more complex tasks autonomously by a robotic agent.",NO
2-s2.0-85053370902,10.7652/xjtuxb201806006,,,A Deep Learning Frame on Embedded Multicore Processors Based on Caffe and Its Parallel Implementation,ar,Article,Gao R.,,Xi'an Jiaotong University,Xi'an,China,,,,,2018-06-10,10 June 2018,Hsi-An Chiao Tung Ta Hsueh/Journal of Xi'an Jiaotong University,0253987X,26196,,Journal,52,6,,,,,0,0,,,,,NO
2-s2.0-85060735489,10.1049/trit.2018.0016,,,Visual programming language environment for different IoT and robotics platforms in computer science education,ar,Article,de Luca G.,,"School of Computing, Informatics, and Decision Systems Engineering",Tempe,United States,,,,,2018-06-01,1 June 2018,CAAI Transactions on Intelligence Technology,24686557,21100970248,24682322,Journal,3,2,,119-130,,,13,1,,,,"This study presents the authors’ recent research and application of a new visual programming language and its development environment: VIPLE (Visual IoT/Robotics Programming Language Environment) at Arizona State University (ASU). ASU VIPLE supports a variety of IoT devices and robots based on an open architecture. Based on computational thinking, VIPLE supports the integration of engineering design process, workflow, fundamental programming concepts, control flow, parallel computing, event-driven programming, and service-oriented computing seamlessly into a wide range of curricula, such as introduction to computing, introduction to engineering, service-oriented computing, and software integration. It is actively used at ASU in several sections of FSE 100: Introduction to Engineering and in CSE 446: Software Integration and Engineering, as well as in several other universities worldwide.",SI
2-s2.0-85049219296,10.1142/S0218213018600059,,,Motion Planning with Energy Reduction for a Floating Robotic Platform under Disturbances and Measurement Noise Using Reinforcement Learning,ar,Article,Tziortziotis K.,,University of Ioannina,Ioannina,Greece,,,,,2018-06-01,1 June 2018,International Journal on Artificial Intelligence Tools,02182130,4700152645,17936349,Journal,27,4,1860005,,,,1,0,,,,"This paper investigates the use of reinforcement learning for the navigation of an over-actuated, i.e. more control inputs than degrees of freedom, marine platform in unknown environment. The proposed approach uses an online least-squared policy iteration scheme for value function approximation in order to estimate optimal policy, in conjunction with a low-level control system that controls the magnitude of the linear velocity, and the orientation of the platform. Primary goal of the proposed scheme is the reduction of the consumed energy. To that end, we propose a variable reward function that depends on the energy consumption of the platform. We evaluate our approach in a complex and realistic simulation environment and report results concerning its performance on estimating optimal navigation policies under different environmental disturbances, and position GPS measurement noise. The proposed framework is compared, in terms of energy consumption, to a baseline approach based on virtual potential fields. The results show that the marine platform successfully discovers the target point following a sub-optimal path, maintaining reduced energy consumption.",NO
2-s2.0-85048695184,10.1007/s12369-017-0454-3,,,Between the Social and the Technical: Negotiation of Human-Centered Robotics Design in a Middle School Classroom,ar,Article,Gomoll A.,,Indiana University School of Education,Bloomington,United States,,,,,2018-06-01,1 June 2018,International Journal of Social Robotics,18754791,19500157063,18754805,Journal,10,3,,309-324,,,12,0,,,,"This paper presents a middle school human-centered robotics (HCR) learning experience and the ways in which it supported students’ orientation to technical and social aspects of Science, Technology, Engineering, and Mathematics (STEM). The interdisciplinary project associated with this analysis aims to engage diverse students in authentic STEM practices by creating robotic technologies that can assist people in their school, and connect with remote peers. The goal of this project is to increase student interest in and knowledge of STEM topics, and to help students recognize STEM as relevant to their daily lives and broader societal issues. The human-centered focus of the curriculum encouraged thinking from multiple perspectives (e.g. design, social science, programming) and allowed for diverse STEM exploration. We present samples from student work and classroom interactions. These samples show challenges and successes in engaging students with STEM as a combination of social and technical questions and skills. We trace the trajectory of one group’s work to highlight moments in which students navigated an engineering design cycle, analyzed and designed social environments, and crossed disciplinary domains through HCR design—using a phenomena, mechanisms, components framework (PMC) to explore systems thinking. Phenomena refers to attention to the function of the robotic technology in the classroom environment. Components included a focus on single parts of the robot, while mechanism addressed how parts of the robot worked together. This qualitative case study demonstrates the capacity social robotics and inquiry-based learning experiences hold for broadening notions of STEM as a social and multidisciplinary learning domain.",NO
2-s2.0-85048668271,10.1109/TCDS.2017.2655539,,,Adaptive robot path planning using a spiking neuron algorithm with axonal delays,ar,Article,Hwu T.,,"Northrop Grumman corporation;University of California, Irvine",Los Angeles;Irvine,United States;United States,,,,,2018-06-01,June 2018,IEEE Transactions on Cognitive and Developmental Systems,23798920,21100784665,23798939,Journal,10,2,,126-137,,,24,1,,,,"A path planning algorithm for outdoor robots, which is based on neuronal spike timing, is introduced. The algorithm is inspired by recent experimental evidence for experience-dependent plasticity of axonal conductance. Based on this evidence, we developed a novel learning rule that altered axonal delays corresponding to cost traversals and demonstrated its effectiveness on real-world environmental maps. We implemented the spiking neuron path planning algorithm on an autonomous robot that can adjust its routes depending on the context of the environment. The robot demonstrates the ability to plan different trajectories that exploit smooth roads when energy conservation is advantageous, or plan the shortest path across a grass field when reducing distance traveled is beneficial. Because the algorithm is suitable for spike-based neuromorphic hardware, it has the potential of realizing orders of magnitude gains in power efficiency and computational gains through parallelization.",NO
2-s2.0-85010748070,10.1007/s10798-017-9397-0,,,"Dancing robots: integrating art, music, and robotics in Singapore’s early childhood centers",ar,Article,Sullivan A.,,Tufts University,Medford,United States,,,,,2018-06-01,1 June 2018,International Journal of Technology and Design Education,09577572,21389,15731804,Journal,28,2,,325-346,,,39,0,,,,"In recent years, Singapore has increased its national emphasis on technology and engineering in early childhood education. Their newest initiative, the Playmaker Programme, has focused on teaching robotics and coding in preschool settings. Robotics offers a playful and collaborative way for children to engage with foundational technology and engineering concepts during their formative early childhood years. This study looks at a sample of preschool children (N = 98) from five early childhood centers in Singapore who completed a 7-week STEAM (Science, Technology, Engineering, Arts, and Mathematics) KIBO robotics curriculum in their classrooms called, “Dances from Around the World.” KIBO is a newly developed robotics kit that teaches both engineering and programming. KIBO’s actions are programmed using tangible programming blocks—no screen-time required. Children’s knowledge of programming concepts were assessed upon completion of the curriculum using the Solve-Its assessment. Results indicate that children were highly successful at mastering foundational programming concepts. Additionally, teachers were successful at promoting a collaborative and creative environment, but less successful at finding ways to engage with the greater school community through robotics. This research study was part of a large country-wide initiative to increase the use of developmentally appropriate engineering tools in early childhood settings. Implications for the design of technology, curriculum, and other resources are addressed.",SI
2-s2.0-85053922301,10.3969/j.issn.0372-2112.2018.05.035,,,RGB-D Scene Parsing Based on Spatial Structured Inference Deep Fusion Networks,ar,Article,Wang Z.,,Harbin Engineering University,Harbin,China,,,,,2018-05-01,1 May 2018,Tien Tzu Hsueh Pao/Acta Electronica Sinica,03722112,24288,,Journal,46,5,,1253-1258,,,4,0,,,,,NO
2-s2.0-85047391698,10.1177/0278364918771476,,,Towards real-time 3D continuous occupancy mapping using Hilbert maps,ar,Article,Guizilini V.,,The University of Sydney,Sydney,Australia,,,,,2018-05-01,1 May 2018,International Journal of Robotics Research,02783649,18050,17413176,Journal,37,6,,566-584,,,5,0,,,,"The ability to model the surrounding space and determine which areas are occupied is of key importance in many robotic applications, ranging from grasping and manipulation to path planning and obstacle avoidance. Occupancy modeling is often hindered by several factors, such as: real-time constraints, that require quick updates and access to estimates; quality of available data, that may contain gaps and partial occlusions; and memory requirements, especially for large-scale environments. In this work we propose a novel framework that elegantly addresses all these issues, by producing an efficient non-stationary continuous occupancy function that can be efficiently queried at arbitrary resolutions. Furthermore, we introduce techniques that allow the learning of individual features for different areas of the input space, that are better able to model its contained information and promote a higher-level understanding of the observed scene. Experimental tests were conducted on both simulated and real large-scale datasets, showing how the proposed framework rivals current state-of-the-art techniques in terms of computational speed while achieving a substantial decrease (of orders of magnitude) in memory requirements and demonstrating better interpolative powers, that are able to smooth out sparse and noisy information.",NO
2-s2.0-85035123497,10.1007/s11432-016-9115-2,,,Path planning for mobile robot using self-adaptive learning particle swarm optimization,ar,Article,Li G.,,Beihang University,Beijing,China,,,,,2018-05-01,1 May 2018,Science China Information Sciences,1674733X,19600161832,18691919,Journal,61,5,052204,,,,68,0,,,,"As a challenging optimization problem, path planning for mobile robot refers to searching an optimal or near-optimal path under different types of constrains in complex environments. In this paper, a self-adaptive learning particle swarm optimization (SLPSO) with different learning strategies is proposed to address this problem. First, we transform the path planning problem into a minimisation multi-objective optimization problem and formulate the objective function by considering three objectives: path length, collision risk degree and smoothness. Then, a novel self-adaptive learning mechanism is developed to adaptively select the most suitable search strategies at different stages of the optimization process, which can improve the search ability of particle swarm optimization (PSO). Moreover, in order to enhance the feasibility of the generated paths, we further apply the new bound violation handling schemes to restrict the velocity and position of each particle. Finally, experiments respectively with a simulated robot and a real robot are conducted and the results demonstrate the feasibility and effectiveness of SLPSO in solving mobile robot path planning problem.",NO
2-s2.0-85046378997,10.1109/ACCESS.2018.2830661,,,"A Survey of Deep Learning: Platforms, Applications and Emerging Research Trends",ar,Article,Hatcher W.G.,,Towson University,Towson,United States,,,,,2018-04-26,26 April 2018,IEEE Access,,21100374601,21693536,Journal,6,,,24411-24432,,,203,1,,,,"Deep learning has exploded in the public consciousness, primarily as predictive and analytical products suffuse our world, in the form of numerous human-centered smart-world systems, including targeted advertisements, natural language assistants and interpreters, and prototype self-driving vehicle systems. Yet to most, the underlying mechanisms that enable such human-centered smart products remain obscure. In contrast, researchers across disciplines have been incorporating deep learning into their research to solve problems that could not have been approached before. In this paper, we seek to provide a thorough investigation of deep learning in its applications and mechanisms. Specifically, as a categorical collection of state of the art in deep learning research, we hope to provide a broad reference for those seeking a primer on deep learning and its various implementations, platforms, algorithms, and uses in a variety of smart-world systems. Furthermore, we hope to outline recent key advancements in the technology, and provide insight into areas, in which deep learning can improve investigation, as well as highlight new areas of research that have yet to see the application of deep learning, but could nonetheless benefit immensely. We hope this survey provides a valuable reference for new deep learning practitioners, as well as those seeking to innovate in the application of deep learning.",NO
2-s2.0-85056725153,10.1515/itit-2017-0032,,,Empowering learners with tools in CS education: Physical computing in secondary schools,ar,Article,Przybylla M.,,Universität Potsdam,Potsdam,Germany,,,,,2018-04-25,25 April 2018,IT - Information Technology,16112776,21100929583,21967032,Journal,60,2,,,,,4,0,,,,"In computer science, computer systems are both, objects of investigation and tools that enable creative learning and design. Tools for learning have a long tradition in computer science education. Already in the late 1960s, Papert developed a concept which had an immense impact on the development of informal education in the following years: his theory of constructionism understands learning as a creative process of knowledge construction that is most effective when learners create something purposeful that they can try out, show around, discuss, analyse and receive praise for. By now, there are numerous learning and programming environments that are based on the constructionist ideas. Modern tools offer opportunities for students to learn in motivating ways and gain impressive results in programming games, animations, implementing 3D models or developing interactive objects. This article gives an overview of computer science education research related to tools and media to be used in educational settings. We analyse different types of tools with a special focus on the categorization and development of tools for student adequate physical computing activities in the classroom. Research around the development and evaluation of tools and learning resources in the domain of physical computing is illustrated with the example of “My Interactive Garden”, a constructionist learning and programming environment. It is explained how the results from empirical studies are integrated in the continuous development of the learning material.",SI
2-s2.0-85048344347,10.4271/05-11-01-0001,,,Classification of Contact Forces in Human-Robot Collaborative Manufacturing Environments,ar,Article,Zhao R.,,University of Nottingham,Nottingham,United Kingdom,,,,,2018-04-02,2 April 2018,SAE International Journal of Materials and Manufacturing,19463979,19700174666,19463987,Journal,11,1,,,,,1,0,,,,,NO
2-s2.0-85048267278,10.1109/TLA.2018.8362135,,,"Green Robotics: Concepts, challenges, and strategies",ar,Article,Alves Filho S.E.,,Universidade do Estado do Rio Grande do Norte,Mossoro,Brazil,,,,,2018-04-01,April 2018,IEEE Latin America Transactions,15480992,19700181218,,Journal,16,4,,1042-1050,,,3,0,,,,"Green initiatives aim to transform products and processes in order to become friendlier with the environment protection. These concepts are well spread in areas as Chain Supply Management and Computing with several researches worldwide about them. However in the area of Robotics this relevant theme has not being well addressed, with some sporadic and isolated works. Actually, to date, we noticed in the literature the lack of concepts and investigations specifically directed to Green Robotics. Towards this direction, overcome these challenges, this work proposes a formalism on how this concept should be treated in Robotics coming up with an approach in order to allow the adoption of a methodology that can be followed, starting with robot construction and programming until the execution of tasks, all respecting environmental concerns. We show the relationship between concepts that are common in Green Supply Chains, Green Computing, and Green Robotics. Besides, we put examples of strategies that are often used to allow sustainability in Robotics and the types of metrics that can be used to verify them. Finally, math formalism for Green Robotics is introduced, in which the several related issues are approached as a multicriteria optimization problem. The applicability is exemplified through an activity scenario of Educational Robotics.",NO
2-s2.0-85044360445,10.1109/TRO.2018.2793890,,,Cooperative Collision Avoidance for Nonholonomic Robots,ar,Article,Alonso-Mora J.,,"Department of Cognitive Robotics, TU Delft",Delft,Netherlands,,,,,2018-04-01,April 2018,IEEE Transactions on Robotics,15523098,95101,,Journal,34,2,,404-420,,,50,0,,,,"In this paper, we present a method, namely € CCA, for collision avoidance in dynamic environments among interacting agents, such as other robots or humans. Given a preferred motion by a global planner or driver, the method computes a collision-free local motion for a short time horizon, which respects the actuator constraints and allows for smooth and safe control. The method builds on the concept of reciprocal velocity obstacles and extends it to respect the kinodynamic constraints of the robot and account for a grid-based map representation of the environment. The method is best suited for large multirobot settings, including heterogeneous teams of robots, in which computational complexity is of paramount importance and the robots interact with one another. In particular, we consider a set of motion primitives for the robot and solve an optimization in the space of control velocities with additional constraints. Additionally, we propose a cooperative approach to compute safe velocity partitions in the distributed case. We describe several instances of the method for distributed and centralized operation and formulated both as convex and nonconvex optimizations. We compare the different variants and describe the benefits and tradeoffs both theoretically and in extensive experiments with various robotic platforms: robotic wheelchairs, robotic boats, humanoid robots, small unicycle robots, and simulated cars.",NO
2-s2.0-85039973992,10.1109/TLT.2017.2682084,,,A Tool for Introducing Computer Science with Automatic Formative Assessment,ar,Article,Benotti L.,,Universidad Nacional de Córdoba,Cordoba,Argentina,,,,,2018-04-01,April-June 2018,IEEE Transactions on Learning Technologies,19391382,19700167026,,Journal,11,2,,179-192,,,20,0,,,,"In this paper we present a software platform called Chatbot designed to introduce high school students to Computer Science (CS) concepts in an innovative way: by programming chatbots. A chatbot is a bot that can be programmed to have a conversation with a human or robotic partner in some natural language such as English or Spanish. While programming their chatbots, students use fundamental CS constructs such as variables, conditionals, and finite state automata, among others. Chatbot uses pattern matching, state of the art lemmatization techniques, and finite state automata in order to provide automatic formative assessment to the students. When an error is found, the formative feedback generated is immediate and task-level. We evaluated Chatbot in two observational studies. An online nation-wide competition where more than 10,000 students participated. And, a mandatory in-class 15-lesson pilot course in three high schools. We measured indicators of student engagement (task completion, participation, self reported interest, etc.) and found that girls' engagement with Chatbot was higher than boys' for most indicators. Also, in the online competition, the task completion rate for the students that decided to use Chatbot was five times higher than for the students that chose to use the renowned animation and game programming tool Alice. Our results suggest that the availability of automatic formative assessment may have an impact on task completion and other engagement indicators among high school students.",NO
2-s2.0-85039858426,10.1007/s00170-017-1466-8,,,A STEP-NC compliant robotic machining platform for advanced manufacturing,ar,Article,Toquica J.S.,,Universidade de Brasília,Brasilia,Brazil,,,,,2018-04-01,1 April 2018,International Journal of Advanced Manufacturing Technology,02683768,20428,14333015,Journal,95,9-12,,3839-3854,,,18,0,,,,"In the era of advanced, intelligent, and flexible manufacturing, machining with industrial robots, it is expected to be set up in the next few years. This is due to the vast progress of these robots in terms of precision and stiffness. Moreover, there is a recent development of off-line programming. Consequently, industrial robots offer a real gain of modularity, flexibility, and access for machining on production lines, and are viable solutions to improve the productivity. At the same time, all the potentials of CAD/CAM solutions available for machining off-line programming are not fully exploited because of old G-code (ISO 6963, 1980) language that only enables the description of elementary actions and tools moves. In the context of Industry 4.0 and the development of smart equipments at all levels of production chain, the manufacturing digital thread has to be profoundly reconsidered in order to guarantee high-level information from the design to the manufacturing. In this paper, a solution is proposed based on the high-level programming STEP-NC standard combined with a suitable CAD/CAM solution for industrial robots machining. A complete platform has been developed to enable advanced and intelligent manufacturing with the possibility to integrate several modules of simulation, optimization, and visualization, as well as in-process fabrication adaptation, cloud manufacturing, and machine learning with database analytics.",NO
2-s2.0-85038814062,10.1016/j.neucom.2017.12.012,S0925231217318398,,Torque sensorless decentralized neuro-optimal control for modular and reconfigurable robots with uncertain environments,ar,Article,Dong B.,,Institute of Automation Chinese Academy of Sciences;Changchun University of Technology,Beijing;Changchun,China;China,,,,,2018-03-22,22 March 2018,Neurocomputing,09252312,24807,18728286,Journal,282,,,60-73,,,16,0,,,,"A technical challenge of addressing the decentralized optimal control problem for modular and reconfigurable robots (MRRs) during environmental contacts is associated with optimal compensation of the uncertain contact force without using force/torque sensors. In this paper, a decentralized control approach is presented for torque sensorless MRRs in contact with uncertain environment via an adaptive dynamic programming (ADP)-based neuro-optimal compensation strategy. The dynamic model of the MRRs is formulated based on a novel joint torque estimation method, which is deployed for each joint model, and the joint dynamic information is utilized effectively to design the feedback controllers, thus making the decentralized optimal control problem of the environmental contacted MRR systems be formulated as an optimal compensation issue of model uncertainty. By using the ADP method, a local online policy iteration algorithm is employed to solve the Hamilton–Jacobi–Bellman (HJB) equation with a modified cost function, which is approximated by constructing a critic neural network, and then the approximate optimal control policy can be derived. The asymptotic stability of the closed-loop MRR system is proved by using the Lyapunov theory. At last, simulations and experiments are performed to verify the effectiveness of the proposed method.",NO
2-s2.0-85043790856,10.1109/TCDS.2016.2647439,,,"A Modular Dynamic Sensorimotor Model for Affordances Learning, Sequences Planning, and Tool-Use",ar,Article,Braud R.,,CY Cergy Paris Université,Cergy-Pontoise,France,,,,,2018-03-01,March 2018,IEEE Transactions on Cognitive and Developmental Systems,23798920,21100784665,23798939,Journal,10,1,,72-87,,,4,0,,,,"This paper proposes a computational model for learning robot control and sequence planning based on the ideomotor principle. This model encodes covariation laws between sensors and motors in a modular fashion and exploits these primitive skills to build complex action sequences, potentially involving tool-use. Implemented for a robotic arm, the model starts with raw unlabeled sensor and motor vectors and autonomously assigns functions to neutral objects in the environment. Our experimental evaluation highlights the emergent properties of such a modular system and we discuss their consequences from ideomotor and sensorimotor-theoretic perspectives.",NO
2-s2.0-85042624828,10.1016/j.robot.2017.12.001,S0921889017302981,,Robot learning from demonstrations: Emulation learning in environments with moving obstacles,ar,Article,Ghalamzan E. A.M.,,University of Birmingham,Birmingham,United Kingdom,,,,,2018-03-01,March 2018,Robotics and Autonomous Systems,09218890,18079,,Journal,101,,,45-56,,,25,0,,,,"Highlights

•

We present an approach to robot learning from demonstrations in dynamic environments.

•

The robot learns the task from demonstrations in a stationary environment.

•

The robot is then able to generalise and perform the task in dynamic environments.

•

We demonstrate the effectiveness of the approach with pick-and-place by YuMi robot.
In this paper, we present an approach to the problem of Robot Learning from Demonstration (RLfD) in a dynamic environment, i.e. an environment whose state changes throughout the course of performing a task. RLfD mostly has been successfully exploited only in non-varying environments to reduce the programming time and cost, e.g. fixed manufacturing workspaces. Non-conventional production lines necessitate Human–Robot Collaboration (HRC) implying robots and humans must work in shared workspaces. In such conditions, the robot needs to avoid colliding with the objects that are moved by humans in the workspace. Therefore, not only is the robot: (i) required to learn a task model from demonstrations; but also, (ii) must learn a control policy to avoid a stationary obstacle. Furthermore, (iii) it needs to build a control policy from demonstration to avoid moving obstacles. Here, we present an incremental approach to RLfD addressing all these three problems. We demonstrate the effectiveness of the proposed RLfD approach, by a series of pick-and-place experiments by an ABB YuMi robot. The experimental results show that a person can work in a workspace shared with a robot where the robot successfully avoids colliding with him.",NO
2-s2.0-85031321658,10.1016/j.chb.2017.09.029,S0747563217305551,,"Phogo: A low cost, free and “maker” revisit to Logo",ar,Article,Molins-Ruano P.,,Universidad Autónoma de Madrid,Madrid,Spain,,,,,2018-03-01,March 2018,Computers in Human Behavior,07475632,19419,,Journal,80,,,428-440,,,4,0,,,,"Highlights

•

A new robotic platform for developing computational thinking is proposed: Phogo.

•

Phogo is inspired in the LOGO project, but with a maker and open approach.

•

Phogo has a low cost and uses Python as the programing language.

•

The use of a physical robot is an opportunity for students with disabilities.
Today it is almost impossible to spend a single day without depending on an information system, a computer or any other form of computation. Though the starting barrier is low, fundamental concepts are still required in order to manage the technicalities of the engineering environment and everyday computational systems. In 1967, Logo proposed to teach abstract programming concepts by providing a set of functions that had intuitive, visible effects over a robotic Turtle. LOGO was a success, but the robots quickly migrated into computer simulations. From LOGO, many followed. Scratch and Lego Mindstorm are some of the most notorious examples. Both introduced graphical block-based programming interfaces. We propose to bring back the powerful ideas behind LOGO by updating it with state of the art technologies. Phogo combines Python, Arduino and 3D printing into a low cost robot that is easy to build and control. The robot has a pen to draw shapes and can be commanded from a computer via a wireless link that is transparent to the students. The use of a physical robot can make programming more accessible for students with disabilities. The open and maker philosophies behind Phogo makes it more interesting as students will be able to access and study the electronic components. The textual programing language can be a long life companion for the students. In this work we discuss LOGO and other projects inspired by it, and we also share the methodology and design decisions behind Phogo, the results of its application in a workshop and the improvements we are currently developing.",SI
2-s2.0-85056261091,10.11936/bjutxb2017020014,,,Humanoid Robot Imitation Learning Based on COM Correction and Compensation,ar,Article,Yu J.,,Beijing University of Technology;Beijing Key Laboratory of Computational Intelligence and Intelligent System,Beijing;Beijing,China;China,,,,,2018-02-01,1 February 2018,Beijing Gongye Daxue Xuebao/Journal of Beijing University of Technology,02540037,145725,,Journal,44,2,,193-199,,,2,0,,,,,NO
2-s2.0-85044504702,10.1109/RITA.2018.2801898,,,Integrating Formative Feedback in Introductory Programming Modules,ar,Article,Anfurrutia F.I.,,Universidad del Pais Vasco,Leioa,Spain,,,,,2018-02-01,February 2018,Revista Iberoamericana de Tecnologias del Aprendizaje,,19700201532,19328540,Journal,13,1,,3-10,,,0,0,,,,"Introductory programming modules are challenging for both the lecturers and students. In previous works, the authors have introduced educational innovations to mitigate these challenges and facilitate learning. This paper presents a further step forward, proposing a learning process enriched with formative feedback. To this end, visual programming environments and educational robots are combined and complemented with automatic source code verification and validation feedback. The feedback integration proposal is presented along with the lessons learned from previously carried out experiments that established the basis of this paper. The proposal has been implemented and tested in the object oriented programming module in the bachelor's in computer management and information systems engineering at the Faculty of Engineering of Vitoria-Gasteiz, UPV/EHU University. The results of the evaluation have been positive and are also presented here.",SI
2-s2.0-85030121361,10.1016/j.eswa.2017.09.023,S0957417417306243,,Automatic discovery of concepts and actions,ar,Article,Tenorio-González A.,,Instituto Nacional de Astrofisica Optica y Electronica,Puebla,Mexico,,,,,2018-02-01,February 2018,Expert Systems with Applications,09574174,24201,,Journal,92,,,192-205,,,2,0,,,,"Highlights

•

Our method ADC simultaneously discovers relational concepts and learns behaviors.

•

ADC automatically constructs its representation of the environment by exploration.

•

ADC introduces novel mechanisms to automatically drive its own learning process.

•

Knowledge incrementally learned by ADC in a task can be re-used in other tasks.

•

Knowledge representation used in ADC is easy to understand by humans.
A truly autonomous artificial intelligence agent should be able to drive its own learning process. That is, decide what to explore and what to learn, identifying what constitutes potential useful data as examples of concepts or what strategy to follow to solve a new task. Different efforts have been developed in machine learning towards this aim. Approaches that introduce new concepts, like predicate invention in Inductive Logic Programming (ILP) techniques, normally require the selection of examples by the user. Techniques that learn behavior policies through exploration like Reinforcement Learning (RL) with intrinsic motivation, to guide the agent into interesting areas to discover new goals, assume that all the states and actions are predefined in advance. In this paper, we describe a system, called ADC, that combines techniques from ILP with predicate invention and RL with intrinsic motivation to discover new concepts, states and actions to learn behavior policies. ADC drives its own learning process, collecting its own examples for autonomously learning concepts. These new concepts can be used to describe its environment and define new states and actions used to learn behaviors to solve tasks. We show the effectiveness of our approach in simulated robotics environments.",NO
2-s2.0-85019620537,10.1016/j.neucom.2017.05.015,S0925231217308238,,Automatic illumination planning for robot vision inspection system,ar,Article,Wang H.,,Shanghai Jiao Tong University,Shanghai,China,,,,,2018-01-31,31 January 2018,Neurocomputing,09252312,24807,18728286,Journal,275,,,19-28,,,12,0,,,,"High-quality original image is very important in robot vision inspection system and illumination is a significant component that directly affect cameras optical imaging system and plays a decisive role on image quality. To guarantee camera imaging system for high-quality images and achieve automatic illumination control in the motion of inspection robot under dark environment, this paper proposes an optimal light intensity planning method based image quality analysis. It is mainly achieved by building a computational model to automatically predict optimal light intensity values for desired image quality when camera observation distances fluctuate. Before regression modeling, it is necessary to extract discriminative features representing image quality. We design feature extractor by deep learning instead of human engineers which required careful engineering and considerable domain expertise. Deep learning methods are representation-learning methods that allows a machine to be fed with raw data and to automatically discover the representations needed for regression or classification. Experimental results demonstrate the feasibility and efficiency of this method.",NO
2-s2.0-85040995337,10.1080/16864360.2017.1419642,,,Using collaborative robots to assist with travel path development for material deposition based additive manufacturing processes,ar,Article,Djuric A.,,Wayne State University,Detroit,United States,,,,,2018-01-10,10 January 2018,Computer-Aided Design and Applications,16864360,4700151607,,Journal,15,4,,542-555,,,2,1,,,,,NO
2-s2.0-85062662049,10.26583/sv.10.5.05,,,The image analysis of the geometric bodies with supplemental interactive block for training new knowledge in a limited natural language,ar,Article,Volchenkov N.,,National Research Nuclear University MEPhI,Moscow,Russian Federation,,,,,2018-01-01,2018,Scientific Visualization,,21100244604,20793537,Journal,10,5,,57-85,,,0,0,,,,,NO
2-s2.0-85059448921,10.11591/ijece.v8i2.pp1230-1237,,,Tool use learning for a real robot,ar,Article,Wicaksono H.,,Universitas Kristen Petra;UNSW Sydney,"Surabaya, East Java;Sydney",Indonesia;Australia,,,,,2018-01-01,2018,International Journal of Electrical and Computer Engineering,20888708,21100373959,,Journal,8,2,,1230-1237,,,3,1,,,,"A robot may need to use a tool to solve a complex problem. Currently, tool use must be pre-programmed by a human. However, this is a difficult task and can be helped if the robot is able to learn how to use a tool by itself. Most of the work in tool use learning by a robot is done using a feature-based representation. Despite many successful results, this representation is limited in the types of tools and tasks that can be handled. Furthermore, the complex relationship between a tool and other world objects cannot be captured easily. Relational learning methods have been proposed to overcome these weaknesses [1, 2]. However, they have only been evaluated in a sensor-less simulation to avoid the complexities and uncertainties of the real world. We present a real world implementation of a relational tool use learning system for a robot. In our experiment, a robot requires around ten examples to learn to use a hook-like tool to pull a cube from a narrow tube.",NO
2-s2.0-85058320033,10.3389/frobt.2018.00110,,,Stage-wise learning of reaching using little prior knowledge,ar,Article,de La Bourdonnaye F.L.,,CNRS Centre National de la Recherche Scientifique,Paris,France,,,,,2018-01-01,2018,Frontiers Robotics AI,,21100868821,22969144,Journal,5,OCT,110,,,,3,1,,,,"In some manipulation robotics environments, because of the difficulty of precisely modeling dynamics and computing features which describe well the variety of scene appearances, hand-programming a robot behavior is often intractable. Deep reinforcement learning methods partially alleviate this problem in that they can dispense with hand-crafted features for the state representation and do not need pre-computed dynamics. However, they often use prior information in the task definition in the form of shaping rewards which guide the robot toward goal state areas but require engineering or human supervision and can lead to sub-optimal behavior. In this work we consider a complex robot reaching task with a large range of initial object positions and initial arm positions and propose a new learning approach with minimal supervision. Inspired by developmental robotics, our method consists of a weakly-supervised stage-wise procedure of three tasks. First, the robot learns to fixate the object with a 2-camera system. Second, it learns hand-eye coordination by learning to fixate its end-effector. Third, using the knowledge acquired in the previous steps, it learns to reach the object at different positions and from a large set of initial robot joint angles. Experiments in a simulated environment show that our stage-wise framework yields similar reaching performances, compared with a supervised setting without using kinematic models, hand-crafted features, calibration parameters or supervised visual modules.",NO
2-s2.0-85057779043,10.1109/ACCESS.2018.2883504,,,Optimal PI<sup>λ</sup> D<sup>μ</sup> controller design for two wheeled inverted pendulum,ar,Article,Erkol H.,,Karabük Üniversitesi,Karabuk,Turkey,,,,,2018-01-01,2018,IEEE Access,,21100374601,21693536,Journal,6,,8548547,75709-75717,,,15,1,,,,"Fractional order controllers have a growing popularity in last years and they give more flexibility to researchers for designing a controller. In this paper, a fractional order PID controller is designed for the position control of a two wheeled inverted pendulum. The pendulum is modeled with DC electrical motors to obtain a more realistic model. Integer order PID controller is also designed to make a comparison with fractional order controller and all controllers are optimized by swarm algorithms to be sure obtained the best performance for each controller. A fractional order PID controller has two extra parameters (λ and μ) and totally five parameters to be optimized. Optimization algorithms are powerful tools for designing a controller, and guarantee finding an optimum result. However, each optimization algorithm has a different performance not only because of the structure of the algorithm but also depending on the optimization problem. Because of this, four popular optimization algorithms (artificial bee colony, particle swarm optimization, grey wolf optimizer, and cuckoo search algorithm) are used to tune controller parameters, and compared regard with the optimized system performance. The results show that the best performance is obtained by the fractional order PID controller, which optimized by artificial bee colony algorithm. The fractional order PID controllers have also better performance than integer order PIDs when used the same optimization algorithm for tuning.",NO
2-s2.0-85057189926,10.1109/ACCESS.2018.2882875,,,RL and ANN based modular path planning controller for resource-constrained robots in the indoor complex dynamic environment,ar,Article,Ullah Z.,,Institute of Computing Technology Chinese Academy of Sciences;University of Chinese Academy of Sciences,Beijing;Beijing,China;China,,,,,2018-01-01,2018,IEEE Access,,21100374601,21693536,Journal,6,,8543176,74557-74568,,,3,1,,,,"Traditional Reinforcement Learning (RL) approaches are designed to work well in static environments. In many real-world scenarios, the environments are complex and dynamic, in which the performance of traditional RL approaches may drastically degrade. One of the factors which results in the dynamicity and complexity of the environment is a change in the position and number of obstacles. This paper presents a path planning approach for autonomous mobile robots in a complex dynamic indoor environment, where the dynamic pattern of obstacles will not drastically affect the performance of RL models. Two independent modules, collision avoidance without considering the goal position and goal-seeking without considering obstacles avoidance, are trained independently using artificial neural networks and RL to obtain their best control policies. Then, a switching function is used to combine the two trained modules for realizing the obstacle avoidance and global path planning in a complex dynamic indoor environment. Furthermore, this control system is designed with a special focus on the computational and memory requirements of resource-constrained robots. The design was tested in a real-world environment on a mini-robot with constrained resources. Along with the static and dynamic obstacles' avoidance, this system has the ability to achieve both static and dynamic targets. This control system can also be used to train a robot in the real world using RL when the robot cannot afford to collide. Robot behavior in the real ground shows a very strong correlation with the simulation results.",NO
2-s2.0-85056135452,10.3991/ijet.v13i10.9463,,,Matlab-realized visual A* path planning teaching platform,ar,Article,Luo M.,,Sichuan Technology and Business College,Dujiangyan,China,,,,,2018-01-01,2018,International Journal of Emerging Technologies in Learning,18688799,21100197967,18630383,Journal,13,10,,196-207,,,2,1,,,,"Path planning in the global known environment is one of the main prob-lems in the field of mobile robots. Based on the characteristics of A* search method, this paper designs a simulation platform which is visible during the op-eration process to achieve graphicalization of the A* algorithm search process. The simulation platform is implemented by Matlab GUI method, which provides multi-parameter setting function, and outputs the specific traversal process of the planning method in the search space into the RGB space. The results of applying simulation platform to the teaching environment shows that this platform can provide an intuitive description of the path planning method. By extracting sam-ple data from the actual audience, the simulation platform proposed in this paper is compared with the platformless dissemination method. The experimental re-sults show that the simulation platform given in this paper can effectively im-prove the dissemination effect of the conventional multimedia teaching method.",NO
2-s2.0-85054512596,10.1109/ACCESS.2018.2873718,,,Reactive execution of learned tasks with real-time collision avoidance in a dynamic environment,ar,Article,Liu G.,,Harbin Institute of Technology,Harbin,China,,,,,2018-01-01,2018,IEEE Access,,21100374601,21693536,Journal,6,,8481490,57366-57375,,,2,1,,,,"This paper addresses the problem of learning from demonstration (LfD) and subsequent robot safety control in an unstructured dynamic environment different from the demonstrations. Generally, LfD has been successfully exploited for task programming, but the existing methods have not solved the problem of allowing the entire arm to avoid obstacles while satisfying the task motion constraints (e.g., the robotic arm approaching the target object while avoiding obstacles moving within the environment). To achieve this, we present an incremental LfD approach that combines a task-parameterized probabilistic model and the robot security domain to control a robot's behavior during task execution. Specifically, we propose a safety-oriented and task-oriented control strategy for redundant manipulators that makes full use of the motion redundancy of the manipulator and the space with no task restraints to satisfy the task constraints for human-robot coexistence. We then demonstrate the effectiveness of the proposed approach through a series of pick-and-pour experiments performed by a manipulator with 7 degree of freedom in a dynamic environment, where the robot must both avoid obstacles and satisfactorily complete the learned task with constraints.",NO
2-s2.0-85054477378,10.1109/LRA.2017.2749280,,,Integration of Planning and Deformation Model Estimation for Robotic Cleaning of Elastically Deformable Objects,ar,Article,Langsfeld J.D.,,A. James Clark School of Engineering,College Park,United States,,,,,2018-01-01,January 2018,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,3,1,8025787,352-359,,,14,0,,,,"In this letter, an approach is presented to estimate the stiffness characteristics of elastically deformable objects, while being processed in a robotic cleaning system. Building on our previous work [J. D. Langsfeld, A. M. Kabir, K. N. Kaipa, and S. K. Gupta, “Robotic bimanual cleaning of deformable objects with online learning of part and tool models,” in Proc. IEEE Int. Conf. Autom. Sci. Eng., 2016, pp. 626-632.], significant extensions are made in this letter by presenting new methods that lead to an overall improvement in the results. The robot system plans the actions of both the grasping and cleaning arms using its current model of the part deformation behavior, and attempts to minimize the overall cleaning time by finding plans that use a small number of grasping positions on the part. A finite-element method approach is used to model the part deformation and a general update algorithm is presented that can modify the stiffness parameters of the model to match observed deformation data collected during cleaning. This allows the system to very quickly discover the correct locations to grasp the part so as to minimize deformation. The methods described in this lettter are shown to achieve better results than the ones from our previous work: The results are much smoother, along with a twofold reduction in parameter-estimation error, and notable faster convergence.",NO
2-s2.0-85054408859,10.1109/ACCESS.2018.2872751,,,UGV Navigation Optimization Aided by Reinforcement Learning-Based Path Tracking,ar,Article,Wei M.,,Wuhan University,Wuhan,China,,,,,2018-01-01,2018,IEEE Access,,21100374601,21693536,Journal,6,,8476521,57814-57825,,,9,1,,,,"The success of robotic, such as UGV systems, largely benefits from the fundamental capability of autonomously finding collision-free path(s) to commit mobile tasks in routinely rough and complicated environments. Optimization of navigation under such circumstance has long been an open problem: 1) to meet the critical requirements of this task typically including the shortest distance and smoothness and 2) more challengingly, to enable a general solution to track the optimal path in real-time outdoor applications. Aiming at the problem, this study develops a two-tier approach to navigation optimization in terms of path planning and tracking. First, a “rope”model has been designed to mimic the deformation of a path in axial direction under external force and the fixedness of the radial plane to contain a UGV in a collision-free space. Second, a deterministic policy gradient (DPG) algorithm has been trained efficiently on abstracted structures of an arbitrarily derived “rope”to model the controller for tracking the optimal path. The learned policy can be generalized to a variety of scenarios. Experiments have been performed over complicated environments of different types. The results indicate that: 1) the rope model helps in minimizing distance and enhancing smoothness of the path, while guarantees the clearance; 2) the DPG can be modeled quickly (in a couple of minutes on an office desktop) and the model can apply to environments of increasing complexity under the circumstance of external disturbances without the need for tuning parameters; and 3) the DPG-based controller can autonomously adjust the UGV to follow the correct path free of risks by itself.",NO
2-s2.0-85052650142,10.1541/ieejeiss.138.1108,,,Operation verification of deep learning applications on small computers,ar,Article,Nishizaki H.,,University of Yamanashi,Kofu,Japan,,,,,2018-01-01,2018,"IEEJ Transactions on Electronics, Information and Systems",03854221,3300147412,13488155,Journal,138,9,,1108-1115,,,0,0,,,,"抄録

Recently, deep learning technologies have been in the spotlight. Deep learning is one of a powerful technology to classify or recognize objects which captured by a camera. Such application has a high affinity with Internet-of-Things (IoT) devices. Therefore, it is considered that these technologies are used in embedded systems and IoT devices. In this paper, we verify deep learning applications like image classification can work well on a small computer such as Raspberry Pi. We develop three deep learning applications by using two types of deep learning frameworks (libraries). We prepare four types of small computers, and these applications are tested on the computers. In addition, we also investigate the relationship between the processing time, the memory consumption and the number of parameters of the deep neural network model. The verification experiments show that a program based on a deep learning library implemented by C++ language fast run and simple neural network models could work in real-time on small computers. Besides, the other experiment also clears that the more parameters increase the processing time and the consumption memory in proportion without depending on the deep learning libraries and small computers.",NO
2-s2.0-85050721547,10.15199/48.2018.08.19,,,Labview academy,ar,Article,Pawłowski P.,,Politechnika Poznanska,Poznan,Poland,,,,,2018-01-01,2018,Przeglad Elektrotechniczny,00332097,18700,24499544,Journal,94,8,,71-74,,,0,0,,,,"The National Instruments NI LabVIEW Academy free-of-charge training program is designed to prepare students to use the LabVIEW environment. The company provides the academic institution an educational package, while the university must provide a laboratory equipped with computers, software, hardware and perform the course of using the LabVIEW environment. During the course, students gain knowledge about the LabVIEW environment and are prepared for the CLAD (Certified LabVIEW Associate Developer) certification exam. The CLAD certificate is a worldrecognized first-level certificate that certifies basic programming skills in the NI LabVIEW environment. In 2018, there are 21 LabVIEW academies active at 13 universities in Poland. This article presents the LabVIEW Academy on the example of its realization at the Poznan University of Technology.",NO
2-s2.0-85049519293,10.3923/jeasci.2018.2951.2956,,,The analysis on research trends for software education in Korea,ar,Article,Lee E.,,Korea Institute for Curriculum and Evaluation,Seoul,South Korea,,,,,2018-01-01,2018,Journal of Engineering and Applied Sciences,1816949X,21100231100,18187803,Journal,13,Specialissue2,,2951-2956,,,0,0,,,,,NO
2-s2.0-85049178282,10.1155/2018/2312984,,,The Experience of the Robot Programming Network Initiative,ar,Article,Casañ G.A.,,Universidad Jaume I,Castellon de la Plana,Spain,,,,,2018-01-01,2018,Journal of Robotics,16879600,21100301602,16879619,Journal,2018,,2312984,,,,3,1,,,,"Since its creation in 2014, the Robot Programming Network (RPN) has been an environment to learn and teach robotics to the general public, which has also allowed us to learn about education. In this paper, we aim to not only present the RPN and the active courses in the system but also show the evolution of this initiative in front of the changing e-learning environment and its possible future evolution towards Massive Online Open Courses (MOOCs) and cloud simulation.",SI
2-s2.0-85044420309,10.3233/ICA-180569,,,"Ontology based design, control and programming of modular robots",ar,Article,Ramos F.,,Universidad de Castilla-La Mancha,Ciudad Real,Spain,,,,,2018-01-01,2018,Integrated Computer-Aided Engineering,10692509,18197,18758835,Journal,25,2,,173-192,,,11,0,,,,"Affiliations: School of Industrial Engineering, University of Castilla-La Mancha, Avda. Camilo José Cela, 3, 13071 Ciudad Real, Spain",NO
2-s2.0-85043297638,10.2200/S00787ED1V01Y201707CSL009,,,Creating Autonomous Vehicle Systems,ar,Article,Liu S.,,,,,,,,,2018-01-01,2018,Synthesis Lectures on Computer Science,19321228,5000158717,19321686,Book Series,6,1,,1-198,,,36,0,,,,"**NOTE** A new edition is available: Creating Autonomous Vehicle Systems, Second Edition

This book is the first technical overview of autonomous vehicles written for a general computing and engineering audience. The authors share their practical experiences of creating autonomous vehicle systems. These systems are complex, consisting of three major subsystems: (1) algorithms for localization, perception, and planning and control; (2) client systems, such as the robotics operating system and hardware platform; and (3) the cloud platform, which includes data storage, simulation, high-definition (HD) mapping, and deep learning model training. The algorithm subsystem extracts meaningful information from sensor raw data to understand its environment and make decisions about its actions. The client subsystem integrates these algorithms to meet real-time and reliability requirements. The cloud platform provides offline computing and storage capabilities for autonomous vehicles. Using the cloud platform, we are able to test new algorithms and update the HD map—plus, train better recognition, tracking, and decision models.

This book consists of nine chapters. Chapter 1 provides an overview of autonomous vehicle systems; Chapter 2 focuses on localization technologies; Chapter 3 discusses traditional techniques used for perception; Chapter 4 discusses deep learning based techniques for perception; Chapter 5 introduces the planning and control sub-system, especially prediction and routing technologies; Chapter 6 focuses on motion planning and feedback control of the planning and control subsystem; Chapter 7 introduces reinforcement learning-based planning and control; Chapter 8 delves into the details of client systems design; and Chapter 9 provides the details of cloud platforms for autonomous driving.

This book should be useful to students, researchers, and practitioners alike. Whether you are an undergraduate or a graduate student interested in autonomous driving, you will find herein a comprehensive overview of the whole autonomous vehicle technology stack. If you are an autonomous driving practitioner, the many practical techniques introduced in this book will be of interest to you. Researchers will also find plenty of references for an effective, deeper exploration of the various technologies.

Table of Contents: Preface / Introduction to Autonomous Driving / Autonomous Vehicle Localization / Perception in Autonomous Driving / Deep Learning in Autonomous Driving Perception / Prediction and Routing / Decision, Planning, and Control / Reinforcement Learning-based Planning and Control / Client Systems for Autonomous Driving / Cloud Platform for Autonomous Driving / Author Biographies",NO
2-s2.0-85042454067,10.3389/fnbot.2018.00005,,,Learning by demonstration for motion planning of upper-limb exoskeletons,ar,Article,Lauretti C.,,Università Campus Bio-Medico di Roma,Rome,Italy,,,,,2018-01-01,2018,Frontiers in Neurorobotics,,21100199837,16625218,Journal,12,FEB,5,,,,23,1,,,,"The reference joint position of upper-limb exoskeletons is typically obtained by means of Cartesian motion planners and inverse kinematics algorithms with the inverse Jacobian; this approach allows exploiting the available Degrees of Freedom (i.e. DoFs) of the robot kinematic chain to achieve the desired end-effector pose; however, if used to operate non-redundant exoskeletons, it does not ensure that anthropomorphic criteria are satisfied in the whole human-robot workspace. This paper proposes a motion planning system, based on Learning by Demonstration, for upper-limb exoskeletons that allow successfully assisting patients during Activities of Daily Living (ADLs) in unstructured environment, while ensuring that anthropomorphic criteria are satisfied in the whole human-robot workspace. The motion planning system combines Learning by Demonstration with the computation of Dynamic Motion Primitives and machine learning techniques to construct task- and patient-specific joint trajectories based on the learnt trajectories. System validation was carried out in simulation and in a real setting with a 4-DoF upper-limb exoskeleton, a 5-DoF wrist-hand exoskeleton and four patients with Limb Girdle Muscular Dystrophy. Validation was addressed to (i) compare the performance of the proposed motion planning with traditional methods; (ii) assess the generalization capabilities of the proposed method with respect to the environment variability. Three ADLs were chosen to validate the system: drinking, pouring and lifting a light sphere. The achieved results showed a 100% success rate in the task fulfillment, with a high level of generalization with respect to the environment variability. Moreover, an anthropomorphic configuration of the exoskeleton is always ensured.",NO
2-s2.0-85040709407,10.1002/cae.21862,,,From Android games to coding in C—An approach to motivate novice engineering students to learn programming: A case study,ar,Article,Dolgopolovas V.,,Vilniaus Universitetas;Institute of Mathematics and Informatics,Vilnius;Vilnius,Lithuania;Lithuania,,,,,2018-01-01,January 2018,Computer Applications in Engineering Education,10613773,18156,10990542,Journal,26,1,,75-90,,,12,0,,,,"This paper deals with the problem of overcoming difficulties and raising the motivation of novice engineering students studying programming. We consider this an important factor for engineering education in general and for programming of embedded devices, as well as for calculations and modeling in the field of scientific computing in particular. We present a case study on how novice engineering students can be motivated to study structured programming and coding in C using game programming in the App Inventor environment. The study is based on the authors’ practical teaching experience in the Applied Sciences University for novice programmers, with students of the Technology of Smart Devices specialty, as well as the authors’ long-time research activities in teaching Computer Science.",NO
2-s2.0-85040107059,10.5302/J.ICROS.2018.17.0196,,,Path planning based on probabilistic roadmap for initial deployment of marsupial robot team,ar,Article,Lee H.,,Seoul National University,Seoul,South Korea,,,,,2018-01-01,2018,"Journal of Institute of Control, Robotics and Systems",19765622,21100201073,,Journal,24,1,,80-89,,,2,0,,,,"In this paper, we present a new path planning approach for the initial deployment of a heterogeneous marsupial robot team consisting of a large-scale carrier and multiple rovers, and for efficient operation of a multi-robot system. In this robot team, the roles are explicitly divided. The carrier oversees the transportation, deployment, and retrieval of the rovers, whereas the rovers are responsible for performing tasks such as reconnaissance and search and rescue. We aim to use this robot team to minimize the maximum amount of time that each rover requires to reach a given task location. However, only a few studies have addressed pathplanning for robot teams. To generate an efficient path, the mobility and energy limitations of the robots and the obstacles in the environment must be considered. Because considering all possible paths on a graph is equivalent to solving a combinatorial optimization problem, we suggest a computationally efficient heuristic algorithm, which combines a greedy clustering method with a probabilistic roadmap. The proposed method is verified through simulations.
#Multi-robot system
#Marsupial robot
#Carrier robot
#Multi-robot path planning",NO
2-s2.0-85030765827,10.1109/TOH.2017.2753233,,28922126,Functional Contour-following via Haptic Perception and Reinforcement Learning,ar,Article,Hellman R.B.,,"University of California, Los Angeles",Los Angeles,United States,,,,,2018-01-01,January-March 2018,IEEE Transactions on Haptics,19391412,12100154405,,Journal,11,1,,61-72,,,12,1,,,,"Many tasks involve the fine manipulation of objects despite limited visual feedback. In such scenarios, tactile and proprioceptive feedback can be leveraged for task completion. We present an approach for real-time haptic perception and decision-making for a haptics-driven, functional contour-following task: the closure of a ziplock bag. This task is challenging for robots because the bag is deformable, transparent, and visually occluded by artificial fingertip sensors that are also compliant. A deep neural net classifier was trained to estimate the state of a zipper within a robot's pinch grasp. A Contextual Multi-Armed Bandit (C-MAB) reinforcement learning algorithm was implemented to maximize cumulative rewards by balancing exploration versus exploitation of the state-action space. The C-MAB learner outperformed a benchmark Q-learner by more efficiently exploring the state-action space while learning a hard-to-code task. The learned C-MAB policy was tested with novel ziplock bag scenarios and contours (wire, rope). Importantly, this work contributes to the development of reinforcement learning approaches that account for limited resources such as hardware life and researcher time. As robots are used to perform complex, physically interactive tasks in unstructured or unmodeled environments, it becomes important to develop methods that enable efficient and effective learning with physical testbeds.",NO
2-s2.0-85029590379,10.1007/978-3-319-66939-7_22,,,Human Activities Transfer Learning for Assistive Robotics,ar,Article,Adama D.,,Nottingham Trent University,Nottingham,United Kingdom,,,,,2018-01-01,2018,Advances in Intelligent Systems and Computing,21945357,5100152904,,Book Series,650,,,253-264,,,4,0,,,,"Assisted living homes aim to deploy tools to promote better living of elderly population. One of such tools is assistive robotics to perform tasks a human carer would normally be required to perform. For assistive robots to perform activities without explicit programming, a major requirement is learning and classifying activities while it observes a human carry out the activities. This work proposes a human activity learning and classification system from features obtained using 3D RGB-D data. Different classifiers are explored in this approach and the system is evaluated on a publicly available data set, showing promising results which is capable of improving assistive robots performance in living environments.",NO
2-s2.0-84995387148,10.1007/s00542-016-3192-9,,,A study of fuzzy control with ant colony algorithm used in mobile robot for shortest path planning and obstacle avoidance,ar,Article,Yen C.,,National Formosa University Taiwan,Yunlin,Taiwan,,,,,2018-01-01,1 January 2018,Microsystem Technologies,09467076,26738,,Journal,24,1,,125-135,,,36,0,,,,"The fuzzy ant colony optimization (FACO) method proposed in this paper minimizes the iterative learning error of the ant colony optimization (ACO) algorithm using fuzzy control. This algorithm finds the shortest path, detects any obstructions in front of the mobile robot using ultrasonic transducers, and adjusts the turning angle of the mobile robot so as to avoid obstacles. To verify the FACO algorithm, simulations using a mobile robot in two environments were carried out. The first environment was shortest-path planning without obstacles. The second environment was shortest-path planning for a single destination with obstacles. This paper also compares tests carried out in a simple Z-shaped environment map and in a complicated environment map. By comparing FACO with a pattern search (PS) algorithm, a genetic algorithm (GA), particle swarm optimization (PSO), and traditional ACO for the cases in the simple Z-shaped environment map, we found that the path distance obtained using FACO was 2.60, 4.40, 2.04, and 6.53% shorter than that using PS, GA, PSO, and ACO, respectively. In the complex environment map, as compared to the self-adaptive ant colony optimization, FACO had a path distance that was 1.38% shorter. Therefore, the results showed that the FACO algorithm can find the shortest path and avoid obstacles for both simple and complex topographies.",NO
2-s2.0-85077808398,10.1126/scirobotics.aay6276,,33137718,A formal methods approach to interpretable reinforcement learning for robotic planning,ar,Article,Li X.,,Boston University,Boston,United States,,,,,2019-12-18,18 December 2019,Science Robotics,,21100886132,24709476,Journal,4,37,eaay6276,,,,14,0,,,,"Growing interest in reinforcement learning approaches to robotic planning and control raises concerns of predictability and safety of robot behaviors realized solely through learned control policies. In addition, formally defining reward functions for complex tasks is challenging, and faulty rewards are prone to exploitation by the learning agent. Here, we propose a formal methods approach to reinforcement learning that (i) provides a formal specification language that integrates high-level, rich, task specifications with a priori, domain-specific knowledge; (ii) makes the reward generation process easily interpretable; (iii) guides the policy generation process according to the specification; and (iv) guarantees the satisfaction of the (critical) safety component of the specification. The main ingredients of our computational framework are a predicate temporal logic specifically tailored for robotic tasks and an automaton-guided, safe reinforcement learning algorithm based on control barrier functions. Although the proposed framework is quite general, we motivate it and illustrate it experimentally for a robotic cooking task, in which two manipulators worked together to make hot dogs.",NO
2-s2.0-85077775212,10.1145/3368858,,,Tiling optimizations for stencil computations using rewrite rules in lift,ar,Article,Stoltzfus L.,,The University of Edinburgh,Edinburgh,United Kingdom,,,,,2019-12-01,December 2019,ACM Transactions on Architecture and Code Optimization,15443566,12100154406,15443973,Journal,16,4,52,,,,2,1,,,,"Stencil computations are a widely used type of algorithm, found in applications from physical simulations to machine learning. Stencils are embarrassingly parallel, therefore fit on modern hardware such as Graphic Processing Units perfectly. Although stencil computations have been extensively studied, optimizing them for increasingly diverse hardware remains challenging. Domain-specific Languages (DSLs) have raised the programming abstraction and offer good performance; however, this method places the burden on DSL implementers to write almost full-fledged parallelizing compilers and optimizers.

Lift has recently emerged as a promising approach to achieve performance portability by using a small set of reusable parallel primitives that DSL or library writers utilize. Lift’s key novelty is in its encoding of optimizations as a system of extensible rewrite rules which are used to explore the optimization space.

This article demonstrates how complex multi-dimensional stencil code and optimizations are expressed using compositions of simple 1D Lift primitives and rewrite rules. We introduce two optimizations that provide high performance for stencils in particular: classical overlapped tiling for multi-dimensional stencils and 2.5D tiling specifically for 3D stencils. We provide an in-depth analysis on how the tiling optimizations affects stencils of different shapes and sizes across different applications. Our experimental results show that our approach outperforms existing compiler approaches and hand-tuned codes.",NO
2-s2.0-85075748062,10.1109/MC.2019.2942579,,,"Cognitive robotics: Making robots sense, understand, and interact",ar,Article,Lange D.,,Unity Technologies,San Francisco,United States,,,,,2019-12-01,December 2019,Computer,00189162,23746,15580814,Trade Journal,52,12,8909928,39-44,,,3,1,,,,"Robots have spread from manufacturing floors to spaces occupied by humans. Although robots in these settings may improve the way humans work, the programming by hand of collaborative robots in such environments is increasingly difficult. We predict that recent breakthroughs in large-scale simulations, deep reinforcement learning, and computer vision collectively bring forth a basic level of cognitive abilities to robots that will lead to significant improvements of robotic applications over the next few years.",NO
2-s2.0-85071724162,10.1016/j.jss.2019.110406,S0164121219301803,,DEEPLINK: Recovering issue-commit links based on deep learning,ar,Article,Ruan H.,,Fudan University;Shanghai Institute of Intelligent Electronics and Systems,Shanghai;Shanghai,China;China,,,,,2019-12-01,December 2019,Journal of Systems and Software,01641212,19309,,Journal,158,,110406,,,,9,0,,,,"Highlights

•

Only 42.2% of issues in 1078 GitHub Java projects are linked to commits.

•

Biased data can cause an effective degradation of link recovery approaches.

•

DeepLink outperformed a link recovery approach by 4.6% in F-measure.
The links between issues in an issue-tracking system and commits resolving the issues in a version control system are important for a variety of software engineering tasks (e.g., bug prediction, bug localization and feature location). However, only a small portion of such links are established by manually including issue identifiers in commit logs, leaving a large portion of them lost in the evolution history. To recover issue-commit links, heuristic-based and learning-based techniques leverage the metadata and text/code similarity in issues and commits; however, they fail to capture the embedded semantics in issues and commits and the hidden semantic correlations between issues and commits. As a result, this semantic gap inhibits the accuracy of link recovery.

To bridge this gap, we propose a semantically-enhanced link recovery approach, named DeepLink, which is built on top of deep learning techniques. Specifically, we develop a neural network architecture, using word embedding and recurrent neural network, to learn the semantic representation of natural language descriptions and code in issues and commits as well as the semantic correlation between issues and commits. In experiments, to quantify the prevalence of missing issue-commit links, we analyzed 1078 highly-starred GitHub Java projects (i.e., 583,795 closed issues) and found that only 42.2% of issues were linked to corresponding commits. To evaluate the effectiveness of DeepLink, we compared DeepLink with a state-of-the-art link recovery approach FRLink using ten GitHub Java projects and demonstrated that DeepLink can outperform FRLink in terms of F-measure.",NO
2-s2.0-85069805719,10.1007/s10514-019-09879-8,,,"Horizon-based lazy optimal RRT for fast, efficient replanning in dynamic environment",ar,Article,Chen Y.,,Harbin Institute of Technology,Harbin,China,,,,,2019-12-01,1 December 2019,Autonomous Robots,09295593,18016,15737527,Journal,43,8,,2271-2292,,,3,0,,,,"Planning of collision-free trajectory for robot motion under hard constraints and unpredictable environment is a difficult issue. To cope with this problem, this paper presents a novel replanning method based on receding horizon control and asymptotically optimal single-query motion planning. The approach, called the horizon-based lazy optimal rapidly-exploring random tree algorithm, enables real-time replanning in both static and dynamic environment with updated information. Previous feasible solutions are fully considered to generate new plans. Contributions include lazy steering and lazy collision checking search tree, forward tree pruning and sampling distribution online learning. The techniques are proven to be efficient, near optimal and fast responsive to change. Moreover, three experiments are performed to test the properties of the proposed algorithm numerically.",NO
2-s2.0-85068868548,10.1007/s10514-019-09875-y,,,A constrained instantaneous learning approach for aerial package delivery robots: onboard implementation and experimental results,ar,Article,Mehndiratta M.,,Singapore Centre for 3D Printing;School of Mechanical and Aerospace Engineering,Singapore City;Singapore City,Singapore;Singapore,,,,,2019-12-01,1 December 2019,Autonomous Robots,09295593,18016,15737527,Journal,43,8,,2209-2228,,,9,0,,,,"Rather than utilizing a sophisticated robot which is trained—and tuned—for a scenario in a specific environment perfectly, most people are interested in seeing robots operating in various conditions where they have never been trained before. In accordance with the goal of utilizing aerial robots for daily operations in real application scenarios, an aerial robot must learn from its own experience and its interactions with the environment. This paper presents an instantaneous learning-based control approach for the precise trajectory tracking of a 3D-printed aerial robot which can adapt itself to the changing working conditions. Considering the fact that model-based controllers suffer from lack of modeling, parameter variations and disturbances in their working environment, we observe that the presented learning-based control method has a compelling ability to significantly reduce the tracking error under aforementioned uncertainties throughout the operation. Three case scenarios are considered: payload mass variations on an aerial robot for a package delivery problem, ground effect when the aerial robot is hovering/flying close to the ground, and wind-gust disturbances encountered in the outdoor environment. In each case study, parameter variations are learned using nonlinear moving horizon estimation (NMHE) method, and the estimated parameters are fed to the nonlinear model predictive controller (NMPC). Thanks to learning capability of the presented framework, the aerial robot can learn from its own experience, and react promptly—unlike iterative learning control which allows the system to improve tracking accuracy from repetition to repetition—to reduce the tracking error. Additionally, the fast C++ execution of NMPC and NMHE codes facilitates a complete onboard implementation of the proposed framework on a low-cost embedded processor.",NO
2-s2.0-85066142680,10.1186/s13638-019-1437-x,,,Indoor robot path planning assisted by wireless network,ar,Article,Wang X.,,Xi'an Polytechnic University,Xi'an,China,,,,,2019-12-01,1 December 2019,Eurasip Journal on Wireless Communications and Networking,16871472,18202,16871499,Journal,2019,1,123,,,,2,1,,,,"Indoor robot global path planning needs to complete the motion between the starting point and the target point according to robot position command transmitted by the wireless network. Behavior dynamics and rolling windows in global path planning methods have limitations in their applications because the path may not be optimal, there could be a pseudo attractor or blind search in an environment with a large state space, there could be an environment where offline learning is not applicable to real-time changes, or there could be a need to set the probability of selecting the robot action. To solve these problems, we propose a behavior dynamics and rolling windows approach to a path planning which is based on online reinforcement learning. It applies Q learning to optimize the behavior dynamics model parameters to improve the performance, behavior dynamics guides the learning process of Q learning and improves learning efficiency, and each round of intensive learning action selection knowledge is gradually corrected as the Q table is updated. The learning process is optimized. The simulation results show that this method has achieved remarkable improvement in path planning. And, in the actual experiment, the robot obtains the target location information by wireless network, and plans an optimized and smooth global path online.",NO
2-s2.0-85065662346,10.1007/s10514-019-09852-5,,,Real-time robot path planning from simple to complex obstacle patterns via transfer learning of options,ar,Article,Saha O.,,"LG Electronics, Korea",Seoul,South Korea,,,,,2019-12-01,1 December 2019,Autonomous Robots,09295593,18016,15737527,Journal,43,8,,2071-2093,,,6,0,,,,"We consider the problem of path planning in an initially unknown environment where a robot does not have an a priori map of its environment but has access to prior information accumulated by itself from navigation in similar but not identical environments. To address the navigation problem, we propose a novel, machine learning-based algorithm called Semi-Markov Decision Process with Unawareness and Transfer (SMDPU-T) where a robot records a sequence of its actions around obstacles as action sequences called options which are then reused by it within a framework called Markov Decision Process with unawareness (MDPU) to learn suitable, collision-free maneuvers around more complex obstacles in future. We have analytically derived the cost bounds of the selected option by SMDPU-T and the worst case time complexity of our algorithm. Our experimental results on simulated robots within Webots simulator illustrate that SMDPU-T takes 24\% planning time and 39\% total time to solve same navigation tasks while, our hardware results on a Turtlebot robot indicate that SMDPU-T on average takes 53\% planning time and 60\% total time as compared to a recent, sampling-based path planner.",NO
2-s2.0-85030790017,10.1109/TSMC.2017.2750911,,,A Real-Time and Fully Distributed Approach to Motion Planning for Multirobot Systems,ar,Article,Zhou Y.,,School of Computer Science and Engineering,Singapore City,Singapore,,,,,2019-12-01,December 2019,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",21682216,12952,21682232,Journal,49,12,8055437,2636-2650,,,10,0,,,,"Motion planning is one of the most critical problems in multirobot systems. The basic target is to generate a collision-free trajectory for each robot from its initial position to the target position. In this paper, we study the trajectory planning for the multirobot systems operating in unstructured and changing environments. Each robot is equipped with some sensors of limited sensing ranges. We propose a fully distributed approach to planning trajectories for such systems. It combines the model predictive control (MPC) strategy and the incremental sequential convex programming (iSCP) method. The MPC framework is applied to detect the local running environment real-timely with the concept of receding horizon. For each robot, a nonlinear programming is built in its current prediction horizon. To construct its own optimization problem, a robot first needs to communicate with its neighbors to retrieve their current states. Then, the robot predicts the neighbors' future positions in the current horizon and constructs the problem without waiting for the prediction information from its neighbors. At last, each robot solves its problem independently via the iSCP method such that the robot can move autonomously. The proposed method is polynomial in its computational complexity.",NO
2-s2.0-85069514748,10.1016/j.matdes.2019.107975,S0264127519304137,,Functionally Graded Materials through robotics-inspired path planning,ar,Article,Eliseeva O.,,Texas A&amp;M University,College Station,United States,,,,,2019-11-15,15 November 2019,Materials and Design,02641275,17797,18734197,Journal,182,,107975,,,,15,1,,,,"Highlights

•

Demonstrated a new method of identifying compositional paths in functional gradients in bulk samples

•

Demonstrated functionally graded compositions can be created in a direct deposition additive manufacturing system

•

Demonstrated the methodology in the functionally graded material going from 316 stainless steel to pure chromium.
Functional grading has recently seen renewed interest with the advancement of additive manufacturing. Unfortunately, the integrity of functional gradients in alloys tends to be compromised by the presence of brittle phases. Recently, CALPHAD-based tools have been used to generate isothermal phase diagrams that are in turn utilized to plan gradient paths that avoid these phases. However, existing frameworks rely extensively on the (limited) ability of humans to visualize and navigate high-dimensional spaces. To tackle this challenge, a Machine Learning approach was used here to map out undesirable regions as ‘obstacles’, while a path-planning algorithm, commonly used in robotics community, was utilized to identify a path in a composition space that would avoid the obstacles, while simultaneously minimizing a cost function. This framework was validated by designing and 3-D printing a functional gradient in bulk samples from 316L stainless steel to pure chromium with a multi-material direct laser deposition system. Both the planned gradient and simple linear gradient samples were fabricated and characterized in as-deposited and heat-treated states to determine local compositions, microstructure and phase constituents. The planned gradient resulted in complete elimination of the detrimental σ phase after heat treatment, demonstrating the success of the methodology.

Graphical abstract

Download : Download high-res image (231KB)Download : Download full-size image",NO
2-s2.0-85072718021,10.1016/j.neucom.2019.07.081,S0925231219310884,,Sequential learning unification controller from human demonstrations for robotic compliant manipulation,ar,Article,Duan J.,,Shenzhen Institute of Advanced Technology;University of Chinese Academy of Sciences,Shenzhen;Beijing,China;China,,,,,2019-11-13,13 November 2019,Neurocomputing,09252312,24807,18728286,Journal,366,,,35-45,,,4,0,,,,"Robotic compliant manipulation not only contains robot motion but also embodies interaction with the environment. Frequently endowing the compliant manipulation skills to the robot by manual programming or off-line training is complicated and time-consuming. In this paper, we propose a sequential learning framework to take both kinematic profile and variable impedance parameter profile into consideration to model a unified control strategy with “motion generation” and “compliant control”. In order to acquire this unification controller efficiently, we use a sequential learning neural network to encode robot motion and a new force-based variable impedance learning algorithm to estimate varying damping and stiffness profiles in three directions. Furthermore, the state-independent stability constraints for variable impedance control are presented. The effectiveness of the proposed learning framework is validated by a set of experiments using the 4-DoF Barrett WAM.",NO
2-s2.0-85074839530,10.1080/0951192X.2019.1686177,,,Operation of a haptic interface for offline programming of welding robots by applying a spring-damper model,ar,Article,Sanchez-Diaz A.,,Universidad Autónoma de Sinaloa,Culiacan,Mexico,,,,,2019-11-02,2 November 2019,International Journal of Computer Integrated Manufacturing,0951192X,18198,13623052,Journal,32,11,,1098-1116,,,0,0,,,,"This paper studies a system of a virtual welding torch employed during the teaching process of welding tasks for offline programming of robotic manipulators. The torch is manipulated by the user in a virtual environment applying a haptic interface. An approach based on a spring-damper model is proposed to compute the force to be felt by the user during the manipulation of the interface. The force is such that more realistic sensations are perceived by the hand’s user if a collision occurs of the torch in the virtual environment. A suitable strategy is employed to represent the virtual torch by two coupled models with spring-damper systems (SDS). Such models are termed kinematic virtual torch (KVT) and dynamic virtual torch (DVT). Thus, in the studied system, the DVT follows the geometric coordinates of the KVT during a manipulation of the torch avoiding penetration of other objects in the scene. Careful analyses are accomplished on manipulation tasks using different SDS configurations in a case study in order to show the efficacy of the proposed approach. As a result, a desired welding task is properly programmed for a robot in an easy and accurate way.",NO
2-s2.0-85076641370,10.1109/RITA.2019.2950130,,,Scratch as Driver to Foster Interests for STEM and Educational Robotics,ar,Article,Plaza P.,,Universidad Nacional de Educacion a Distancia,Madrid,Spain,,,,,2019-11-01,November 2019,Revista Iberoamericana de Tecnologias del Aprendizaje,,19700201532,19328540,Journal,14,4,8890651,117-126,,,10,0,,,,"Today, there are a multitude of initiatives that favor the learning of Science, Technology, Engineering, and Mathematics (STEM) and educational robotics (ER). Thanks to the available means, it is very easy to access a wide variety of tools based on programmable hardware. Although there are many options, most of them either require a high economic investment or require a great deal of time for the development of educational activities. Through the results shown in this paper, the great potential of Scratch as a solution for students who are just starting out in the knowledge related to STEM and ER is shown. To show the usefulness of Scratch a course has been designed, which dedicates three modules to the use of Scratch. The three modules have different levels of difficulty for the students, a basic level of difficulty, another intermediate level of difficulty and a last module with an advanced degree of difficulty.",SI
2-s2.0-85074693150,10.1007/s00502-019-00741-4,,,Skill-based programming of complex robotic assembly tasks for industrial application,ar,Article,Akkaladevi S.,,Profactor GmbH,Steyr,Austria,,,,,2019-11-01,1 November 2019,Elektrotechnik und Informationstechnik,0932383X,144631,,Journal,136,7,,326-333,,,6,0,,,,"In recent years, a paradigm shift is underway as robots leave their typical application field and move into domains that have been untouched by robotic automation. These new kinds of automation systems allow more product variations, smaller life cycles, smaller batch sizes and pave the way from mass production to mass customization. This is due to completely new breed of safe robot technology but also novel ways of setting up new applications like e.g. kinesthetic programming. However, the topic of reducing the programming effort for complex tasks using natural modes of communication is still open. This paper addresses the key developments in this field, shows different ways of programming, and gives relevant use cases in industrial assembly. The technology coverage starts with an online workflow editor called XROB that allows easy-to-use setup of process workflows and related skill parameters. However, in order to reduce the programming effort, a novel way to demonstrate process trajectories by using instrumented hand guided process tools is presented. Finally, the paper gives an overview of a promising approach that allows programming without touching the robot just by demonstrating the process by an expert. The semantic relations between activities executed by the human and robot skills are captured to learn the task sequence of the assembly process. The acquired process knowledge is refined to execute robotic tasks with the help of an interactive graphical user interface (GUI). The system queries the user for feedback, asking for specific information to help the robot complete the task at hand. The given examples show the usability of flexible programming tools in the automation chain and the presented results provide strong evidence of the technological potential in the field.",NO
2-s2.0-85070095236,10.1111/coin.12233,,,An ambient intelligence approach for learning in smart robotic environments,ar,Article,Bacciu D.,,Università di Pisa,Pisa,Italy,,,,,2019-11-01,1 November 2019,Computational Intelligence,08247935,23737,14678640,Journal,35,4,,1061-1088,,,1,0,,,,"Smart robotic environments combine traditional (ambient) sensing devices and mobile robots. This combination extends the type of applications that can be considered, reduces their complexity, and enhances the individual values of the devices involved by enabling new services that cannot be performed by a single device. To reduce the amount of preparation and preprogramming required for their deployment in real-world applications, it is important to make these systems self-adapting. The solution presented in this paper is based upon a type of compositional adaptation where (possibly multiple) plans of actions are created through planning and involve the activation of pre-existing capabilities. All the devices in the smart environment participate in a pervasive learning infrastructure, which is exploited to recognize which plans of actions are most suited to the current situation. The system is evaluated in experiments run in a real domestic environment, showing its ability to proactively and smoothly adapt to subtle changes in the environment and in the habits and preferences of their user(s), in presence of appropriately defined performance measuring functions.",NO
2-s2.0-85066065840,10.1111/coin.12215,,,An evolutionary-based approach for dealing with numerical and categorical attributes in ILP,ar,Article,Muñoz-Texzocotetla O.,,Universidad Autónoma Metropolitana,Mexico City,Mexico,,,,,2019-11-01,1 November 2019,Computational Intelligence,08247935,23737,14678640,Journal,35,4,,827-857,,,0,0,,,,"Inductive logic programming (ILP) induces concepts from a set of positive examples, a set of negative examples, and background knowledge. ILP has been applied on tasks such as natural language processing, finite element mesh design, network mining, robotics, and drug discovery. These data sets usually contain numerical and multivalued categorical attributes; however, only a few relational learning systems are capable of handling them in an efficient way. In this paper, we present an evolutionary approach, called Grouping and Discretization for Enriching the Background Knowledge (GDEBaK), to deal with numerical and multivalued categorical attributes in ILP. This method uses evolutionary operators to create and test numerical splits and subsets of categorical values in accordance with a fitness function. The best subintervals and subsets are added to the background knowledge before constructing candidate hypotheses. We implemented GDEBaK embedded in Aleph and compared it to lazy discretization in Aleph and discretization in Top-down Induction of Logical Decision Trees (TILDE) systems. The results obtained showed that our method improves accuracy and reduces the number of rules in most cases. Finally, we discuss these results and possible lines for future work.",NO
2-s2.0-85059701060,10.1007/s10846-018-0971-9,,,Robotic Task Planning Using a Backchaining Theorem Prover for Multiplicative Exponential First-Order Linear Logic,ar,Article,Kortik S.,,Bilkent Üniversitesi,Ankara,Turkey,,,,,2019-11-01,1 November 2019,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,96,2,,179-191,,,0,0,,,,"In this paper, we propose an exponential multiplicative fragment of linear logic to encode and solve planning problems efficiently in STRIPS domain, that we call the Linear Planning Logic (LPL). Linear logic is a resource aware logic treating resources as single use assumptions, therefore enabling encoding and reasoning of domains with dynamic state. One of the most important examples of dynamic state domains is robotic task planning, since informational or physical states of a robot include non-monotonic characteristics. Our novel theorem prover is using the backchaining method which is suitable for logic languages like Lolli and Prolog. Additionally, we extend LPL to be able to encode non-atomic conclusions in program formulae. Following the introduction of the language, our theorem prover and its implementation, we present associated algorithmic properties through small but informative examples. Subsequently, we also present a navigation domain using the hexapod robot RHex to show LPL’s operation on a real robotic planning problem. Finally, we provide comparisons of LPL with two existing linear logic theorem provers, llprover and linTAP. We show that LPL outperforms these theorem provers for planning domains.",NO
2-s2.0-85073918973,10.1108/IJICC-02-2019-0017,,,"Design and performance evaluation of a parking management system for automated, multi-story and robotic parking structure",ar,Article,Serpen G.,,The University of Toledo,Toledo,United States,,,,,2019-10-29,29 Oct 2019,International Journal of Intelligent Computing and Cybernetics,1756378X,19700182406,17563798,Journal,12,4,,444-465,,,3,0,,,,"Purpose

The purpose of this paper is to present design and performance evaluation through simulation of a parking management system (PMS) for a fully automated, multi-story, puzzle-type and robotic parking structure with the overall objective of minimizing customer wait times while maximizing the space utilization.

Design/methodology/approach

The presentation entails development and integration of a complete suite of path planning, elevator scheduling and resource allocation algorithms. The PMS aims to manage multiple concurrent requests, in real time and in a dynamic context, for storage and retrieval of vehicles loaded onto robotic carts for a fully automated, multi-story and driving-free parking structure. The algorithm suite employs the incremental informed search algorithm D* Lite with domain-specific heuristics and the uninformed search algorithm Uniform Cost Search for path search and planning. An optimization methodology based on nested partitions and Genetic algorithm is adapted for scheduling of a group of elevators. The study considered a typical business day scenario in the center of a metropolis.

Findings

The simulation study indicates that the proposed design for the PMS is able to serve concurrent storage-retrieval requests representing a wide range of Poisson distributed customer arrival rates in real time while requiring reasonable computing resources under realistic scenarios. The customer waiting times for both storage and retrieval requests are within acceptable bounds, which are set as no more than 5 min, even in the presence of up to 100 concurrent storage and retrieval requests. The design is able to accommodate a variety of customer arrival rates and presence of immobilized vehicles which are assumed to be scattered across the floors of the structure to make it possible for deployment in real-time environments.

Originality/value

The intelligent system design is novel as the fully automated robotic parking structures are just in the process of being matured from a technology standpoint.",NO
2-s2.0-85073956616,10.1080/1475939X.2019.1670248,,,Humanoid robots: learning a programming language to learn a traditional language,ar,Article,Keane T.,,Swinburne University of Technology,Melbourne,Australia,,,,,2019-10-20,20 October 2019,"Technology, Pedagogy and Education",1475939X,5800179620,17475139,Journal,28,5,,533-546,,,3,0,,,,"This research is part of a larger three-year study investigating the impact of humanoid robots on students’ learning and engagement. In this case study, Aboriginal and non-Aboriginal students worked with a humanoid robot to develop, in parallel, both their programming skills and their understanding of the traditional Narungga language and culture. For six months a school engaged students in learning two languages: the coding language required to program the robot and the Narungga language. Qualitative data were collected and triangulated to determine how the humanoid robot was utilised in the classroom and re-occurring themes were identified through the case study. This research drew on questionnaires, interviews and journals from teachers to understand the impact of humanoid robots on student learning. The case study demonstrated how using humanoid robots enhanced pride and interest in Aboriginal language and culture.",SI
2-s2.0-85060085888,10.1007/s10514-019-09829-4,,,Reinforcement learning and model predictive control for robust embedded quadrotor guidance and control,ar,Article,Greatwood C.,,Bristol Robotics Laboratory;University of Bristol,Bristol;Bristol,United Kingdom;United Kingdom,,,,,2019-10-15,15 October 2019,Autonomous Robots,09295593,18016,15737527,Journal,43,7,,1681-1693,,,16,1,,,,"A new method for enabling a quadrotor micro air vehicle (MAV) to navigate unknown environments using reinforcement learning (RL) and model predictive control (MPC) is developed. An efficient implementation of MPC provides vehicle control and obstacle avoidance. RL is used to guide the MAV through complex environments where dead-end corridors may be encountered and backtracking is necessary. All of the presented algorithms were deployed on embedded hardware using automatic code generation from Simulink. Results are given for flight tests, demonstrating that the algorithms perform well with modest computing requirements and robust navigation.",NO
2-s2.0-85077065603,10.11990/jheu.201811054,,,Research on multi-robot task assignment and path planning algorithm,ar,Article,Zhang Z.,,Harbin Engineering University,Harbin,China,,,,,2019-10-05,5 October 2019,Harbin Gongcheng Daxue Xuebao/Journal of Harbin Engineering University,10067043,29706,,Journal,40,10,,1753-1759,,,1,0,,,,,NO
2-s2.0-85071442524,10.1109/LRA.2019.2931199,,,RL-RRT: Kinodynamic Motion Planning via Learning Reachability Estimators from RL Policies,ar,Article,Chiang H.T.L.,,The University of New Mexico;Google LLC,Albuquerque;Mountain View,United States;United States,,,,,2019-10-01,October 2019,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,4,4,8772207,4298-4305,,,17,0,,,,"This letter addresses two challenges facing samplingbased kinodynamic motion planning: a way to identify good candidate states for local transitions and the subsequent computationally intractable steering between these candidate states. Through the combination of sampling-based planning, a Rapidly Exploring Randomized Tree (RRT) and an efficient kinodynamic motion planner through machine learning, we propose an efficient solution to long-range planning for kinodynamic motion planning. First, we use deep reinforcement learning to learn an obstacle-avoiding policy that maps a robot's sensor observations to actions, which is used as a local planner during planning and as a controller during execution. Second, we train a reachability estimator in a supervised manner, which predicts the RL policy's time to reach a state in the presence of obstacles. Lastly, we introduce RL-RRT that uses the RL policy as a local planner, and the reachability estimator as the distance function to bias tree-growth towards promising regions. We evaluate our method on three kinodynamic systems, including physical robot experiments. Results across all three robots tested indicate that RL-RRT outperforms state of the art kinodynamic planners in efficiency, and also provides a shorter path finish time than a steering function free method. The learned local planner policy and accompanying reachability estimator demonstrate transferability to the previously unseen experimental environments, making RL-RRT fast because the expensive computations are replaced with simple neural network inference.",NO
2-s2.0-85069791396,10.1109/LRA.2019.2925731,,,Deep visual mpc-policy learning for navigation,ar,Article,Hirose N.,,Stanford University,Palo Alto,United States,,,,,2019-10-01,October 2019,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,4,4,8750823,3184-3191,,,12,0,,,,"Humans can routinely follow a trajectory defined by a list of images/landmarks. However, traditional robot navigation methods require accurate mapping of the environment, localization, and planning. Moreover, these methods are sensitive to subtle changes in the environment. In this letter, we propose PoliNet, a deep visual model predictive control-policy learning method that can perform visual navigation while avoiding collisions with unseen objects on the navigation path. PoliNet takes in as input a visual trajectory and 360° images from robot's current view and outputs velocity commands fora planning horizon of N steps that optimally balance between trajectory following and obstacle avoidance. PoliNet is trained using a differentiable neural image predictive model and a traversability estimation model in an model predictive control setup, with minimal human supervision. PoliNet can be applied to visual trajectory in new scenes without retraining. We show experimentally that the robot can follow a visual trajectory even if it does not start from the exact same position and in the presence of previously unseen obstacles. We validated our algorithm with tests both in a realistic simulation environment and in the real world outperforming state-of-the-art baselines under similar conditions in success rate, coverage rate of the trajectory, and with lower computational load. We also show that we can generate visual trajectory in simulation and execute the corresponding path in the real environment.",NO
2-s2.0-85060555434,10.1007/s10846-019-00986-3,,,Design of Direct Teaching Behavior of Collaborative Robot Based on Force Interaction,ar,Article,Ren T.,,Tsinghua University,Beijing,China,,,,,2019-10-01,1 October 2019,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,96,1,,83-93,,,6,0,,,,"Direct teaching can help users without the expertise of robots to quickly program a robot and plan trajectories in a complex environment. It is one of the typical applications of human-robot cooperation for improving production efficiency. However, the existing direct teaching system and related research have the problem that the human-robot communication is not intuitive enough, and the personnel safety in the teaching-playback process cannot be fully guaranteed. Based on the self-developed torque-controlled robot platform, we propose a force interaction method to achieve natural command communication. Then, combined with the analysis of the security threats in the operation process, a proper behavior of the direct teaching robot is designed to form a complete teaching-playback strategy. The proposed force recognition method and direct teaching behavior are verified on a 7-DOF collaborative robot.",NO
2-s2.0-85075633714,10.1109/MSSC.2019.2939336,,,Peeking into the Black Box: A Tutorial on Automated Design Optimization and Parameter Search,ar,Article,Javaheripi M.,,The Electrical and Computer Engineering Department,San Diego,United States,,,,,2019-09-01,Fall 2019,IEEE Solid-State Circuits Magazine,19430582,19700186850,19430590,Trade Journal,11,4,8901478,23-28,,,5,0,,,,"Automated optimization algorithms are extensively used to search for optimal design parameters in applications ranging from designing compilers and analog circuits to crafting embedded machine -learning technology. System optimization is particularly laborious as the pertinent design space includes various conflicting objectives and a swarm of free parameters. Automating parameter optimization can enhance system quality while ensuring low design cost and high performance. In this tutorial, we review several recent optimization tools for selecting design parameters and architecture. These tools include heuristic methods, reinforcement learning (RL) and evolutionary strategies. We elaborate on the basics of each algorithm and explain the benefits and tradeoffs when each is applied to system design. To demonstrate how these methods can be applied, we review several real world examples: analog circuit design, neural network compression, and the design of domain -specific accelerators. We also touch on possible research directions and remaining challenges that need to be addressed.",NO
2-s2.0-85075368516,10.1007/s41315-019-00096-1,,,Learning from demonstration for locally assistive mobility aids,ar,Article,Poon J.,,Nara Institute of Science and Technology,Ikoma,Japan,,,,,2019-09-01,1 September 2019,International Journal of Intelligent Robotics and Applications,23665971,21100935977,2366598X,Journal,3,3,,255-268,,,2,1,,,,"Active assistive systems for mobility aids are largely restricted to environments mapped a-priori, while passive assistance primarily provides collision mitigation and other hand-crafted behaviors in the platform’s immediate space. This paper presents a framework providing active short-term assistance, combining the freedom of location independence with the intelligence of active assistance. Demonstration data consisting of on-board sensor data and driving inputs is gathered from an able-bodied expert maneuvring the mobility aid around a generic interior setting, and used in constructing a probabilistic intention model built with Radial Basis Function Networks. This allows for short-term intention prediction relying only upon immediately available user input and on-board sensor data, to be coupled with real-time path generation based upon the same expert demonstration data via Dynamic Policy Programming, a stochastic optimal control method. Together these two elements provide a combined assistive mobility system, capable of operating in restrictive environments without the need for additional obstacle avoidance protocols. Experimental results in both simulation and on the University of Technology Sydney semi-autonomous wheelchair in settings not seen in training data show promise in assisting users of power mobility aids.",NO
2-s2.0-85072633841,10.1515/cdbme-2019-0008,,,Combination of sensor-embedded and secure server-distributed artificial intelligence for healthcare applications,ar,Article,Gembaczka P.,,Fraunhofer Institute for Microelectronic Circuits and Systems IMS,Duisburg,Germany,,,,,2019-09-01,1 September 2019,Current Directions in Biomedical Engineering,,21100894488,23645504,Journal,5,1,,29-32,,,2,1,,,,,NO
2-s2.0-85071753361,10.18178/ijmerr.8.5.764-770,,,The effects for programming learning using actual robots control with scratch,ar,Article,Osogami M.,,Fukui University of Technology,Fukui,Japan,,,,,2019-09-01,1 September 2019,International Journal of Mechanical Engineering and Robotics Research,,21100788860,22780149,Journal,8,5,,764-770,,,0,0,,,,"—Recently, the ICT (Information and Communication Technology) engineers ’workforce shortage has been occurred with the progress of ICT development. In the new educational guidelines of Japan, the learning contents about ICT have been extended. Along with this, effective teaching materials for learning programming are in demand. In this study, we constructed a programming learning environment which can control actual robots using Scratch, which was developed at MIT. Using questionnaire data, we analyzed the effect of the learning environment on the learning experience of students. And by the results, it was found that with this learning environment, it is possible to improve the learning effect of any students, regardless of their original interest in computer operation.",SI
2-s2.0-85068934415,10.1016/j.robot.2019.07.002,S0921889018306493,,Collision-free allocation of temporally constrained tasks in multi-robot systems,ar,Article,D'Emidio M.,,Università degli Studi dell'Aquila,L'Aquila,Italy,,,,,2019-09-01,September 2019,Robotics and Autonomous Systems,09218890,18079,,Journal,119,,,151-172,,,6,0,,,,"Highlights

•

Investigation about Pickup and delivery tasks with deadlines in a multi-robot systems.

•

Task swapping between robots can results in negative effects.

•

Allocation of tasks and ensuring collision free trajectories is computationally hard.

•

A novel measure for ordering temporally constrained tasks performs good.

•

New scoring function for optimization of multiple objectives is effective.

•

Proving, theoretically and experimentally, the correctness of the new algorithm.

•

Extensive simulation showing the effectiveness of the proposed algorithm.
Multi-robot systems (MRS) are a reference solution for many prominent real-world applications, e.g. management of warehouses or exploration of unknown environments. One of the most fundamental computational problems in MRS is that of planning the assignment of tasks to robots when such tasks have deadlines, i.e. constraints on when the execution must take place.

The problem, when multiple objective functions of interest need to be optimized, is both NP-Hard and hard to approximate, and few heuristics are known in the literature to handle it. Unfortunately, none of them guarantees that the trajectories used by the robots when moving between tasks’ locations are collision-free at planning time. Rather, they implement a reactive behavior, i.e. they abort the execution of a planned task whenever something goes wrong, e.g. trajectories of robots intersect or a deadline is missed due to some obstacle. This approach induces negative effects on the global performance of the system in the form of waste of energy, due to high distances traveled by the fleet members, or in the form of high convergence time to execute tasks. Therefore, planning the assignments of temporally constrained tasks with the guarantee of avoiding collisions can be a desirable feature for multi-robot systems.

In this paper, we present CFAT-D (Collision-Free Allocation of Tasks having Deadlines), a new algorithm that can allocate temporally constrained tasks while guaranteeing that used trajectories are collision-free at planning time. We prove CFAT-D to be correct and showcase its effectiveness through an extensive experimental evaluation. Finally, we provide a roadmap toward the practical implementation of the new strategy in real-world environments.",NO
2-s2.0-85067212468,10.1016/j.sysarc.2019.05.005,S1383762118306088,,MakeCode and CODAL: Intuitive and efficient embedded systems programming for education,ar,Article,Devine J.,,Lancaster University,Lancaster,United Kingdom,,,,,2019-09-01,September 2019,Journal of Systems Architecture,13837621,12398,,Journal,98,,,468-483,,,7,1,,,,"Historically, embedded systems development has been a specialist skill, requiring knowledge of low-level programming languages, complex compilation toolchains, and specialist hardware, firmware, device drivers and applications. However, it has now become commonplace for a broader range of non-specialists to engage in the making (design and development) of embedded systems - including educators to motivate and excite their students in the classroom. This diversity brings its own set of unique requirements, and the complexities of existing embedded systems development platforms introduce insurmountable barriers to entry.

In this paper we present the motivation, requirements, implementation, and evaluation of a new programming platform that enables novice users to create effective and efficient software for embedded systems. The platform has two major components: (1) Microsoft MakeCode (www.makecode.com), a web app that encapsulates an accessible IDE for microcontrollers; and (2) CODAL, an efficient component-oriented C++ runtime for microcontrollers. We show how MakeCode and CODAL combine to provide an accessible, cross-platform, installation-free, high level programming experience for embedded devices without sacrificing performance and efficiency.",SI
2-s2.0-85047627817,10.1109/TCDS.2018.2841002,,,Automatic Object Searching and Behavior Learning for Mobile Robots in Unstructured Environment by Deep Belief Networks,ar,Article,Wang J.,,Sichuan University,Chengdu,China,,,,,2019-09-01,September 2019,IEEE Transactions on Cognitive and Developmental Systems,23798920,21100784665,23798939,Journal,11,3,8367845,395-404,,,5,0,,,,"Automatic object searching is one of the essential skills for domestic robots to operate in unstructured human environments. It involves concatenation of several capabilities, including object identification, obstacle avoidance, path planning, and navigation. In this paper, we propose an automatic object searching framework for a mobile robot equipped with a single RGB-D camera. The obstacle avoidance is achieved by a behavior learning algorithm based on deep belief networks. The target object is recognized using scale-invariant feature transform descriptors and the relative position between the target and mobile robot is estimated from the RGB-D data. Subsequently, the mobile robot makes a path planning to the target location using an improved bug-based algorithm. The framework is tested in indoor environments and requires the robot to perform obstacle avoidance and automatically search and approach the target object. The results indicate that the system is collision free and reliable in performing searching tasks. This system's functions make itself have the potential of being used for local navigation in unstructured environments.",NO
2-s2.0-85080911365,10.2316/J.2019.206-5213,,,Robotic obstacle avoidance in a partially observable environment using feature ranking,ar,Article,Gharbieh W.,,Princess Sumaya University,Amman,Jordan,,,,,2019-08-29,29 August 2019,International Journal of Robotics and Automation,08268185,25482,,Journal,34,5,,572-579,,,1,0,,,,"In this paper, a decision-making system that is based on feature ranking is presented to allow a robot to navigate back and forth between two points. The path of the robot contains an unknown number of both static and moving obstacles that get in its way. To simulate the use of real sensors, the implementation uses only local information available within a predeﬁned radius for decision- making. To address this problem, feature ranking is introduced, where the top k obstacles are taken into consideration in planning the robot path. Feature ranking is applied to linear regression and neural networks to compare their generalization ability against a baseline policy. During the development of the system, the robot undergoes a learning phase, where the moving obstacles move at 50% of the robot’s speed. When learning phase is complete, the generalization ability of the policy learned by both algorithms is tested by generating environments with various obstacle speeds. The results show that the policy developed performs much better than the baseline policy with the neural network outperforming linear regression in the majority of the environments.",NO
2-s2.0-85070370844,10.1108/JET-12-2018-0069,,,High-functioning autistic children programming robotic behaviour,ar,Article,Lahav O.,,Tel Aviv University,Tel Aviv-Yafo,Israel,,,,,2019-08-19,19 Aug 2019,Journal of Enabling Technologies,,21100818512,23986263,Journal,13,2,,82-91,,,0,0,,,,"Purpose

The purpose of this paper is to examine the ability of high-functioning autistic (HFA) children to programme robotic behaviour and sought to elucidate how they describe and construct a robot’s behaviour using iconic programming software.

Design/methodology/approach

The robotic learning environment is based on the iPad, an iconic programming app (KinderBot), and EV3. Two case studies, of A. and N., both HFA children of average age 10.5, are the focus of this research.

Findings

The research revealed how the participants succeeded in programming the behaviour of an “other” at different programming complexity levels (from simple action to combinations of states of two binary sensors and rule with subroutine). A transformation from procedural to declarative description was also found.

Practical implications

This research on the ability of HFA children to programme robotic behaviour yielded results that can be implemented in K-12 education. Furthermore, learning to programme robots and understand how robotic technologies work may help HFA children to better understand other technology in their environment.

Originality/value

In this research, the authors present an innovative approach that for the first time enables HFA children to “design” the behaviour of smart artefacts to use their sensors to adapt in accordance with the environment. For most HFA children, this would be the first opportunity to “design” the behaviour of the other, as opposed to oneself, since in most of their experience they have been largely controlled by another person.",SI
2-s2.0-85071281551,10.3390/s19163488,,31404963,"Olfaction, vision, and semantics for mobile robots. Results of the IRO project",ar,Article,Monroy J.,,Universidad de Málaga,Malaga,Spain,,,,,2019-08-02,2 August 2019,Sensors (Switzerland),14248220,130124,,Journal,19,16,3488,,,,2,1,,,,"Olfaction is a valuable source of information about the environment that has not been sufficiently exploited in mobile robotics yet. Certainly, odor information can contribute to other sensing modalities, e.g., vision, to accomplish high-level robot activities, such as task planning or execution in human environments. This paper organizes and puts together the developments and experiences on combining olfaction and vision into robotics applications, as the result of our five-years long project IRO: Improvement of the sensory and autonomous capability of Robots through Olfaction. Particularly, it investigates mechanisms to exploit odor information (usually coming in the form of the type of volatile and its concentration) in problems such as object recognition and scene–activity understanding. A distinctive aspect of this research is the special attention paid to the role of semantics within the robot perception and decision-making processes. The obtained results have improved the robot capabilities in terms of efficiency, autonomy, and usefulness, as reported in our publications. View Full-Text",NO
2-s2.0-85079785241,10.1007/s42452-019-0941-2,,,A simple and highly portable MATLAB interface for learning robotics,ar,Article,Calusdian J.,,Naval Postgraduate School,Monterey,United States,,,,,2019-08-01,August 2019,SN Applied Sciences,,21101037132,25233971,Journal,1,8,890,,,,1,1,,,,"In order to attract engineering students from across a wide range of disciplines and subject areas to the study of robotics, it was highly desirable to have an easy-to-use MATLAB-based interface for students to use to program robots and conduct robot experiments. Undoubtedly, MATLAB is one of the most prevalent programming languages engineering students use for modeling, analysis, and data visualization. In this paper, a simple and highly portable MATLAB interface is introduced to support laboratory instruction and experimentation in robotics. This robot interface leverages student’s prior knowledge and skills in MATLAB so that it is easy for them to begin working and learning about many of the fascinating aspects of robotics. The interface was specifically developed for the Pioneer family of mobile robots, which uses a client–server communication model based on the Advanced Robotics Control and Operations Software (ARCOS). The interface client was developed using basic MATLAB functions and communicates directly with the ARCOS server operating on many Pioneer robots. The interface is very light weight and highly portable to any computing platform that supports MATLAB.",SI
2-s2.0-85071875228,10.3390/electronics8080899,,,Pybokids: An innovative python-based educational framework using real and simulated Arduino robots,ar,Article,Vega J.,,Universidad Rey Juan Carlos,Madrid,Spain,,,,,2019-08-01,August 2019,Electronics (Switzerland),,21100829272,20799292,Journal,8,8,899,,,,12,1,,,,"In western countries, robotics is becoming increasingly common in primary and secondary education, both as a specific discipline and a tool to make science, technology, engineering, and mathematics (STEM) subjects more appealing to children. The impact of robotics on society is also growing yearly, with new robotics applications in such things as autonomous cars, vacuum cleaners, and the area of logistics. In addition, the labor market is constantly demanding more professionals with robotics skills. This paper presents the PyBoKids framework for teaching robotics in secondary school, where its aim is to improve pre-university robotics education. It is based on the Python programming language and robots using an Arduino microprocessor. It includes a software infrastructure and a collection of practical exercises directed at pre-university students. The software infrastructure provides support for real and simulated robots. Moreover, we describe a pilot teaching project based on this framework, which was used by more than 2000 real students over the last two years. View Full-Text",SI
2-s2.0-85070437289,10.1109/TRO.2019.2911800,,,Adaptive Motion Planning for a Collaborative Robot Based on Prediction Uncertainty to Enhance Human Safety and Work Efficiency,ar,Article,Kanazawa A.,,"Hitachi, Ltd.",Tokyo,Japan,,,,,2019-08-01,August 2019,IEEE Transactions on Robotics,15523098,95101,19410468,Journal,35,4,8727974,817-832,,,15,1,,,,"Industrial robots are expected to share the same workspace with human workers and work in cooperation with humans to improve the productivity and maintain the quality of products. In this situation, the worker's safety and work-time efficiency must be enhanced simultaneously. In this paper, we extend a task scheduling system proposed in the previous work by installing an online trajectory generation system. On the basis of the probabilistic prediction of the worker's motion and the receding horizon scheme for the trajectory planning, the proposed motion planning system calculates an optimal trajectory that realizes collision avoidance and the reduction of waste time simultaneously. Moreover, the proposed system plans the robot's trajectory adaptively based on updated predictions and its uncertainty to deal not only with the regular behavior of workers but also with their irregular behavior. We apply the proposed system to an assembly process where a two-link planar manipulator supports a worker by delivering parts and tools. After implementing the proposed system, we experimentally evaluate the effectiveness of the adaptive motion planning system.",NO
2-s2.0-85067878520,10.1177/0278364919856695,,,Probabilistic planning with formal performance guarantees for mobile service robots,ar,Article,Lacerda B.,,University of Oxford,Oxford,United Kingdom,,,,,2019-08-01,1 August 2019,International Journal of Robotics Research,02783649,18050,17413176,Journal,38,9,,1098-1123,,,13,1,,,,"We present a framework for mobile service robot task planning and execution, based on the use of probabilistic verification techniques for the generation of optimal policies with attached formal performance guarantees. Our approach is based on a Markov decision process model of the robot in its environment, encompassing a topological map where nodes represent relevant locations in the environment, and a range of tasks that can be executed in different locations. The navigation in the topological map is modeled stochastically for a specific time of day. This is done by using spatio-temporal models that provide, for a given time of day, the probability of successfully navigating between two topological nodes, and the expected time to do so. We then present a methodology to generate cost optimal policies for tasks specified in co-safe linear temporal logic. Our key contribution is to address scenarios in which the task may not be achievable with probability one. We introduce a task progression function and present an approach to generate policies that are formally guaranteed to, in decreasing order of priority: maximize the probability of finishing the task; maximize progress towards completion, if this is not possible; and minimize the expected time or cost required. We illustrate and evaluate our approach with a scalability evaluation in a simulated scenario, and report on its implementation in a robot performing service tasks in an office environment for long periods of time.",NO
2-s2.0-85065093052,10.1016/j.robot.2019.03.005,S0921889018303506,,A Survey of Knowledge Representation in Service Robotics,ar,Article,Paulius D.,,"University of South Florida, Tampa",Tampa,United States,,,,,2019-08-01,August 2019,Robotics and Autonomous Systems,09218890,18079,,Journal,118,,,13-30,,,32,1,,,,"Highlights

•

The main contribution of our paper is a focused discussion on what a knowledge representation is as it pertains to the robotics field: a comprehensive tool that encompasses high-level knowledge and low-level features.

•

This paper aims to define and discuss knowledge representation for robots, to review the literature for existing solutions, and to identify possible issues in the creation of an effective representation. We also review several tools and/or models that have been successfully applied to smaller sub-problems in robot learning and manipulation, which can be used as components to knowledge representations.

•

We discuss key characteristics of representations that allow them to function, in spite of the highly variable nature of a robot’s working environment and the objects found within it. We also propose specific requirements that are necessary to build the ideal knowledge representation, drawing on concepts discussed in previous works.
Within the realm of service robotics, researchers have placed a great amount of effort into learning, understanding, and representing motions as manipulations for task execution by robots. The task of robot learning and problem-solving is very broad, as it integrates a variety of tasks such as object detection, activity recognition, task/motion planning, localization, knowledge representation and retrieval, and the intertwining of perception/vision and machine learning techniques. In this paper, we solely focus on knowledge representations and notably how knowledge is typically gathered, represented, and reproduced to solve problems as done by researchers in the past decades. In accordance with the definition of knowledge representations, we discuss the key distinction between such representations and useful learning models that have extensively been introduced and studied in recent years, such as machine learning, deep learning, probabilistic modeling, and semantic graphical structures. Along with an overview of such tools, we discuss the problems which have existed in robot learning and how they have been built and used as solutions, technologies or developments (if any) which have contributed to solving them. Finally, we discuss key principles that should be considered when designing an effective knowledge representation.",NO
2-s2.0-85056131534,10.1007/s11633-018-1154-7,,,Synthesizing Robot Programs with Interactive Tutor Mode,ar,Article,Li H.,,Tsinghua University,Beijing,China,,,,,2019-08-01,1 August 2019,International Journal of Automation and Computing,14768186,5200152703,17518520,Journal,16,4,,462-474,,,0,0,,,,"With the rapid development of the robotic industry, domestic robots have become increasingly popular. As domestic robots are expected to be personal assistants, it is important to develop a natural language-based human-robot interactive system for end-users who do not necessarily have much programming knowledge. To build such a system, we developed an interactive tutoring framework, named “Holert”, which can translate task descriptions in natural language to machine-interpretable logical forms automatically. Compared to previous works, Holert allows users to teach the robot by further explaining their intentions in an interactive tutor mode. Furthermore, Holert introduces a semantic dependency model to enable the robot to “understand” similar task descriptions. We have deployed Holert on an open-source robot platform, Turtlebot 2. Experimental results show that the system accuracy could be significantly improved by 163.9% with the support of the tutor mode. This system is also efficient. Even the longest task session with 10 sentences can be handled within 0.7 s.",NO
2-s2.0-85071946269,10.3785/j.issn.1008-973X.2019.07.010,,,Self-learning framework for attribution relationship of people carrying objects under family environment,ar,Article,Wu H.,,Shandong University,Jinan,China,,,,,2019-07-01,1 July 2019,Zhejiang Daxue Xuebao (Gongxue Ban)/Journal of Zhejiang University (Engineering Science),1008973X,15156,,Journal,53,7,,1315-1322,,,0,0,,,,"It is necessary for service robots to have the ability to independently obtain the attribution relationship between people and their carrying objects in order to satisfy the requirements of robot personalized service and enable robots to select exclusive objects to perform inference and planning according to different service individual. A self-learning framework for the attribution relationship between people and their carrying objects was proposed aiming at the problem of the attribution relationship between people carrying objects and people in the family environment. The method of detecting and locating people carrying objects was used based on the object detection model SSD and the human posture estimation model OpenPose in order to realize the detection of human carrying objects. The face detection and recognition model MTCNN were used to complete the service individual identification by extracting the objects features by convolutional neural network based on migration learning and using the backend classifier to complete the object instance attribute identification. The self-learning of the attribution relationship was completed through the self-learning strategy. The experimental results show that the proposed self-learning framework for attribution relationship of people carrying objects can accurately and efficiently complete the learning of attribution relationship, effectively eliminating the influence of environmental interference factors on attribution learning. The proposed framework has good accuracy and robustness.",NO
2-s2.0-85068453400,10.1109/LRA.2019.2923386,,,Interaction Templates for Multi-Robot Systems,ar,Article,Motes J.,,Texas AandM University,Uvalde,United States,,,,,2019-07-01,July 2019,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,4,3,8737744,2926-2933,,,3,0,,,,"This letter describes a framework for multi-robot problems that require or utilize interactions between robots. Solutions consider interactions on a motion planning level to determine the feasibility and cost of the multi-robot team solution. Modeling these problems with current integrated task and motion planning (TMP) approaches typically requires reasoning about the possible interactions and checking many of the possible robot combinations when searching for a solution. We present a multi-robot planning method called Interaction Templates (ITs), which moves certain types of robot interactions from the task planner to the motion planner. ITs model interactions between a set of robots with a small roadmap. This roadmap is then tiled into the environment and connected to the robots’ individual roadmaps. The resulting combined roadmap allows interactions to be considered by the motion planner. We apply ITs to homogeneous and heterogeneous robot teams under both required and optional cooperation scenarios, which previously required a task planning method. We show improved performance over a current TMP planning approach.",NO
2-s2.0-85067048886,10.1177/0278364919845047,,,Detection and correction of subtle context-dependent robot model inaccuracies using parametric regions,ar,Article,Mendoza J.P.,,Carnegie Mellon University,Pittsburgh,United States,,,,,2019-07-01,1 July 2019,International Journal of Robotics Research,02783649,18050,17413176,Journal,38,8,,887-909,,,0,1,,,,"Autonomous robots frequently rely on models of their sensing and actions for intelligent decision making. Unfortunately, in complex environments, robots are bound to encounter situations in which their models do not accurately represent the world. Furthermore, these context-dependent model inaccuracies may be subtle, such that multiple observations may be necessary to distinguish them from noise. This paper formalizes the problem of detection and correction of such subtle contextual model inaccuracies in autonomous robots, and presents an algorithm to address this problem. The solution relies on reasoning about these contextual inaccuracies as parametric regions of inaccurate modeling (RIMs) in the robot’s planning space. Empirical results from various real robot domains demonstrate that, by explicitly searching for RIMs, robots are capable of efficiently detecting subtle contextual model inaccuracies, which in turn can lead to task performance improvement.",NO
2-s2.0-85065464850,10.1109/LRA.2019.2898714,,,Specifying dual-arm robot planning problems through natural language and demonstration,ar,Article,Behrens J.K.,,Robert Bosch GmbH,Gerlingen,Germany,,,,,2019-07-01,July 2019,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,4,3,8638957,2622-2629,,,4,0,,,,"Multi-modal robot programming with natural language and demonstration is a promising technique for efficient teaching of manipulation tasks in industrial environments. In particular, with modern dual-arm robots designed to quickly take over tasks at typical industrial workbenches, the direct teaching of task sequences hardly utilizes the robots' capabilities. We therefore propose a two-staged approach that combines natural language instructions and demonstration with simultaneous task allocation and motion scheduling based on constraint programming. Instead of providing a task description and demonstrations that are replayed to a large extent, the user describes tasks to be scheduled with all relevant constraints and demonstrates relevant locations relative to workpieces and other objects. With explicitly stated constraints on the partial ordering of tasks, the solver allocates the tasks to the robot arms and schedules them in time while avoiding self-collisions and reducing the makespan in our experiment by 33%. The linguistic concepts of naming and grouping enable systematic reuse of sub-task ensembles. The proposed approach is evaluated with four variants of a gluing use-case from furniture assembly in user studies with ten participants. In these user studies, we observed a speed-up for the task definition of more than six times compared to a textual specification of the planning problems using the Python-based planner API.",NO
2-s2.0-85064654584,10.1016/j.robot.2019.04.006,S0921889018303075,,Trajectory generation with multi-stage cost functions learned from demonstrations,ar,Article,Hu J.,,State Key Laboratory of Industrial Control Technology,Hangzhou,China,,,,,2019-07-01,July 2019,Robotics and Autonomous Systems,09218890,18079,,Journal,117,,,57-67,,,2,0,,,,"Highlights

•

A novel multi-stage cost learning method is presented.

•

Learn cost functions without restrictions of limited numbers or simple forms.

•

Achieve better segmentation accuracy than two nonparametric segmentation method.

•

Generate trajectories that maintain properties of each substage in new environment.
Learning from demonstration provides an effective method to resolve the problem of teaching robot to execute complex motions without expert knowledge about the robot system. In this paper, we present a novel learning from demonstration method based on multi-stage cost learning. The recorded demonstrations are assumed to be composed of several substages chained together. Leveraging this assumption, a segmentation and cost learning framework is proposed to search for the cutting points that divide the unsegmented demonstrations into multiple substages and retrieve cost function for each substage. To the best of our knowledge, it is the first solution to learn multi-stage cost functions in continuous domain without restricting the possible cost functions into limited numbers or simple forms. To generate new trajectory, a complete objective functional is constructed based on the learned multi-stage cost functions plus other constraints like obstacle avoidance and is optimized with functional gradient method. The generated trajectory can adapt to new environments while maintain the specific properties of each substage as demonstrations. The effectiveness of the proposed method is verified through simulation study and experiments conducted on a real robot manipulator.",NO
2-s2.0-85064006237,10.1109/LRA.2019.2901898,,,Robot Motion Planning in Learned Latent Spaces,ar,Article,Ichter B.,,Google LLC,Mountain View,United States,,,,,2019-07-01,July 2019,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,4,3,8653875,2407-2414,,,27,1,,,,"This letter presents latent sampling-based motion planning (L-SBMP), a methodology toward computing motion plans for complex robotic systems by learning a plannable latent representation. Recent works in control of robotic systems have effectively leveraged local, low-dimensional embeddings of high-dimensional dynamics. In this letter, we combine these recent advances with techniques from sampling-based motion planning (SBMP) in order to design a methodology capable of planning for high-dimensional robotic systems beyond the reach of traditional approaches (e.g., humanoids, or even systems where planning occurs in the visual space). Specifically, the learned latent space is constructed through an autoencoding network, a dynamics network, and a collision checking network, which mirror the three main algorithmic primitives of SBMP, namely state sampling, local steering, and collision checking. Notably, these networks can be trained through only raw data of the system's states and actions along with a supervising collision checker. Building upon these networks, an RRT-based algorithm is used to plan motions directly in the latent space-we refer to this exploration algorithm as learned latent RRT. This algorithm globally explores the latent space and is capable of generalizing to new environments. The overall methodology is demonstrated on two planning problems, namely a visual planning problem, whereby planning happens in the visual (pixel) space, and a humanoid robot planning problem.",NO
2-s2.0-85063446798,10.1109/LRA.2019.2903261,,,PRIMAL: Pathfinding via Reinforcement and Imitation Multi-Agent Learning,ar,Article,Sartoretti G.,,The Robotics Institute,Pittsburgh,United States,,,,,2019-07-01,July 2019,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,4,3,8661608,2378-2385,,,39,1,,,,"Multi-agent path finding (MAPF) is an essential component of many large-scale, real-world robot deployments, from aerial swarms to warehouse automation. However, despite the community's continued efforts, most state-of-the-art MAPF planners still rely on centralized planning and scale poorly past a few hundred agents. Such planning approaches are maladapted to realworld deployments, where noise and uncertainty often require paths be recomputed online, which is impossible when planning times are in seconds to minutes. We present PRIMAL, a novel framework for MAPF that combines reinforcement and imitation learning to teach fully decentralized policies, where agents reactively plan paths online in a partially observable world while exhibiting implicit coordination. This framework extends our previous work on distributed learning of collaborative policies by introducing demonstrations of an expert MAPF planner during training, as well as careful reward shaping and environment sampling. Once learned, the resulting policy can be copied onto any number of agents and naturally scales to different team sizes and world dimensions. We present results on randomized worlds with up to 1024 agents and compare success rates against state-of-the-art MAPF planners. Finally, we experimentally validate the learned policies in a hybrid simulation of a factory mockup, involving both real world and simulated robots.",NO
2-s2.0-85050271198,10.1177/0037549718785440,,,Distributed path planning of a multi-robot system based on the neighborhood artificial potential field approach,ar,Article,Matoui F.,,Université de Gabès,,Tunisia,,,,,2019-07-01,1 July 2019,Simulation,00375497,14452,17413133,Journal,95,7,,637-657,,,10,0,,,,"The current study is set up to investigate the problem of planning the trajectories of a multi-robot system. It puts emphasis on the idea of using distributed architecture to plan the trajectories of a group of wheeled mobile robots. Each robot must be able to detect and avoid collision with both static and dynamic obstacles present in its environment/neighborhood. This study seeks to improve the artificial potential field (APF) method in order to have good trajectory planning of a multi-robot system. In order to address the purpose of this work, we employed the hybrid approach, which is a combination of three techniques: the APF method; the neighborhood system; and the notion of priority between the robots. Moreover, the minimum local problem is handled in this paper using the non-minimum speed algorithm. The implemented approach is adapted to solve the trajectory planning problem for a multi-robot system. So, the problem of intersection of robots at the same passage point is solved through using the method of assignment of priority between robots. We also used the neighborhood detection technique to reduce the influence area of each robot and to optimize the time of calculation. The overall system equations associated to the robots are updated at each time of simulation to react at any condition that might suddenly emerge. The approach is implemented with MATLAB/Simulink and Solidworks/Simmechanics.",NO
2-s2.0-85052520247,10.1007/s10514-018-9798-2,,,Environment-adaptive interaction primitives through visual context for human–robot motor skill learning,ar,Article,Cui Y.,,Nara Institute of Science and Technology,Ikoma,Japan,,,,,2019-06-15,15 June 2019,Autonomous Robots,09295593,18016,15737527,Journal,43,5,,1225-1240,,,1,1,,,,"In situations where robots need to closely co-operate with human partners, consideration of the task combined with partner observation maintains robustness when partner behavior is erratic or ambiguous. This paper documents our approach to capture human–robot interactive skills by combining their demonstrative data with additional environmental parameters automatically derived from observation of task context without the need for heuristic assignment, as an extension to overcome shortcomings of the interaction primitives framework. These parameters reduce the partner observation period required before suitable robot motion can commence, while also enabling success in cases where partner observation alone was inadequate for planning actions suited to the task. Validation in a collaborative object covering exercise with a humanoid robot demonstrate the robustness of our environment-adaptive interaction primitives, when augmented with parameters directly drawn from visual data of the task scene.",NO
2-s2.0-85062451927,10.1108/ILS-05-2018-0035,,,Teachers’ goals predict computational thinking gainsin robotics,ar,Article,Witherspoon E.B.,,University of Pittsburgh,Pittsburgh,United States,,,,,2019-06-10,10 Jun 2019,Information and Learning Science,23985348,21100805777,,Journal,120,5-6,,308-326,,,7,0,,,,"Purpose

Computational thinking (CT) is widely considered to be an important component of teaching generalizable computer science skills to all students in a range of learning environments, including robotics. However, despite advances in the design of robotics curricula that can teach CT, actual enactment in classrooms may often fail to reach this target. This study aims to understand whether the various instructional goals teachers’ hold when using these curricula may offer one potential explanation for disparities in outcomes.

Design/methodology/approach

In this study, the authors examine results from N = 206 middle-school students’ pre- and post-tests of CT, attitudinal surveys and surveys of their teacher’s instructional goals to determine if student attitudes and learning gains in CT are related to the instructional goals their teachers endorsed while implementing a shared robotics programming curriculum.

Findings

The findings provide evidence that despite using the same curriculum, students showed differential learning gains on the CT assessment when in classrooms with teachers who rated CT as a more important instructional goal; these effects were particularly strong for women. Students in classroom with teachers who rated CT more highly also showed greater maintenance of positive attitudes toward programming.

Originality/value

While there is a growing body of literature regarding curricular interventions that provide CT learning opportunities, this study provides a critical insight into the role that teachers may play as a potential support or barrier to the success of these curricula. Implications for the design of professional development and teacher educative materials that attend to teachers’ instructional goals are discussed.",SI
2-s2.0-85067009122,10.1108/EL-10-2018-0213,,,A Chinese ancient book digital humanities research platform to support digital humanities research,ar,Article,Chen C.M.,,National Chengchi University,Taipei,Taiwan,,,,,2019-06-03,3 Jun 2019,Electronic Library,02640473,15420,,Journal,37,2,,314-336,,,2,0,,,,"Purpose

With the rapid development of digital humanities, some digital humanities platforms have been successfully developed to support digital humanities research for humanists. However, most of them have still not provided a friendly digital reading environment and practicable social network analysis tool to support humanists on interpreting texts and exploring characters’ social network relationships. Moreover, the advancement of digitization technologies for the retrieval and use of Chinese ancient books is arising an unprecedented challenge and opportunity. For these reasons, this paper aims to present a Chinese ancient books digital humanities research platform (CABDHRP) to support historical China studies. In addition to providing digital archives, digital reading, basic search and advanced search functions for Chinese ancient books, this platform still provides two novel functions that can more effectively support digital humanities research, including an automatic text annotation system (ATAS) for interpreting texts and a character social network relationship map tool (CSNRMT) for exploring characters’ social network relationships.

Design/methodology/approach

This study adopted DSpace, an open-source institutional repository system, to serve as a digital archives system for archiving scanned images, metadata, and full texts to develop the CABDHRP for supporting digital humanities (DH) research. Moreover, the ATAS developed in the CABDHRP used the Node.js framework to implement the system’s front- and back-end services, as well as application programming interfaces (APIs) provided by different databases, such as China Biographical Database (CBDB) and TGAZ, used to retrieve the useful linked data (LD) sources for interpreting ancient texts. Also, Neo4j which is an open-source graph database management system was used to implement the CSNRMT of the CABDHRP. Finally, JavaScript and jQuery were applied to develop a monitoring program embedded in the CABDHRP to record the use processes from humanists based on xAPI (experience API). To understand the research participants’ perception when interpreting the historical texts and characters’ social network relationships with the support of ATAS and CSNRMT, semi-structured interviews with 21 research participants were conducted.

Findings

An ATAS embedded in the reading interface of CABDHRP can collect resources from different databases through LD for automatically annotating ancient texts to support digital humanities research. It allows the humanists to refer to resources from diverse databases when interpreting ancient texts, as well as provides a friendly text annotation reader for humanists to interpret ancient text through reading. Additionally, the CSNRMT provided by the CABDHRP can semi-automatically identify characters’ names based on Chinese word segmentation technology and humanists’ support to confirm and analyze characters’ social network relationships from Chinese ancient books based on visualizing characters’ social networks as a knowledge graph. The CABDHRP not only can stimulate humanists to explore new viewpoints in a humanistic research, but also can promote the public to emerge the learning interest and awareness of Chinese ancient books.

Originality/value

This study proposed a novel CABDHRP that provides the advanced features, including the automatic word segmentation of Chinese text, automatic Chinese text annotation, semi-automatic character social network analysis and user behavior analysis, that are different from other existed digital humanities platforms. Currently, there is no this kind of digital humanities platform developed for humanists to support digital humanities research.",NO
2-s2.0-85070913094,10.3772/j.issn.1002-0470.2019.06.008,,,Design of a human-machine interaction system for industrial robots based on QT,ar,Article,Xu J.,,Zhejiang University of Technology,Hangzhou,China,,,,,2019-06-01,1 June 2019,Gaojishu Tongxin/Chinese High Technology Letters,10020470,16121,,Journal,29,6,,576-584,,,0,0,,,,,NO
2-s2.0-85070532339,10.20965/jrm.2019.p0412,,,Teaching material imitating the advanced driver-assistance system for measurement and control education,ar,Article,Umeno T.,,University of Teacher Education Fukuoka,Munakata,Japan,,,,,2019-06-01,June 2019,Journal of Robotics and Mechatronics,09153942,21100197345,18838049,Journal,31,3,,412-418,,,0,0,,,,"
	",NO
2-s2.0-85069040659,10.3390/machines7020042,,,Unmanned ground vehicle modelling in Gazebo/ROS-based environments,ar,Article,Rivera Z.B.,,MEID4 Srl,Fisciano,Italy,,,,,2019-06-01,1 June 2019,Machines,,21100838145,20751702,Journal,7,2,42,,,,33,1,,,,"The fusion of different technologies is the base of the fourth industrial revolution. Companies are encouraged to integrate new tools in their production processes in order to improve working conditions and increase productivity and production quality. The integration between information, communication technologies and industrial automation can create highly flexible production models for products and services that can be customized through real-time interactions between consumer, production and machinery throughout the production process. The future of production, therefore, depends on increasingly intelligent machinery through the use of digital systems. The key elements for future integrated devices are intelligent systems and machines, based on human–machine interaction and information sharing. To do so, the implementation of shared languages that allow different systems to dialogue in a simple way is necessary. In this perspective, the use of advanced prototyping tools like Open-Source programming systems, the development of more detailed multibody models through the use of CAD software and the use of self-learning techniques will allow for developing a new class of machines capable of revolutionizing our companies. The purpose of this paper is to present a waypoint navigation activity of a custom Wheeled Mobile Robot (WMR) in an available simulated 3D indoor environment by using the Gazebo simulator. Gazebo was developed in 2002 at the University of Southern California. The idea was to create a high-fidelity simulator that gave the possibility to simulate robots in outdoor environments under various conditions. In particular, we wanted to test the high-performance physics Open Dynamics Engine (ODE) and the sensors feature present in Gazebo for prototype development activities. This choice was made for the possibility of emulating not only the system under analysis, but also the world in which the robot will operate. Furthermore, the integration tools available with Solidworks and Matlab-Simulink, well known commercial platforms of modelling and robotics control respectively, are also explored. View Full-Text",NO
2-s2.0-85063740287,10.1016/j.robot.2019.02.015,S0921889018302227,,"A service assistant combining autonomous robotics, flexible goal formulation, and deep-learning-based brain–computer interfacing",ar,Article,Kuhner D.,,Universität Freiburg,Freiburg im Breisgau,Germany,,,,,2019-06-01,June 2019,Robotics and Autonomous Systems,09218890,18079,,Journal,116,,,98-113,,,17,1,,,,"Highlights

•

BCI-controlled autonomous robotic service assistant.

•

First online brain–computer-interface using deep learning.

•

Menu-driven language generation based on referring expressions.

•

Modular ROS-based mobile robot interaction.

•

Experimental evaluation with a real robot.
As autonomous service robots become more affordable and thus available for the general public, there is a growing need for user-friendly interfaces to control these systems. Control interfaces typically get more complicated with increasing complexity of robotic tasks and environments. Traditional control modalities such as touch, speech or gesture are not necessarily suited for all users. While some users can make the effort to familiarize themselves with a robotic system, users with motor disabilities may not be capable of controlling such systems even though they need robotic assistance most. In this paper, we present a novel framework that allows these users to interact with a robotic service assistant in a closed-loop fashion, using only thoughts. The system is composed of several interacting components: a brain–computer interface (BCI) that uses non-invasive neuronal signal recording and co-adaptive deep learning, high-level task planning based on referring expressions, navigation and manipulation planning as well as environmental perception. We extensively evaluate the BCI in various tasks, determine the performance of the goal formulation user interface and investigate its intuitiveness in a user study. Furthermore, we demonstrate the applicability and robustness of the system in real-world scenarios, considering fetch-and-carry tasks, close human–robot interactions and in presence of unexpected changes. As our results show, the system is capable of adapting to frequent changes in the environment and reliably accomplishes given tasks within a reasonable amount of time. Combined with high-level task planning based on referring expressions and an autonomous robotic system, interesting new perspectives open up for non-invasive BCI-based human–robot interactions.",NO
2-s2.0-85061598599,10.1016/j.ijcci.2019.01.002,S2212868917300971,,"CyberPLAYce—A tangible, interactive learning tool fostering children's computational thinking through storytelling",ar,Article,Soleimani A.,,Kennesaw State University,Kennesaw,United States,,,,,2019-06-01,June 2019,International Journal of Child-Computer Interaction,22128689,21100228541,,Journal,20,,,9-23,,,4,0,,,,"The learning environment plays a critical role in a child’s life, affecting both cognitive development and effectiveness in work or play. As the boundary between physical and digital worlds blurs, there is a need for new digital tools and physical environments to support the everyday, cyber–physicalinteractions of children. This paper presents a Research-through-Design example of CyberPLAYce, a tangible, interactive, learning construction kit for children supporting storytelling and computational thinking (CT). The construction kit facilitates and enhances child-to-child, child-to-machine, and child-to-environment interactions through semi-structured play. It offers young students the opportunity to materialize their ideas through the construction of cyber–physical story algorithms allowing them to physically alter story segments while constructing and enhancing the storyline. The CyberPLAYce research places an emphasis on the importance of employing tangible learning tools in order to enhance children’s active engagement. We focus on the motivations for CyberPLAYce, its participatory design, and results of an empirical study concerning CT with 8-12 year-old storytellers in a classroom setting. Results from the study suggest that cyber–physical activities afforded by CyberPLAYce cultivate engaged storytelling and CT practices in children. This multidisciplinary design-research contributes to construction tools for children, cyber–physical storytelling and story-construction activities, and tangible computing and programming activities that support CT.",SI
2-s2.0-85056302210,10.1007/s00521-018-3845-y,,,A neuroplasticity-inspired neural circuit for acoustic navigation with obstacle avoidance that learns smooth motion paths,ar,Article,Shaikh D.,,Syddansk Universitet,Odense,Denmark,,,,,2019-06-01,1 June 2019,Neural Computing and Applications,09410643,24800,,Journal,31,6,,1765-1781,,,2,0,,,,"Acoustic spatial navigation for mobile robots is relevant in the absence of reliable visual information about the target that must be localised. Reactive robot navigation in such goal-directed phonotaxis tasks requires generating smooth motion paths towards the acoustic target while simultaneously avoiding obstacles. We have reported earlier on a neural circuit for acoustic navigation which learned stable robot motion paths for a simulated mobile robot. However, in complex environments, the learned motion paths were not smooth. Here, we extend our earlier architecture, by adding a path-smoothing behaviour, to generate smooth motion paths for a simulated mobile robot. This allows the robot to learn to smoothly navigate towards a virtual sound source while avoiding randomly placed obstacles in the environment. We demonstrate through five independent learning trials in simulation that the proposed extension learns motion paths that are not only smooth but also relatively shorter as compared to those generated without learning as well as by our earlier architecture.",NO
2-s2.0-85054637979,10.1109/TCDS.2018.2875309,,,Episodic Memory Multimodal Learning for Robot Sensorimotor Map Building and Navigation,ar,Article,Chin W.,,Tokyo Metropolitan University,Hachioji,Japan,,,,,2019-06-01,June 2019,IEEE Transactions on Cognitive and Developmental Systems,23798920,21100784665,23798939,Journal,11,2,8488558,210-220,,,6,0,,,,"In this paper, an unsupervised learning model of episodic memory is proposed. The proposed model, enhanced episodic memory adaptive resonance theory (EEM-ART), categorizes and encodes experiences of a robot to the environment and generates a cognitive map. EEM-ART consists of multilayer ART networks to extract novel events and encode spatio-temporal connection as episodes by incrementally generating cognitive neurons. The model connects episodes to construct a sensorimotor map for the robot to continuously perform path planning and goal navigation. Experimental results for a mobile robot indicate that EEM-ART can process multiple sensory sources for learning events and encoding episodes simultaneously. The model overcomes perceptual aliasing and robot localization by recalling the encoded episodes with a new anticipation function and generates sensorimotor map to connect episodes together to execute tasks continuously with little to no human intervention.",NO
2-s2.0-85069749028,10.20368/1971-8829/1625,,,Learning distributed algorithms by programming robots,ar,Article,Luccio F.L.,,Università Ca' Foscari Venezia,Venice,Italy,,,,,2019-05-01,May 2019,Journal of E-Learning and Knowledge Society,18266223,17700155804,19718829,Journal,15,2,,89-100,,,3,0,,,,"The learning process of theoretical concepts such as the model of a distributed environment and different distributed algorithms together with their execution and correctness requires time and is often considered by students a hard and non-challenging issue. In this paper we suggest adopting a more practical approach based on real implementations of distributed algorithms with the help of robots. A learning-by-doing approach can, in our opinion, help students acquiring a deeper knowledge of the model and of the algorithms, and can also stimulate them, and let them improve their teamwork skills. In this paper, we present a specific case study of a practical project, run for two consecutive years at the University Cà Foscari of Venice, inside an International Master of Computer Science course of Advanced Algorithms. The students for their final exam had to work in groups and their task was to design and implement a distributed algorithm to solve an assigned problem, using a Lego Mindstorm EV3 robot and a Makeblock mBot robot. In this paper, we discuss the positive effects of such a non-traditional teamwork approach by analyzing the teacher’s perception, the feasible impact on the students’ grades, and the students’ involvement and positive feeling, highlighted by the results of some questionnaires proposed at the beginning and the end of the projects. We finally discuss the limits of such an approach and possible improvements.",SI
2-s2.0-85067015868,10.1111/cgf.13644,,,Learning a Generative Model for Multi-Step Human-Object Interactions from Videos,ar,Article,Wang H.,,Stanford University,Palo Alto,United States,,,,,2019-05-01,May 2019,Computer Graphics Forum,01677055,25023,14678659,Journal,38,2,,367-378,,,7,0,,,,,NO
2-s2.0-85062619374,10.1016/j.robot.2018.11.017,S0921889017308692,,A real-time framework for kinodynamic planning in dynamic environments with application to quadrotor obstacle avoidance,ar,Article,Allen R.E.,,Lincoln Laboratory,Lexington,United States,,,,,2019-05-01,May 2019,Robotics and Autonomous Systems,09218890,18079,,Journal,115,,,174-193,,,11,0,,,,"Highlights

•

Full-stack framework for path planning and obstacle avoidance for agile robots.

•

Demonstrated on a quadrotor capable of dodging a fencing blade while flying indoors.

•

Fusion of sampling-based planning, machine learning, and reactive control.
The objective of this paper is to present a full-stack, real-time motion planning framework for kinodynamic robots and then show how it is applied and demonstrated on a physical quadrotor system operating in a laboratory environment. The proposed framework utilizes an offline–online computation paradigm, neighborhood classification through machine learning, sampling-based motion planning with an optimal cost distance metric, and trajectory smoothing to achieve real-time planning for aerial vehicles. This framework accounts for dynamic obstacles with an event-based replanning structure and a locally reactive control layer that minimizes replanning events. The approach is demonstrated on a quadrotor navigating moving obstacles in an indoor space and stands as, arguably, one of the first demonstrations of full-online kinodynamic motion planning, with execution cycles of 3 Hz to 5 Hz. For the quadrotor, a simplified dynamics model is used during the planning phase to accelerate online computation. A trajectory smoothing phase, which leverages the differentially flat nature of quadrotor dynamics, is then implemented to guarantee a dynamically feasible trajectory.",NO
2-s2.0-85062269308,10.1016/j.robot.2019.02.013,S0921889018308285,,Solving the optimal path planning of a mobile robot using improved Q-learning,ar,Article,Low E.S.,,Universiti Tun Hussein Onn Malaysia,Batu Pahat,Malaysia,,,,,2019-05-01,May 2019,Robotics and Autonomous Systems,09218890,18079,,Journal,115,,,143-161,,,64,0,,,,"Highlights

•

We propose an improved Q-learning to solve path planning of a mobile robot.

•

The flower pollination algorithm is used to initialize the Q-table prior to the implementation of Q-learning.

•

Its effectiveness is tested in solving the optimal path in different test cases.

•

Performance comparison with classical Q-learning and other modified Q-learning is made.

•

The proposed model shows improvement in terms of computational time than others.
Q-learning, a type of reinforcement learning, has gained increasing popularity in autonomous mobile robot path planning recently, due to its self-learning ability without requiring a priori model of the environment. Yet, despite such advantage, Q-learning exhibits slow convergence to the optimal solution. In order to address this limitation, the concept of partially guided Q-learning is introduced wherein, the flower pollination algorithm (FPA) is utilized to improve the initialization of Q-learning. Experimental evaluation of the proposed improved Q-learning under the challenging environment with a different layout of obstacles shows that the convergence of Q-learning can be accelerated when Q-values are initialized appropriately using the FPA. Additionally, the effectiveness of the proposed algorithm is validated in a real-world experiment using a three-wheeled mobile robot.",NO
2-s2.0-85056355946,10.1109/TPDS.2018.2879950,,,Fast and communication-efficient algorithm for distributed support vector machine training,ar,Article,Dass J.,,Texas A&amp;M University,College Station,United States,,,,,2019-05-01,1 May 2019,IEEE Transactions on Parallel and Distributed Systems,10459219,26098,15582183,Journal,30,5,8526323,1065-1076,,,2,0,,,,"Support Vector Machines (SVM) are widely used as supervised learning models to solve the classification problem in machine learning. Training SVMs for large datasets is an extremely challenging task due to excessive storage and computational requirements. To tackle so-called big data problems, one needs to design scalable distributed algorithms to parallelize the model training and to develop efficient implementations of these algorithms. In this paper, we propose a distributed algorithm for SVM training that is scalable and communication-efficient. The algorithm uses a compact representation of the kernel matrix, which is based on the QR decomposition of low-rank approximations, to reduce both computation and storage requirements for the training stage. This is accompanied by considerable reduction in communication required for a distributed implementation of the algorithm. Experiments on benchmark data sets with up to five million samples demonstrate negligible communication overhead and scalability on up to 64 cores. Execution times are vast improvements over other widely used packages. Furthermore, the proposed algorithm has linear time complexity with respect to the number of samples making it ideal for SVM training on decentralized environments such as smart embedded systems and edge-based internet of things, IoT.",NO
2-s2.0-85069186700,10.3873/j.issn.1000-1328.2019.04.008,,,Analysis of Space Manipulator Route Planning Based on Sarsa (λ) Reinforcement Learning,ar,Article,Xu,,Shanghai Institute of Spaceflight Control Technology;Shanghai Key Laboratory of Aerospace Intelligent Control Technology,Shanghai;Shanghai,China;China,,,,,2019-04-01,1 April 2019,Yuhang Xuebao/Journal of Astronautics,10001328,13628,,Journal,40,4,,435-443,,,2,0,,,,,NO
2-s2.0-85064677483,10.1109/TMECH.2019.2899365,,,Incremental reinforcement learning with prioritized sweeping for dynamic environments,ar,Article,Wang Z.,,Nanjing University;The University of Hong Kong,Nanjing;Pokfulam,China;Hong Kong,,,,,2019-04-01,April 2019,IEEE/ASME Transactions on Mechatronics,10834435,19113,1941014X,Journal,24,2,8642342,621-632,,,20,0,,,,"In this paper, a novel incremental learning algorithm is presented for reinforcement learning (RL) in dynamic environments, where the rewards of state-action pairs may change over time. The proposed incremental RL (IRL) algorithm learns from the dynamic environments without making any assumptions or having any prior knowledge about the ever-changing environment. First, IRL generates a detector-agent to detect the changed part of the environment (drift environment) by executing a virtual RL process. Then, the agent gives priority to the drift environment and its neighbor environment for iteratively updating their state-action value functions using new rewards by dynamic programming. After the prioritized sweeping process, IRL restarts a canonical learning process to obtain a new optimal policy adapting to the new environment. The novelty is that IRL fuses the new information into the existing knowledge system incrementally as well as weakening the conflict between them. The IRL algorithm is compared to two direct approaches and various state-of-the-art transfer learning methods for classical maze navigation problems and an intelligent warehouse with multiple robots. The experimental results verify that IRL can effectively improve the adaptability and efficiency of RL algorithms in dynamic environments.",NO
2-s2.0-85064572941,10.1007/s13748-018-00168-6,,,Path planning of a mobile robot in a free-space environment using Q-learning,ar,Article,Jiang J.,,Zhengzhou University,Zhengzhou,China,,,,,2019-04-01,1 April 2019,Progress in Artificial Intelligence,21926352,21100781972,21926360,Journal,8,1,,133-142,,,8,0,,,,"This paper proposes an improved Q-learning algorithm for the path planning of a mobile robot in a free-space environment. Existing Q-learning methods for path planning focus on the mesh routing environment; therefore, new methods must be developed for free-space environments in which robots move continuously. For the free-space environment, we construct fuzzified state variables for dividing the continuous space to avoid the curse of dimensionality. The state variables include the distances to the target point and obstacles and the heading of the robot. Based on the defined state variables, we propose an integrated learning strategy on the basis of the space allocation to accelerate the convergence during the learning process. Simulation experiments show that the path planning of mobile robots can be realized quickly, and the probability of obstacle collisions can be reduced. The results of the experiments also demonstrate the considerable advantages of the proposed learning algorithm compared to two commonly used methods.",NO
2-s2.0-85063311433,10.1109/LRA.2019.2897342,,,Bayesian active learning for collaborative task specification using equivalence regions,ar,Article,Wilde N.,,University of Waterloo,Waterloo,Canada,,,,,2019-04-01,April 2019,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,4,2,8633961,1691-1698,,,4,0,,,,"Specifying complex task behaviors while ensuring good robot performance may be difficult for untrained users. We study a framework for users to specify rules for acceptable behavior in a shared environment such as industrial facilities. As non-expert users might have little intuition about how their specification impacts the robot's performance, we design a learning system that interacts with users to find an optimal solution. Using active preference learning, we iteratively show alternative paths that the robot could take on an interface. From the user feedback on ranking the alternatives, we learn about the weights that users place on each part of their specification. We extend the user model from our previous work to a discrete Bayesian learning model and introduce a greedy algorithm for proposing alternative that operates on the notion of equivalence regions of user weights. We prove that using this algorithm, the revision active learning process converges on the user-optimal path. Using simulations performed in realistic industrial environments, we demonstrate the convergence and robustness of our approach.",NO
2-s2.0-85063310728,10.1109/LRA.2019.2893975,,,Learning to Predict Ego-Vehicle Poses for Sampling-Based Nonholonomic Motion Planning,ar,Article,Banzhaf H.,,Robert Bosch GmbH,Gerlingen,Germany,,,,,2019-04-01,April 2019,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,4,2,8618353,1053-1060,,,5,0,,,,"Pathological hand tremor (PHT) is among the most common movement symptoms of several neurological disorders including Parkinson's disease and essential tremor. Extracting PHT is of paramount importance in several engineering and clinical applications such as assistive and robotic rehabilitation technologies. In such systems, PHT is modeled as the input noise to the system and thus there is a surge of interest in estimation an compensation of the noise. Although various works in the literature have attempted to estimate and extract the PHT, in this letter, first, we argue that the ground truth signal used in existing works to optimize the performance of tremor extraction techniques is not accurate enough, and thus the performance measures for the prior techniques are not perfectly reliable. In addition, most of the existing tremor extraction techniques impose unrealistic assumptions, which are, typically, violated in practical settings. This letter proposes a novel technique that for the first time incorporates deep bidirectional recurrent neural networks as a processing tool for PHT extraction. Moreover, we devise an intuitively pleasing training strategy that enables the network to perform not only online estimation but also online prediction of the voluntary hand motion in a myopic fashion, which is currently a significantly important unmet need for rehabilitative and assistive robotic technologies designed for patients with pathological tremor.",NO
2-s2.0-85062921473,10.1109/LRA.2019.2899434,,,Fast and Continuous Foothold Adaptation for Dynamic Locomotion Through CNNs,ar,Article,Magaña O.,,Istituto Italiano di Tecnologia,Genoa,Italy,,,,,2019-04-01,April 2019,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,4,2,8642374,2140-2147,,,12,0,,,,"Legged robots can outperform wheeled machines for most navigation tasks across unknown and rough terrains. For such tasks, visual feedback is a fundamental asset to provide robots with terrain awareness. However, robust dynamic locomotion on difficult terrains with real-time performance guarantees remains a challenge. We present here a real-time, dynamic foothold adaptation strategy based on visual feedback. Our method adjusts the landing position of the feet in a fully reactive manner, using only on-board computers and sensors. The correction is computed and executed continuously along the swing phase trajectory of each leg. To efficiently adapt the landing position, we implement a self-supervised foothold classifier based on a convolutional neural network. Our method results in an up to 200 times faster computation with respect to the full-blown heuristics. Our goal is to react to visual stimuli from the environment, bridging the gap between blind reactive locomotion and purely vision-based planning strategies. We assess the performance of our method on the dynamic quadruped robot HyQ, executing static and dynamic gaits (at speeds up to 0.5 m/s) in both simulated and real scenarios; the benefit of safe foothold adaptation is clearly demonstrated by the overall robot behavior.",NO
2-s2.0-85062642389,10.1109/LRA.2019.2898035,,,Combining Imitation Learning with Constraint-Based Task Specification and Control,ar,Article,Perico C.A.V.,,KU Leuven,3000 Leuven,Belgium,,,,,2019-04-01,April 2019,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,4,2,8637010,1892-1899,,,11,0,,,,"This letter combines an combines an imitation learning approach with a model-based and constraint-based task specification and control methodology. Imitation learning provides an intuitive way for the end user to specify context of a new robot application without the need of traditional programming skills. On the other hand, constraint-based robot programming allows us to define complex tasks involving different kinds of sensor input. Combination of both enables adaptation of complex tasks to new environments and new objects with a small number of demonstrations. The proposed method uses a statistical uni-modal model to describe the demonstrations in terms of a number of weighted basis functions. This is then combined with model-based descriptions of other aspects of the task at hand. This approach was tested in a use case inspired by an industrial application, in which the required transfer motions were learned from a small number of demonstrations, and gradually improved by adding new demonstrations. Information on a collision-free path was introduced through a small number of demonstrations. The method showed a high level of composability with force and vision controlled tasks. The use case showed that the deployment of a complex constraint-based task with sensor interactions can be expedited using imitation learning.",NO
2-s2.0-85062600380,10.1109/LRA.2019.2899918,,,Learning Navigation Behaviors End-to-End with AutoRL,ar,Article,Chiang H.T.L.,,Google LLC,Mountain View,United States,,,,,2019-04-01,April 2019,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,4,2,8643443,2007-2014,,,41,1,,,,"We learn end-to-end point-to-point and pathfollowing navigation behaviors that avoid moving obstacles. These policies receive noisy lidar observations and output robot linear and angular velocities. The policies are trained in small, static environments with AutoRL, an evolutionary automation layer around reinforcement learning (RL) that searches for a deep RL reward and neural network architecture with large-scale hyper-parameter optimization. AutoRL first finds a reward that maximizes task completion and then finds a neural network architecture that maximizes the cumulative of the found reward. Empirical evaluations, both in simulation and on-robot, show that AutoRL policies do not suffer from the catastrophic forgetfulness that plagues many other deep reinforcement learning algorithms, generalize to new environments and moving obstacles, are robust to sensor, actuator, and localization noise, and can serve as robust building blocks for larger navigation tasks. Our path-following and point-to-point policies are, respectively, 23% and 26% more successful than comparison methods across new environments.",NO
2-s2.0-85049471588,10.1109/TASE.2018.2840345,,,Facilitating Human-Robot Collaborative Tasks by Teaching-Learning-Collaboration from Human Demonstrations,ar,Article,Wang W.,,Clemson University,Clemson,United States,,,,,2019-04-01,April 2019,IEEE Transactions on Automation Science and Engineering,15455955,17340,,Journal,16,2,8403899,640-653,,,36,1,,,,"Collaborative robots are widely employed in strict hybrid assembly tasks involved in intelligent manufacturing. In this paper, we develop a teaching-learning-collaboration (TLC) model for the collaborative robot to learn from human demonstrations and assist its human partner in shared working situations. The human could program the robot using natural language instructions according to his/her personal working preferences via this approach. Afterward, the robot learns from human assembly demonstrations by taking advantage of the maximum entropy inverse reinforcement learning algorithm and updates its task-based knowledge using the optimal assembly strategy. In the collaboration process, the robot is able to leverage its learned knowledge to actively assist the human in the collaborative assembly task. Experimental results and analysis demonstrate that the proposed approach presents considerable robustness and applicability in human-robot collaborative tasks. Note to Practitioners-This paper is motivated by the human-robot collaborative assembly problem in the context of advanced manufacturing. Collaborative robotics makes a huge shift from the traditional robot-in-a-cage model to robots interacting with people in an open working environment. When the human works with the robot in the shared workspace, it is significant to lessen human programming effort and improve the human-robot collaboration efficiency once the task is updated. We develop a TLC model for the robot to learn from human demonstrations and assist its human partner in collaborative tasks. Once the task is changed, the human may code the robot via natural language instructions according to his/her personal working preferences. The robot can learn from human assembly demonstrations to update its task-based knowledge, which can be leveraged by the robot to actively assist the human to accomplish the collaborative task. We demonstrate the advantages of the proposed approach via a set of experiments in rea...
(Show More)",NO
2-s2.0-85062939263,10.1007/s12532-018-0139-4,,,CasADi: a software framework for nonlinear optimization and optimal control,ar,Article,Andersson J.A.E.,,University of Wisconsin-Madison,Madison,United States,,,,,2019-03-14,14 March 2019,Mathematical Programming Computation,18672949,19400158592,18672957,Journal,11,1,,,,,371,0,,,,"We present CasADi, an open-source software framework for numerical optimization. CasADi is a general-purpose tool that can be used to model and solve optimization problems with a large degree of flexibility, larger than what is associated with popular algebraic modeling languages such as AMPL, GAMS, JuMP or Pyomo. Of special interest are problems constrained by differential equations, i.e. optimal control problems. CasADi is written in self-contained C++, but is most conveniently used via full-featured interfaces to Python, MATLAB or Octave. Since its inception in late 2009, it has been used successfully for academic teaching as well as in applications from multiple fields, including process control, robotics and aerospace. This article gives an up-to-date and accessible introduction to the CasADi framework, which has undergone numerous design improvements over the last 7 years.",NO
2-s2.0-85068359418,10.1049/trit.2018.1062,,,Teaching a robot to use electric tools with regrasp planning,ar,Article,Raessa M.,,Osaka University,Suita,Japan,,,,,2019-03-01,1 March 2019,CAAI Transactions on Intelligence Technology,24686557,21100970248,24682322,Journal,4,1,,54-63,,,4,1,,,,"This study presents a straightforward method to teach robots to use tools. Teaching robots is crucial in quickly deploying and reconfiguring robots in next-generation factories. Conventional methods require third-party systems like wearable devices or complicated vision system to capture, analyse, and map human grasps, motion, and tool poses to robots. These systems assume lots of experience from their users. Unlike the conventional methods, this study does not involve learning human motion and skills. Instead, it only learns the object goal poses from the human user whilst employs regrasp planning to generate robot motion. The method is most suitable for a robot to learn the usage of electric tools that can be operated by simply switching on and off. The proposed method is validated using a dual-arm robot with hand-mounted cameras and several tools. Experimental results show that the proposed method is robust, feasible, and simple to teach robots. It can find a collision-free and kino-dynamic feasible grasp sequences and motion trajectories when the goal pose is reachable. The method allows the robot to automatically choose placements or handover considering the surrounding environment as intermediate states to change the pose of the tool and use tools following human demonstrations.",NO
2-s2.0-85062420398,10.3390/s19051016,,30818870,Robotic active information gathering for spatial field reconstruction with rapidly-exploring random trees and online learning of gaussian processes,ar,Article,Viseras A.,,Deutsches Zentrum fur Luft- Und Raumfahrt, Cologne,Germany,,,,,2019-03-01,1 March 2019,Sensors (Switzerland),14248220,130124,,Journal,19,5,1016,,,,9,1,,,,"Information gathering (IG) algorithms aim to intelligently select a mobile sensor actions required to efficiently obtain an accurate reconstruction of a physical process, such as an occupancy map, or a magnetic field. Many recent works have proposed algorithms for IG that employ Gaussian processes (GPs) as underlying model of the process. However, most algorithms discretize the state space, which makes them computationally intractable for robotic systems with complex dynamics. Moreover, they are not suited for online information gathering tasks as they assume prior knowledge about GP parameters. This paper presents a novel approach that tackles the two aforementioned issues. Specifically, our approach includes two intertwined steps: (i) a Rapidly-Exploring Random Tree (RRT) search that allows a robot to identify unvisited locations, and to learn the GP parameters, and (ii) an RRT*-based informative path planning that guides the robot towards those locations by maximizing the information gathered while minimizing path cost. The combination of the two steps allows an online realization of the algorithm, while eliminating the need for discretization. We demonstrate that our proposed algorithm outperforms state-of-the-art both in simulations, and in a lab experiment in which a ground-based robot explores the magnetic field intensity within an indoor environment populated with obstacles. View Full-Text",NO
2-s2.0-85053546868,10.1007/s11042-018-6634-9,,,Brain programming as a new strategy to create visual routines for object tracking: Towards automation of video tracking design,ar,Article,Olague G.,,Centro de Investigacion Cientifica y de Educacion Superior de Ensenada,Ensenada,Mexico,,,,,2019-03-01,1 March 2019,Multimedia Tools and Applications,13807501,25627,15737721,Journal,78,5,,5881-5918,,,12,0,,,,"This work describes the use of brain programming for automating the video tracking design process. The challenge is that of creating visual programs that learn to detect a toy dinosaur from a database while tested in a visual-tracking scenario. When planning an object tracking system, two sub-tasks need to be approached: detection of moving objects in each frame and correct association of detection to the same object over time. Visual attention is a skill performed by the brain whose functionality is to perceive salient visual features. The automatic design of visual attention programs through an optimization paradigm is applied to the detection-based tracking of objects in a video from a moving camera. A system based on the acquisition and integration steps of the natural dorsal stream was engineered to emulate its selectivity and goal-driven behavior useful to the task of tracking objects. This is considered a challenging problem since many difficulties can arise due to abrupt object motion, changing appearance patterns of both the object and the scene, nonrigid structures, object-to-object and object-to-scene occlusions, as well as camera motion, models, and parameters. Tracking relies on the quality of the detection process and automatically designing such stage could significantly improve tracking methods. Experimental results confirm the validity of our approach using three different kinds of robotic systems. Moreover, a comparison with the method of regions with convolutional neural networks is provided to illustrate the benefit of the approach.",NO
2-s2.0-85064413620,10.19665/j.issn1001-2400.2019.01.008,,,Method for robot obstacle avoidance based on the improved dueling network,ar,Article,Zhou Y.,,Xidian University,Xi'an,China,,,,,2019-02-20,20 February 2019,Xi'an Dianzi Keji Daxue Xuebao/Journal of Xidian University,10012400,27686,,Journal,46,1,,,,,0,0,,,,,NO
2-s2.0-85067073147,10.3390/electronics8020228,,,DSCblocks: An open-source platform for learning embedded systems based on algorithm visualizations and digital signal controllers,ar,Article,Ariza J.Á.,,Corporación Universitaria Minuto de Dios,Bogota,Colombia,,,,,2019-02-01,February 2019,Electronics (Switzerland),,21100829272,20799292,Journal,8,2,228,,,,4,1,,,,"DSCBlocks is an open-source platform in hardware and software developed in JavaFX, which is focused on learning embedded systems through Digital Signal Controllers (DSCs). These devices are employed in industrial and educational sectors due to their robustness, number of peripherals, processing speed, scalability and versatility. The platform uses graphical blocks designed in Google’s tool Blockly that can be used to build different Algorithm Visualizations (AVs). Afterwards, the algorithms are converted in real-time to C language, according to the specifications of the compiler for the DSCs (XC16) and they can be downloaded in one of the two models of development board for the dsPIC 33FJ128GP804 and dsPIC 33FJ128MC802. The main aim of the platform is to provide a flexible environment, drawing on the educational advantages of the AVs with different aspects concerning the embedded systems, such as declaration of variables and functions, configuration of ports and peripherals, handling of Real-Time Operating System (RTOS), interrupts, among others, that are employed in several fields such as robotics, control, instrumentation, etc. In addition, some experiments that were designed in the platform are presented in the manuscript. The educational methodology and the assessment provided by the students (n = 30) suggest that the platform is suitable and reliable to learn concepts relating to embedded systems. View Full-Text",SI
2-s2.0-85062288813,10.1142/S0219843619500026,,,Vision-based 3D modeling of unknown dynamic environments for real-time humanoid navigation,ar,Article,Wahrmann D.,,Technical University of Munich,Munich,Germany,,,,,2019-02-01,1 February 2019,International Journal of Humanoid Robotics,02198436,4700152208,,Journal,16,1,1950002,,,,8,0,,,,"In order to achieve real autonomy, robots have to be able to navigate in completely unknown environments. Due to the complexity of computer vision algorithms, almost every approach for robotic navigation is either based on previous knowledge of the environment, such as markers or as resulting from learning methods, or makes strong simplifying assumptions about it (height-map representations, static scenarios). While showing impressive success in certain applications, these approaches limit the potential of legged robots to achieve the amazing flexibility of humans in more complex environments. In this work, we present a strategy for full 3D vision processing that is able to handle changing, dynamic environments. These are modeled using 3D geometries that are processed in real-time by the motion planner of our biped robot Lola for avoiding moving obstacles and walking over platforms. In order to allow for a more intuitive development of such systems in the future, we present tools for visualization including two mixed reality applications using both an external camera and Microsoft’s HoloLens. We validate our system in simulations and experiments with our full-size humanoid robot Lola and publish our framework open source for the benefit of the community.",NO
2-s2.0-85059818575,10.1016/j.sysarc.2018.12.010,S1383762118301735,,An integrated hardware/software design methodology for signal processing systems,ar,Article,Li L.,,"University of Maryland, College Park",College Park,United States,,,,,2019-02-01,February 2019,Journal of Systems Architecture,13837621,12398,,Journal,93,,,1-19,,,15,1,,,,"This paper presents a new methodology for design and implementation of signal processing systems on system-on-chip (SoC) platforms. The methodology is centered on the use of lightweight application programming interfaces for applying principles of dataflow design at different layers of abstraction. The development processes integrated in our approach are software implementation, hardware implementation, hardware-software co-design, and optimized application mapping. The proposed methodology facilitates development and integration of signal processing hardware and software modules that involve heterogeneous programming languages and platforms. As a demonstration of the proposed design framework, we present a dataflow-based deep neural network (DNN) implementation for vehicle classification that is streamlined for real-time operation on embedded SoC devices. Using the proposed methodology, we apply and integrate a variety of dataflow graph optimizations that are important for efficient mapping of the DNN system into a resource constrained implementation that involves cooperating multicore CPUs and field-programmable gate array subsystems. Through experiments, we demonstrate the flexibility and effectiveness with which different design transformations can be applied and integrated across multiple scales of the targeted computing system.",NO
2-s2.0-85056807191,10.1016/j.robot.2018.11.005,S0921889018303567,,Bio-inspired on-line path planner for cooperative exploration of unknown environment by a Multi-Robot System,ar,Article,de Almeida J.P.L.S.,,Universidade Tecnológica Federal do Paraná;Federal Institute of Paraná (IFPR),Curitiba;Colombo,Brazil;Brazil,,,,,2019-02-01,February 2019,Robotics and Autonomous Systems,09218890,18079,,Journal,112,,,32-48,,,22,0,,,,"Highlights

•

A cooperative and distributed autonomous navigation system to multi-robot is developed.

•

Path planning and motion control are implemented in an independent and distributed way.

•

Cooperation and autonomy are achieved by sensing, information sharing and pheromone detection.

•

Previous knowledge is unnecessary for navigation: only end robots’ positions are known.

•

Sensing and communication are limited, as occur for real peripheral devices of robots.
This paper aims to present a cooperative and distributed navigation strategy, that is an on-line path planner, for an autonomous multi-robot system. The robots are intended to navigate and explore an unknown environment in order to find and reach obligatory passage points or way-points (goals), and then achieve a known final position. All robots in the team are homogeneous, independent and have limited communication skills. However they interact among them and with the environment to autonomously decide about their paths and tasks: if they should explore the environment, or avoid visiting a previously explored region, or to reach a discovered goal. Information sharing is directly carried out when the robots are into a communication area and/or indirectly by stigmergy. In this case, artificial pheromone, as a repulsive field, is used to mark regions that have already been explored by other members of the team, therefore avoiding redundant exploration and time waste. Fuzzy controllers are used for robots’ motion. The proposed on line path planner performance is evaluated in different simulated environment scenarios and the main results are presented.",NO
2-s2.0-85055712092,10.1109/TRO.2018.2875388,,,Robot-Robot Gesturing for Anchoring Representations,ar,Article,Kondaxakis P.,,Blue Ocean Robotics,Odense,Denmark,,,,,2019-02-01,February 2019,IEEE Transactions on Robotics,15523098,95101,,Journal,35,1,8502843,216-230,,,1,0,,,,"In a multirobot system, using shared symbols for objects in the environment is a prerequisite for collaboration. Sharing symbols requires that each agent has anchored a symbol with an internal, sensor level representation, as well as that these symbols match between the agents. The problem can be solved easily when the internal representations can be communicated between the agents. However, with heterogeneous embodiments the available sensors are likely to differ, making it impossible to share the internal representations directly. We propose the use of pointing gestures to align symbols between a heterogeneous group of robots. We describe a planning framework that minimizes the required effort for anchoring representations across robots. The framework allows planning for both the gesturing and observing agents in a decentralized fashion. It considers both implicit sources of failure, such as ambiguous pointing, as well as costs required by actions. Simulation experiments demonstrate that the resulting planning problem has a complex solution structure with multiple local minima. Demonstration with a heterogeneous two-robot system shows the practical viability of this approach.",NO
2-s2.0-85045063103,10.1007/s10514-018-9725-6,,,Robot learning of industrial assembly task via human demonstrations,ar,Article,Kyrarini M.,,Universität Bremen,Bremen,Germany,,,,,2019-01-31,31 January 2019,Autonomous Robots,09295593,18016,15737527,Journal,43,1,,239-257,,,25,1,,,,"Human–robot collaboration in industrial applications is a challenging robotic task. Human working together with the robot at a workplace to complete a task may create unpredicted events for the robot, as humans can act unpredictably. Humans tend to perform a task in a not fully repetitive manner using their expertise and cognitive capabilities. The traditional robot programming cannot cope with these challenges of human–robot collaboration. In this paper, a framework for robot learning by multiple human demonstrations is introduced. Through the demonstrations, the robot learns the sequence of actions for an assembly task (high-level learning) without the need of pre-programming. Additionally, the robot learns every path as needed for object manipulation (low-level learning). Once the robot has the knowledge of the demonstrated task, it can perform the task in collaboration with the human. However, the need for adaptation of the learned knowledge may arise as the human collaborator could introduce changes in the environment, such as placing an object to be manipulated in a position and orientation different from the demonstrated ones. In this paper, a novel real-time adaptation algorithm to cope with these changes in the environment, introduced by the human factor, is proposed. The proposed algorithm is able to identify the sequence of actions needed to be performed in a new environment. A Gaussian Mixture Model-based modification algorithm is able to adapt the learned path in order to enable robot to successfully complete the task without the need of additional training by demonstration. The proposed framework copes with changes in the position and orientation of the objects to be manipulated and also provides obstacle avoidance. Moreover, the framework enables the human collaborator to suggest different sequence of actions for the learned task, which will be performed by the robot. The proposed algorithm was tested on a dual-arm industrial robot in an assembly scenario and the results are presented. Shown results demonstrate a potential of the proposed robot learning framework to enable continuous human–robot collaboration.",NO
2-s2.0-85053930296,10.1007/s00170-018-2732-0,,,Automatic extraction and identification of narrow butt joint based on ANFIS before GMAW,ar,Article,Yang L.,,University of Chinese Academy of Sciences;Institute of Automation Chinese Academy of Sciences,Beijing;Beijing,China;China,,,,,2019-01-16,16 January 2019,International Journal of Advanced Manufacturing Technology,02683768,20428,14333015,Journal,100,1-4,,609-622,,,4,0,,,,"To improve the automation level of the welding robots, the automatic extraction and identification of the weld seam is the pre-requisite of the intelligent welding robots. During the real industrial environment, the welding environment often has the characteristics of weak texture, poor contrast, reflections from metallic surfaces, and imperfections on the work piece. These characteristics will seriously affect the accurate extraction of weld seam. To realize the automatic path planning of welding robots, a new method of automatic extraction and identification of narrow butt joint under weak contrast is realized to serve the 3D path teaching of welding robots. To achieve accurate extraction of narrow butt joint under weak contrast, this paper designs a new seam extraction operator to achieve accurate and fast extraction of weld seam with various shapes and sizes. And the shape feature of weld seam is used to construct feature vector. Finally, to get optimal classification performance, the adaptive network-based fuzzy inference system (ANFIS) is adopted in this paper to finish identification of narrow butt joints. The experimental results show that the proposed algorithm could quickly and accurately realize the extraction and identification of the narrow butt joints under weak contrast.",NO
2-s2.0-85112866404,10.1051/cocv/2017034,,,A novel online gait optimization approach for biped robots with point-feet,ar,Article,Anjidani M.,,Iran University of Science and Technology,Tehran,Iran,,,,,2019-01-01,2019,"ESAIM - Control, Optimisation and Calculus of Variations",12928119,25955,12623377,Journal,25,,81,,,,0,0,,,,"Designing a stable walking gait for biped robots with point-feet is stated as a constrained nonlinear optimization problem which is normally solved by an offline numerical optimization method. On the result of an unknown modeling error or environment change, the designed gait may be ineffective and an online gait improvement is impossible after the optimization. In this paper, we apply Generalized Path Integral Stochastic Optimal Control to closed-loop model of planar biped robots with point-feet which leads to an online Reinforcement Learning algorithm to design the walking gait. We study the ability of the proposed method to adapt the controller of RABBIT, which is a planar biped robot with point-feet, for stable walking. The simulation results show that the method, starting a dynamically unstable initial gait, quickly compensates the modeling error and reaches to a walking with exponential stability and desired features in a new situation which was impossible by the past methods.",NO
2-s2.0-85078425536,10.1109/ACCESS.2019.2953894,,,Learning Articulated Constraints from a One-Shot Demonstration for Robot Manipulation Planning,ar,Article,Liu Y.,,Harbin Institute of Technology,Harbin,China,,,,,2019-01-01,2019,IEEE Access,,21100374601,21693536,Journal,7,,8903534,172584-172596,,,1,1,,,,"Robots manipulating in domestic environments generally need to interact with articulated objects, such as doors, drawers, laptops and swivel chairs. The rigid bodies that make up these objects are connected by a revolute pair or a prismatic pair. Robots are expected to learn and understand the objects' articulated constraints with a simple interaction method. In this way, the autonomy of robot manipulation will be greatly improved in an environment with unstructured constraints. In this paper, a method is proposed to obtain the articulated objects' constraint model by learning from a one-shot continuous visual demonstration which contains multistep movements, and this enables human teacher to continuously demonstrate several tasks at once without manual segmentation. At the end of this paper, a six-degree-of-freedom robot uses the constraint model obtained by demonstration learning to achieve manipulation planning of various tasks based on the AG-CBiRRT algorithm.",NO
2-s2.0-85078048883,10.1109/ACCESS.2019.2960859,,,Intelligent path planning for auvs in dynamic environments: An eda-based learning fixed height histogram approach,ar,Article,Liu R.D.,,South China University of Technology,Guangzhou,China,,,,,2019-01-01,2019,IEEE Access,,21100374601,21693536,Journal,7,,8936928,185433-185446,,,6,1,,,,"Autonomous underwater vehicles (AUVs) are robots that require path planning to complete missions in different kinds of underwater environments. The goal of path planning is to find a feasible path from the start-point to the target-point in a given environment. In most practical applications, environments have dynamic factors, such as ocean flows and moving obstacles, which make the AUV path planning more challenging. This paper proposes an estimation of distribution algorithm (EDA) based approach, termed as learning fixed-height histogram (LFHH) to solve path planning problems for AUVs in dynamic environment. The LFHH uses a learning transformation strategy (LTS) to improve its accuracy and convergence speed. Besides, a smooth method is employed to accelerate the speed of finding feasible paths. Moreover, a planning window is adopted to help handle dynamic factors. LFHH is tested in both complex 2-D and 3-D environments with time-variant dynamic factors, and experimental results validate the effectiveness of LFHH.",NO
2-s2.0-85077251465,10.1109/TCDS.2019.2962228,,,Incremental Learning Framework for Autonomous Robots based on Q-learning and the Adaptive Kernel Linear Model,ar,Article,Hu Y.,,Shenyang Institute of Automation Chinese Academy of Sciences,Shenyang,China,,,,,2019-01-01,2019,IEEE Transactions on Cognitive and Developmental Systems,23798920,21100784665,23798939,Journal,,,,,,,2,0,,,,"The performance of autonomous robots in varying environments needs to be improved. For such incremental improvement, here we propose an incremental learning framework based on Q-learning and the adaptive kernel linear (AKL) model. The AKL model is used for storing behavioral policies that are learned by Q-learning. Both the structure and parameters of the AKL model can be trained using a novel L2-norm kernel recursive least squares (L2-KRLS) algorithm. AKL model initially without nodes and gradually accumulates content. The proposed framework allows to learn new behaviors without forgetting the previous ones. A novel local -greedy policy is proposed to speed the convergence rate of Q-learning. It calculates the exploration probability of each state for generating and selecting more important training samples. The performance of our incremental learning framework was validated in two experiments. A curve fitting example shows that the L2-KRLS based AKL model is suitable for incremental learning. The second experiment is based on robot learning tasks. The results show that our framework can incrementally learn behaviors in varying environments. Local -greedy policy-based Q-learning is faster than existing Q-learning algorithms.",NO
2-s2.0-85075451620,10.14201/eks2019_20_a17,,,State of the art in the teaching of computational thinking and programming in childhood education,ar,Article,González-González C.S.,,Universidad de la Laguna,San Cristobal de La Laguna,Spain,,,,,2019-01-01,2019,Education in the Knowledge Society,,21100903490,24448729,Journal,20,,a17,,,,21,1,,,,"Aprender a programar es la nueva alfabetización del siglo XXI. El pensamiento computacional, estrechamente relacionado con la programación, requiere pensar y resolver problemas con diferentes niveles de abstracción y es independiente de los dispositivos de hardware. En este artículo se analizan las principales iniciativas relacionadas con el pensamiento computacional en las escuelas, el uso de herramientas específicas, tales como los kits de robótica o entornos de programación educativa, y principales estrategias de enseñanza-aprendizaje utilizadas en educación infantil.",SI
2-s2.0-85074580915,10.1007/s11276-019-02140-1,,,A heuristic search algorithm for Hamiltonian circuit problems in directed graphs,ar,Article,Jin D.,,Zhongnan University of Economics and Law,Wuhan,China,,,,,2019-01-01,2019,Wireless Networks,10220038,17569,15728196,Journal,,,,,,,0,0,,,,"A heuristic search algorithm is given that determines and resolves the Hamiltonian circuit problem in directed graphs. The heuristic information of each vertex is a set composed of its possible path length values from the starting vertex, which is obtained by the path length extension algorithm. A detailed analysis of algorithm examples shows that the heuristic algorithm can greatly reduce the number of processing nodes compared to the backtracking algorithm without information; meanwhile, the algorithm’s time complexity is related to the number of loops in the directed graph. If a directed graph G(V, E) only contains loops that contain the starting point, then the Hamiltonian problem of G can be determined in polynomial time. The algorithm is implemented using C++ and Python programming, and all of the test graphs are generated by the random graph algorithm. The experiments show that the heuristic algorithm can reduce the number of extended nodes by at least 10% in directed random graphs with no or only a few loops. This heuristic algorithm can save time in applications that perform tasks while extending nodes because it reduce the number of extended nodes.",NO
2-s2.0-85072921192,10.1515/pjbr-2019-0025,,,Teaching semantics and skills for human-robot collaboration,ar,Article,Angleraud A.,,Tampere University,Tampere,Finland,,,,,2019-01-01,1 January 2019,Paladyn,,21100810658,20814836,Journal,10,1,,318-329,,,2,1,,,,"Recent advances in robotics allow for collaboration between humans and machines in performing tasks at home or in industrial settings without harming the life ofthe user. While humans can easily adapt to each other and work in team, it is not as trivial for robots. In their case, interaction skills typically come at the cost of extensive programming and teaching. Besides, understanding the semantics of a task is necessary to work efficiently and react to changes in the task execution process. As a result, in order to achieve seamless collaboration, appropriate reasoning, learning skills and interaction capabilities are needed. For us humans, a cornerstone of our communication is language that we use to teach, coordinate and communicate. In this paper we thus propose a system allowing (i) to teach new action semantics based on the already available knowledge and (ii) to use natural language communication to resolve ambiguities that could arise while giving commands to the robot. Reasoning then allows new skills to be performed either autonomously or in collaboration with a human. Teaching occurs through a web application and motions are learned with physical demonstration ofthe robotic arm. We demonstrate the utility of our system in two scenarios and reflect upon the challenges that it introduces.",NO
2-s2.0-85071119221,10.1109/ACCESS.2019.2932257,,,Deep Reinforcement Learning with Optimized Reward Functions for Robotic Trajectory Planning,ar,Article,Xie J.,,Capital Normal University,Beijing,China,,,,,2019-01-01,2019,IEEE Access,,21100374601,21693536,Journal,7,,8782495,105669-105679,,,11,1,,,,"To improve the efficiency of deep reinforcement learning (DRL)-based methods for robotic trajectory planning in the unstructured working environment with obstacles. Different from the traditional sparse reward function, this paper presents two brand-new dense reward functions. First, the azimuth reward function is proposed to accelerate the learning process locally with a more reasonable trajectory by modeling the position and orientation constraints, which can reduce the blindness of exploration dramatically. To further improve the efficiency, a reward function at subtask-level is proposed to provide global guidance for the agent in the DRL. The subtask-level reward function is designed under the assumption that the task can be divided into several subtasks, which reduces the invalid exploration greatly. The extensive experiments show that the proposed reward functions are able to improve the convergence rate by up to three times with the state-of-the-art DRL methods. The percentage increase in convergence means is 2.25%-13.22% and the percentage decreases with respect to standard deviation by 10.8%-74.5%.",NO
2-s2.0-85070918794,10.12928/TELKOMNIKA.V17I3.12232,,,Exploration of genetic network programming with two-stage reinforcement learning for mobile robot,ar,Article,Sendari S.,,Universitas Negeri Malang,Malang,Indonesia,,,,,2019-01-01,2019,Telkomnika (Telecommunication Computing Electronics and Control),16936930,21100256101,23029293,Journal,17,3,,1447-1454,,,2,0,,,,"This paper observes the exploration of Genetic Network Programming Two-Stage Reinforcement Learning for mobile robot navigation. The proposed method aims to observe its exploration when inexperienced environments used in the implementation. In order to deal with this situation, individuals are trained firstly in the training phase, that is, they learn the environment with ϵ-greedy policy and learning rate α parameters. Here, two cases are studied, i.e., case A for low exploration and case B for high exploration. In the implementation, the individuals implemented to get experience and learn a new environment on-line. Then, the performance of learning processes are observed due to the environmental changes.",NO
2-s2.0-85070076205,10.14569/ijacsa.2019.0100757,,,Let's code: A kid-friendly interactive application designed to teach arabic-speaking children text-based programming,ar,Article,Almanie T.,,King Saud University,Riyadh,Saudi Arabia,,,,,2019-01-01,2019,International Journal of Advanced Computer Science and Applications,2158107X,21100867241,21565570,Journal,10,7,,413-418,,,0,1,,,,"Programming is the cornerstone for the development of all of the technologies we encounter in our daily lives. It also plays an important role in enhancing creativity, problem-solving, and logical thinking. Due to the importance of programming in combination with the shortage of Arabic content that aims to teach children programming, we decided to develop Let’s Code, an interactive mobile-based application designed for Arabic-speaking children from 8 to 12 years old. The application focuses on the basics of programming such as data types, variables, and control structures using the Python programming language through a simple, attractive, and age-appropriate design. The application presents its users with an interesting storyline that involves a trip to space with “Labeeb”, a robot character designed to explain programming concepts to the child throughout the trip. Each planet represents a level in the application and introduces a programming concept through a set of lessons and exercises. The application can be used by educational institutions and parents to teach programming and will provide an opportunity through which Arabic-speaking children can keep up with the development and dissemination of technology.",NO
2-s2.0-85068581706,10.3389/fnbot.2019.00040,,,Toward a brain-inspired system: Deep recurrent reinforcement learning for a simulated self-driving agent,ar,Article,Chen J.,,Tongji University,Shanghai,China,,,,,2019-01-01,2019,Frontiers in Neurorobotics,,21100199837,16625218,Journal,13,,40,,,,5,1,,,,"An effective way to achieve intelligence is to simulate various intelligent behaviors in the human brain. In recent years, bio-inspired learning methods have emerged, and they are different from the classical mathematical programming principle. From the perspective of brain inspiration, reinforcement learning has gained additional interest in solving decision-making tasks as increasing neuroscientific research demonstrates that significant links exist between reinforcement learning and specific neural substrates. Because of the tremendous research that focuses on human brains and reinforcement learning, scientists have investigated how robots can autonomously tackle complex tasks in the form of making a self-driving agent control in a human-like way. In this study, we propose an end-to-end architecture using novel deep-Q-network architecture in conjunction with a recurrence to resolve the problem in the field of simulated self-driving. The main contribution of this study is that we trained the driving agent using a brain-inspired trial-and-error technique, which was in line with the real world situation. Besides, there are three innovations in the proposed learning network: raw screen outputs are the only information which the driving agent can rely on, a weighted layer that enhances the differences of the lengthy episode, and a modified replay mechanism that overcomes the problem of sparsity and accelerates learning. The proposed network was trained and tested under a third-party OpenAI Gym environment. After training for several episodes, the resulting driving agent performed advanced behaviors in the given scene. We hope that in the future, the proposed brain-inspired learning system would inspire practicable self-driving control solutions.",NO
2-s2.0-85068231816,10.1080/10494820.2019.1636090,,,Using robot-based practices to develop an activity that incorporated the 6E model to improve elementary school students’ learning performances,ar,Article,Hsiao H.,,National Taiwan Normal University,Taipei,Taiwan,,,,,2019-01-01,2019,Interactive Learning Environments,10494820,145681,17445191,Journal,,,,,,,10,0,,,,"This study used robot-based practices to develop an activity that incorporated the 6E model. The sixth-grade students learned interdisciplinary knowledge about how to use Arduino electronic components, microcontrollers, and hands-on tools to make a “Crab Robot.” In addition, the students learned how to use Scratch programming language to control the robot and complete the “Crab Robot Crossing the Road” task. The study implemented a quasi-experimental design to examine whether the students who learned the robot-based activity using the 6E model acquired better learning motivation, learning performance, computational thinking ability, and hands-on ability than those who learned the activity through lectures. This study adopted purposive sampling to select 70 sixth-grade students from four classes, which were divided into the experimental group (6E model) and the control group (lectures). The experiment was conducted over a period of 18 weeks (for a total duration of 1,440 minutes). The results from the pretests-posttests showed that both groups of students improved their learning motivation, learning performance, computational thinking ability, and hands-on ability; however, the experimental group’s scores were significantly better. More importantly, this study provides a pedagogy manuscript for instructors who want to teach mechatronics programs and programming design education.",SI
2-s2.0-85068064287,10.1080/01691864.2019.1632223,,,Survey on frontiers of language and robotics,ar,Article,Tangiuchi T.,,Ritsumeikan University Biwako-Kusatsu Campus,Kusatsu,Japan,,,,,2019-01-01,2019,Advanced Robotics,01691864,18003,15685535,Journal,33,15-16,,700-730,,,9,1,,,,"The understanding and acquisition of a language in a real-world environment is an important task for future robotics services. Natural language processing and cognitive robotics have both been focusing on the problem for decades using machine learning. However, many problems remain unsolved despite significant progress in machine learning (such as deep learning and probabilistic generative models) during the past decade. The remaining problems have not been systematically surveyed and organized, as most of them are highly interdisciplinary challenges for language and robotics. This study conducts a survey on the frontier of the intersection of the research fields of language and robotics, ranging from logic probabilistic programming to designing a competition to evaluate language understanding systems. We focus on cognitive developmental robots that can learn a language from interaction with their environment and unsupervised learning methods that enable robots to learn a language without hand-crafted training data.",NO
2-s2.0-85065726674,10.4018/IJGCMS.2019010103,,,Modeling games in the K-12 science classroom,ar,Article,Krinks K.D.,,Lipscomb University,Nashville,United States,,,,,2019-01-01,2019,International Journal of Gaming and Computer-Mediated Simulations,19423888,19700186859,19423896,Journal,11,1,,31-50,,,1,0,,,,"Digital games can be used as a productive and engaging medium to foster scientific expertise and have shown promise in supporting the co-development of scientific concepts and representational practices. This study focuses on the integration of a disciplinarily-integrated game, SURGE NextG, with complementary model-based activities to support the development of scientific modeling in Newtonian mechanics. Two pedagogical approaches were designed. Students in both approaches modeled the motion of an object inside and outside the game environment. One approach involved the material integration of virtual game play through a physical modeling activity in the classroom. The second approach involved a complementary modeling tool using an agent-based computational programming platform. While both modeling activities demonstrated affordances to support productive student learning, this study highlights the significance of designing multiple complementary representations of the same phenomenon as a core element of game play and related modeling activities.
Request access from your librarian to read this article's full text.",NO
2-s2.0-85065610859,10.3390/en12071229,,,Optimal design of wireless charging electric bus system based on reinforcement learning,ar,Article,Lee H.,,Korea Advanced Institute of Science and Technology,Daejeon,South Korea,,,,,2019-01-01,2019,Energies,,62932,19961073,Journal,12,7,1229,,,,4,1,,,,"The design of conventional electric vehicles (EVs) is affected by numerous limitations, such as a short travel distance and long charging time. As one of the first wireless charging systems, the Online Electric Vehicle (OLEV) was developed to overcome the limitations of the current generation of EVs. Using wireless charging, an electric vehicle can be charged by power cables embedded in the road. In this paper, a model and algorithm for the optimal design of a wireless charging electric bus system is proposed. The model is built using a Markov decision process and is used to verify the optimal number of power cables, as well as optimal pickup capacity and battery capacity. Using reinforcement learning, the optimization problem of a wireless charging electric bus system in a diverse traffic environment is then solved. The numerical results show that the proposed algorithm maximizes average reward and minimizes total cost. We show the effectiveness of the proposed algorithm compared with obtaining the exact solution via mixed integer programming (MIP). View Full-Text",NO
2-s2.0-85063543874,10.3390/robotics8010008,,,The Robotic construction kit as a tool for cognitive stimulation in children and adolescents: The RE4BES protocol,ar,Article,D'Amico A.,,Università degli Studi di Palermo;MetaIntelligenze Onlus,Palermo;Palermo,Italy;Italy,,,,,2019-01-01,2019,Robotics,,21100833833,22186581,Journal,8,1,8,,,,5,1,,,,"Through numerous experiences, the robotics has been demonstrated to have good potential in the field of strengthening social skills in children with Special Educational Needs and in particular with autism spectrum disorder. There are still not many experimental studies on the cognitive enhancement and social skills of children with special needs conducted with robotics construction kits that, requiring both the construction of the robot body and the programming of its “mind“, bring into play a multiplicity of cognitive and social skills. For the aforementioned reasons our team from the University of Palermo and from the Center MetaIntelligenze ONLUS developed the treatment protocol RE4BES, which is a collection of guidelines for realizing robotics personalized activities for children with special needs. In this paper, two studies will be described concerning the first application of activities drawn from the RE4BES protocol. The first study concerns the use of the robotic construction kits for the stimulation of visuo-spatial abilities; in the second study the robot construction kits have been used to stimulate the attentional abilities in a child with severe difficulties on focused attention tasks. View Full-Text",NO
2-s2.0-85061816279,10.1109/ACCESS.2019.2895913,,,A study on the suitability of visual languages for non-expert robot programmers,ar,Article,Rodriguez Corral J.,,Universidad de Cádiz,Cadiz,Spain,,,,,2019-01-01,2019,IEEE Access,,21100374601,21693536,Journal,7,,8629035,17535-17550,,,9,1,,,,"A visual programming language allows users and developers to create programs by manipulating program elements graphically. Several studies have shown the benefits of visual languages for learning purposes and their applicability to robot programming. However, at present, there are not enough comparative studies on the suitability of textual and visual languages for this purpose. In this paper, we study if, as with a textual language, the use of a visual language could also be suitable in the context of robot programming and, if so, what the main advantages of using a visual language would be. For our experiments, we selected a sample of 60 individuals among students with adequate knowledge of procedural programming, that was divided into three groups. For the first group of 20 students, a learning scenario based on a textual object-oriented language was used for programming a specific commercial robotic ball with sensing, wireless communication, and output capabilities, whereas for the second and the third group, two learning scenarios based on visual languages were used for programming the robot. After taking a course for programming the robot in the corresponding learning scenario, each group was evaluated by completing three programming exercises related to the robot features (i.e. motion, lighting, and collision detection). Our results show that the students that worked with visual languages perceived a higher clarity level in their understanding of the course exposition, and a higher enjoyment level in the use of the programming environment. Moreover, they also achieved an overall better mark.",SI
2-s2.0-85061598787,10.1177/1729881419830204,,,Q-learning trajectory planning based on Takagi–Sugeno fuzzy parallel distributed compensation structure of humanoid manipulator,ar,Article,Wen S.,,Yanshan University,Qinhuangdao,China,,,,,2019-01-01,1 January 2019,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,16,1,,,,,7,1,,,,"NAO is the first robot created by SoftBank Robotics. Famous around the world, NAO is a tremendous programming tool and he has especially become a standard in education and research. Aiming at the large error and poor stability of the humanoid robot NAO manipulator during trajectory tracking, a novel framework based on fuzzy controller reinforcement learning trajectory planning strategy is proposed. Firstly, the Takagi–Sugeno fuzzy model based on the dynamic equation of the NAO right arm is established. Secondly, the design and the gain solution of the state feedback controller based on the parallel feedback compensation strategy are studied. Finally, the ideal trajectory of the motion is planned by reinforcement learning algorithm so that the end of the manipulator can track the desired trajectory and realize the valid obstacle avoidance. Simulation and experiment shows that the end of the manipulator based on this scheme has good controllability and stability and can meet the accuracy requirements of trajectory tracking accuracy, which verifies the effectiveness of the proposed framework.",NO
2-s2.0-85061210087,10.1145/3281629,,,Representations and optimizations for embedded parallel dataflow languages,ar,Article,Alexandrov A.,,Technical University of Berlin,Berlin,Germany,,,,,2019-01-01,January 2019,ACM Transactions on Database Systems,03625915,13044,15574644,Journal,44,1,4,,,,4,0,,,,"Parallel dataflow engines such as Apache Hadoop, Apache Spark, and Apache Flink are an established alternative to relational databases for modern data analysis applications. A characteristic of these systems is a scalable programming model based on distributed collections and parallel transformations expressed by means of second-order functions such as map and reduce. Notable examples are Flink’s DataSet and Spark’s RDD programming abstractions. These programming models are realized as EDSLs—domain specific languages embedded in a general-purpose host language such as Java, Scala, or Python. This approach has several advantages over traditional external DSLs such as SQL or XQuery. First, syntactic constructs from the host language (e.g., anonymous functions syntax, value definitions, and fluent syntax via method chaining) can be reused in the EDSL. This eases the learning curve for developers already familiar with the host language. Second, it allows for seamless integration of library methods written in the host language via the function parameters passed to the parallel dataflow operators. This reduces the effort for developing analytics dataflows that go beyond pure SQL and require domain-specific logic.

At the same time, however, state-of-the-art parallel dataflow EDSLs exhibit a number of shortcomings. First, one of the main advantages of an external DSL such as SQL—the high-level, declarative Select-From-Where syntax—is either lost completely or mimicked in a non-standard way. Second, execution aspects such as caching, join order, and partial aggregation have to be decided by the programmer. Optimizing them automatically is very difficult due to the limited program context available in the intermediate representation of the DSL.

In this article, we argue that the limitations listed above are a side effect of the adopted type-based embedding approach. As a solution, we propose an alternative EDSL design based on quotations. We present a DSL embedded in Scala and discuss its compiler pipeline, intermediate representation, and some of the enabled optimizations. We promote the algebraic type of bags in union representation as a model for distributed collections and its associated structural recursion scheme and monad as a model for parallel collection processing. At the source code level, Scala’s comprehension syntax over a bag monad can be used to encode Select-From-Where expressions in a standard way. At the intermediate representation level, maintaining comprehensions as a first-class citizen can be used to simplify the design and implementation of holistic dataflow optimizations that accommodate for nesting and control-flow. The proposed DSL design therefore reconciles the benefits of embedded parallel dataflow DSLs with the declarativity and optimization potential of external DSLs like SQL.",NO
2-s2.0-85060110922,10.1177/1729881418820227,,,A monocular vision–based perception approach for unmanned aerial vehicle close proximity transmission tower inspection,ar,Article,Bian J.,,Institute of Automation Chinese Academy of Sciences,Beijing,China,,,,,2019-01-01,1 January 2019,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,16,1,,,,,11,1,,,,"Employing unmanned aerial vehicles to conduct close proximity inspection of transmission tower is becoming increasingly common. This article aims to solve the two key problems of close proximity navigation—localizing tower and simultaneously estimating the unmanned aerial vehicle positions. To this end, we propose a novel monocular vision–based environmental perception approach and implement it in a hierarchical embedded unmanned aerial vehicle system. The proposed framework comprises tower localization and an improved point–line-based simultaneous localization and mapping framework consisting of feature matching, frame tracking, local mapping, loop closure, and nonlinear optimization. To enhance frame association, the prominent line feature of tower is heuristically extracted and matched followed by the intersections of lines are processed as the point feature. Then, the bundle adjustment optimization leverages the intersections of lines and the point-to-line distance to improve the accuracy of unmanned aerial vehicle localization. For tower localization, a transmission tower data set is created and a concise deep learning-based neural network is designed to perform real-time and accurate tower detection. Then, it is in combination with a keyframe-based semi-dense mapping to locate the tower with a clear line-shaped structure in 3-D space. Additionally, two reasonable paths are planned for the refined inspection. In experiments, the whole unmanned aerial vehicle system developed on Robot Operating System framework is evaluated along the paths both in a synthetic scene and in a real-world inspection environment. The final results show that the accuracy of unmanned aerial vehicle localization is improved, and the tower reconstruction is fast and clear. Based on our approach, the safe and autonomous unmanned aerial vehicle close proximity inspection of transmission tower can be realized.",NO
2-s2.0-85059796164,10.3390/s19010176,,30621314,Towards goal-directed navigation through combining learning based global and local planners,ar,Article,Zhou X.,,Harbin Engineering University,Harbin,China,,,,,2019-01-01,1 January 2019,Sensors (Switzerland),14248220,130124,,Journal,19,1,176,,,,8,1,,,,"Robot navigation is a fundamental problem in robotics and various approaches have been developed to cope with this problem. Despite the great success of previous approaches, learning-based methods are receiving growing interest in the research community. They have shown great efficiency in solving navigation tasks and offer considerable promise to build intelligent navigation systems. This paper presents a goal-directed robot navigation system that integrates global planning based on goal-directed end-to-end learning and local planning based on reinforcement learning (RL). The proposed system aims to navigate the robot to desired goal positions while also being adaptive to changes in the environment. The global planner is trained to imitate an expert’s navigation between different positions by goal-directed end-to-end learning, where both the goal representations and local observations are incorporated to generate actions. However, it is trained in a supervised fashion and is weak in dealing with changes in the environment. To solve this problem, a local planner based on deep reinforcement learning (DRL) is designed. The local planner is first implemented in a simulator and then transferred to the real world. It works complementarily to deal with situations that have not been met during training the global planner and is able to generalize over different situations. The experimental results on a robot platform demonstrate the effectiveness of the proposed navigation system. View Full-Text",NO
2-s2.0-85059059829,10.1177/0278364918812981,,,I-Planner: Intention-aware motion planning using learning-based human motion prediction,ar,Article,Park J.S.,,The University of North Carolina at Chapel Hill,Chapel Hill,United States,,,,,2019-01-01,1 January 2019,International Journal of Robotics Research,02783649,18050,17413176,Journal,38,1,,23-39,,,12,1,,,,We present a motion planning algorithm to compute collision-free and smooth trajectories for high-degree-of-freedom (high-DOF) robots interacting with humans in a shared workspace. Our approach uses offline learning of human actions along with temporal coherence to predict the human actions. Our intention-aware online planning algorithm uses the learned database to compute a reliable trajectory based on the predicted actions. We represent the predicted human motion using a Gaussian distribution and compute tight upper bounds on collision probabilities for safe motion planning. We also describe novel techniques to account for noise in human motion prediction. We highlight the performance of our planning algorithm in complex simulated scenarios and real-world benchmarks with 7-DOF robot arms operating in a workspace with a human performing complex tasks. We demonstrate the benefits of our intention-aware planner in terms of computing safe trajectories in such uncertain environments.,NO
2-s2.0-85056207076,10.1177/0735633117746747,,,Developing the Computer Programming Self-Efficacy Scale for Computer Literacy Education,ar,Article,Tsai M.,,National Taiwan University of Science and Technology,Taipei,Taiwan,,,,,2019-01-01,1 January 2019,Journal of Educational Computing Research,07356331,18874,15414140,Journal,56,8,,1345-1360,,,39,0,,,,"Computer programming has been gradually emphasized in recent computer literacy education and regarded as a requirement for all middle school students in some countries. To understand young students’ perceptions about their own learning in computer programming, this study aimed to develop an instrument, Computer Programming Self-Efficacy Scale (CPSES), for all students above middle school levels. Based on Berland and Lee’s computational thinking framework, this study developed the CPSES items at a literacy level and finally the instrument included the five subscales: Logical Thinking, Algorithm, Debug, Control, and Cooperation. An exploratory factor analysis and reliability tests were conducted in this study. The reliability alpha was .96 for the overall scale, and ranged from .84 to .96 for the subscales. This study also confirmed the positive correlation between computer programming experience and computer programming self-efficacy. In addition, for low- and middle-experienced learners, significant gender differences were found in two subscales: Algorithm and Debug. The CPSES can be applied as an evaluation tool in computer education, robotics education, as well as integrated STEM or STEAM education in which computer programming was regarded as a part of computer literacy.",NO
2-s2.0-85050633474,10.1109/TFUZZ.2018.2859184,,,LDS-FCM: A linear dynamical system based fuzzy C-Means method for tactile recognition,ar,Article,Liu C.,,Tsinghua University,Beijing,China,,,,,2019-01-01,January 2019,IEEE Transactions on Fuzzy Systems,10636706,24242,,Journal,27,1,8418835,72-83,,,14,0,,,,"Tactile sensing is becoming an indispensable robotic ability for object recognition and grasping manipulation despite dealing with tactile data as the force distribution over the array sensors continuously changes as a function of time. In this paper, we propose an efficient feature extractor named linear dynamic systems based fuzzy C-means method (LDS) to encode the tactile sequences, both spatially and temporally. To this end, we decompose every input sequence into multiple subsequences, each of which is locally described by a finite-ordered observability matrix of the LDS model. A fuzzy c-means method is then applied to cluster the local LDS descriptors for learning a codebook. Conditioned on the resulting codebook, the global tactile representation is formulated by employing two different frameworks to integrate the subsequences within each tactile sequence, namely, the Vector of locally aggregated descriptor and Bag-of-Word approaches. The effectiveness of the proposed model is verified by a variety of experimental evaluations on five benchmark datasets. Results reveal that our proposed method achieves a higher classification accuracy than the state-of-the-art models with a large margin.",NO
2-s2.0-85049847869,10.1017/S1471068418000054,S1471068418000054,,Multi-shot ASP solving with clingo,ar,Article,Gebser M.,,Universität Potsdam,Potsdam,Germany,,,,,2019-01-01,1 January 2019,Theory and Practice of Logic Programming,14710684,28424,14753081,Journal,19,1,,27-82,,,41,0,,,,"We introduce a new flexible paradigm of grounding and solving in Answer Set Programming (ASP), which we refer to as multi-shot ASP solving, and present its implementation in the ASP system clingo. Multi-shot ASP solving features grounding and solving processes that deal with continuously changing logic programs. In doing so, they remain operative and accommodate changes in a seamless way. For instance, such processes allow for advanced forms of search, as in optimization or theory solving, or interaction with an environment, as in robotics or query answering. Common to them is that the problem specification evolves during the reasoning process, either because data or constraints are added, deleted, or replaced. This evolutionary aspect adds another dimension to ASP since it brings about state changing operations. We address this issue by providing an operational semantics that characterizes grounding and solving processes in multi-shot ASP solving. This characterization provides a semantic account of grounder and solver states along with the operations manipulating them. The operative nature of multi-shot solving avoids redundancies in relaunching grounder and solver programs and benefits from the solver's learning capacities. clingo accomplishes this by complementing ASP's declarative input language with control capacities. On the declarative side, a new directive allows for structuring logic programs into named and parameterizable subprograms. The grounding and integration of these subprograms into the solving process is completely modular and fully controllable from the procedural side. To this end, clingo offers a new application programming interface that is conveniently accessible via scripting languages. By strictly separating logic and control, clingo also abolishes the need for dedicated systems for incremental and reactive reasoning, like iclingo and oclingo, respectively, and its flexibility goes well beyond the advanced yet still rigid solving processes of the latter.",NO
2-s2.0-85039808369,10.1109/TII.2017.2786280,,,Designing Dynamic and Collaborative Automation and Robotics Software Systems,ar,Article,Salcic Z.,,The University of Auckland,Auckland,New Zealand,,,,,2019-01-01,January 2019,IEEE Transactions on Industrial Informatics,15513203,144912,,Journal,15,1,8234634,540-549,,,11,0,,,,"The heterogeneity of execution platforms and operating software in manufacturing machines and robots, as well as various sensors and actuators, creates challenges for integration into larger systems. Existing approaches make use of different types of middleware to mitigate the challenges of designing interoperable systems. However, middleware can significantly impede modular design and composition of software systems that are dynamic in nature. This paper elaborates upon those challenges and proposes using an approach called service-oriented SystemJ (SOSJ), based on the system-level programming language SystemJ enhanced with service oriented features. This approach allows developers to design dynamic software systems while adopting and incorporating legacy solutions. The approach is demonstrated on the integration of an industrial automation system, incorporating the use of multiple modular mechatronics stations and service robotics systems, represented by robot operating system-enabled Baxter robots. The proposed approach offers a simple service interface based on abstract objects for integrating robots and automation machines in the SOSJ world, without the need to modify the underlying mechatronics or robotics systems.",NO
2-s2.0-85099357270,10.6041/j.issn.1000-1298.2020.12.002,,,Trajectory Planning Method for Apple Picking Manipulator Based on Stepwise Migration Strategy,ar,Article,Zheng C.,,Beijing Forestry University,Beijing,China,,,,,2020-12-25,25 December 2020,Nongye Jixie Xuebao/Transactions of the Chinese Society for Agricultural Machinery,10001298,59863,,Journal,51,12,,15-23,,,1,0,,,,"Picking trajectory planning is one of the important research aspects of apple picking manipulator. The unstructured natural environment leads to low training efficiency for picking trajectory planning based on deep reinforcement learning. A deep deterministic policy gradient algorithm (DDPG) based on a stepwise migration strategy was proposed for apple picking trajectory planning. Firstly, a progressive spatially constrained stepwise training strategy based on DDPG was put forward to solve the problem of hard converging in natural environments. Secondly, the transfer learning idea was utilized to migrate the strategies obtained from the obstacle free scenario to the simple obstacle scenario, from the simple obstacle scenario to the hybrid obstacle scenario, to accelerate the training process in an obstacle scenario from prior strategies and guide the obstacle avoidance trajectory planning of the apple picking manipulator. Finally, the simulation experiments on the multi degree of freedom apple picking manipulator for picking trajectory planning were carried out, and the results showed that the stepwise migration strategy can improve the training efficiency and network performance of the DDPG algorithm. It was validated that the trajectory planning method for apple picking manipulator based on stepwise migration strategy was feasible. ",NO
2-s2.0-85095565048,10.1016/j.jsr.2020.09.002,S0022437520301067,33334472,Safety climate at agricultural cooperatives,ar,Article,Hanson E.,,North Dakota State University,Fargo,United States,,,,,2020-12-01,December 2020,Journal of Safety Research,00224375,29284,,Journal,75,,,150-154,,,0,0,,,,"Introduction: This study identifies determinants of safety climate at agricultural cooperatives. Methods: An extensive survey was designed to build upon past research done in collaboration with DuPont (Risch et al., 2014). In 2014 and 2015, the survey was administered to 1930 employees at 14 different agricultural cooperatives with 154 locations. Injury incidence data were also collected from each location to better understand the overall health and safety environment in this sector. An ordered probit model is used to identify variables that are associated with better safety climates. Results: Safety system components such as discipline programs, inspection programs, modified duty programs, off-the-job safety training programs, and recognition programs are positively related to individual safety climate for both managerial employees and nonmanagerial employees. Variables representing an employee’s agricultural background, distance between their workplace and childhood home, and formal education are not associated with managerial safety climate. However, agricultural background and childhood home distance are associated with nonmanagerial safety climate. Conclusions: Improving occupational health and safety is a priority for many agricultural cooperatives. Lower safety climate emerges as nonmanagerial employees have more experience with production agriculture and work nearer to their home community. Practical applications: Employees of agricultural cooperatives face a host of health and safety challenges that are likely to persist into the future. The safety system components associated with safety climate indicate that continuous feedback is important for improving occupational health and safety. Occupational health and safety programming should also acknowledge that many employees have experiences that influence their attitudes and behaviors.",NO
2-s2.0-85093654162,10.1016/j.asoc.2020.106796,S1568494620307341,,Optimal path planning approach based on Q-learning algorithm for mobile robots,ar,Article,Maoudj A.,,Centre de Développement des Technologies Avancées,Algiers,Algeria,,,,,2020-12-01,December 2020,Applied Soft Computing Journal,15684946,18136,,Journal,97,,106796,,,,5,0,,,,"Highlights

•

The mobile robot path optimization problem is handled and modeled.

•

An Efficient Q-Learning (EQL) algorithm is proposed.

•

In EQL, a new definition of states space and actions space is proposed.

•

New reward function is proposed to initialize Q-table.

•

Learning process is sped up by exploiting a new efficient selection strategy.

•

Results on benchmarks from literature demonstrate EQL efficiency and superiority.
In fact, optimizing path within short computation time still remains a major challenge for mobile robotics applications. In path planning and obstacles avoidance, Q-Learning (QL) algorithm has been widely used as a computational method of learning through environment interaction. However, less emphasis is placed on path optimization using QL because of its slow and weak convergence toward optimal solutions. Therefore, this paper proposes an Efficient Q-Learning (EQL) algorithm to overcome these limitations and ensure an optimal collision-free path in less possible time. In the QL algorithm, successful learning is closely dependent on the design of an effective reward function and an efficient selection strategy for an optimal action that ensures exploration and exploitation. In this regard, a new reward function is proposed to initialize the Q-table and provide the robot with prior knowledge of the environment, followed by a new efficient selection strategy proposal to accelerate the learning process through search space reduction while ensuring a rapid convergence toward an optimized solution. The main idea is to intensify research at each learning stage, around the straight-line segment linking the current position of the robot to Target (optimal path in terms of length). During the learning process, the proposed strategy favors promising actions that not only lead to an optimized path but also accelerate the convergence of the learning process. The proposed EQL algorithm is first validated using benchmarks from the literature, followed by a comparison with other existing QL-based algorithms. The achieved results showed that the proposed EQL gained good learning proficiency; besides, the training performance is significantly improved compared to the state-of-the-art. Concluded, EQL improves the quality of the paths in terms of length, computation time and robot safety, furthermore outperforms other optimization algorithms.",NO
2-s2.0-85089028908,10.1007/s10846-020-01240-x,,,iADA*: Improved Anytime Path Planning and Replanning Algorithm for Autonomous Vehicle,ar,Article,Maw A.A.,,Konkuk University,Seoul,South Korea,,,,,2020-12-01,December 2020,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,100,3-4,,1005-1013,,,4,0,,,,"Path planning of autonomous mobile robots in a real-world environment presents several challenges which are usually not raised in other areas. The real world is inherently complex, uncertain and dynamic. Therefore, accurate models of path planning are difficult to obtain and quickly become outdated. Anytime planners are ideal for this type of problem as they can find an initial solution very quickly and then improve it as time allows. This paper proposes a new anytime incremental search algorithm named improved Anytime Dynamic A*(iADA*). The algorithm is based on the currently popular anytime heuristic search algorithm, which is Anytime Dynamic A*(ADA*). The iADA* algorithm improves the calculation of the path lengths and decreases the calculating frequency of the path throughout the search, making it significantly faster. The algorithm is designed to provide an efficient solution to a complex, dynamic search environment when the locally changes affected. Our study shows that the two-dimensional path-planning iADA* experiments were between 2.0 to 3.7 times faster than ADA*, both in partially known and fully unknown dynamic environments. Additionally, in this paper shows the experiment results of the comparison with other four existing algorithms based on computing time and path lengths. iADA* was an average 2.57 times reduced on the computational time for the environment which locally changes effected. For the path length is little increase, but it is not the worst case. According to the experiments, the more the environmental problems and complexity increases, the more iADA* provides a rapid in-search time and total time to obtain the final solution.",NO
2-s2.0-85082935296,10.1007/s12652-020-01877-4,,,Motion path planning of soccer training auxiliary robot based on genetic algorithm in fixed-point rotation environment,ar,Article,Ding H.,,Henan University of Science and Technology,Luoyang,China,,,,,2020-12-01,December 2020,Journal of Ambient Intelligence and Humanized Computing,18685137,19400158593,18685145,Journal,11,12,,6261-6270,,,2,0,,,,"Soccer training assisted robot system is a combination of robotics and artificial intelligence. Motion path planning is an important part of soccer training assisted robot decision system. Path planning aims to find an optimal path, complete dynamic and static obstacle avoidance, and thus can timely and quickly carry out the path planning of the soccer training assisted robot cooperation strategy. Aiming at the problem of soccer training auxiliary robot motion path planning, this paper proposes a global path planning method based on genetic algorithm, which avoids the problem of unsmooth path and large computation. Under the premise of ensuring the completeness of search, this method transforms the soccer training assisted robot path planning problem into the path search problem of the soccer training assisted robot system center. Under the premise of using the fixed-point rotation method on a large scale, the genetic algorithm is adopted for the case of some special narrow-channel environments, and the action area is determined by simple search. Finally, the planning path of each soccer training-assisted robot in the system is obtained. Finally, the simulation results verify the effectiveness of the algorithm.",NO
2-s2.0-85079823443,10.1007/s12532-020-00179-2,,,OSQP: an operator splitting solver for quadratic programs,ar,Article,Stellato B.,,Massachusetts Institute of Technology,Cambridge,United States,,,,,2020-12-01,1 December 2020,Mathematical Programming Computation,18672949,19400158592,18672957,Journal,12,4,,637-672,,,63,1,,,,"We present a general-purpose solver for convex quadratic programs based on the alternating direction method of multipliers, employing a novel operator splitting technique that requires the solution of a quasi-definite linear system with the same coefficient matrix at almost every iteration. Our algorithm is very robust, placing no requirements on the problem data such as positive definiteness of the objective function or linear independence of the constraint functions. It can be configured to be division-free once an initial matrix factorization is carried out, making it suitable for real-time applications in embedded systems. In addition, our technique is the first operator splitting method for quadratic programs able to reliably detect primal and dual infeasible problems from the algorithm iterates. The method also supports factorization caching and warm starting, making it particularly efficient when solving parametrized problems arising in finance, control, and machine learning. Our open-source C implementation OSQP has a small footprint, is library-free, and has been extensively tested on many problem instances from a wide variety of application areas. It is typically ten times faster than competing interior-point methods, and sometimes much more when factorization caching or warm start is used. OSQP has already shown a large impact with tens of thousands of users both in academia and in large corporations.",NO
2-s2.0-85096079619,10.1145/3396235,,,Optimizing Tensor Contractions for Embedded Devices with Racetrack and DRAM Memories,ar,Article,Khan A.A.,,Technische Universität Dresden,Dresden,Germany,,,,,2020-11-01,November 2020,ACM Transactions on Embedded Computing Systems,15399087,10300153313,15583465,Journal,19,6,44,,,,1,0,,,,"Tensor contraction is a fundamental operation in many algorithms with a plethora of applications ranging from quantum chemistry over fluid dynamics and image processing to machine learning. The performance of tensor computations critically depends on the efficient utilization of on-chip/off-chip memories. In the context of low-power embedded devices, efficient management of the memory space becomes even more crucial, in order to meet energy constraints. This work aims at investigating strategies for performance- and energy-efficient tensor contractions on embedded systems, using racetrack memory (RTM)-based scratch-pad memory (SPM) and DRAM-based off-chip memory. Compiler optimizations such as the loop access order and data layout transformations paired with architectural optimizations such as prefetching and preshifting are employed to reduce the shifting overhead in RTMs. Optimizations for off-chip memory such as memory access order, data mapping and the choice of a suitable memory access granularity are employed to reduce the contention in the off-chip memory. Experimental results demonstrate that the proposed optimizations improve the SPM performance and energy consumption by 32% and 73%, respectively, compared to an iso-capacity SRAM. The overall DRAM dynamic energy consumption improvements due to memory optimizations amount to 80%.",NO
2-s2.0-85091499704,10.1007/s00170-020-06066-3,,,Design and characterization of an instrumented hand-held power tool to capture dynamic interaction with the workpiece during manual operations,ar,Article,Phan G.H.,,Viet Nam National University Ho Chi Minh City;Đại học Công nghệ Thành phố Hồ Chí Minh,Ho Chi Minh City;Ho Chi Minh City,Viet Nam;Viet Nam,,,,,2020-11-01,1 November 2020,International Journal of Advanced Manufacturing Technology,02683768,20428,14333015,Journal,111,1-2,,199-212,,,1,0,,,,"In recent years, robots have contributed extensively to the automation of repetitive tasks for which position control-based approaches represent effective solutions. However, other contact tasks such as finishing, deburring and grinding require both position and force control. To date, despite the availability of cost-effective robotic solutions, such tasks are still carried out manually by skilled operators mainly because programming is time consuming and not sufficiently flexible to be readapted to product or task changes. An alternative approach is teaching by demonstration, by instrumenting hand-held tools for capturing both the force and the contact point while an expert operator performs tooling tasks. This paper presents a novel approach for instrumenting hand-held tools for polishing/grinding used in monitoring the performance of skilled human operators which can be, in future work, translated into planning strategies for robot programming and control. More specifically, the instrumented tool is designed to monitor interaction forces with the workpiece and point of contact, where these interaction forces arise. The key element in our design is a flexible coupler which, ideally, only transmits rotation torques to spin the polishing/grinding wheel while all the remaining torque and force components are transmitted through a parallel structure and sensed by a 6-axis loadcell. Sensing torques, in addition to forces, also allows for a dynamic estimation of the point of contact.",NO
2-s2.0-85094106971,10.1049/el.2020.1895,,,Solving path planning problem based on logistic beetle algorithm search-pigeon-inspired optimisation algorithm,ar,Article,Liu A.,,Xiangtan University,Xiangtan,China,,,,,2020-10-15,15 October 2020,Electronics Letters,00135194,24918,,Journal,56,21,,1105-1108,,,1,0,,,,"Mobile robot path planning is an important part of the mobile robot field. The swarm intelligence optimisation algorithm has certain advantages in solving such multi-objective optimisation problems, so this Letter proposes to apply the pigeon-inspired optimisation (PIO) algorithm to the path planning problem. However, the traditional PIO algorithm is suffering from the problems of easy to get into local optimisation, low stability and premature convergence. To overcome its shortcomings, this Letter proposes a logistic beetle algorithm search–PIO (LBAS-PIO) algorithm. In the optimisation process of the LBAS-PIO algorithm, the PIO algorithm is initialised by the logistic mapping, making the search space more extensive. Learning from the idea of the beetle algorithm search, each pigeon has its own judgment of the environment and the number of iterations and search time are reduced. Further, the path evaluation function of the algorithm and the execution order of the operators are optimised to make the algorithm smoother and easier to find the global optimal solution. Simulation and experimental results illustrated the superiority of the LBAS-PIO algorithm and the LBAS-PIO algorithm better meets the needs of mobile robots for the optimal path planning.",NO
2-s2.0-85096418871,10.1111/cgf.14157,,,InstanceFusion: Real-time Instance-level 3D Reconstruction Using a Single RGBD Camera,ar,Article,Lu F.,,Beihang University,Beijing,China,,,,,2020-10-01,October 2020,Computer Graphics Forum,01677055,25023,14678659,Journal,39,7,,433-445,,,1,0,,,,,NO
2-s2.0-85094147328,10.1109/TMECH.2020.2997799,,,Joining Force of Human Muscular Task Planning with Robot Robust and Delicate Manipulation for Programming by Demonstration,ar,Article,Wang F.,,Faculty of Robot Science and Engineering,Shenyang,China,,,,,2020-10-01,October 2020,IEEE/ASME Transactions on Mechatronics,10834435,19113,1941014X,Journal,25,5,9099988,2574-2584,,,3,0,,,,"Recently, programing by demonstration (PbD) received much attention for its capacity of fast programming with increasing demands in the robot manipulation area, especially in industrial applications. However, one of the biggest challenges of PbD is the recognition of demonstrator's finger high-fidelity motions especially in the environments with uncertainties, which limits the efficiency and accuracy of PbD. In this article, inspired by human dexterity, a novel PbD approach using the implicit muscular task planning strategy is presented to extract features from the arms' giant movement and the hands' fine motions during the demonstrator's operation. Furthermore, we integrate a deep reinforcement learning control method that further improves the manipulations' adaptive ability in the unknown or dynamic environments. The experimental results show that our proposed approach can deal with relative complex assembly tasks with a success rate of more than 67% within a fit tolerance of 4.2 mm by one-shot demonstration.",NO
2-s2.0-85092189608,10.1109/TASE.2020.2974771,,,Planning Jerk-Optimized Trajectory with Discrete Time Constraints for Redundant Robots,ar,Article,Dai C.,,"The Department of Design Engineering, TU Delft;Chinese University of Hong Kong",Delft;Hong Kong,Netherlands;Hong Kong,,,,,2020-10-01,October 2020,IEEE Transactions on Automation Science and Engineering,15455955,17340,15583783,Journal,17,4,9025760,1711-1724,,,6,0,,,,"We present a method for effectively planning the motion trajectory of robots in manufacturing tasks, the tool paths of which are usually complex and have a large number of discrete time constraints as waypoints. Kinematic redundancy also exists in these robotic systems. The jerk of motion is optimized in our trajectory planning method at the meanwhile of fabrication process to improve the quality of fabrication. Our method is based on a sampling strategy and consists of two major parts. After determining an initial path by graph search, a greedy algorithm is adopted to optimize a path by locally applying adaptive filers in the regions with large jerks. The filtered result is obtained by numerical optimization. In order to achieve efficient computation, an adaptive sampling method is developed for learning a collision-indication function that is represented as a support-vector machine. Applications in robot-assisted 3-D printing are given in this article to demonstrate the functionality of our approach. Note to Practitioners-In robot-assisted manufacturing applications, robotic arms are employed to realize the motion of workpieces (or machining tools) specified as a sequence of waypoints with the positions of tool tip and the tool orientations constrained. The required degree of freedom (DOF) is often less than the robotic hardware system (e.g., a robotic arm has six-DOF). Specifically, rotations of the workpiece around the axis of a tool can be arbitrary (see Fig. 1 for an example). By using this redundancy, i.e., there are many possible poses of a robotic arm to realize a given waypoint, the trajectory of robots can be optimized to consider the performance of motion in velocity, acceleration, and jerk in the joint space. In addition, when fabricating complex models, each tool path can have a large amount of waypoints. It is crucial for a motion planning algorithm to compute a smooth and collision-free trajectory of robot to improve the fabrication quality. The time...
(Show More)",NO
2-s2.0-85091916739,10.1109/LRA.2020.3026638,,,Mobile robot path planning in dynamic environments through globally guided reinforcement learning,ar,Article,Wang B.,,Chinese University of Hong Kong,Hong Kong,Hong Kong,,,,,2020-10-01,October 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,4,9205217,6932-6939,,,5,0,,,,"Path planning for mobile robots in large dynamic environments is a challenging problem, as the robots are required to efficiently reach their given goals while simultaneously avoiding potential conflicts with other robots or dynamic objects. In the presence of dynamic obstacles, traditional solutions usually employ re-planning strategies, which re-call a planning algorithm to search for an alternative path whenever the robot encounters a conflict. However, such re-planning strategies often cause unnecessary detours. To address this issue, we propose a learning-based technique that exploits environmental spatio-temporal information. Different from existing learning-based methods, we introduce a globally guided reinforcement learning approach (G2RL), which incorporates a novel reward structure that generalizes to arbitrary environments. We apply G2RL to solve the multi-robot path planning problem in a fully distributed reactive manner. We evaluate our method across different map types, obstacle densities, and the number of robots. Experimental results show that G2RL generalizes well, outperforming existing distributed methods, and performing very similarly to fully centralized state-of-the-art benchmarks.",NO
2-s2.0-85091625482,10.3390/s20195493,,32992750,Deep reinforcement learning for indoor mobile robot path planning,ar,Article,Gao J.,,Guangdong University of Technology,Guangzhou,China,,,,,2020-10-01,1 October 2020,Sensors (Switzerland),14248220,130124,,Journal,20,19,5493,1-15,,,10,1,,,,"This paper proposes a novel incremental training mode to address the problem of Deep Reinforcement Learning (DRL) based path planning for a mobile robot. Firstly, we evaluate the related graphic search algorithms and Reinforcement Learning (RL) algorithms in a lightweight 2D environment. Then, we design the algorithm based on DRL, including observation states, reward function, network structure as well as parameters optimization, in a 2D environment to circumvent the time-consuming works for a 3D environment. We transfer the designed algorithm to a simple 3D environment for retraining to obtain the converged network parameters, including the weights and biases of deep neural network (DNN), etc. Using these parameters as initial values, we continue to train the model in a complex 3D environment. To improve the generalization of the model in different scenes, we propose to combine the DRL algorithm Twin Delayed Deep Deterministic policy gradients (TD3) with the traditional global path planning algorithm Probabilistic Roadmap (PRM) as a novel path planner (PRM+TD3). Experimental results show that the incremental training mode can notably improve the development efficiency. Moreover, the PRM+TD3 path planner can effectively improve the generalization of the model. View Full-Text",NO
2-s2.0-85090323171,10.1109/LRA.2020.3010220,,,Neural manipulation planning on constraint manifolds,ar,Article,Qureshi A.H.,,The Electrical and Computer Engineering Department,San Diego,United States,,,,,2020-10-01,October 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,4,9143433,6089-6096,,,4,0,,,,"The presence of task constraints imposes a significant challenge to motion planning. Despite all recent advancements, existing algorithms are still computationally expensive for most planning problems. In this letter, we present Constrained Motion Planning Networks (CoMPNet), the first neural planner for multimodal kinematic constraints. Our approach comprises the following components: i) constraint and environment perception encoders; ii) neural robot configuration generator that outputs configurations on/near the constraint manifold(s), and iii) a bidirectional planning algorithm that takes the generated configurations to create a feasible robot motion trajectory. We show that CoMPNet solves practical motion planning tasks involving both unconstrained and constrained problems. Furthermore, it generalizes to new unseen locations of the objects, i.e., not seen during training, in the given environments with high success rates. When compared to the state-of-the-art constrained motion planning algorithms, CoMPNet outperforms by order of magnitude improvement in computational speed with a significantly lower variance.",NO
2-s2.0-85089815882,10.1016/j.mechatronics.2020.102418,S0957415820300945,,One-Shot kinesthetic programming by demonstration for soft collaborative robots,ar,Article,Müller D.,,Universität Stuttgart,Stuttgart,Germany,,,,,2020-10-01,October 2020,Mechatronics,09574158,21096,,Journal,70,,102418,,,,3,0,,,,"Robots have long been part of production lines and, since they are widely used in a variety of applications, they have become a mass product. Yet, their integration into production is costly due to the necessity of skilled engineers programming them. The goal of this article is to reduce these costs via a programming by demonstration approach, allowing unskilled workers to complete the task of said engineers. Rather than just working next to a robot, this enables a collaborative work environment where humans use manipulators as tools for various tasks.

This work aims at automatically generating a trajectory by a single kinesthetic demonstration, which is performed by a non-expert user. The proposed approach adapts and extends the trajectory generator of a previous work and develops a method that gives guarantees on the deviation between the demonstrated path and the generated path. In contrast to the previous work, an expert user is not required. Furthermore, instead of teaching a series of points the whole trajectory is recorded in a single demonstration. To ensure real-time compatibility on the target hardware, one focus of this paper is on the complexity of the algorithm. The method is validated using a soft quasi continuum manipulator as an example for a collaborative robot.",NO
2-s2.0-85088835141,10.1016/j.robot.2020.103604,S0921889020304449,,Collective navigation of a multi-robot system in an unknown environment,ar,Article,Olcay E.,,Technical University of Munich,Munich,Germany,,,,,2020-10-01,October 2020,Robotics and Autonomous Systems,09218890,18079,,Journal,132,,103604,,,,6,0,,,,"Highlights

•

Collective motion planning.

•

Collaborative decision-making.

•

Obstacle avoidance.
The navigation of autonomous, mobile multi-robot systems in changing environments is a challenging problem investigated over the past years. Cooperative, multiple robots are employed for many different tasks to increase the efficiency and success of a mission. However, many of the existing collective path planning approaches do not guarantee a reliable escape in environments with complex, non-convex obstacles without any prior knowledge. In this study, we developed a navigation framework for multi-robot systems in unknown areas that solely exploit the sensing information and shared data among the agents. The key contribution of this paper is the simultaneous, collision-free motion planning for fully autonomous robots in a collective manner. Furthermore, our communication architecture enables the robots to find an appropriate path to a desired, joint target position, despite the limited sensing and communication range.",NO
2-s2.0-85088531534,10.1109/LRA.2020.3006797,,,Building Energy-Cost Maps from Aerial Images and Ground Robot Measurements with Semi-Supervised Deep Learning,ar,Article,Wei M.,,University of Minnesota Twin Cities,Minneapolis,United States,,,,,2020-10-01,October 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,4,9131808,5136-5142,,,0,0,,,,"Planning energy-efficient paths is an important capability in many robotics applications. Obtaining an energy-cost map for a given environment enables planning such paths between any given pair of locations within the environment. However, efficiently building an energy map is challenging, especially for large environments. Some of the prior work uses physics-based laws (friction and gravity force) to model energy costs across environments. These methods work well for uniform surfaces, but they do not generalize well to uneven terrains. In this letter, we present a method to address this mapping problem in a data-driven fashion for the cases where an aerial image of the environment can be obtained. To efficiently build an energy-cost map, we train a neural network that learns to predict the complete energy maps by combining aerial images and sparse ground robot energy-consumption measurements. Field experiments are performed to validate our results. We show that our method can efficiently build an energy-cost map accurately even across different types of ground robots.",NO
2-s2.0-85086699581,10.1007/s10458-020-09453-y,,,Agent programming in the cognitive era,ar,Article,Bordini R.H.,,Pontifícia Universidade Católica do Rio Grande do Sul,Porto Alegre,Brazil,,,,,2020-10-01,1 October 2020,Autonomous Agents and Multi-Agent Systems,13872532,24157,15737454,Journal,34,2,37,,,,9,1,,,,"It is claimed that, in the nascent ‘Cognitive Era’, intelligent systems will be trained using machine learning techniques rather than programmed by software developers. A contrary point of view argues that machine learning has limitations, and, taken in isolation, cannot form the basis of autonomous systems capable of intelligent behaviour in complex environments. In this paper, we explore the contributions that agent-oriented programming can make to the development of future intelligent systems. We briefly review the state of the art in agent programming, focussing particularly on BDI-based agent programming languages, and discuss previous work on integrating AI techniques (including machine learning) in agent-oriented programming. We argue that the unique strengths of BDI agent languages provide an ideal framework for integrating the wide range of AI capabilities necessary for progress towards the next-generation of intelligent systems. We identify a range of possible approaches to integrating AI into a BDI agent architecture. Some of these approaches, e.g., ‘AI as a service’, exploit immediate synergies between rapidly maturing AI techniques and agent programming, while others, e.g., ‘AI embedded into agents’ raise more fundamental research questions, and we sketch a programme of research directed towards identifying the most appropriate ways of integrating AI capabilities into agent programs.",NO
2-s2.0-85086585185,10.1016/j.ijleo.2020.165096,S0030402620309323,,Path planning for indoor Mobile robot based on deep learning,ar,Article,Zhang L.,,Xi'an Jiaotong University,Xi'an,China,,,,,2020-10-01,October 2020,Optik,00304026,110152,,Journal,219,,165096,,,,4,0,,,,"This paper aims to give an optimal path planning of a mobile robot in a known indoor environment. An algorithm based on deep learning, ray tracing algorithm, waiting rule, and Rapidly-exploring Random Tree is proposed to solve the problem of obstacle avoidance and path planning. Firstly, GoogLeNet is used to classify obstacles. Here, it helps to distinguish between static and dynamic obstacles. Secondly, for the static obstacle avoidance, the ray tracing algorithm is proposed to avoid the obstacles which are identified by GoogLeNet. And for the dynamic obstacle avoidance, this paper proposed a waiting rule for dynamic obstacle avoidance. Thirdly, the RRT method plans a path from the start point to the goal point. The novelty of this paper is that the type of obstacles is distinguished by deep learning, and the two different kinds of obstacles used ray tracing algorithm and waiting rule to avoid obstacles collision, respectively. In experimental results, rapidly-exploring random tree is compared with genetic algorithm, and particle swarm optimization method in static environment, and it is compared with artificial potential field approach in dynamic environment. Experiments are carried out in the two-dimensional environment and successfully applied to the path planning of mobile robots in multi-obstacles environment, and they prove the feasibility of the algorithm.",NO
2-s2.0-85084044628,10.1007/s10846-020-01196-y,,,A Global/Local Path Planner for Multi-Robot Systems with Uncertain Robot Localization,ar,Article,de Almeida J.P.L.S.,,Universidade Tecnológica Federal do Paraná;Federal Institute of Paraná (IFPR),Curitiba;Colombo,Brazil;Brazil,,,,,2020-10-01,1 October 2020,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,100,1,,311-333,,,1,0,,,,"This paper proposes a path planner for multi-robot systems based on the solution of the multiple traveling salesman problem by genetic algorithm. The main planning goal is to build an efficient path to each robot of the system which jointly ensures that several a priori known points (ways-points) in the environment can be attained by at least one of the robots. During navigation, each robot try to follow its planned path while performing tasks and deviating from unknown static and dynamic obstacles. As the robots have limited sensing and communication skills, their positions can easily become uncertain and the robots will be unable to follow their planned paths. To circumvent this problem, each robot has a local planner, able to recalculate its position and then to resume its planned path. This computation is based on the knowledge about way-points positions, information exchanged with other robots and a self localization algorithm by triangulation. The proposed global/local path planner is firstly validated by computer simulations. An experimental study is also carried out with a small system with very simple mobile robots with differential drive and Bluetooth communication. The obtained results confirm the efficacy of the proposed path planner.",NO
2-s2.0-85081635829,10.1177/0020720920907879,,,A reproducible educational plan to teach mini autonomous race car programming,ar,Article,Eken S.,,Kocaeli Üniversitesi,Kocaeli,Turkey,,,,,2020-10-01,1 October 2020,International Journal of Electrical Engineering and Education,00207209,17966,20504578,Journal,57,4,,340-360,,,0,0,,,,"As autonomous cars and complex features of them grow in popularity, ensuring that analyses and capabilities are reproducible and repeatable has taken on importance in education plans too. This paper describes a reproducible research plan on mini autonomous race car programming. This educational plan is designed and implemented as part of a summer internship program at Kocaeli University and it consists of theoretical courses and laboratory assignments. A literate programming approach with the Python language is used for programming the race car. To assess the educational program’s impact on the learning process and to evaluate the acceptance and satisfaction level of students, they answered an electronic questionnaire after finishing the program. According to students’ feedback, the reproducible educational program is useful for learning and consolidating new concepts of mini autonomous car programming.",NO
2-s2.0-85079737377,10.1007/s11265-020-01522-5,,,An FPGA-Based Accelerated Optimization Algorithm for Real-Time Applications,ar,Article,Psarakis M.,,University of Piraeus,Piraeus,Greece,,,,,2020-10-01,1 October 2020,Journal of Signal Processing Systems,19398018,11400153333,19398115,Journal,92,10,,1155-1176,,,4,0,,,,"Many modern applications, such as industrial control, image processing and machine learning, are based on optimization algorithms that must solve compute-intensive problems under real-time constraints taking into account real-world parameters that evolve in time. Among others, evolutionary algorithms (EAs) are increasingly used in real-time applications to solve such complex optimization problems. Moreover, Field Programmable Gate Arrays (FPGAs) have been proved an effective platform for the implementation of these algorithms satisfying real-time and low-power requirements. In this paper, we study the FPGA-based acceleration of the Big Bang-Big Crunch (BB-BC) algorithm. BB-BC is an optimization method inspired by the corresponding evolutionary theory of the universe [1]. The BB-BC method is performed in two phases: in the Bing Bang phase, similarly to other Genetic Algorithms (GAs) it generates a random population of candidate solutions, while in the Big Crunch phase it shrinks these candidates around an optimal point. It has been shown that the BB-BC method outperforms classical GA algorithms for several optimization problems in terms of convergence speed. We show that the BB-BC algorithm does not suffer from the design limitations of the classical GAs that impede the performance of their hardware-based accelerators. We propose an efficient fully pipelined design of both BB-BC phases and a parallel scheme which integrates several BB-BC pipelined engines to improve system performance. We implement the proposed FPGA-based accelerator on a Xilinx Virtex-5 development board for three different fitness functions and compare the execution time against its software counterpart (in C language) and a CUDA program running on a massively parallel computing platform (GPU). We also compare the proposed optimized FPGA architecture with an RTL design generated by a high-level synthesis (HLS) design flow. We propose an Adaptive Neuro-fuzzy Inference System (ANFIS) model for fitness function approximation method to reduce the execution latency of complex fitness functions. We also demonstrate the efficiency of the proposed FPGA architecture on an image search problem, finding the darkest pixel of a grey image. The experimental results show that the proposed approach achieves significant speedup compared to the other software versions of the BB-BC algorithm and converges much faster than a typical GA algorithm making it an ideal solution for real-time embedded applications.",NO
2-s2.0-85091595539,10.2200/S01036ED1V01Y202007CSL012,,,Creating autonomous vehicle systems,ar,Article,Liu S.,,,,,,,,,2020-09-09,9 September 2020,Synthesis Lectures on Computer Science,19321228,5000158717,19321686,Book Series,8,2,,1-242,,,5,0,,,,"This book is one of the first technical overviews of autonomous vehicles written for a general computing and engineering audience. The authors share their practical experiences designing autonomous vehicle systems. These systems are complex, consisting of three major subsystems: (1) algorithms for localization, perception, and planning and control; (2) client systems, such as the robotics operating system and hardware platform; and (3) the cloud platform, which includes data storage, simulation, high-definition (HD) mapping, and deep learning model training. The algorithm subsystem extracts meaningful information from sensor raw data to understand its environment and make decisions as to its future actions. The client subsystem integrates these algorithms to meet real-time and reliability requirements. The cloud platform provides offline computing and storage capabilities for autonomous vehicles. Using the cloud platform, new algorithms can be tested so as to update the HD map—in addition to training better recognition, tracking, and decision models.

Since the first edition of this book was released, many universities have adopted it in their autonomous driving classes, and the authors received many helpful comments and feedback from readers. Based on this, the second edition was improved by extending and rewriting multiple chapters and adding two commercial test case studies. In addition, a new section entitled “Teaching and Learning from this Book” was added to help instructors better utilize this book in their classes. The second edition captures the latest advances in autonomous driving and that it also presents usable real-world case studies to help readers better understand how to utilize their lessons in commercial autonomous driving projects.

This book should be useful to students, researchers, and practitioners alike. Whether you are an undergraduate or a graduate student interested in autonomous driving, you will find herein a comprehensive overview of the whole autonomous vehicle technology stack. If you are an autonomous driving practitioner, the many practical techniques introduced in this book will be of interest to you. Researchers will also find extensive references for an effective, deeper exploration of the various technologies.

Table of Contents: Preface to the Second Edition / Teaching and Learning from This Book / Introduction to Autonomous Driving / Autonomous Vehicle Localization / Perception in Autonomous Driving / Deep Learning in Autonomous Driving Perception / Prediction and Routing / Decision, Planning, and Control / Reinforcement Learning-Based Planning and Control / Client Systems for Autonomous Driving / Cloud Platform for Autonomous Driving / Autonomous Last-Mile Delivery Vehicles in Complex Traffic Environments / PerceptIn's Autonomous Vehicles Lite / Author Biographies",NO
2-s2.0-85095859054,10.15866/ireaco.v13i5.19089,,,Designing and implementing a didactic module of artificial vision for the selection of objects according to colors and morphological characteristics,ar,Article,Ocaña W.S.,,Universidad de las Fuerzas Armadas ESPE,Sangolqui,Ecuador,,,,,2020-09-01,September 2020,International Review of Automatic Control,19746059,21100228305,25332260,Journal,13,5,,244-254,,,0,0,,,,"This present research describes the design and the implementation of a didactic module for the selection of objects, according to their colors and morphological characteristics using a robotic arm, through artificial vision, as well as the visualization of the process in a virtual environment. The project is equipped with a robotic arm that serves to select, capture, and locate nylon elements of different colors and shapes, placing them in different classification trays; it will also be visualized on a graphic interface through a monitor. Elements such as the Arduino data processing card, a 1920×1080 pixel HD camera to improve the visualization of the shapes and color of the element and a conveyor belt that will allow the movement of the elements have been used. Using the images obtained by the camera and processed in binary form in the Arduino, an automated control of the robotic arm that allows controlled movement and proper positioning in the corresponding sorting tray is obtained. The processing of the images uses a specific programming to make the edge detection and to obtain the points of the image that belongs to the border of the desired figure. Due to the imperfections of the image a process of filters in the image is followed as the scaling, the dilation of the image that allows suppressing the background of the figure and finally the erosion that helps to join or to obtain an outline to the desired shape. With the design and the construction of this didactic module of artificial vision, students and teaching staff will be provided with a better visualization of an industrial environment in automated inspection and quality control tasks, with the aim of improving the repetitiveness and precision obtained in a manual inspection process.
Copyright © 2020 Praise Worthy Prize - All rights reserved.",NO
2-s2.0-85092128779,10.1109/JIOT.2020.3004339,,,AirScope: Mobile Robots-Assisted Cooperative Indoor Air Quality Sensing by Distributed Deep Reinforcement Learning,ar,Article,Hu Z.,,Peking University,Beijing,China,,,,,2020-09-01,September 2020,IEEE Internet of Things Journal,,21100338350,23274662,Journal,7,9,9123492,9189-9200,,,1,0,,,,"Indoor air pollution has become a growing health risk, but it is challenging to provide low-cost air quality monitoring for the indoor environment. In this article, we present “AirScope,” a mobile sensing system that employs cooperative robots to monitor the indoor air quality. Since the wireless coverage can be incomplete in some indoor areas, AirScope allows the robots to defer uploading the data to the central server by utilizing their own data buffers. In order to guarantee the timeliness of the data in the server, AirScope aims to minimize the average data latency by properly planning the routes of the robots. Such a route planning strategy has to be implemented in a distributed way since the robots that are out of wireless coverage can only make plans on their own. In addition, the cooperation of the robots is also necessary because the aggregation of the robots in a small area increases the average data latency of the other unattended areas. To solve this distributed and cooperative routing planning problem, we propose a solution based on distributed deep Q-learning (DDQL). We evaluate the system performance by simulations and real-world experiments. The results show that AirScope is effective to reduce data latency, where the proposed DDQL is 8% better than the greedy algorithm and 24% better than the random strategy.",NO
2-s2.0-85091794442,10.1049/trit.2019.0094,,,Learning synergies based in-hand manipulation with reward shaping,ar,Article,Deng Z.,,Universität Hamburg,Hamburg,Germany,,,,,2020-09-01,1 September 2020,CAAI Transactions on Intelligence Technology,24686557,21100970248,24682322,Journal,5,3,,141-149,,,1,1,,,,"In-hand manipulation is a fundamental ability for multi-fingered robotic hands that interact with their environments. Owing to the high dimensionality of robotic hands and intermittent contact dynamics, effectively programming a robotic hand for in-hand manipulations is still a challenging problem. To address this challenge, this work employs deep reinforcement learning (DRL) algorithm to learn in-hand manipulations for multi-fingered robotic hands. A reward-shaping method is proposed to assist the learning of in-hand manipulation. The synergy of robotic hand postures is analysed to build a low-dimensional hand posture space. Two additional rewards are designed based on both the analysis of hand synergies and its learning history. The two additional rewards cooperating with an extrinsic reward are used to assist the in-hand manipulation learning. Three value functions are trained jointly with respect to their reward functions. Then they cooperate to optimise a control policy for in-hand manipulation. The reward shaping not only improves the exploration efficiency of the DRL algorithm but also provides a way to incorporate domain knowledge. The performance of the proposed learning method is evaluated with object rotation tasks. Experimental results demonstrated that the proposed learning method enables multi-fingered robotic hands to learn in-hand manipulation effectively.",NO
2-s2.0-85086709272,10.1016/j.asoc.2020.106488,S1568494620304270,,Neuro-genetic programming for multigenre classification of music content,ar,Article,Campobello G.,,Università degli Studi di Messina,Messina,Italy,,,,,2020-09-01,September 2020,Applied Soft Computing Journal,15684946,18136,,Journal,94,,106488,,,,5,0,,,,"Highlights

•

Music-genre recognition.

•

Fuzzy-like modeling.

•

Low-complexity analytical models.

•

Reduced number of input features (feature selection).

•

Applied genetic programming.
A machine learning approach based on hybridization of genetic programming and neural networks is used to derive mathematical models for music genre classification. We design three multi-label classifiers with different trade-offs between complexity and accuracy, which are able to identify the degree of belonging of music content to ten different music genres. Our approach is innovative as it entirely relies on simple analytical functions and a reduced number of features. Resulting classifiers have an extremely low computational complexity and are suitable to be easily integrated in low-cost embedded systems for real-time applications. The GTZAN dataset is used for model training and to evaluate the accuracy of the proposed classifiers. Despite of the reduced number of features used in our approach, the accuracy of our models is found to be similar to that of more complex music genre classification tools previously published in the literature.",NO
2-s2.0-85085730446,10.1016/j.asoc.2020.106443,S1568494620303835,,A parallel compact cuckoo search algorithm for three-dimensional path planning,ar,Article,Song P.C.,,Shandong University of Science and Technology,Qingdao,China,,,,,2020-09-01,September 2020,Applied Soft Computing Journal,15684946,18136,,Journal,94,,106443,,,,27,0,,,,"Highlights

•

Compact Cuckoo Search Algorithm.

•

Parallel Cuckoo Search Algorithm.

•

Algorithm that reduce the computation time and the memory.

•

Parallel Compact Cuckoo Search Algorithm.

•

Optimization methods for 3D path planning.
The three-dimensional (3D) path planning of unmanned robots focuses on avoiding collisions with obstacles and finding an optimized path to the target location in a complex three-dimensional environment. An improved cuckoo search algorithm based on compact and parallel techniques for three-dimensional path planning problems is proposed. This paper implements the compact cuckoo search algorithm, and then, a new parallel communication strategy is proposed. The compact scheme can effectively save the memory of the unmanned robot. The parallel scheme can increase the accuracy and achieve faster convergence. The proposed algorithm is tested on several selected functions and three-dimensional path planning. Results compared with other methods show that the proposed algorithm can provide more competitive results and achieve more efficient execution.",NO
2-s2.0-85092378813,10.7641/CTA.2020.90622,,,Rapidly-exploring random tree algorithm for path re-planning based on reinforcement learning under the peculiar environment,ar,Article,Zou Q.J.,,Dalian University;National Defense Science and Technology Research Center for Unmanned Systems,Dalian;Changsha,China;China,,,,,2020-08-01,1 August 2020,Kongzhi Lilun Yu Yingyong/Control Theory and Applications,10008152,12585,,Journal,37,8,,1737-1748,,,2,0,,,,,NO
2-s2.0-85085364733,10.1007/s10956-020-09831-x,,,TechCheck: Development and Validation of an Unplugged Assessment of Computational Thinking in Early Childhood Education,ar,Article,Relkin E.,,Tufts University,Medford,United States,,,,,2020-08-01,1 August 2020,Journal of Science Education and Technology,10590145,23646,15731839,Journal,29,4,,482-498,,,10,0,,,,"There is a need for developmentally appropriate Computational Thinking (CT) assessments that can be implemented in early childhood classrooms. We developed a new instrument called TechCheck for assessing CT skills in young children that does not require prior knowledge of computer programming. TechCheck is based on developmentally appropriate CT concepts and uses a multiple-choice “unplugged” format that allows it to be administered to whole classes or online settings in under 15 min. This design allows assessment of a broad range of abilities and avoids conflating coding with CT skills. We validated the instrument in a cohort of 5–9-year-old students (N = 768) participating in a research study involving a robotics coding curriculum. TechCheck showed good reliability and validity according to measures of classical test theory and item response theory. Discrimination between skill levels was adequate. Difficulty was suitable for first graders and low for second graders. The instrument showed differences in performance related to race/ethnicity. TechCheck scores correlated moderately with a previously validated CT assessment tool (TACTIC-KIBO). Overall, TechCheck has good psychometric properties, is easy to administer and score, and discriminates between children of different CT abilities. Implications, limitations, and directions for future work are discussed.",NO
2-s2.0-85084643991,10.1007/s10956-020-09833-9,,,Mining Effective Learning Behaviors in a Web-Based Inquiry Science Environment,ar,Article,Chen C.M.,,National Chengchi University,Taipei,Taiwan,,,,,2020-08-01,1 August 2020,Journal of Science Education and Technology,10590145,23646,15731839,Journal,29,4,,519-535,,,3,0,,,,"Analyzing learners’ learning behaviors helps teachers understand how learning behaviors of learners influence learning performance. To determine which learning behaviors influence learners’ science-based inquiry learning performance, this work develops an xAPI (Experience Application Programming Interface)-based learning record store module embedded in a Collaborative Web-based Inquiry Science Environment (CWISE) to record detailed data about students’ learning processes. This work discusses whether the significant correlation and cause-effect relationship among science inquiry competence, learning time, and learning performance exist, and examines whether remarkable shifts and differences in the learning behaviors of learners with different learning performances and inquiry competences exist by using sequential pattern mining and lag sequential analysis. The results demonstrate that inquire ability, total learning time in the designed inquiry learning course, and learning time in an inquiry buoyancy simulation experiment are positively correlated with learning performance and can predict learning performance, and the learning time in the inquiry buoyancy simulation experiment appears to be the most significant predictor. The results of lag sequential analyses indicate that learners with high learning performance and high inquiry competence re-adjust hypotheses after performing an inquiry buoyancy simulation experiment, while learners with low learning performance and low inquiry competence lack this critical inquiry learning behavior. This study presents a systematic analysis method to insight the effective learning behaviors in a web-based inquiry learning environment based on mining students’ learning processes, thus providing potential benefits in guiding learners to adjust their learning behaviors and strategies.",NO
2-s2.0-85083184469,10.1016/j.apm.2020.03.004,S0307904X2030130X,,Trajectory planning based on non-convex global optimization for serial manipulators,ar,Article,Zhang S.,,Beihang University,Beijing,China,,,,,2020-08-01,August 2020,Applied Mathematical Modelling,0307904X,28065,,Journal,84,,,89-105,,,5,0,,,,"Highlights

•

The trajectory planning problem is modelled with non-convex optimization.

•

The accurate global optimum can be obtained by non-convex model transformation.

•

The feasible success rate of the optimization solver is improved to nearly 100%.

•

The calculation time of local optimization is reduced by about 50%.

•

The methodology is verified in a 250 Hz real-time system with a 6-DOF serial robot.
To perform specific tasks in dynamic environments, robots are required to rapidly update trajectories according to changing factors. A continuous trajectory planning methodology for serial manipulators based on non-convex global optimization is presented in this paper. First, a kinematic trajectory planning model based on non-convex optimization is constructed to balance motion rapidity and safety. Then, a model transformation method for the non-convex optimization model is presented. In this way, the accurate global solution can be obtained with an iterative solver starting from arbitrary initializations, which can greatly improve the computational accuracy and efficiency. Furthermore, an efficient initialization method for the iterative solver based on multivariable-multiple regression is presented, which further speeds up the solution process. The results show that trajectory planning efficiency is significantly enhanced by model transformation and initialization improvement for the iterative solver. Consequently, real-time continuous trajectory planning for serial manipulators with many degrees of freedom can be achieved, which lays a basis for performing dynamic tasks in complex environments.",NO
2-s2.0-85081335867,10.1007/s12555-019-0497-3,,,Human-swarm Interactions for Formation Control Using Interpreters,ar,Article,Suresh A.,,"University of California, San Diego",San Diego,United States,,,,,2020-08-01,1 August 2020,"International Journal of Control, Automation and Systems",15986446,25479,20054092,Journal,18,8,,2131-2144,,,2,0,,,,"In this work, we develop a novel Human-Swarm Interaction (HSI) framework for formation control using the notion of an interpreter, enabling the user to control a robotic swarm's shape and formation using abstraction. The user conveys their intended commands by drawing shapes through arm gestures and motions which are recorded by an off-the-shelf wearable device. We propose a novel interpreter system, which acts as an intermediary between the user and the swarm to simplify the roles of both. The interpreter takes in high level input in the form of shapes drawn by the user, and translates it into swarm control commands by planning in the shape space using novel shape morphing dynamics (SMD), which is also used for user feedback. The proposed interpreter employs machine learning, estimation and optimal control techniques to translate the users intention into swarm control parameters. The dynamics of the swarm are realized by means of a novel decentralized formation controller based on distributed linear iterations and dynamic average consensus. Theoretical guarantees of convergence along with convergence rate of the proposed swarm controller are given. The resulting shape morphing dynamics are illustrated and discussed through simulations. The entire framework is demonstrated theoretically as well as experimentally in a 2D environment, with a human controlling a swarm of simulated robots in real time with the help of a Graphical User Environemnt (GUI).",NO
2-s2.0-85081315440,10.1109/TRO.2020.2974094,,,Learning-Based Proxy Collision Detection for Robot Motion Planning Applications,ar,Article,Das N.,,The Electrical and Computer Engineering Department,San Diego,United States,,,,,2020-08-01,August 2020,IEEE Transactions on Robotics,15523098,95101,19410468,Journal,36,4,9023003,1096-1114,,,10,0,,,,"This article demonstrates that collision detection-intensive applications such as robotic motion planning may be accelerated by performing collision checks with a machine learning model. We propose Fastron, a learning-based algorithm, to model a robot's configuration space to be used as a proxy collision detector in place of standard geometric collision checkers. We demonstrate that leveraging the proxy collision detector results in up to an order of magnitude faster performance in robot simulation and planning than state-of-the-art collision detection libraries. Our results show that Fastron learns a model more than 100 times faster than a competing C-space modeling approach, while also providing theoretical guarantees of learning convergence. Using the open motion planning libraries (OMPLs), we were able to generate initial motion plans across all experiments with varying robot and environment complexities and workspace obstacle locations. With Fastron, we can repeatedly generate new motion plans at a 56 Hz rate, showing its application toward autonomous surgical assistance task in shared environments with human-controlled manipulators. All performance gains were achieved despite using only CPU-based calculations, suggesting further computational gains with a GPU approach that can parallelize tensor algebra. Code is available online.",NO
2-s2.0-85089726065,10.1145/3412821.3412829,,,Quatros: A Preemptive Multithreaded Embedded OS for Education,ar,Article,Sun W.F.,,National Tsing Hua University,Hsinchu,Taiwan,,,,,2020-07-27,27 July 2020,ACM SIGBED Review,,21100900336,15513688,Journal,17,1,,49-55,,,0,0,,,,"Hands-on experience is crucial to truly understanding the principles of operating systems (OS). This paper describes a preemptive, multithreaded embedded OS assigned as a project in a junior-level OS course. It targets the popular 8051 instruction set architecture (ISA) and can run with as little as 128 bytes of RAM and 1 KB of program memory with preemption and synchronization primitives such as semaphores. It is written in C and assembly and compiled using the open-source Small Device C Compiler (SDCC). It runs on the free EdSim51 simulator, which simulates common peripherals such as LCD, keypads, 7-segment LEDs, ADC, and UART all in high fidelity. This course project has received positive feedback from students who took the course.",NO
2-s2.0-85088016295,10.3390/s20143871,,32664434,A novel statistical method for scene classification based on multi-object categorization and logistic regression,ar,Article,Ahmed A.,,Air University Islamabad,Islamabad,Pakistan,,,,,2020-07-02,2 July 2020,Sensors (Switzerland),14248220,130124,,Journal,20,14,3871,1-20,,,22,1,,,,"In recent years, interest in scene classification of different indoor-outdoor scene images has increased due to major developments in visual sensor techniques. Scene classification has been demonstrated to be an efficient method for environmental observations but it is a challenging task considering the complexity of multiple objects in scenery images. These images include a combination of different properties and objects i.e., (color, text, and regions) and they are classified on the basis of optimal features. In this paper, an efficient multiclass objects categorization method is proposed for the indoor-outdoor scene classification of scenery images using benchmark datasets. We illustrate two improved methods, fuzzy c-mean and mean shift algorithms, which infer multiple object segmentation in complex images. Multiple object categorization is achieved through multiple kernel learning (MKL), which considers local descriptors and signatures of regions. The relations between multiple objects are then examined by intersection over union algorithm. Finally, scene classification is achieved by using Multi-class Logistic Regression (McLR). Experimental evaluation demonstrated that our scene classification method is superior compared to other conventional methods, especially when dealing with complex images. Our system should be applicable in various domains such as drone targeting, autonomous driving, Global positioning systems, robotics and tourist guide applications. View Full-Text",NO
2-s2.0-85089838282,10.1177/1729881420936851,,,Continuous shared control in prosthetic hand grasp tasks by Deep Deterministic Policy Gradient with Hindsight Experience Replay,ar,Article,Gao Z.,,Huazhong University of Science and Technology,Wuhan,China,,,,,2020-07-01,1 July 2020,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,17,4,,,,,0,1,,,,"Grasp using a prosthetic hand in real life can be a difficult task. The amputee users are often capable of planning the reaching trajectory and hand grasp location selection, however, failed in precise finger movements, such as adapting the fingers to the surface of the object without excessive force. It is much efficient to leave that part to the machine autonomy. In order to combine the intention and planning ability of users with robotic control, the shared control is introduced in which users’ inputs and robot control methods are combined to achieve a goal. The shared control problem can be formulated as a Partially Observable Markov Decision Process. To find the optimal control policy, we adopt an adaptive dynamic programming and reinforcement learning-based control algorithm-Deep Deterministic Policy Gradient combined with Hindsight Experience Replay. We proposed the algorithm with a prediction layer using the reparameterization technique. The system was tested in a modified simulation environment for the ability to follow the user’s intention and keep the contact force in boundary for safety.",NO
2-s2.0-85087047848,10.1007/s10514-020-09922-z,,,Exploration of the applicability of probabilistic inference for learning control in underactuated autonomous underwater vehicles,ar,Article,Ariza Ramirez W.,,Australian Maritime College,Launceston,Australia,,,,,2020-07-01,1 July 2020,Autonomous Robots,09295593,18016,15737527,Journal,44,6,,1121-1134,,,2,0,,,,"Underwater vehicles are employed in the exploration of dynamic environments where tuning of a specific controller for each task would be time-consuming and unreliable as the controller depends on calculated mathematical coefficients in idealised conditions. For such a case, learning task from experience can be a useful alternative. This paper explores the capability of probabilistic inference learning to control autonomous underwater vehicles that can be used for different tasks without re-programming the controller. Probabilistic inference learning uses a Gaussian process model of the real vehicle to learn the correct policy with a small number of real field experiments. The use of probabilistic reinforcement learning looks for a simple implementation of controllers without the burden of coefficients calculation, controller tuning or system identification. A series of computational simulations were employed to test the applicability of model-based reinforcement learning in underwater vehicles. Three simulation scenarios were evaluated: waypoint tracking, depth control and 3D path tracking control. The 3D path tracking is done by coupling together a line-of-sight law with probabilistic inference for learning control. As a comparison study LOS-PILCO algorithm can perform better than a robust LOS-PID. The results show that probabilistic model-based reinforcement learning can be a deployable solution to motion control of underactuated AUVs as it can generate capable policies with minimum quantity of episodes.",NO
2-s2.0-85082016665,10.1016/j.future.2020.03.021,S0167739X19318758,,Smishing Detector: A security model to detect smishing through SMS content analysis and URL behavior analysis,ar,Article,Mishra S.,,Jaypee Institute of Information Technology,Noida,India,,,,,2020-07-01,July 2020,Future Generation Computer Systems,0167739X,12264,,Journal,108,,,803-815,,,10,0,,,,"Highlights

•

An efficient model titled ‘Smishing Detector’ to detect and block Smishing attacks.

•

APK Download Detector module to verify the URL in SMS.

•

Reduces false-positive results by using efficient techniques.

•

A user interface to skip the steps involved in detecting the Smishing SMS.

•

A prototype of the system is developed for real-time application.
Smartphone’s popularity and their constant connectivity to the World Wide Web have made these devices vulnerable to phishing and smishing attacks. Phishing is a practice of sending malicious emails to users. Smishing is a combined form of SMS and Phishing in which invaders send SMS containing malicious content to the victim. This content sometimes includes links which redirect the user to websites containing malicious applications and user interfaces. Researchers have proposed various methods in past years to detect smishing but still, we lack a method that significantly avoids false-positive results i.e. falsely categorizing a message as malicious when it is genuine. Hence, we have proposed a model called ’Smishing Detector’ to identify smishing messages while reducing false-positive results at every possible step. The proposed method consists of four modules, namely, SMS Content Analyzer, URL Filter, Source Code Analyzer and Apk Download Detector. SMS Content Analyzer analyzes the text message contents. Naive Bayes Classification Algorithm is used to identify the malicious contents and keywords present in the text message. URL Filter inspects the URL to identify malicious features. Source Code Analyzer examines the source code of the website to identify the harmful code embedded in it. Form tag and URL domain present in the source code are also inspected in this module. APK Download Detector identifies whether any malicious file is downloaded while invoking the URL. User consent taken while downloading the file is also inspected in this module. Finally, we have developed a prototype of the proposed system which has been validated with experiments on SMS datasets. In this paper, we have demonstrated the results of each module separately and also we have demonstrated the final results. The results of the experiments show an overall accuracy of 96.29%. We have compared this model with other models proposed by various researchers and we have found that this model covers more security aspects as compared to other models.",NO
2-s2.0-85080990784,10.1007/s11370-020-00316-9,,,Motion planning in semistructured environments with teaching roadmaps,ar,Article,Qiu Q.,,Shanghai Jiao Tong University,Shanghai,China,,,,,2020-07-01,1 July 2020,Intelligent Service Robotics,18612776,9500154152,18612784,Journal,13,3,,331-342,,,0,0,,,,"Motion planning is a hot topic in robotics, and the sampling-based algorithms have gained their popularities in research areas. However, these methods are still not suitable for real-world motion planning problems, because it is computationally expensive to completely explore the high-dimensional configuration space (C-space) of robots. Inspired by the related works on learning from demonstration, we propose a novel motion planning method named teaching roadmaps, which can take advantage of the optimal teaching data and quickly find a new path in the similar scenarios. The theoretical analysis and our experiments indicated that our approach is probabilistically complete, and it can find a feasible path faster than other sampling-based methods in similar environments.",NO
2-s2.0-85079443083,10.1007/s10514-020-09903-2,,,An informative path planning framework for UAV-based terrain monitoring,ar,Article,Popović M.,,Imperial College London,London,United Kingdom,,,,,2020-07-01,1 July 2020,Autonomous Robots,09295593,18016,15737527,Journal,44,6,,889-911,,,12,1,,,,"Unmanned aerial vehicles represent a new frontier in a wide range of monitoring and research applications. To fully leverage their potential, a key challenge is planning missions for efficient data acquisition in complex environments. To address this issue, this article introduces a general informative path planning framework for monitoring scenarios using an aerial robot, focusing on problems in which the value of sensor information is unevenly distributed in a target area and unknown a priori. The approach is capable of learning and focusing on regions of interest via adaptation to map either discrete or continuous variables on the terrain using variable-resolution data received from probabilistic sensors. During a mission, the terrain maps built online are used to plan information-rich trajectories in continuous 3-D space by optimizing initial solutions obtained by a coarse grid search. Extensive simulations show that our approach is more efficient than existing methods. We also demonstrate its real-time application on a photorealistic mapping scenario using a publicly available dataset and a proof of concept for an agricultural monitoring task.",NO
2-s2.0-85076000870,10.1007/s10994-019-05862-7,,,Learning higher-order logic programs,ar,Article,Cropper A.,,University of Oxford,Oxford,United Kingdom,,,,,2020-07-01,1 July 2020,Machine Learning,08856125,24775,15730565,Journal,109,7,,1289-1322,,,4,1,,,,"A key feature of inductive logic programming is its ability to learn first-order programs, which are intrinsically more expressive than propositional programs. In this paper, we introduce techniques to learn higher-order programs. Specifically, we extend meta-interpretive learning (MIL) to support learning higher-order programs by allowing for higher-order definitions to be used as background knowledge. Our theoretical results show that learning higher-order programs, rather than first-order programs, can reduce the textual complexity required to express programs, which in turn reduces the size of the hypothesis space and sample complexity. We implement our idea in two new MIL systems: the Prolog system \text {Metagol}_{ho} and the ASP system \text {HEXMIL}_{ho}. Both systems support learning higher-order programs and higher-order predicate invention, such as inventing functions for map/3 and conditions for filter/3. We conduct experiments on four domains (robot strategies, chess playing, list transformations, and string decryption) that compare learning first-order and higher-order programs. Our experimental results support our theoretical claims and show that, compared to learning first-order programs, learning higher-order programs can significantly improve predictive accuracies and reduce learning times.",NO
2-s2.0-85072981373,10.1109/JAS.2019.1911732,,,Path planning for intelligent robots based on deep Q-learning with experience replay and heuristic knowledge,ar,Article,Jiang L.,,Zhejiang Sci-Tech University,Hangzhou,China,,,,,2020-07-01,July 2020,IEEE/CAA Journal of Automatica Sinica,23299266,21100367773,23299274,Journal,7,4,8853432,1179-1189,,,10,0,,,,"Path planning and obstacle avoidance are two challenging problems in the study of intelligent robots. In this paper, we develop a new method to alleviate these problems based on deep Q-learning with experience replay and heuristic knowledge. In this method, a neural network has been used to resolve the “curse of dimensionality” issue of the Q-table in reinforcement learning. When a robot is walking in an unknown environment, it collects experience data which is used for training a neural network; such a process is called experience replay. Heuristic knowledge helps the robot avoid blind exploration and provides more effective data for training the neural network. The simulation results show that in comparison with the existing methods, our method can converge to an optimal action strategy with less time and can explore a path in an unknown environment with fewer steps and larger average reward.",NO
2-s2.0-85091286885,10.1145/3386329,,,History of Logo,ar,Article,Solomon C.,,Cynthia Solomon Consulting,Somerville,United States,,,,,2020-06-12,12 June 2020,Proceedings of the ACM on Programming Languages,,21101020042,24751421,Journal,4,HOPL,79,,,,7,1,,,,"Logo is more than a programming language. It is a learning environment where children explore mathematical ideas and create projects of their own design. Logo, the first computer language explicitly designed for children, was invented by Seymour Papert, Wallace Feurzeig, Daniel Bobrow, and Cynthia Solomon in 1966 at Bolt, Beranek and Newman, Inc. (BBN).

Logo’s design drew upon two theoretical frameworks: Jean Piaget’s constructivism and Marvin Minsky’s artificial intelligence research at MIT. One of Logo’s foundational ideas was that children should have a powerful programming environment. Early Lisp served as a model with its symbolic computation, recursive functions, operations on linked lists, and dynamic scoping of variables.

Logo became a symbol for change in elementary mathematics education and in the nature of school itself. The search for harnessing the computer’s potential to provide new ways of teaching and learning became a central focus and guiding principle in the Logo language development as it encompassed a widening scope that included natural language, music, graphics, animation, story telling, turtle geometry, robots, and other physical devices.",SI
2-s2.0-85091181039,10.1609/aimag.v41i2.5300,,,Integrated artificial intelligence systems,ar,Article,Brachman R.,,Jacobs Technion-Cornell Institute,New York,United States,,,,,2020-06-01,June 2020,AI Magazine,07384602,23629,,Journal,41,2,,66-82,,,0,0,,,,"From Shakey the Robot to self-driving cars, from the personal computer to personal assistants on our phones, the Defense Advanced Research Projects Agency (DARPA) has led the development of integrated artificial intelligence (AI) systems for more than half a century. From the earliest days of AI, it was apparent that a robust, generally intelligent system should include a complete set of capabilities: perception, memory, reasoning, learning, planning, and action; and when DARPA initiated AI research in the 1960s, ambitious projects such as Shakey the Robot went after the complete package. As DARPA realized the challenges, they backed away from the ultimate goal of integrated AI and tried to make progress on the individual problems of image understanding, speech and language understanding, knowledge representation and reasoning, planning and decision aids, machine learning, and robotic manipulation. Yet, even as researchers struggled to make progress in these subdisciplines, DARPA periodically resurrected the challenge of integrated intelligent systems and pushed the community to try again. In the 1980s, DARPA’s Strategic Computing Initiative took on challenges of integrated AI projects such as the Autonomous Land Vehicle and the Pilot’s Associate. These did not succeed, but instead set the stage for the several decades of more siloed research that followed, until it was time to try again. In the 2000s, DARPA took on the integrated AI problem again with its Grand Challenges, which led to the first self-driving cars, and projects such as the Personalized Assistant that Learns, which produced Apple’s Siri. These efforts created complex, richly-integrated systems that represented quantum leaps ahead in machine intelligence. The integration of sophisticated capabilities in a fundamental way is the key to general intelligence. This is the story of DARPA’s persistent long-term support for this essential premise of AI",NO
2-s2.0-85086999089,10.1109/TMECH.2020.2981625,,,Using Potential Field Function with a Velocity Field Controller to Learn and Reproduce the Therapist's Assistance in Robot-Assisted Rehabilitation,ar,Article,Najafi M.,,University of Alberta,Edmonton,Canada,,,,,2020-06-01,June 2020,IEEE/ASME Transactions on Mechatronics,10834435,19113,1941014X,Journal,25,3,9040645,1622-1633,,,1,0,,,,"Rehabilitative and assistive practices usually elicit intense and repetitive exercises. Thus, there has been an increasing interest in robotic systems as they are robust and cost-effective in comparison to conventional physical motor-therapy with a therapist. These robots have applications in therapeutic and in-home environments, where there is a necessity for a user-friendly procedure to program the robots for a specific task easily. Our group has suggested robot learning from demonstration (LfD) as an intuitive procedure to program robots via short-term physical interaction in rehabilitation and assistive applications. In this article, a therapist assists a patient, and cooperatively performs a task on a robotic manipulator. Then, using a nonparametric potential field function, the therapist's motion, and interaction force (assistance/resistance) is modeled time-independently via a convex optimization algorithm. Next, in the therapist's absence, the robot provides the patient with the same level of interaction force provided by the therapist along the trajectory. A velocity field controller is also designed to compensate and regulate the patient's deviation from the velocity observed in the demonstration phase. Finally, the efficacy, advantages, and stability of the proposed framework are evaluated in three different experimental scenarios involving spring arrays and an individual with cerebral palsy (CP).",NO
2-s2.0-85086760300,10.3390/s20123515,,32575907,A multitasking-oriented robot arm motion planning scheme based on deep reinforcement learning and twin synchro-control,ar,Article,Liu C.,,Beijing Institute of Technology;Beijing Advanced Innovation Center for Intelligent Robots and Systems,Beijing;Beijing,China;China,,,,,2020-06-01,June 2020,Sensors (Switzerland),14248220,130124,,Journal,20,12,3515,1-35,,,6,1,,,,"Humanoid robots are equipped with humanoid arms to make them more acceptable to the general public. Humanoid robots are a great challenge in robotics. The concept of digital twin technology complies with the guiding ideology of not only Industry 4.0, but also Made in China 2025. This paper proposes a scheme that combines deep reinforcement learning (DRL) with digital twin technology for controlling humanoid robot arms. For rapid and stable motion planning for humanoid robots, multitasking-oriented training using the twin synchro-control (TSC) scheme with DRL is proposed. For switching between tasks, the robot arm training must be quick and diverse. In this work, an approach for obtaining a priori knowledge as input to DRL is developed and verified using simulations. Two simple examples are developed in a simulation environment. We developed a data acquisition system to generate angle data efficiently and automatically. These data are used to improve the reward function of the deep deterministic policy gradient (DDPG) and quickly train the robot for a task. The approach is applied to a model of the humanoid robot BHR-6, a humanoid robot with multiple-motion mode and a sophisticated mechanical structure. Using the policies trained in the simulations, the humanoid robot can perform tasks that are not possible to train with existing methods. The training is fast and allows the robot to perform multiple tasks. Our approach utilizes human joint angle data collected by the data acquisition system to solve the problem of a sparse reward in DRL for two simple tasks. A comparison with simulation results for controllers trained using the vanilla DDPG show that the designed controller developed using the DDPG with the TSC scheme have great advantages in terms of learning stability and convergence speed. View Full-Text",NO
2-s2.0-85086432605,10.3390/electronics9060972,,,Two open solutions for industrial robot control: The case of puma 560,ar,Article,Jokić D.,,International Burch University,Sarajevo,Bosnia and Herzegovina,,,,,2020-06-01,June 2020,Electronics (Switzerland),,21100829272,20799292,Journal,9,6,972,1-15,,,5,1,,,,"In this paper we present two different, software and reconfigurable hardware, open architecture approaches to the PUMA 560 robot controller implementation, fully document them and provide the full design specification, software code and hardware description. Such solutions are necessary in today’s robotics and industry: deprecated old control units render robotic installations useless and allow no upgrades, advancements, or innovation in an inherently innovative ecosystem. For the sake of simplicity, just the first robot axis is considered. The first approach described is a PC solution with data acquisition I/O board (Humusoft MF634). This board is supported with Matlab Real-Time Windows Toolbox for real-time applications and thus whole controller was designed in Matlab environment. The second approach is a robot controller developed on field programmable gate arrays (FPGA) board. The complexity of FPGA design can be overcome by using a third party software package, such as self-developed Matlab FPGA Real Time Toolbox. In both cases, parameters of motion controller are calculated by using simulation of the PUMA 560 robot first axis motion. Simulations were conducted in Matlab/Simulink using Robotics Toolbox. View Full-Text",NO
2-s2.0-85086234229,10.1109/JXCDC.2020.2999581,,,ACortex: An Energy-Efficient Multipurpose Mixed-Signal Inference Accelerator,ar,Article,Bavandpour M.,,"University of California, Santa Barbara",Santa Barbara,United States,,,,,2020-06-01,June 2020,IEEE Journal on Exploratory Solid-State Computational Devices and Circuits,,21100905985,23299231,Journal,6,1,9107115,98-106,,,2,1,,,,"We introduce “aCortex,” an extremely energy-efficient, fast, compact, and versatile neuromorphic processor architecture suitable for the acceleration of a wide range of neural network inference models. The most important feature of our processor is a configurable mixed-signal computing array of vector-by-matrix multiplier (VMM) blocks utilizing embedded nonvolatile memory arrays for storing weight matrices. Analog peripheral circuitry for data conversion and high-voltage programming are shared among a large array of VMM blocks to facilitate compact and energy-efficient analog-domain VMM operation of different types of neural network layers. Other unique features of aCortex include configurable chain of buffers and data buses, simple and efficient instruction set architecture and its corresponding multiagent controller, programmable quantization range, and a customized refresh-free embedded dynamic random access memory. The energy-optimal aCortex with 4-bit analog computing precision was designed in a 55-nm process with embedded NOR flash memory. Its physical performance was evaluated using experimental data from testing individual circuit elements and physical layout of key components for several common benchmarks, namely, Inception-v1 and ResNet-152, two state-of-the-art deep feedforward networks for image classification, and GNTM, Google's deep recurrent network for language translation. The system-level simulation results for these benchmarks show the energy efficiency of 97, 106, and 336 TOp/J, respectively, combined with up to 15 TOp/s computing throughput and 0.27-MB/mm 2 storage efficiency. Such estimated performance results compare favorably with those of previously reported mixed-signal accelerators based on much less mature aggressively scaled resistive switching memories.",NO
2-s2.0-85085904596,10.1109/TNNLS.2019.2927869,,31398138,Deep Reinforcement Learning-Based Automatic Exploration for Navigation in Unknown Environment,ar,Article,Li H.,,Chinese Academy of Sciences,Beijing,China,,,,,2020-06-01,June 2020,IEEE Transactions on Neural Networks and Learning Systems,2162237X,21100235616,21622388,Journal,31,6,8789673,2064-2076,,,21,0,,,,"This paper investigates the automatic exploration problem under the unknown environment, which is the key point of applying the robotic system to some social tasks. The solution to this problem via stacking decision rules is impossible to cover various environments and sensor properties. Learning-based control methods are adaptive for these scenarios. However, these methods are damaged by low learning efficiency and awkward transferability from simulation to reality. In this paper, we construct a general exploration framework via decomposing the exploration process into the decision, planning, and mapping modules, which increases the modularity of the robotic system. Based on this framework, we propose a deep reinforcement learning-based decision algorithm that uses a deep neural network to learning exploration strategy from the partial map. The results show that this proposed algorithm has better learning efficiency and adaptability for unknown environments. In addition, we conduct the experiments on the physical robot, and the results suggest that the learned policy can be well transferred from simulation to the real robot.",NO
2-s2.0-85085272330,10.1016/j.cola.2020.100970,S2590118420300307,,"Visual Programming Environments for End-User Development of intelligent and social robots, a systematic review",ar,Article,Coronado E.,,Tokyo University of Agriculture and Technology,Fuchu,Japan,,,,,2020-06-01,June 2020,Journal of Computer Languages,26659182,21100904890,25901184,Journal,58,,100970,,,,17,0,,,,"Robots are becoming interactive and robust enough to be adopted outside laboratories and in industrial scenarios as well as interacting with humans in social activities. However, the design of engaging robot-based applications requires the availability of usable, flexible and accessible development frameworks, which can be adopted and mastered by researchers and practitioners in social sciences and adult end users as a whole. This paper surveys Visual Programming Environments aimed at enabling a paradigm fostering the so-called End-User Development of applications involving robots with social capabilities. The focus of this article is on those Visual Programming Environments that are designed to support social research goals as well as to cater for professional needs of people not trained in more traditional text-based computer programming languages. This survey excludes interfaces aimed at supporting expert programmers, at allowing industrial robots to perform typical industrial tasks (such as pick and place operations), and at teaching children how to code. After having performed a systematic search, sixteen programming environments have been included in this survey. Our goal is two-fold: first, to present these software tools with their technical features and Authoring Artificial Intelligence modeling approaches, and second, to present open challenges in the development of Visual Programming Environments for end users and social researchers, which can be informative and valuable to the community. The results show that the most recent such tools are adopting distributed and Component-Based Software Engineering approaches and web technologies. However, few of them have been designed to enable the independence of end users from high-tech scribes. Moreover, findings indicate the need for (i) more objective and comparative evaluations, as well as usability and user experience studies with real end users; and (ii) validations of these tools for designing applications aimed at working “in-the-wild” rather than only in laboratories and structured settings.",SI
2-s2.0-85083435403,10.1109/MRA.2020.2977601,,,GPU-accelerated vision for robots: Improving system throughput using OpenCV and CUDA,ar,Article,Cervera E.,,Universidad Jaume I,Castellon de la Plana,Spain,,,,,2020-06-01,June 2020,IEEE Robotics and Automation Magazine,10709932,18027,1558223X,Journal,27,2,9047171,151-158,,,1,0,,,,"OpenCV is an open source computer vision and machine learning library for C/C++/Python available for Windows, Linux, macOS, and Android platforms. It contains low-level image processing functions as well as high-level algorithms such as object identification, face recognition, and action classification in videos. OpenCV has become very popular, with more than 47,000 people in its user community and 18 million downloads (see https://opencv.org/about/). Under a Berkeley Software Distribution (BSD) license, it can be used for both academic and commercial applications.",NO
2-s2.0-85083088888,10.1016/j.robot.2020.103515,S0921889019309972,,Skill transfer learning for autonomous robots and human–robot cooperation: A survey,ar,Article,Liu Y.,,South China University of Technology,Guangzhou,China,,,,,2020-06-01,June 2020,Robotics and Autonomous Systems,09218890,18079,,Journal,128,,103515,,,,10,0,,,,"Designing a robot system with reasoning and learning ability has gradually become a research focus in robotics research field. Recently, Skill Transfer Learning (STL), i.e., the ability of transferring human skills to robots, has become a research thrust for autonomous robots and human–robot cooperation. It provides the following benefits: (i) the skill transfer learning system with independent decision-making and learning ability enables the robot to learn and acquire manipulation skills in a complex and dynamic environment, which can overcome the shortages of conventional methods such as traditional programming, and greatly improve the adaptability of the robot to complex environments and (ii) human physiological signals allow us to extract motion control characteristics from physiological levels which create a rich sensory signal. In this survey, we provide an overview of the most important applications of STL by analyzing and categorizing existing works in autonomous robots and human–robot cooperation area. We close this survey by discussing remaining open challenges and promising research topics in future.",NO
2-s2.0-85078254727,10.1002/rob.21931,,,Autonomous aerial cinematography in unstructured environments with learned artistic decision-making,ar,Article,Bonatti R.,,The Robotics Institute,Pittsburgh,United States,,,,,2020-06-01,1 June 2020,Journal of Field Robotics,15564959,4700152301,15564967,Journal,37,4,,606-641,,,13,0,,,,"Aerial cinematography is revolutionizing industries that require live and dynamic camera viewpoints such as entertainment, sports, and security. However, safely piloting a drone while filming a moving target in the presence of obstacles is immensely taxing, often requiring multiple expert human operators. Hence, there is a demand for an autonomous cinematographer that can reason about both geometry and scene context in real-time. Existing approaches do not address all aspects of this problem; they either require high-precision motion-capture systems or global positioning system tags to localize targets, rely on prior maps of the environment, plan for short time horizons, or only follow fixed artistic guidelines specified before the flight. In this study, we address the problem in its entirety and propose a complete system for real-time aerial cinematography that for the first time combines: (a) vision-based target estimation; (b) 3D signed-distance mapping for occlusion estimation; (c) efficient trajectory optimization for long time-horizon camera motion; and (d) learning-based artistic shot selection. We extensively evaluate our system both in simulation and in field experiments by filming dynamic targets moving through unstructured environments. Our results indicate that our system can operate reliably in the real world without restrictive assumptions. We also provide in-depth analysis and discussions for each module, with the hope that our design tradeoffs can generalize to other related applications. Videos of the complete system can be found at https://youtu.be/ookhHnqmlaU.",NO
2-s2.0-85086407531,10.3389/frobt.2020.00060,,,Learning to Avoid Obstacles With Minimal Intervention Control,ar,Article,Duan A.,,Istituto Italiano di Tecnologia;Università degli Studi di Genova,Genoa;Genoa,Italy;Italy,,,,,2020-05-28,28 May 2020,Frontiers in Robotics and AI,,21100868821,22969144,Journal,7,,60,,,,0,1,,,,"Programming by demonstration has received much attention as it offers a general framework which allows robots to efficiently acquire novel motor skills from a human teacher. While traditional imitation learning that only focuses on either Cartesian or joint space might become inappropriate in situations where both spaces are equally important (e.g., writing or striking task), hybrid imitation learning of skills in both Cartesian and joint spaces simultaneously has been studied recently. However, an important issue which often arises in dynamical or unstructured environments is overlooked, namely how can a robot avoid obstacles? In this paper, we aim to address the problem of avoiding obstacles in the context of hybrid imitation learning. Specifically, we propose to tackle three subproblems: (i) designing a proper potential field so as to bypass obstacles, (ii) guaranteeing joint limits are respected when adjusting trajectories in the process of avoiding obstacles, and (iii) determining proper control commands for robots such that potential human-robot interaction is safe. By solving the aforementioned subproblems, the robot is capable of generalizing observed skills to new situations featuring obstacles in a feasible and safe manner. The effectiveness of the proposed method is validated through a toy example as well as a real transportation experiment on the iCub humanoid robot.",NO
2-s2.0-85085640694,10.1145/3392858,,,C-Reference: Improving 2D to 3D Object Pose Estimation Accuracy via Crowdsourced Joint Object Estimation,ar,Article,Song J.Y.,,"University of Michigan, Ann Arbor",Ann Arbor,United States,,,,,2020-05-28,28 May 2020,Proceedings of the ACM on Human-Computer Interaction,,21100908414,25730142,Journal,4,CSCW1,51,,,,2,0,,,,"Converting widely-available 2D images and videos, captured using an RGB camera, to 3D can help accelerate the training of machine learning systems in spatial reasoning domains ranging from in-home assistive robots to augmented reality to autonomous vehicles. However, automating this task is challenging because it requires not only accurately estimating object location and orientation, but also requires knowing currently unknown camera properties (e.g., focal length). A scalable way to combat this problem is to leverage people's spatial understanding of scenes by crowdsourcing visual annotations of 3D object properties. Unfortunately, getting people to directly estimate 3D properties reliably is difficult due to the limitations of image resolution, human motor accuracy, and people's 3D perception (i.e., humans do not ""see"" depth like a laser range finder). In this paper, we propose a crowd-machine hybrid approach that jointly uses crowds' approximate measurements of multiple in-scene objects to estimate the 3D state of a single target object. Our approach can generate accurate estimates of the target object by combining heterogeneous knowledge from multiple contributors regarding various different objects that share a spatial relationship with the target object. We evaluate our joint object estimation approach with 363 crowd workers and show that our method can reduce errors in the target object's 3D location estimation by over 40%, while requiring only $35$% as much human time. Our work introduces a novel way to enable groups of people with different perspectives and knowledge to achieve more accurate collective performance on challenging visual annotation tasks.",NO
2-s2.0-85078102951,10.1016/j.neucom.2020.01.016,S0925231220300436,,Deterministic generative adversarial imitation learning,ar,Article,Zuo G.,,Beijing University of Technology;Beijing Key Laboratory of Computational Intelligence and Intelligent System,Beijing;Beijing,China;China,,,,,2020-05-07,7 May 2020,Neurocomputing,09252312,24807,18728286,Journal,388,,,60-69,,,6,0,,,,"•

The proposed method introduces the deterministic policy into the generative adversarial imitation learning method, so that the robot can quickly imitate the demonstration policy without reward engineering.

•

Drawing on the idea of learning from demonstration (LfD), the method inputs the demonstration data both into the generator and the discriminator in order to improve the stability of training process by leveraging from the demonstration data rather than simply from the exploration data.
This paper proposes a deterministic generative adversarial imitation learning method which allows the robot to implement the motion planning task rapidly by learning from the demonstration data without reward function. In our method, the deep deterministic policy gradient method is used as the generator for learning the action policy on the basis of discriminator, and the demonstration data is input into the generator to ensure its stability. Three experiments on the push and pick-and-place tasks are conducted in the gym robotic environment. Results show that the learning speed of our method is much faster than the stochastic generative adversarial imitation learning method, and it can effectively learn from the demonstration data in different states of the task with higher learning stability. The proposed method can complete the motion planning task without environmental reward quickly and improve the stability of the training process.

Graphical abstract

Download : Download high-res image (145KB)Download : Download full-size image",NO
2-s2.0-85084641643,10.1177/1729881420921607,,,Transportable open-source application program interface and user interface for generic humanoids: TOUGH,ar,Article,Jagtap V.,,Worcester Polytechnic Institute,Worcester,United States,,,,,2020-05-01,1 May 2020,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,17,3,,,,,0,1,,,,"Humanoid robotics is a complex and highly diverse field. Humanoid robots may have dozens of sensors and actuators that together realize complicated behaviors. Adding to the complexity is that each type of humanoid has unique application program interfaces, thus software written for one humanoid does not easily transport to others. This article introduces the transportable open-source application program interface and user interface for generic humanoids, a set of application program interfaces that simplifies the programming and operation of diverse humanoid robots. These application program interfaces allow for quick implementation of complex tasks and high-level controllers. Transportable open-source application program interface and user interface for generic humanoids has been developed for, and tested on, Boston Dynamics’ Atlas V5 and NASA’s Valkyrie R5 robots. It has proved successful for experiments on both robots in simulation and hardware, demonstrating the seamless integration of manipulation, perception, and task planning. To encourage the rapid adoption of transportable open-source application program interface and user interface for generic humanoids for education and research, the software is available as Docker images, which enable quick setup of multiuser simulation environments.",NO
2-s2.0-85083309124,10.18178/ijiet.2020.10.5.1384,,,Evaluation of teaching assistant robot for programming classes,ar,Article,Yoshino K.,,Kanagawa Institute of Technology,Atsugi,Japan,,,,,2020-05-01,May 2020,International Journal of Information and Education Technology,,21100921050,20103689,Journal,10,5,,327-334,,,0,1,,,,"—This paper describes a robot for supporting teachers who are teaching computer programming classes. In its latest series of “Courses of Study”, the Ministry of Education, Culture, Sports, Science and Technology (MEXT) of Japan strongly recommends the use of active learning systems and the introduction of computer programming education courses in elementary schools. Programming instruction typically includes explanations of the basic syntax used in programming languages, the application of that syntax, and related exercises. However, the teachers in programming classes commonly spend much more time correcting errors, that is, debugging their students’ programs, than they spend teaching. These delays can affect the progress of programming lessons and the motivation of the participating students. With these points in mind, we have developed a teaching assistant robot that is designed to support efficient classroom management of programming classes by advising and assisting students who are encountering problems. Herein, we describe the tasks performed by the teaching assistant robot in a classroom environment in which actual programming lessons are assumed to be taught. In particular, we explain the problems encountered by students in the process of learning basic programming techniques, the causes of the problems, the method by which the teaching assistant robot identifies those problems, and the contents of advice provided by the teaching assistant robot corresponding to those problems. We also show the effectiveness of the teaching assistant robot by conducting evaluation experiments.

Index Terms—Teaching assistant robot, supporting teachers, programming class, image processing, pepper robot.

K. Yoshino is with the Kanagawa Institute of Technology, Atsugi, Japan (e-mail: kazuyosi@rm.kanagawa-it.ac.jp).
S. Zhang is with the Kanagawa University, Hiratsuka, Japan (e-mail: zhang@info.kanagawa-u.ac.jp).",NO
2-s2.0-85084478912,10.3390/A13040093,,,Path planning for laser cladding robot on artificial joint surface based on topology reconstruction,ar,Article,Li Y.,,Central South University,Changsha,China,,,,,2020-04-01,1 April 2020,Algorithms,,21100199795,19994893,Journal,13,4,93,,,,1,1,,,,"Artificial joint surface coating is a hot issue in the interdisciplinary fields of manufacturing, materials and biomedicine. Due to the complex surface characteristics of artificial joints, there are some problems with efficiency and precision in automatic cladding path planning for coating fabrication. In this study, a path planning method for a laser cladding robot for artificial joints surface was proposed. The key of this method was the topological reconstruction of the artificial joint surface. On the basis of the topological relation, a set of parallel planes were used to intersect the CAD model to generate a set of continuous, directed and equidistant surface transversals on the artificial joint surface. The arch height error method was used to extract robot interpolation points from surface transversal lines according to machining accuracy requirements. The coordinates and normal vectors of interpolation points were used to calculate the position and pose of the robot tool center point (TCP). To ensure that the laser beam was always perpendicular to the artificial joint surface, a novel laser cladding set-up with a robot was designed, of which the joint part clamped by a six-axis robot moved while the laser head was fixed on the workbench. The proposed methodology was validated with the planned path on the surface of an artificial acetabular cup using simulation and experimentation via an industrial NACHI robot. The results indicated that the path planning method based on topological reconstruction was feasible and more efficient than the traditional robot teaching method. View Full-Text",NO
2-s2.0-85083029159,10.1109/LRA.2020.2974427,,,Learning Constraints from Locally-Optimal Demonstrations under Cost Function Uncertainty,ar,Article,Chou G.,,"University of Michigan, Ann Arbor",Ann Arbor,United States,,,,,2020-04-01,April 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,2,9000621,3682-3690,,,6,0,,,,"We present an algorithm for learning parametric constraints from locally-optimal demonstrations, where the cost function being optimized is uncertain to the learner. Our method uses the Karush-Kuhn-Tucker (KKT) optimality conditions of the demonstrations within a mixed integer linear program (MILP) to learn constraints which are consistent with the local optimality of the demonstrations, by either using a known constraint parameterization or by incrementally growing a parameterization that is consistent with the demonstrations. We provide theoretical guarantees on the conservativeness of the recovered safe/unsafe sets and analyze the limits of constraint learnability when using locally-optimal demonstrations. We evaluate our method on high-dimensional constraints and systems by learning constraints for 7-DOF arm and quadrotor examples, show that it outperforms competing constraint-learning approaches, and can be effectively used to plan new constraint-satisfying trajectories in the environment.",NO
2-s2.0-85081611558,10.1109/LRA.2020.2972836,,,Model-Based Generalization under Parameter Uncertainty Using Path Integral Control,ar,Article,Abraham I.,,NVIDIA;Northwestern University,Santa Clara;Evanston,United States;United States,,,,,2020-04-01,April 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,2,8988215,2864-2871,,,7,0,,,,"This letter addresses the problem of robot interaction in complex environments where online control and adaptation is necessary. By expanding the sample space in the free energy formulation of path integral control, we derive a natural extension to the path integral control that embeds uncertainty into action and provides robustness for model-based robot planning. Our algorithm is applied to a diverse set of tasks using different robots and validate our results in simulation and real-world experiments. We further show that our method is capable of running in real-time without loss of performance. Videos of the experiments as well as additional implementation details can be found at https://sites.google.com/view/emppi.",NO
2-s2.0-85081104567,10.1109/LRA.2020.2970945,,,Learning to Walk a Tripod Mobile Robot Using Nonlinear Soft Vibration Actuators with Entropy Adaptive Reinforcement Learning,ar,Article,Kim J.I.,,Institute of Advanced Machines and Design,Seoul,South Korea,,,,,2020-04-01,April 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,2,8978537,2317-2324,,,7,0,,,,"Soft mobile robots have shown great potential in unstructured and confined environments by taking advantage of their excellent adaptability and high dexterity. However, there are several issues to be addressed, such as actuating speeds and controllability, in soft robots. In this letter, a new vibration actuator is proposed using the nonlinear stiffness characteristic of a hyperelastic material, which creates continuous vibration of the actuator. By integrating three proposed actuators, we also present an advanced soft mobile robot with high degrees of freedom of movement. However, since the dynamic model of the soft mobile robot is generally hard to obtain(intractable), it is difficult to design a controller for the robot. In this regard, we present a method to train a controller, using a novel reinforcement learning (RL) algorithm called adaptive soft actor-critic (ASAC). ASAC gradually reduces a parameter called an entropy temperature, which regulates the entropy of the control policy. In this way, the proposed method can narrow down the search space during training, and reduce the duration of demanding data collection processes in realworld experiments. For the verification of the robustness and the controllability of our robot and the RL algorithm, experiments for zig-zagging path tracking and obstacle avoidance were conducted, and the robot successfully finished the missions with only an hour of training time.",NO
2-s2.0-85081063619,10.1109/LRA.2020.2972825,,,Robust Humanoid Contact Planning with Learned Zero- A nd One-Step Capturability Prediction,ar,Article,Lin Y.C.,,"University of Michigan, Ann Arbor",Ann Arbor,United States,,,,,2020-04-01,April 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,2,8989791,2451-2458,,,2,0,,,,"Humanoid robots maintain balance and navigate by controlling the contact wrenches applied to the environment. While it is possible to plan dynamically-feasible motion that applies appropriate wrenches using existing methods, a humanoid may also be affected by external disturbances. Existing systems typically rely on controllers to reactively recover from disturbances. However, such controllers may fail when the robot cannot reach contacts capable of rejecting a given disturbance. In this letter, we propose a search-based footstep planner which aims to maximize the probability of the robot successfully reaching the goal without falling as a result of a disturbance. The planner considers not only the poses of the planned contact sequence, but also alternative contacts near the planned contact sequence that can be used to recover from external disturbances. Although this additional consideration significantly increases the computation load, we train neural networks to efficiently predict multi-contact zero-step and one-step capturability, which allows the planner to generate robust contact sequences efficiently. Our results show that our approach generates footstep sequences that are more robust to external disturbances than a conventional footstep planner in four challenging scenarios.",NO
2-s2.0-85081046788,10.1109/LRA.2020.2972837,,,Benchmark for Bimanual Robotic Manipulation of Semi-Deformable Objects,ar,Article,Chatzilygeroudis K.,,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,,,,,2020-04-01,April 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,2,8989777,2443-2450,,,6,1,,,,"We propose a new benchmarking protocol to evaluate algorithms for bimanual robotic manipulation semi-deformable objects. The benchmark is inspired from two real-world applications: (a) watchmaking craftsmanship, and (b) belt assembly in automobile engines. We provide two setups that try to highlight the following challenges: (a) manipulating objects via a tool, (b) placing irregularly shaped objects in the correct groove, (c) handling semideformable objects, and (d) bimanual coordination. We provide CAD drawings of the task pieces that can be easily 3D printed to ensure ease of reproduction, and detailed description of tasks and protocol for successful reproduction, as well as meaningful metrics for comparison. We propose four categories of submission in an attempt to make the benchmark accessible to a wide range of related fields spanning from adaptive control, motion planning to learning the tasks through trial-and-error learning.",NO
2-s2.0-85080895730,10.1109/LRA.2020.2970653,,,Faster confined space manufacturing teleoperation through dynamic autonomy with task dynamics imitation learning,ar,Article,Owan P.,,University of Washington,Seattle,United States,,,,,2020-04-01,April 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,2,8976114,2357-2364,,,4,0,,,,"Confined space manufacturing tasks, such as cleaning pilot holes prior to installing fasteners during aircraft wing assembly, currently require human experts to be inside ergonomically-challenging environments. Small rapidly deployable robots can substantially improve manufacturing safety and productivity. However, relatively rapid full automation remains elusive due to high-level of uncertainty in the environment, lack of cost-effective programming for low volume production, and difficulty of deploying adequate number of sensors in the confined space. Moreover, currently, teleoperation (remote human control of a robot via a force-reflection device) with typical levels of training and limited transparency of hardware is too slow for manufacturing applications, requiring experts to spend more time for each task to achieve the same cleaning quality. In this context, the main contribution of this article is to reduce cycle times for remote manufacturing by learning statistical dynamic autonomy from higher quality expert demonstrations in an ideal offline scenario. During the task, to keep cycle times low, the dynamic autonomy imitates the faster expert demonstrations when certain, and employs the slower human teleoperation when uncertain. A user study (n = 8) with an experimental robot platform shows that for the same cleaning quality, the dynamic autonomy reduces process completion time by 54.0% and human operator energy expenditure by 80.5% as compared with teleoperation without dynamic autonomy.",NO
2-s2.0-85079815240,10.1109/LRA.2020.2969937,,,Exploiting bias for cooperative planning in multi-agent tree search,ar,Article,Ma A.,,"University of California, San Diego",San Diego,United States,,,,,2020-04-01,April 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,2,8972364,1819-1826,,,1,0,,,,"Graph search over states and actions is a valuable tool for robotic planning and navigation. However, the required computation is sensitive to the size of the state and action spaces, a fact which is further exacerbated in multi-agent planning by the number of agents and the presence of sparse reward signals dependent on the cooperation of agents. To tackle these problems, we introduce an algorithm that is pre-trained in a centralized fashion but implemented on robots in a distributed way at runtime. The centralized portion uses imitation learning to iteratively construct policies that help guide an individual agent`s own runtime search as well as predict other agents' future actions by exploiting previously discovered joint actions. Our algorithm includes a novel method of tree search based on a mixture of the individual and joint action space, which can be interpreted as a cascading effect where agents are biased by exploration of new actions, exploitation of previously profitable ones, and recommendation provided by deep neural nets. Simulations show the efficacy of the proposed method in cooperative scenarios with sparse rewards.",NO
2-s2.0-85078838096,10.1002/advs.201901957,,,Toward “On-Demand” Materials Synthesis and Scientific Discovery through Intelligent Robots,ar,Article,Li J.,,"The Chinese University of Hong Kong, Shenzhen",Shenzhen,China,,,,,2020-04-01,1 April 2020,Advanced Science,,21100470165,21983844,Journal,7,7,1901957,,,,16,1,,,,"A Materials Acceleration Operation System (MAOS) is designed, with unique language and compiler architecture. MAOS integrates with virtual reality (VR), collaborative robots, and a reinforcement learning (RL) scheme for autonomous materials synthesis, properties investigations, and self-optimized quality assurance. After training through VR, MAOS can work independently for labor and intensively reduces the time cost. Under the RL framework, MAOS also inspires the improved nucleation theory, and feedback for the optimal strategy, which can satisfy the demand on both of the CdSe quantum dots (QDs) emission wavelength and size distribution quality. Moreover, it can work well for extensive coverages of inorganic nanomaterials. MAOS frees the experimental researchers out of the tedious labor as well as the extensive exploration of optimal reaction conditions. This work provides a walking example for the “On-Demand” materials synthesis system, and demonstrates how artificial intelligence technology can reshape traditional materials science research in the future.",NO
2-s2.0-85078765814,10.1109/LRA.2020.2965855,,,Cooperative Aerial-Ground Multi-Robot System for Automated Construction Tasks,ar,Article,Krizmancic M.,,"University of Zagreb, Faculty of Electrical Engineering and Computing",Zagreb,Croatia,,,,,2020-04-01,April 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,2,8955969,798-805,,,6,0,,,,"In this letter, we study a cooperative aerial-ground robotic team and its application to the task of automated construction. We propose a solution for planning and coordinating the mission of constructing a wall with a predefined structure for a heterogeneous system consisting of one mobile robot and up to three unmanned aerial vehicles. The wall consists of bricks of various weights and sizes, some of which need to be transported using multiple robots simultaneously. To that end, we use hierarchical task representation to specify interrelationships between mission subtasks and employ effective scheduling and coordination mechanism, inspired by Generalized Partial Global Planning. We evaluate the performance of the method under different optimization criteria and validate the solution in the realistic Gazebo simulation environment.",NO
2-s2.0-85078704548,10.1109/LRA.2020.2965078,,,Interactive Gibson Benchmark: A Benchmark for Interactive Navigation in Cluttered Environments,ar,Article,Xia F.,,Stanford University,Palo Alto,United States,,,,,2020-04-01,April 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,2,8954627,713-720,,,15,0,,,,"We present Interactive Gibson Benchmark, the first comprehensive benchmark for training and evaluating Interactive Navigation solutions. Interactive Navigation tasks are robot navigation problems where physical interaction with objects (e.g., pushing) is allowed and even encouraged to reach the goal. Our benchmark comprises two novel elements: 1) a new experimental simulated environment, the Interactive Gibson Environment, that generate photo-realistic images of indoor scenes and simulates realistic physical interactions of robots and common objects found in these scenes; 2) the Interactive Navigation Score, a novel metric to study the interplay between navigation and physical interaction of Interactive Navigation solutions. We present and evaluate multiple learning-based baselines in Interactive Gibson Benchmark, and provide insights into regimes of navigation with different trade-offs between navigation, path efficiency and disturbance of surrounding objects. We make our benchmark publicly available1 and encourage researchers from related robotics disciplines (e.g., planning, learning, control) to propose, evaluate, and compare their Interactive Navigation solutions in Interactive Gibson Benchmark.",NO
2-s2.0-85077924455,10.1016/j.autcon.2020.103078,S0926580519305813,,Complete coverage path planning using reinforcement learning for Tetromino based cleaning and maintenance robot,ar,Article,Krishna Lakshmanan A.,,"Singapore University of Technology and Design;Birla Institute of Technology and Science, Pilani",;Pilani,Singapore;India,,,,,2020-04-01,April 2020,Automation in Construction,09265805,24931,,Journal,112,,103078,,,,29,0,,,,"Highlights

•

The reinforcement learning based complete coverage path planning is tested on reconfigurable tiling robot called hTetro.

•

The model minimizing the transformational and rotational actions generates the path with lower cost than tiling methods.

•

The model is able to determine the optimal set of morphologies required for each environment.

•

The algorithm can generate a path in a plethora of environments with different obstacle settings.

•

The model also takes lesser time to generate this path compared to conventional methods.
Tiling robotics have been deployed in autonomous complete area coverage tasks such as floor cleaning, building inspection, and maintenance, surface painting. One class of tiling robotics, polyomino-based reconfigurable robots, overcome the limitation of fixed-form robots in achieving high-efficiency area coverage by adopting different morphologies to suit the needs of the current environment. Since the reconfigurable actions of these robots are produced by real-time intelligent decisions during operations, an optimal path planning algorithm is paramount to maximize the area coverage while minimizing the energy consumed by these robots. This paper proposes a complete coverage path planning (CCPP) model trained using deep blackreinforcement learning (RL) for the tetromino based reconfigurable robot platform called hTetro to simultaneously generate the optimal set of shapes for any pretrained arbitrary environment shape with a trajectory that has the least overall cost. To this end, a Convolutional Neural Network (CNN) with Long Short Term Memory (LSTM) layers is trained using Actor Critic Experience Replay (ACER) reinforcement learning algorithm. The results are compared with existing approaches which are based on the traditional tiling theory model, including zigzag, spiral, and greedy search schemes. The model is also compared with the Travelling salesman problem (TSP) based Genetic Algorithm (GA) and Ant Colony Optimization (ACO) schemes. The proposed scheme generates a path with lower cost while also requiring lesser time to generate it. The model is also highly robust and can generate a path in any pretrained arbitrary environments.",NO
2-s2.0-85067803118,10.1007/s10845-019-01479-8,,,Artificial intelligence planners for multi-head path planning of SwarmItFIX agents,ar,Article,Veeramani S.,,Indian Institute of Information Technology Design and Manufacturing Kancheepuram,Chennai,India,,,,,2020-04-01,1 April 2020,Journal of Intelligent Manufacturing,09565515,24363,15728145,Journal,31,4,,815-832,,,2,0,,,,"Sheet metal manufacturing is finding wide applications in automotive and aerospace industries. Handling of giant sheet materials in manufacturing industries is one of the key problems. Utilization of robots, viz SwarmItFIX, will address this problem and automate the fixturing process, which greatly reduces lead time and thus the production cost. Implementation of intelligence into the robots will further improve efficiency in handling and reduce manufacturing inaccuracies. In this work, two different novel planners are proposed which do path planning for the heads of the SwarmItFIX agents. The environment of the problem is modeled as a Markov Decision Problem. The first planner uses the Value Iteration and Policy Iteration (PI) algorithms individually and the second planner performs the Monte Carlo control reinforcement learning. Finally, when the simulation is done and parameters of the proposed three algorithms along with existing Constraint Satisfaction Problem algorithm are compared with each other. It is observed that the proposed PI algorithm returns the plan much faster than the other algorithms. In the near future, the efficient planning model will be tested and implemented into the SwarmItFIX setup at the PMAR laboratory, University of Genoa, Italy.",NO
2-s2.0-85057148773,10.1109/TCYB.2018.2878977,,30475740,Robot-Assisted Pedestrian Regulation Based on Deep Reinforcement Learning,ar,Article,Wan Z.,,University of Rhode Island,Kingston,United States,,,,,2020-04-01,April 2020,IEEE Transactions on Cybernetics,21682267,21100274221,21682275,Journal,50,4,8540942,1669-1682,,,11,0,,,,"Pedestrian regulation can prevent crowd accidents and improve crowd safety in densely populated areas. Recent studies use mobile robots to regulate pedestrian flows for desired collective motion through the effect of passive human-robot interaction (HRI). This paper formulates a robot motion planning problem for the optimization of two merging pedestrian flows moving through a bottleneck exit. To address the challenge of feature representation of complex human motion dynamics under the effect of HRI, we propose using a deep neural network to model the mapping from the image input of pedestrian environments to the output of robot motion decisions. The robot motion planner is trained end-to-end using a deep reinforcement learning algorithm, which avoids hand-crafted feature detection and extraction, thus improving the learning capability for complex dynamic problems. Our proposed approach is validated in simulated experiments, and its performance is evaluated. The results demonstrate that the robot is able to find optimal motion decisions that maximize the pedestrian outflow in different flow conditions, and the pedestrian-accumulated outflow increases significantly compared to cases without robot regulation and with random robot motion.",NO
2-s2.0-85116896933,10.12133/j.smartag.2020.2.1.202003-SA002,,,Indoor phenotyping platforms and associated trait measurement: Progress and prospects,ar,Article,Xu L.,,Nanjing Agricultural University,Nanjing,China,,,,,2020-03-20,20 March 2020,Smart Agriculture,20968094,21101061461,,Journal,2,1,,23-42,,,2,0,,,,,NO
2-s2.0-85082672598,10.3389/fnbot.2020.00016,,,Robustness Through Simplicity: A Minimalist Gateway to Neurorobotic Flight,ar,Article,Levy S.D.,,Washington and Lee University,Lexington,United States,,,,,2020-03-16,16 March 2020,Frontiers in Neurorobotics,,21100199837,16625218,Journal,14,,16,,,,2,1,,,,"In attempting to build neurorobotic systems based on flying animals, engineers have come to rely on existing firmware and simulation tools designed for miniature aerial vehicles (MAVs). Although they provide a valuable platform for the collection of data for Deep Learning and related AI approaches, such tools are deliberately designed to be general (supporting air, ground, and water vehicles) and feature-rich. The sheer amount of code required to support such broad capabilities can make it a daunting task to adapt these tools to building neurorobotic systems for flight. In this paper we present a complementary pair of simple, object-oriented software tools (multirotor flight-control firmware and simulation platform), each consisting of a core of a few thousand lines of C++ code, that we offer as a candidate solution to this challenge. By providing a minimalist application programming interface (API) for sensors and PID controllers, our software tools make it relatively painless for engineers to prototype neuromorphic approaches to MAV sensing and navigation. We conclude our discussion by presenting a simple PID controller we built using the popular Nengo neural simulator in conjunction with our flight-simulation platform.",NO
2-s2.0-85082701724,10.3389/frobt.2020.00021,,,Identification of the Students Learning Process During Education Robotics Activities,ar,Article,Scaradozzi D.,,Laboratoire d’Informatique et Systèmes;Università Politecnica delle Marche,Marseille;Ancona,France;Italy,,,,,2020-03-13,13 March 2020,Frontiers in Robotics and AI,,21100868821,22969144,Journal,7,,21,,,,3,1,,,,"This paper presents the design of an assessment process and its outcomes to investigate the impact of Educational Robotics activities on students' learning. Through data analytics techniques, the authors will explore the activities' output from a pedagogical and quantitative point of view. Sensors are utilized in the context of an Educational Robotics activity to obtain a more effective robot–environment interaction. Pupils work on specific exercises to make their robot smarter and to carry out more complex and inspirational projects: the integration of sensors on a robotic prototype is crucial, and learners have to comprehend how to use them. In the presented study, the potential of Educational Data Mining is used to investigate how a group of primary and secondary school students, using visual programming (Lego Mindstorms EV3 Education software), design programming sequences while they are solving an exercise related to an ultrasonic sensor mounted on their robotic artifact. For this purpose, a tracking system has been designed so that every programming attempt performed by students' teams is registered on a log file and stored in an SD card installed in the Lego Mindstorms EV3 brick. These log files are then analyzed using machine learning techniques (k-means clustering) in order to extract different patterns in the creation of the sequences and extract various problem-solving pathways performed by students. The difference between problem-solving pathways with respect to an indicator of early achievement is studied.",SI
2-s2.0-85084124812,10.1007/s11412-020-09318-2,,,Unpacking the relationship between existing and new measures of physiological synchrony and collaborative learning: a mixed methods study,ar,Article,Schneider B.,,Harvard University,Cambridge,United States,,,,,2020-03-01,1 March 2020,International Journal of Computer-Supported Collaborative Learning,15561607,4700152632,15561615,Journal,15,1,,89-113,,,6,0,,,,"Over the last decade, there has been a renewed interest in capturing twenty-first century skills using new data collection tools. In this article, we leverage an existing dataset where electrodermal activity (EDA) was used to identify markers of productive collaboration. The data came from 42 pairs of participants (N = 84) who had no coding experience and were asked to program a robot to solve a variety of mazes. Because little is known on how physiological synchrony relates to collaborative learning, we explored four different measures of synchrony: Signal Matching (SM), Instantaneous Derivative Matching (IDM), Directional Agreement (DA) and Pearson’s Correlation (PC). Overall, we found PC to be positively associated with learning gains (r = 0.35) and DA with collaboration quality (r = 0.3). To gain further insights into these results, we also qualitatively analyzed two groups and identified situations with high or low physiological synchrony. We observed higher synchrony values when members of a productive group reacted to an external event (e.g., following instructions, receiving a hint), oscillations when they were watching a video or interacting with each other, and lower values when they were programming and / or seem to be confused. Based on these results, we developed a new measure of collaboration using electrodermal data: we computed the number of cycles between low and high synchronization. We found this measure to be significantly correlated with collaboration quality (r = 0.57) and learning gains (r = 0.47). This measure was not significantly correlated with the measures of physiological synchrony mentioned above, suggesting that it is capturing a different construct. We compare those results with prior studies and discuss implications for measuring collaborative process through physiological sensors.",NO
2-s2.0-85082439932,10.1177/1729881420911491,,,Continuous reinforcement learning to adapt multi-objective optimization online for robot motion,ar,Article,Zhang K.,,Beijing Institute of Technology;The University of North Carolina at Charlotte,Beijing;Charlotte,China;United States,,,,,2020-03-01,1 March 2020,International Journal of Advanced Robotic Systems,17298806,144749,17298814,Journal,17,2,,,,,2,1,,,,"This article introduces a continuous reinforcement learning framework to enable online adaptation of multi-objective optimization functions for guiding a mobile robot to move in changing dynamic environments. The robot with this framework can continuously learn from multiple or changing environments where it encounters different numbers of obstacles moving in unknown ways at different times. Using both planned trajectories from a real-time motion planner and already executed trajectories as feedback observations, our reinforcement learning agent enables the robot to adapt motion behaviors to environmental changes. The agent contains a Q network connected to a long short-term memory network. The proposed framework is tested in both simulations and real robot experiments over various, dynamically varied task environments. The results show the efficacy of online continuous reinforcement learning for quick adaption to different, unknown, and dynamic environments.",NO
2-s2.0-85078967725,10.1016/j.micpro.2020.102990,S0141933119300146,,CNN-Grinder: From Algorithmic to High-Level Synthesis descriptions of CNNs for Low-end-low-cost FPGA SoCs,ar,Article,Mousouliotis P.,,Aristotle University of Thessaloniki,Thessaloniki,Greece,,,,,2020-03-01,March 2020,Microprocessors and Microsystems,01419331,15552,,Journal,73,,102990,,,,11,0,,,,"Although High-Level Synthesis (HLS) tools have been in the scene for almost fifteen years, researchers have been reluctant to use them for accelerating their algorithms on FPGA SoCs. We present CNN-Grinder, a template-driven workflow for converting algorithmic descriptions of mobile-friendly convolutional neural networks (CNNs), such as SqueezeNet v1.1 and ZynqNet, to HLS code which can be used for programming low-end-low-cost FPGA SoCs. In contrast to other works, which from the user perspective are acting as a black box, CNN-Grinder does not hide its inner workings by automating the procedure of algorithmic-to-HLS description but it exposes every step in a clear and concise way. CNN-Grinder provides the means to developers to map a CNN on an FPGA SoC by providing easy to follow steps and templates which are not constrained to specific CNN architectures and FPGA devices. Our workflow is accompanied by the SqueezeJet-2 accelerator, which is used for the acceleration of the convolutional and the max-pooling layers of the SqueezeNet v1.1 and the ZynqNet CNNs making possible to achieve more than 10fps CNN inference at 100MHz using a batch size equal to 1 on a low-end-low-cost FPGA SoC such as the Xilinx XC7Z020. Finally, an analytical model of the SqueezeJet-2 accelerator is developed and evaluated against related results produced by the Xilinx Vivado HLS tool.",NO
2-s2.0-85077502803,10.1016/j.ast.2019.105657,S1270963819325660,,Reinforcement learning in dual-arm trajectory planning for a free-floating space robot,ar,Article,Wu Y.H.,,Nanjing University of Aeronautics and Astronautics,Nanjing,China,,,,,2020-03-01,March 2020,Aerospace Science and Technology,12709638,12507,,Journal,98,,105657,,,,21,0,,,,"A free-floating space robot exhibits strong dynamic coupling between the arm and the base, and the resulting position of the end of the arm depends not only on the joint angles but also on the state of the base. Dynamic modeling is complicated for multiple degree of freedom (DOF) manipulators, especially for a space robot with two arms. Therefore, the trajectories are typically planned offline and tracked online. However, this approach is not suitable if the target has relative motion with respect to the servicing space robot. To handle this issue, a model-free reinforcement learning strategy is proposed for training a policy for online trajectory planning without establishing the dynamic and kinematic models of the space robot. The model-free learning algorithm learns a policy that maps states to actions via trial and error in a simulation environment. With the learned policy, which is represented by a feedforward neural network with 2 hidden layers, the space robot can schedule and perform actions quickly and can be implemented for real-time applications. The feasibility of the trained policy is demonstrated for both fixed and moving targets.",NO
2-s2.0-85077186394,10.1016/j.addma.2019.101003,S2214860419319670,,Building free-form thin shell parts using supportless extrusion-based additive manufacturing,ar,Article,Bhatt P.M.,,University of Southern California,Los Angeles,United States,,,,,2020-03-01,March 2020,Additive Manufacturing,,21100349533,22148604,Journal,32,,101003,,,,14,0,,,,"Conventional material extrusion additive manufacturing is capable of building complex structures. Overhanging features require the use of support structures. Printing the support structure requires additional time and material. Conventional processes need time to remove support material and may lead to degraded surface finish. The use of support structures can be avoided by dynamically reorienting the build-platform. This paper presents a novel approach to build accurate thin shell parts using supportless extrusion-based additive manufacturing. We describe the layer slicing algorithm, the tool-path planning algorithm, and the neural network-based compensated trajectory generation scheme to use a 3 degree of freedom build-platform and a 3 degree of freedom extrusion tool to build accurate thin shell parts using two manipulators. Such thin shell parts cannot be built without supports by previous supportless AM processes. We illustrate the usefulness of our algorithms by building several thin shell parts.",NO
2-s2.0-85076755811,10.1002/cae.22188,,,A teaching method for the theory and application of robot kinematics based on MATLAB and V-REP,ar,Article,Zhou D.,,"China University of Mining &amp; Technology, Beijing",Beijing,China,,,,,2020-03-01,1 March 2020,Computer Applications in Engineering Education,10613773,18156,10990542,Journal,28,2,,239-253,,,7,0,,,,"With the continuous development of the world, robots are necessary for achieving high production rates and competitiveness. With an increasing robot demand, many universities offer robotics courses. These courses teach students the mathematical principles of robot-related algorithms. However, it is difficult for students to apply pure mathematical algorithms in robotics to real robot development in a traditional classroom. This paper's motivation is to present a new robotics teaching method: Algorithm, Virtual experiment, Programming and Controller (AVPC), which shows students the steps of complete robot algorithm development, verification, and application process, taking the kinematics of an educational desktop 6-DOF robotic arm as a typical teaching case. For the low-cost educational desktop six-axis robotic arm, an inverse kinematics algorithm is proposed. The inverse solution algorithm is realized in MATLAB, and then the dynamic model of the desktop robotic arm is established in Virtual Robot Experimentation Platform (V-REP). The inverse kinematics algorithm in MATLAB is used to control the virtual robot arm movement in V-REP to the specified position and orientation through the application programming interface (API) interface, thus verifying the correctness of the inverse kinematics algorithm. The inverse algorithm is implemented by using C language function in the microcontroller, and the running time of the algorithm is compared with that of the iterative solution method. In the present study, we investigated the students’ feelings and exam scores of using the new teaching method. The results show that the new teaching method has a significant impact on the improvement of students’ learning effect of robotics.",NO
2-s2.0-85075351718,10.1007/s41315-019-00114-2,,,An educational Arduino robot for visual Deep Learning experiments,ar,Article,Hu H.,,Renmin University of China,Beijing,China,,,,,2020-03-01,1 March 2020,International Journal of Intelligent Robotics and Applications,23665971,21100935977,2366598X,Journal,4,1,,73-81,,,1,0,,,,"Deep Learning methods are gaining popularity with both academy and industry. We are in dire need of student affordable educational platform that can support doing Deep Learning experiments. In this paper, we present a mobile robot platform based on Arduino for educational experiments in visual Deep Learning. The educational robot uses Arduino open-source hardware and supports various programming interfaces, including C/C++, Python and Matlab. The robot uses an attached android mobile phone to capture images and video streams. Visual Deep Learning models such as DNNs and CNNs can be examined and practiced with the robot.",NO
2-s2.0-85068894164,10.1007/s10514-019-09871-2,,,Hierarchical reinforcement learning via dynamic subspace search for multi-agent planning,ar,Article,Ma A.,,"University of California, San Diego",San Diego,United States,,,,,2020-03-01,1 March 2020,Autonomous Robots,09295593,18016,15737527,Journal,44,3-4,,485-503,,,4,0,,,,"We consider scenarios where a swarm of unmanned vehicles (UxVs) seek to satisfy a number of diverse, spatially distributed objectives. The UxVs strive to determine an efficient plan to service the objectives while operating in a coordinated fashion. We focus on developing autonomous high-level planning, where low-level controls are leveraged from previous work in distributed motion, target tracking, localization, and communication. We rely on the use of state and action abstractions in a Markov decision processes framework to introduce a hierarchical algorithm, Dynamic Domain Reduction for Multi-Agent Planning, that enables multi-agent planning for large multi-objective environments. Our analysis establishes the correctness of our search procedure within specific subsets of the environments, termed ‘sub-environment’ and characterizes the algorithm performance with respect to the optimal trajectories in single-agent and sequential multi-agent deployment scenarios using tools from submodularity. Simulated results show significant improvement over using a standard Monte Carlo tree search in an environment with large state and action spaces.",NO
2-s2.0-85065535899,10.1108/AA-11-2018-0188,,,An extended DMP framework for robot learning and improving variable stiffness manipulation,ar,Article,Bian F.,,Harbin Institute of Technology,Harbin,China,,,,,2020-02-18,18 Feb 2020,Assembly Automation,01445154,24904,,Journal,40,1,,85-94,,,4,0,,,,"Purpose

The purpose of this paper is to present a method which enables a robot to learn both motion skills and stiffness profiles from humans through kinesthetic human-robot cooperation.

Design Methodology Approach

Admittance control is applied to allow robot-compliant behaviors when following the reference trajectories. By extending the dynamical movement primitives (DMP) model, a new concept of DMP and stiffness primitives is introduced to encode a kinesthetic demonstration as a combination of trajectories and stiffness profiles, which are subsequently transferred to the robot. Electromyographic signals are extracted from a human’s upper limbs to obtain target stiffness profiles. By monitoring vibrations of the end-effector velocities, a stability observer is developed. The virtual damping coefficient of admittance controller is adjusted accordingly to eliminate the vibrations.

Findings

The performance of the proposed methods is evaluated experimentally. The result shows that the robot can perform tasks in a variable stiffness mode as like the human dose in the teaching phase.

Originality Value

DMP has been widely used as a teaching by demonstration method to represent movements of humans and robots. The proposed method extends the DMP framework to allow a robot to learn not only motion skills but also stiffness profiles. Additionally, the authors proposed a stability observer to eliminate vibrations when the robot is disturbed by environment.",NO
2-s2.0-85076035415,10.1080/01691864.2019.1694068,,,System for augmented human–robot interaction through mixed reality and robot training by non-experts in customer service environments,ar,Article,El Hafi L.,,Ritsumeikan University Biwako-Kusatsu Campus,Kusatsu,Japan,,,,,2020-02-16,16 February 2020,Advanced Robotics,01691864,18003,15685535,Journal,34,3-4,,157-172,,,12,0,,,,"Human–robot interaction during general service tasks in home or retail environment has been proven challenging, partly because (1) robots lack high-level context-based cognition and (2) humans cannot intuit the perception state of robots as they can for other humans. To solve these two problems, we present a complete robot system that has been given the highest evaluation score at the Customer Interaction Task of the Future Convenience Store Challenge at the World Robot Summit 2018, which implements several key technologies: (1) a hierarchical spatial concepts formation for general robot task planning and (2) a mixed reality interface to enable users to intuitively visualize the current state of the robot perception and naturally interact with it. The results obtained during the competition indicate that the proposed system allows both non-expert operators and end users to achieve human–robot interactions in customer service environments. Furthermore, we describe a detailed scenario including employee operation and customer interaction which serves as a set of requirements for service robots and a road map for development. The system integration and task scenario described in this paper should be helpful for groups facing customer interaction challenges and looking for a successfully deployed base to build on.",NO
2-s2.0-85083318262,10.1109/RITA.2020.2978416,,,Using UML for Learning How to Design and Model Cyber-Physical Systems,ar,Article,Ordinez L.,,Universidad Nacional de la Patagonia San Juan Bosco,Comodoro Rivadavia,Argentina,,,,,2020-02-01,February 2020,Revista Iberoamericana de Tecnologias del Aprendizaje,,19700201532,19328540,Journal,15,1,9023990,50-60,,,4,0,,,,"In this paper a methodology for teaching and learning the modeling of embedded systems and, in a more generic vision cyber-physical systems (CPS) is presented. To this end, a subset of tools from UML is used in an intuitive and ordered way starting with an informal description of the system until implementation details are obtained. However, the codification of the system is left out as the programming language depends on the hardware platform to be used. The method has been used in grade courses for several years now with an important accumulated experience that shows how students are able to adopt it and learn to elicit the different types of requirements, actors and functions.",NO
2-s2.0-85078798997,10.3390/s20030706,,32012874,Depth image–based deep learning of grasp planning for textureless planar-faced objects in vision-guided robotic bin-picking,ar,Article,Jiang P.,,Toshiba Corporation,Tokyo,Japan,,,,,2020-02-01,1 February 2020,Sensors (Switzerland),14248220,130124,,Journal,20,3,706,,,,9,1,,,,"Bin-picking of small parcels and other textureless planar-faced objects is a common task at warehouses. A general color image–based vision-guided robot picking system requires feature extraction and goal image preparation of various objects. However, feature extraction for goal image matching is difficult for textureless objects. Further, prior preparation of huge numbers of goal images is impractical at a warehouse. In this paper, we propose a novel depth image–based vision-guided robot bin-picking system for textureless planar-faced objects. Our method uses a deep convolutional neural network (DCNN) model that is trained on 15,000 annotated depth images synthetically generated in a physics simulator to directly predict grasp points without object segmentation. Unlike previous studies that predicted grasp points for a robot suction hand with only one vacuum cup, our DCNN also predicts optimal grasp patterns for a hand with two vacuum cups (left cup on, right cup on, or both cups on). Further, we propose a surface feature descriptor to extract surface features (center position and normal) and refine the predicted grasp point position, removing the need for texture features for vision-guided robot control and sim-to-real modification for DCNN model training. Experimental results demonstrate the efficiency of our system, namely that a robot with 7 degrees of freedom can pick randomly posed textureless boxes in a cluttered environment with a 97.5% success rate at speeds exceeding 1000 pieces per hour. View Full-Text",NO
2-s2.0-85078252566,10.3390/s20030642,,31979281,3d trajectory planning method for UAVs swarm in building emergencies,ar,Article,Madridano Á.,,Universidad Carlos III de Madrid,Madrid,Spain,,,,,2020-02-01,1 February 2020,Sensors (Switzerland),14248220,130124,,Journal,20,3,642,,,,19,1,,,,"The development in Multi-Robot Systems (MRS) has become one of the most exploited fields of research in robotics in recent years. This is due to the robustness and versatility they present to effectively undertake a set of tasks autonomously. One of the essential elements for several vehicles, in this case, Unmanned Aerial Vehicles (UAVs), to perform tasks autonomously and cooperatively is trajectory planning, which is necessary to guarantee the safe and collision-free movement of the different vehicles. This document includes the planning of multiple trajectories for a swarm of UAVs based on 3D Probabilistic Roadmaps (PRM). This swarm is capable of reaching different locations of interest in different cases (labeled and unlabeled), supporting of an Emergency Response Team (ERT) in emergencies in urban environments. In addition, an architecture based on Robot Operating System (ROS) is presented to allow the simulation and integration of the methods developed in a UAV swarm. This architecture allows the communications with the MavLink protocol and control via the Pixhawk autopilot, for a quick and easy implementation in real UAVs. The proposed method was validated by experiments simulating building emergences. Finally, the obtained results show that methods based on probability roadmaps create effective solutions in terms of calculation time in the case of scalable systems in different situations along with their integration into a versatile framework such as ROS. View Full-Text",NO
2-s2.0-85075241368,10.1007/s10766-019-00647-w,,,Message Passing Optimization in Robot Operating System,ar,Article,Jiang Z.,,,,,,,,,2020-02-01,1 February 2020,International Journal of Parallel Programming,08857458,28325,15737640,Journal,48,1,,119-136,,,5,0,,,,"With the development of deep learning, autonomous robot systems grow rapidly and require better performance. Robot Operating System 2 (ROS2) has been widely adopted as the main communication framework in autonomous robot systems. However, the performance of ROS2 has become the bottleneck of these real-time systems. From our observations, we find that it can take a large amount of time to serialize complex message in communication, especially for some high-level programming languages, including Python, Java and so on. To address this challenge, we propose a novel technique, called adaptive two-layer serialization algorithm, which can achieve good performance in communication for different kinds of messages. Experimental results show that our algorithm can achieve significant performance improvement over traditional methods in ROS2, up to 93% improvement in our framework. We have successfully applied our proposed techniques in a real autonomous robot system.",NO
2-s2.0-85066622576,10.1007/s00500-019-04067-3,,,A new fallback beetle antennae search algorithm for path planning of mobile robots with collision-free capability,ar,Article,Wu Q.,,Hangzhou Dianzi University,Hangzhou,China,,,,,2020-02-01,1 February 2020,Soft Computing,14327643,28554,14337479,Journal,24,3,,2369-2380,,,24,0,,,,"With the development of technology, mobile robots are becoming more and more common in industrial production and daily life. Various rules are set to ensure that mobile robots can move without collision. This paper proposes a novel intelligent optimization algorithm, named fallback beetle antennae search algorithm. Based on the analysis of biological habits, when the creature enters blind alley during the foraging process, it will retreat a distance and then restart the search process. We introduce a fallback mechanism in the traditional beetle antenna search algorithm. In addition, the proposed algorithm possesses the characteristic of low time complexity. It can plan a collision-free path in a short period of time. Moreover, the effectiveness and superiority of the algorithm are verified by simulations in different types of environments and comparisons with existing path planning algorithms.",NO
2-s2.0-85106805750,10.3991/ijoe.v16i14.17069,,,MakeCode for Lego Mindstorms EV3,ar,Article,Voštinár P.,,Matej Bel University,Banska Bystrica,Slovakia,,,,,2020-01-01,2020,International journal of online and biomedical engineering,,21100906923,26268493,Journal,16,4,,42-53,,,0,1,,,,"Computer Science is nowadays very popular and requested in almost all companies. Many companies would like to have more IT professionals. Therefore we would like to motivate students from the beginning of their education to learn Computer Science, especially programming. There are many educational aids, which could be used for showing students, that programming is not so hard, as they think. The contribution describes our experience with using the online environment Microsoft MakeCode and the most popular educational robot Lego Mindstorms EV3 in an extracurricular activity for primary school children at Matej Bel University, Slovakia. In this paper, we present environment MakeCode and examples of tasks, which we are using for teaching programming in this environment.",SI
2-s2.0-85103755759,10.14357/199222642004014,,,About digital literacy and environments for its development,ar,Article,Betelin Vladimir B.,,Russian Academy of Sciences,Moscow,Russian Federation,,,,,2020-01-01,2020,Informatika i ee Primeneniya,19922264,21100793172,23109912,Journal,14,4,,100-107,,,0,0,,,,,NO
2-s2.0-85102840743,10.1109/ACCESS.2020.3035083,,,BIPES: Block based integrated platform for embedded systems,ar,Article,Da Silva A.G.,,Academic Directory,Mossoro,Brazil,,,,,2020-01-01,2020,IEEE Access,,21100374601,21693536,Journal,8,,,197955-197968,,,0,1,,,,"This article proposes the BIPES, a Block based Integrated Platform for Embedded Systems, including its architecture, design and validation results. BIPES is an open source software and service that is freely available through the website http://www.bipes.net.br and has been conceived from our experience of several years developing embedded systems and Internet of Things (IoT) applications, and teaching. It allows anyone to quickly and reliably design, program, build, deploy and monitor embedded systems, IoT devices and applications using blocks or Python based programming. It is fully based on web environment, so absolutely no software installation is needed on the client developer machine. In this way, a tablet, a netbook, a Chromebook or any other device can be used to program and test several types of devices. Mainly, it relies on MicroPython or CircuitPython, WebREPL, WebSockets, Web Serial API, HTML, JavaScript and Google Blockly to allow no-code programming (blocks) to be translated into Python code and then deployed to the target board. Moreover, it does not require server side processing, so it can be deployed as a Progressive Web Application (PWA), allowing it to be used even when the computer is offline. It is compatible with several low cost boards such as: mBed, BBC micro:bit, ESP8266, ESP32 and Raspberry Pi using only a web browser and without the need to install any software on the device where the user develops the programming.",SI
2-s2.0-85102550158,10.1109/ACCESS.2020.3030190,,,"Collaborative multi-robot search and rescue: Planning, coordination, perception, and active vision",ar,Article,Queralta J.P.,,Turun yliopisto,Turku,Finland,,,,,2020-01-01,2020,IEEE Access,,21100374601,21693536,Journal,8,,,191617-191643,,,14,1,,,,"Search and rescue (SAR) operations can take significant advantage from supporting autonomous or teleoperated robots and multi-robot systems. These can aid in mapping and situational assessment, monitoring and surveillance, establishing communication networks, or searching for victims. This paper provides a review of multi-robot systems supporting SAR operations, with system-level considerations and focusing on the algorithmic perspectives for multi-robot coordination and perception. This is, to the best of our knowledge, the first survey paper to cover (i) heterogeneous SAR robots in different environments, (ii) active perception in multi-robot systems, while (iii) giving two complementary points of view from the multi-agent perception and control perspectives. We also discuss the most significant open research questions: shared autonomy, sim-to-real transferability of existing methods, awareness of victims' conditions, coordination and interoperability in heterogeneous multi-robot systems, and active perception. The different topics in the survey are put in the context of the different challenges and constraints that various types of robots (ground, aerial, surface, or underwater) encounter in different SAR environments (maritime, urban, wilderness, or other post-disaster scenarios). The objective of this survey is to serve as an entry point to the various aspects of multi-robot SAR systems to researchers in both the machine learning and control fields by giving a global overview of the main approaches being taken in the SAR robotics area.",NO
2-s2.0-85098582915,10.1109/ACCESS.2020.3045027,,,Coverage Path Planning for Decomposition Reconfigurable Grid-Maps Using Deep Reinforcement Learning Based Travelling Salesman Problem,ar,Article,Kyaw P.T.,,Singapore University of Technology and Design;Yangon Technological University,;Yangon,Singapore;Myanmar,,,,,2020-01-01,2020,IEEE Access,,21100374601,21693536,Journal,8,,9294048,225945-225956,,,7,1,,,,"Optimizing the coverage path planning (CPP) in robotics has become essential to accomplish efficient coverage applications. This work presents a novel approach to solve the CPP problem in large complex environments based on the Travelling Salesman Problem (TSP) and Deep Reinforcement Learning (DRL) leveraging the grid-based maps. The proposed algorithm applies the cellular decomposition methods to decompose the environment and generate the coverage path by recursively solving each decomposed cell formulated as TSP. A solution to TSP is determined by training Recurrent Neural Network (RNN) with Long Short Term Memory (LSTM) layers using Reinforcement Learning (RL). We validated the proposed method by systematically benchmarked with other conventional methods in terms of path length, execution time, and overlapping rate under four different map layouts with various obstacle density. The results depict that the proposed method outperforms all considered parameters than the conventional schemes. Moreover, simulation experiments demonstrate that the proposed approach is scalable to the larger grid-maps and guarantees complete coverage with efficiently generated coverage paths.",NO
2-s2.0-85098215196,10.4316/AECE.2020.04003,,,Fault Tolerant Distributed Python Software Transactional Memory,ar,Article,Popovic M.,,University of Novi Sad,21000 Novi Sad,Serbia,,,,,2020-01-01,2020,Advances in Electrical and Computer Engineering,15827445,18000156702,18447600,Journal,20,4,,19-28,,,0,1,,,,,NO
2-s2.0-85098000260,10.36897/jme/130944,,,An effective programming by demonstration method for smes’ industrial robots,ar,Article,Eissa A.M.,,"Arab Academy for Science, Technology and Maritime Transport",Alexandria,Egypt,,,,,2020-01-01,2020,Journal of Machine Engineering,18957595,21100781705,23918071,Journal,20,4,,86-98,,,0,1,,,,"Traditional programming methods often require expertise and significant time investment, which does not conform with Small and Medium size Enterprises (SMEs) nature in which High-Mix, Low-Volume (HMLV) orders are usually encountered. In this research, a Programming by Demonstration (PbD) method which aims to reduce the programming time and complexity while keeping a suitable level of execution accuracy is proposed. For this purpose, a special teaching tool is designed and manufactured. The tool has 5-spherical passive markers to indicate the position and orientation along the desired 3D path. An optical tracking system using stereo camera is used to capture the 3D pose of the teaching tool. The capturing algorithm is based on Circle Hough Transform (CHT) and Singular Value Decomposition (SVD). The developed tool and programming method have been tested experimentally. The results show successful capturing of the desired path points with a competitive level of accuracy compared with other methods.",NO
2-s2.0-85096988505,10.3233/JIFS-200869,,,Multi-robot path planning based on improved artificial potential field and fuzzy inference system,ar,Article,Zhao T.,,Sichuan University,Chengdu,China,,,,,2020-01-01,2020,Journal of Intelligent and Fuzzy Systems,10641246,23917,18758967,Journal,39,5,,7621-7637,,,3,0,,,,Note: [1] This work is supported by Chengdu Science and Technology Program (2019-YF05-00958-SN) and Sichuan Science and Technology Program (2020YFG0115).,NO
2-s2.0-85096098282,10.1109/TCDS.2020.3034452,,,Off-policy Deep Reinforcement Learning Based on Steffensen Value Iteration,ar,Article,Cheng Y.,,China University of Mining and Technology,Xuzhou,China,,,,,2020-01-01,2020,IEEE Transactions on Cognitive and Developmental Systems,23798920,21100784665,23798939,Journal,,,,,,,0,0,,,,"As an important machine learning method, deep reinforcement learning (DRL) has been rapidly developed in recent years and has achieved breakthrough results in many fields such as video games, natural language processing, and robot control. However, due to the inherit trial-and-error learning mechanism of reinforcement learning and the time-consuming training of deep neural network itself, the convergence speed of DRL is very slow and consequently limits the real applications of DRL. In this paper, aiming to improve the convergence speed of DRL, we proposed a novel Steffensen value iteration (SVI) method by applying the Steffensen iteration to the value function iteration of off-policy DRL from the perspective of fixed-point iteration. The proposed SVI is theoretically proved to be convergent and have a faster convergence speed than Bellman value iteration. The proposed SVI has versatility, which can be easily combined with existing off-policy RL algorithms. In this paper, we proposed two speedy off-policy DRLs by combining SVI with DDQN and TD3 respectively, namely SVI-DDQN and SVI-TD3. Experiments on several discrete-action and continuous-action tasks from the Atari 2600 and MuJoCo platforms demonstrated that our proposed SVI-based DRLs can achieve higher average reward in a shorter time than the comparative algorithm.",NO
2-s2.0-85092228012,10.4028/www.scientific.net/JERA.50.15,,,An algorithm-centric approach to enhance business process compliance management,ar,Article,Arogundade O.T.,,Federal University of Agriculture,Umuahia,Nigeria,,,,,2020-01-01,2020,International Journal of Engineering Research in Africa,16633571,21100216324,16634144,Journal,50,,,15-28,,,0,0,,,,"The diversity of enterprise domains is one of the significant factors that add to the challenges confronting organizations when managing compliance, and it, therefore, contributes to the cost of compliance. In particular, there is an indication that the inadequacy of a general approach to analyzing compliance documents impedes adequate compliance management practice. Taking an algorithmic-centric approach to tackling this challenge, this paper proposed algorithms and techniques intended to aid useful extraction, classification and analysis of dataflow, control flow, and time constraints in compliance management domain for different stakeholders. The algorithms and techniques were implemented and validated through two case studies and afterward evaluated for its adoption in practice.",NO
2-s2.0-85092087418,10.1177/0278364920959444,,,PAC-Bayes control: learning policies that provably generalize to novel environments,ar,Article,Majumdar A.,,Princeton University,Princeton,United States,,,,,2020-01-01,2020,International Journal of Robotics Research,02783649,18050,17413176,Journal,,,,,,,0,0,,,,"Our goal is to learn control policies for robots that provably generalize well to novel environments given a dataset of example environments. The key technical idea behind our approach is to leverage tools from generalization theory in machine learning by exploiting a precise analogy (which we present in the form of a reduction) between generalization of control policies to novel environments and generalization of hypotheses in the supervised learning setting. In particular, we utilize the probably approximately correct (PAC)-Bayes framework, which allows us to obtain upper bounds that hold with high probability on the expected cost of (stochastic) control policies across novel environments. We propose policy learning algorithms that explicitly seek to minimize this upper bound. The corresponding optimization problem can be solved using convex optimization (relative entropy programming in particular) in the setting where we are optimizing over a finite policy space. In the more general setting of continuously parameterized policies (e.g., neural network policies), we minimize this upper bound using stochastic gradient descent. We present simulated results of our approach applied to learning (1) reactive obstacle avoidance policies and (2) neural network-based grasping policies. We also present hardware results for the Parrot Swing drone navigating through different obstacle environments. Our examples demonstrate the potential of our approach to provide strong generalization guarantees for robotic systems with continuous state and action spaces, complicated (e.g., nonlinear) dynamics, rich sensory inputs (e.g., depth images), and neural network-based policies.",NO
2-s2.0-85090020631,10.1080/10494820.2020.1811734,,,Assessing teachers’ PCK to teach computational thinking via robotic programming,ar,Article,Çakıroğlu Ü.,,Trabzon University,Trabzon,Turkey,,,,,2020-01-01,2020,Interactive Learning Environments,10494820,145681,17445191,Journal,,,,,,,0,0,,,,"Recent years have witnessed an increasing emphasis on integrating computational thinking into school curriculums. This study deals with suggesting a course model including data collection tools for evaluating teachers’ pedagogical content knowledge in teaching computational thinking via teaching robot programming. Taking the advantages of virtual educational robotics, the study addressed some steps to be used during the teacher training sessions. The results provide implications for educators who desire to provide training programs for teachers to prepare them to teach robotics. Using the suggested model, the instructional activities and the assessment tools will be structured for practitioners’ use.",SI
2-s2.0-85089504527,10.1109/ACCESS.2020.3012886,,,An Improved Real-Time Path Planning Method Based on Dragonfly Algorithm for Heterogeneous Multi-Robot System,ar,Article,Ni J.,,Hohai University Changzhou,Changzhou,China,,,,,2020-01-01,2020,IEEE Access,,21100374601,21693536,Journal,8,,9152817,140558-140568,,,4,1,,,,"Heterogeneous multi-robot system is one of the most important research directions in the robotic field. Real-time path planning for heterogeneous multi-robot system under unknown 3D environment is a new challenging research and a hot spot in this field. In this paper, an improved real-time path planning method is proposed for a heterogeneous multi-robot system, which is composed of many unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). In the proposed method, the 3D environment is modelled as a neuron topology map, based on the grid method combined with the bio-inspired neural network. Then a new 3D dynamic movement model for multi-robots is established based on an improved Dragonfly Algorithm (DA). Thus, the movements of the robots are optimized according to the activities of the neurons in the bio-inspired neural network to realize the real-time path planning. Furthermore, some simulations have been carried out. The results show that the proposed method can effectively guide the heterogeneous UAV/UGV system to the target, and has better performance than traditional methods in the real-time path planning tasks.",NO
2-s2.0-85089305471,10.14201/eks.22366,,,"Computational thinking in early childhood education, beyond floor robots",ar,Article,Álvarez-Herrero J.F.,,Universitat d'Alacant,Alicante,Spain,,,,,2020-01-01,2020,Education in the Knowledge Society,,21100903490,24448729,Journal,21,,,,,,3,1,,,,"La robótica educativa, la programación y el pensamiento computacional se están incorporando en las aulas de muchos centros educativos y a cualquier edad. En muchos casos esta incorporación en los planes de estudios está bien argumentada y documentada, pero en otros casos se hace de manera precipitada y sin reflexión previa. En la Educación Infantil, el desarrollo del pensamiento computacional parece haber encontrado en la robótica de suelo una herramienta que permite su mejora y progreso. Con la intención de comprobar si esto es realmente así, se testeó a 50 expertos (docentes en activo, formadores de futuros docentes y técnicos comerciales de robótica educativa) de toda España. De los resultados se desprende que, si bien sí hay un elevado porcentaje de considerar la robótica de suelo como una excelente herramienta para el desarrollo del pensamiento computacional en Educación Infantil, no hay un consenso a la hora de usar otro tipo de prácticas que vayan más allá y que también beneficien dicho proceso de aprendizaje. Por todo ello, consideramos se hace necesario establecer un marco común y unas pautas que posibiliten la correcta implementación de la robótica, la programación y el pensamiento computacional en Educación Infantil. Y ello se basa en ofrecer una formación de calidad que permita desarrollar estos conceptos.",NO
2-s2.0-85088094447,10.3991/ijim.v14i10.14391,,,Implementing web services using PHP soap approach,ar,Article,Hammoudeh M.A.A.,,Al Qassim University,Buraidah,Saudi Arabia,,,,,2020-01-01,2020,International Journal of Interactive Mobile Technologies,18657923,21100394784,,Journal,14,10,,35-45,,,1,1,,,,"Recently, the utilization of IT in the Higher Education institutions has expanded, thus e-Learning must to turn out to be completely embedded into e-Learning and showing practice rather than the traditional approaches to e-Learning. However, this development inside e-Learning frameworks isn't yet completely realized, and the most significant difficulties to this objective are holding students inside instruction and attracting them to take part in Higher Education. One of the methodologies that have been taken to address these difficulties is to utilize the Web services approach to encourage working and participation between Higher Education institutions. Taking account that XML documents are the most commonly applied and successful type of Web services. Being PHP is the best choice for web developers, especially for Web services. This paper will present the proposed approach which aims to expand the current architecture of Web services to meet the technical requirements of the e-Learning framework. It will give an outline of certain strategies that help designers to create SOAP with PHP language. It will portray how to expand PHP Sakai and Moodle to help Web services by utilizing the PHP SOAP method. Besides, it will delineate that this utilization of Web services is a direct advancement of Web programming models, and it will exhibit how PHP can be utilized as a fast and easy development tool for creating them. The spotlight of this paper is to research the expansion of Web services to support PHP Sakai and Moodle by utilizing the PHP SOAP strategy.",NO
2-s2.0-85087966204,10.46300/9106.2020.14.42,,,The reasonable and conscious understanding system of reality under uncertainty,ar,Article,Khayut B.,,Intelligent Decisions Technologies Systems,,Israel,,,,,2020-01-01,2020,"International Journal of Circuits, Systems and Signal Processing",,20000195053,19984464,Journal,14,,,296-308,,,3,1,,,,"The modern autonomous Expert and Statistical Systems of Artificial Intelligence (AI) cannot continuously, independently and consciously think, learn and develop. This is happening because the models, methods and technologies of their processing in these systems cannot synchronously actualized (trained), function, independently, systemically, situationally, continuously, accurately and on their own in the conditions unpredictability, uncertainty of changing situations and lack of data, information and knowledge about the objects during the process of their continuous perception from the fuzzy environmental reality. Consequently, the need arises to create self-learning, self-developing and self-organized computational intelligent systems that continuously perceive and process changing data, information and knowledge in their changing, uncertainty and previously unknown situation in the surrounding reality. To solve the above problems and to create a system of General AI, we offer the new concept of creating a Computational Intelligent System of a Reasonable and Conscious Understanding of reality under uncertainty through of developed by us following models, methods and technologies of: a) perception the reality of environment, b) self-developing memory, c) situational control of data, information, knowledge, objects, models and processes, d) presentation, generalization and explanation of knowledge, e) fuzzy inference, f) decision making, g) reasoning and thinking, h) cognition, and h) Dialog Control in communication with human, robots and systems through of the intelligent interface, which integrating this functionality into a coherent Reasonable and Conscious Understanding System of reality Under Uncertainty",NO
2-s2.0-85086930203,10.28945/4532,,,"Technological structure for technology integration in the classroom, inspired by the maker culture",ar,Article,Silva J.B.,,Universidade Federal de Santa Catarina,Florianopolis,Brazil,,,,,2020-01-01,2020,Journal of Information Technology Education: Research,15479714,21100199856,15393585,Journal,19,,4532,167-204,,,3,1,,,,"Aim/Purpose
This paper presented the framework for the integration of digital technologies in education, implemented in InTecEdu Program, developed by Remote Experimentation Laboratory (RExLab), Federal University of Santa Catarina (UFSC), Brazil.

Background
The main objective of the model presented is to arouse interest in science and technology among adolescents. Therefore, it sought to develop STEM competencies (Science, Technology, Engineering, and Mathematics) in children and adolescents. Understanding learning in STAM areas can favor the development of professionals who can supply the demand in related sectors, especially in the scientific-technological scope. To fulfill the main objective, strategies related to students and teachers were developed. With activities aimed at students, it was hoped to promote vocations to scientific-technological careers and encourage entrepreneurship. On the other hand, the activities related to teachers aimed at training them to integrate technology into their lesson plans. Inspired by the Maker Culture, the model sought to make it possible for teachers to become the main agents in the process of integrating technology in their lesson plans, since they were in charge of building and producing their digital content and other resources to support their didactic activities. The maker movement is a technological extension of the “Do It Yourself!” culture, which encourages ordinary people to build, modify, repair, and manufacture their objects, with their own hands. The training actions were preceded by a diagnosis, inspired by the Technological Pedagogical Content Knowledge (TPACK) model, as well as the lesson plans prepared and made available by the teachers.

Methodology
Methodologically, the framework’s work plan was composed of five Work Packages (WP), which include management, resource mapping, strategies related to teachers, strategies related to students, and the dissemination and exploitation of results. In the 2014-2018 period, 367 teachers participated in training activities, intending to integrate technologies into lesson plans. At the end of 2018, 27 Basic Education schools, including an indigenous and a rural school, from the public-school system, in the states of Santa Catarina, Minas Gerais, and the Rio Grande do Sul, in Brazil, using the project’s Virtual Learning Environment (VLE). In these 70 teachers, 230 classes, and 6,766 students accessed didactic content, produced by teachers, at VLE. Also, 20 laboratories were available in 26 instances, for use in practical activities in disciplines in the STEM areas. Specifically, in the STEM areas, 3,360 students from 98 classes from 9 schools had integrated the Remote Laboratories, in lesson plans in the subjects of Physics and Biology (High School), Science (Elementary School).

Contribution
The main results of the application of the framework are related to the training of human resources, knowledge production, and educational innovation. About the training of human resources, we sought to contribute to the training of teachers concerning technology in education and, with that, arouse greater interest on the part of students, as well as obtain improvements in their learning from teaching methodologies supported on the use of digital technologies. On the other hand, the production of knowledge, in the program and the socialization of research, is favored by the model based on open-source resources, both in terms of software and hardware and with open educational resources. This characteristic favor and expands the potential for reapplying research and, consequently, its contribution to educational innovation.

Findings
The results, about students, indicated an increase in motivation due to the creation of new teaching and learning opportunities. The fact of extending the classroom and school, through remote laboratories, to support practical activities and the use of VLE, was also pointed out as a very positive factor. On the other hand, the realization of the workshops, inspired by practices of the Maker Culture, provided an approximation of these to the skills of the real world, which will certainly favor their employability. Regarding the teachers, it is noticed the continuity and expansion in the use of technological resources in the classroom; many sought and have participated in new training actions.

Recommendations for Practitioners
Provision of a repository of practices for sharing and reuse of lesson plans developed by teachers participating in the research. Technical documents, manuals, and guides for robotics, computer programming, electronics and new technology workshops for students.

Recommendation for Researchers
Technical documents, manuals, and guides for remote laboratories. Data collected in the applied questionnaires. Technical documents, manuals, and guides for robotics, computer programming, electronics and new technology workshops for students.

Impact on Society
The main results of the framework application are related to human resources formation, knowledge production, and educational innovation. Regarding the formation of human resources, we sought to contribute to the formation of teachers concerning technology in education and, about the students the creation of teaching and learning opportunities, to extend the classroom and also the school, through the remote laboratories, to support the practical activities and the use of the VLE.

Future Research
The socialization and reapplication of the framework since it is based on open-source resources, both software and hardware, and with open educational resources.",NO
2-s2.0-85086299613,10.1109/ACCESS.2020.2997636,,,Development and Stability Analysis of an Imitation Learning-Based Pose Planning Approach for Multi-Section Continuum Robot,ar,Article,Seleem I.A.,,Egypt-Japan University of Science and Technology,New Borg El-Arab,Egypt,,,,,2020-01-01,2020,IEEE Access,,21100374601,21693536,Journal,8,,9099824,99366-99379,,,2,1,,,,"Recently, continuum flexible robots have been designed for the use in diverse applications; including the exploration of confined static and dynamic environments. One of the challenging tasks for those robots is planning optimal trajectories due to, not only the redundant Degrees of Freedom (DOF) they own but also their compliant behaviour. In this paper, an Imitation-based Pose Planning (IbPP) approach is proposed to teach a two-section continuum robot the motion primitives that will facilitate achieving and generalizing for spatial point-to-point motion which involves both position and orientation goals encoded in a dual quaternion form. Two novel approaches are proposed in this research to intuitively generate the motion demonstrations that will be used in the proposed IbPP. Namely, a flexible input interface, acting as a twin robot, is designed to allow a human to demonstrate different motions for the robot end-effector. Alternatively, as a second approach, the Microsoft Kinect sensor is used to provide motion demonstrations faster via human arm movements. Based on the kinematic model of the two-section continuum robot, a Model Reference Adaptive Control (MRAC) algorithm is developed to achieve tracking the generated trajectory from the IbPP and to guarantee the robustness against the model uncertainties and external disturbances. Moreover, controller stability analysis is developed based on Lyapunov criteria. Finally, simulations are conducted for the two-section continuum robot to prove the ability of the proposed IbPP with the two proposed inputs to learn and generalize for spatial motions, which in future could be easily accommodated for robots with multiple sections. In addition, the proposed MRAC shows a significant performance towards following the required trajectory and rejecting the external disturbance.",NO
2-s2.0-85085568741,10.1155/2020/7842768,,,Multi-USV System Cooperative Underwater Target Search Based on Reinforcement Learning and Probability Map,ar,Article,Liu Y.,,Shanghai University,Shanghai,China,,,,,2020-01-01,2020,Mathematical Problems in Engineering,1024123X,13082,15635147,Journal,2020,,7842768,,,,4,1,,,,"Unmanned surface vehicle (USV) is a robotic system with autonomous planning, driving, and navigation capabilities. With the continuous development of applications, the missions faced by USV are becoming more and more complex, so it is difficult for a single USV to meet the mission requirements. Compared with a single USV, a multi-USV system has some outstanding advantages such as fewer perceptual constraints, larger operation ranges, and stronger operation capability. In the search mission about multiple stationary underwater targets by a multi-USV system in the environment with obstacles, we propose a novel cooperative search algorithm (CSBDRL) based on reinforcement learning (RL) method and probability map method. CSBDRL is composed of the environmental sense module and policy module, which are organized by the “divide and conquer” policy-based architecture. The environmental sense module focuses on providing environmental sense values by using the probability map method. The policy module focuses on learning the optimal policy by using RL method. In CSBDRL, the mission environment is modeled and the corresponding reward function is designed to effectively explore the environment and learning policies. We test CSBDRL in the simulation environment and compare it with other methods. The results prove that compared with other methods, CSBDRL makes the multi-USV system have a higher search efficiency, which can ensure targets are found more quickly and accurately while ensuring the USV avoids obstacles in time during the mission.",NO
2-s2.0-85084260189,10.5302/J.ICROS.2020.20.0007,,,A study on the implementation of a ball and plate system using lw-rcp and machine vision based on odroid,ar,Article,Park J.,,Inha University,Incheon,South Korea,,,,,2020-01-01,2020,"Journal of Institute of Control, Robotics and Systems",19765622,21100201073,,Journal,26,4,,213-221,,,0,0,,,,"In this paper, we propose the architecture of a ball-and-plate system as an educational platform that can help students comprehensively study control engineering, robotics, machine vision, and embedded systems. In addition, we describe how to implement the sub-systems and present an example of an education plan using the proposed system. In the proposed system, we use an LW-RCP(Light Weight-Rapid Control Prototyping) system, which is lab-built, to help students implement the control algorithm. An RCP system makes it easy for students who are not familiar with u-Controller or the C language to implement controllers. We also use Odroid, a low-cost SBC (single-board computer), and a single camera to calculate the position of ball using a machine vision algorithm. In this structure, the measurement subsystem is more durable compared with contact-based sensing systems and student can test their own machine vision algorithms for better measurements. We adopt the Stewart platform, a type of parallel robot, to generate roll-and-pitch actuation for the ball-and-plate system. By adopting the Stewart platform, we can handle more complicated control problems for movement that requires more than two degrees of freedom. Additionally, we implement an LQ controller, which is a typical model-based controller, and apply it to the ball-plate system. Finally, through experiments, we illustrate the usefulness of the proposed system.
#education platform
#ball-and-plate system
#machine vision
#stewart paltform
#RCP
#u-controller
#SBC
#odroid
#LQ",NO
2-s2.0-85084080343,10.3991/IJET.V15I05.12173,,,Implementing bloom's taxonomy tool for better learning outcomes of plc and robotics course,ar,Article,Gummineni M.,,"SR Engineering College, Warangal",Warangal,India,,,,,2020-01-01,2020,International Journal of Emerging Technologies in Learning,18688799,21100197967,18630383,Journal,15,5,,184-192,,,1,1,,,,"Instrumentation subject has a major and vital role in the industrial field. The concepts of sensors, actuators, signal interface, and conditioning, programming the microprocessor and microcontroller are the most important requisites to comprehend and contribute to the real-world application. The application of these concepts is PLC and Robotics course where the students can apply and practical experience the output. To design a project and to implement we need multidisciplinary concepts and sequence of steps viz., defining an idea, requirements and the fabricating parts to bring out a visual structure in order to perform an intended function. To inculcate this culture it’s much more important to follow and implement the standard and well-known methodology called Bloom’s taxonomy in the classroom environment for a better outcome of the course. Current leading technology PLC and Robotics course, (which require prerequisite knowledge of courses like Instrumentation, Microprocessors, Mechatronics) are very well connected for applying the gained concepts to continue the stream of the learning process. The paper presents how to bring better learning Outcomes and also create interest in the course PLC and Robotics by implementing Bloom’s taxonomy by conducting activities in the classroom.",NO
2-s2.0-85082306006,10.1109/ACCESS.2020.2974498,,,An Improved Chicken Swarm Optimization Algorithm and its Application in Robot Path Planning,ar,Article,Liang X.,,Beijing University Of Civil Engineering And Architecture,Beijing,China,,,,,2020-01-01,2020,IEEE Access,,21100374601,21693536,Journal,8,,9000844,49543-49550,,,11,1,,,,"Chicken swarm optimization (CSO) algorithm is one of very effective intelligence optimization algorithms, which has good performance in solving global optimization problems (GOPs). However, the CSO algorithm performs relatively poorly in complex GOPs for some weaknesses, which results the iteration easily fall into a local minimum. An improved chicken swarm optimization algorithm (ICSO) is proposed and applied in robot path planning. Firstly, an improved search strategy with Levy flight characteristics is introduced in the hen's location update formula, which helps to increase the perturbation of the proposed algorithm and the diversity of the population. Secondly, a nonlinear weight reduction strategy is added in the chicken's position update formula, which may enhance the chicken's self-learning ability. Finally, multiple sets of unconstrained functions are used and a robot simulation experimental environment is established to test the ICSO algorithm. The numerical results show that, comparing to particle swarm optimization (PSO) and basic chicken swarm optimization (CSO), the ICSO algorithm has better convergence accuracy and stability for unconstrained optimization, and has stronger search capability in the robot path planning.",NO
2-s2.0-85082173319,10.1109/ACCESS.2020.2978077,,,The experience-memory Q-Learning algorithm for robot path planning in unknown environment,ar,Article,Zhao M.,,Beihang University,Beijing,China,,,,,2020-01-01,2020,IEEE Access,,21100374601,21693536,Journal,8,,9022975,47824-47844,,,3,1,,,,"In order to solve the problem of slow convergence speed and long planned path when the robot plans a path in unknown environment by using Q-learning algorithm, we propose the Experience-Memory Q-Learning (EMQL) algorithm based on the continuous update of the shortest distance from the current state node to the start point. The autonomous learning ability of the robot is enhanced by the different role assignments of two tables in the proposed algorithm. EM table with 
(m∗1)
 dimension is designed to record the distance information, reflecting the learning process of the robot. Q table is adopted as an auxiliary guidance for the experience transfer strategy and experience reuse strategy, and these strategies enable the robot accomplish the task even if the destination is changed or the path is blocked. Further, the learning efficiency of the robot in the EMQL algorithm is improved by the dual reward mechanism consisting of static reward and dynamic reward. The static reward is designed to prevent the robot from exploring a state node excessively. The dynamic reward is responsible for helping the robot avoid searching blindly in unknown environment. We test the effectiveness of the proposed algorithm on both grid maps and road network maps. The comparison results in planning time, iteration times and path length show that the performance of the EMQL algorithm is superior to Q-learning algorithm in convergence speed and optimization ability. Additionally, the practicability of the proposed algorithm is validated in a real-world experiment using the Turtlebot3 burger robot.",NO
2-s2.0-85081113053,10.1109/ACCESS.2020.2974051,,,Two-Step CNN Framework for Text Line Recognition in Camera-Captured Images,ar,Article,Chernyshova Y.S.,,Federal Research Center Informatics and Management of the Russian Academy of Sciences;Smart Engines Service LLC,Moscow;Moscow,Russian Federation;Russian Federation,,,,,2020-01-01,2020,IEEE Access,,21100374601,21693536,Journal,8,,8999509,32587-32600,,,26,1,,,,"In this paper, we introduce an “on the device” text line recognition framework that is designed for mobile or embedded systems. We consider per-character segmentation as a language-independent problem and individual character recognition as a language-dependent one. Thus, the proposed solution is based on two separate artificial neural networks (ANN) and dynamic programming instead of employing image processing methods for the segmentation step or end-to-end ANN. To satisfy the tight constraints on memory size imposed by embedded systems and to avoid overfitting, we employ ANNs with a small number of trainable parameters. The primary purpose of our framework is the recognition of low-quality images of identity documents with complex backgrounds and a variety of languages and fonts. We demonstrate that our solution shows high recognition accuracy on natural datasets even being trained on purely synthetic data. We use MIDV-500 and Census 1961 Project datasets for text line recognition. The proposed method considerably surpasses the algorithmic method implemented in Tesseract 3.05, the LSTM method (Tesseract 4.00), and unpublished method used in the ABBYY FineReader 15 system. Also, our framework is faster than other compared solutions. We show the language-independence of our segmenter with the experiment with Cyrillic, Armenian, and Chinese text lines.",NO
2-s2.0-85079752882,10.1109/ACCESS.2020.2972410,,,LearnBlock: A Robot-Agnostic Educational Programming Tool,ar,Article,Bachiller-Burgos P.,,Universidad de Extremadura,Badajoz,Spain,,,,,2020-01-01,2020,IEEE Access,,21100374601,21693536,Journal,8,,8986589,30012-30026,,,4,1,,,,"Education is evolving to prepare students for the current sociotechnical changes. An increasing effort to introduce programming and other STEM-related subjects into the core curriculum of primary and secondary education is taking place around the world. The use of robots stands out among STEM initiatives, since robots are proving to be an engaging tool for learning programming and other STEM-related contents. Block-based programming is the option chosen for most educational robotic platforms. However, many robotics kits include their own software tools, as well as their own set of programming blocks. LearnBlock, a new educational programming tool, is proposed here. Its major novelty is its loosely coupled software architecture which makes it, to the best of our knowledge, the first robot-agnostic educational tool. Robot-agnosticism is provided not only in block code, but also in generated code, unifying the translation from blocks to the final programming language. The set of blocks can be easily extended implementing additional Python functions, without modifying the core code of the tool. Moreover, LearnBlock provides an integrated educational programming environment that facilitates a progressive transition from a visual to a general-purpose programming language. To evaluate LearnBlock and demonstrate that it is platform-agnostic, several tests were conducted. Each of them consists of a program implementing a robot behaviour. The block code of each test can run on several educational robots without changes.",SI
2-s2.0-85079382903,10.11591/ijece.v10i3.pp3066-3073,,,Trajectory reconstruction for robot programming by demonstration,ar,Article,Elhachemi Amar R.H.,,Université des Sciences et de la Technologie d’Oran Mohamed-Boudiaf,Oran,Algeria,,,,,2020-01-01,2020,International Journal of Electrical and Computer Engineering,20888708,21100373959,,Journal,10,3,,3066-3073,,,1,1,,,,The reproduction of hand movements by a robot remains difficult and conventional learning methods do not allow us to faithfully recreate these movements because it is very difficult when the number of crossing points is very large. Programming by Demonstration gives a better opportunity for solving this problem by tracking the user’s movements with a motion capture system and creating a robotic program to reproduce the performed tasks. This paper presents a Programming by Demonstration system in a trajectory level for the reproduction of hand/tool movement by a manipulator robot; this was realized by tracking the user’s movement with the ArToolkit and reconstructing the trajectories by using the constrained cubic spline. The results obtained with the constrained cubic spline were compared with cubic spline interpolation. Finally the obtained trajectories have been simulated in a virtual environment on the Puma 600 robot.,NO
2-s2.0-85079037644,10.3390/mi11010071,,,Collaboration and task planning of turtle-inspired multiple amphibious spherical robots,ar,Article,Zheng L.,,Jilin Agricultural Science and Technology University;Kagawa University;Changchun University of Science and Technology,Jilin;Takamatsu;Changchun,China;Japan;China,,,,,2020-01-01,1 January 2020,Micromachines,,21100229176,2072666X,Journal,11,1,71,,,,13,1,,,,"Amphibious Spherical Robots (ASRs) use an electric field to communicate and collaborate effectively in a turbid water of confined spaces where other mode communication modalities failed. This paper proposes an embedded architecture formation strategy for a group of turtle-inspired amphibious robots to maintain a long distance-parameterized path based on dynamic visual servoing. Inspired by this biological phenomenon, we design an artificial multi-robot cooperative mode and explore an electronic communication and collaborate devices, the control method is based in particular on underwater environment and also conduct a detailed analysis of control motion module. The objectives of control strategies are divided into four categories: The first strategy is that the leader robot controls the action of the overall robots to maintain collaborate together during motion along a desired geometric path and to follow a timing law that the communication efficiency and the arrival times to assigned sites. Furthermore, we design an adaptive visual servoing controller for trajectory tracking task, taking into account system dynamics with environment interactions. After that, the third strategy is a centralized optimization algorithm for the redistribution of target mission changes. Finally, this paper also proposes a new method of control strategies in order to guarantee that each robot in the team moves together according to the preset target toward its location in the group formation based on communication and stability modules. View Full-Text",NO
2-s2.0-85078670070,10.1155/2020/3849309,,,Learning from Demonstrations and Human Evaluative Feedbacks: Handling Sparsity and Imperfection Using Inverse Reinforcement Learning Approach,ar,Article,Mourad N.,,University of Tehran,Tehran,Iran,,,,,2020-01-01,2020,Journal of Robotics,16879600,21100301602,16879619,Journal,2020,,3849309,,,,0,1,,,,"Programming by demonstrations is one of the most efficient methods for knowledge transfer to develop advanced learning systems, provided that teachers deliver abundant and correct demonstrations, and learners correctly perceive them. Nevertheless, demonstrations are sparse and inaccurate in almost all real-world problems. Complementary information is needed to compensate these shortcomings of demonstrations. In this paper, we target programming by a combination of nonoptimal and sparse demonstrations and a limited number of binary evaluative feedbacks, where the learner uses its own evaluated experiences as new demonstrations in an extended inverse reinforcement learning method. This provides the learner with a broader generalization and less regret as well as robustness in face of sparsity and nonoptimality in demonstrations and feedbacks. Our method alleviates the unrealistic burden on teachers to provide optimal and abundant demonstrations. Employing an evaluative feedback, which is easy for teachers to deliver, provides the opportunity to correct the learner’s behavior in an interactive social setting without requiring teachers to know and use their own accurate reward function. Here, we enhance the inverse reinforcement learning () to estimate the reward function using a mixture of nonoptimal and sparse demonstrations and evaluative feedbacks. Our method, called  from demonstration and human’s critique (), has two phases. The teacher first provides some demonstrations for the learner to initialize its policy. Next, the learner interacts with the environment and the teacher provides binary evaluative feedbacks. Taking into account possible inconsistencies and mistakes in issuing and receiving feedbacks, the learner revises the estimated reward function by solving a single optimization problem. The  is devised to handle errors and sparsities in demonstrations and feedbacks and can generalize different combinations of these two sources expertise. We apply our method to three domains: a simulated navigation task, a simulated car driving problem with human interactions, and a navigation experiment of a mobile robot. The results indicate that the  significantly enhances the learning process where the standard  methods fail and learning from feedbacks () methods has a high regret. Also, the  works well at different levels of sparsity and optimality of the teacher’s demonstrations and feedbacks, where other state-of-the-art methods fail.",NO
2-s2.0-85078442738,10.1063/1.5136351,,,Feature engineering and symbolic regression methods for detecting hidden physics from sparse sensor observation data,ar,Article,Vaddireddy H.,,Oklahoma State University,Stillwater,United States,,,,,2020-01-01,1 January 2020,Physics of Fluids,10706631,29210,10897666,Journal,32,1,015113,,,,16,0,,,,"We put forth a modular approach for distilling hidden flow physics from discrete and sparse observations. To address functional expressiblity, a key limitation of the black-box machine learning methods, we have exploited the use of symbolic regression as a principle for identifying relations and operators that are related to the underlying processes. This approach combines evolutionary computation with feature engineering to provide a tool for discovering hidden parameterizations embedded in the trajectory of fluid flows in the Eulerian frame of reference. Our approach in this study mainly involves gene expression programming (GEP) and sequential threshold ridge regression (STRidge) algorithms. We demonstrate our results in three different applications: (i) equation discovery, (ii) truncation error analysis, and (iii) hidden physics discovery, for which we include both predicting unknown source terms from a set of sparse observations and discovering subgrid scale closure models. We illustrate that both GEP and STRidge algorithms are able to distill the Smagorinsky model from an array of tailored features in solving the Kraichnan turbulence problem. Our results demonstrate the huge potential of these techniques in complex physics problems, and reveal the importance of feature selection and feature engineering in model discovery approaches.",NO
2-s2.0-85076405909,10.11591/ijece.v10i2.pp2200-2207,,,A cognitive robot equipped with autonomous tool innovation expertise,ar,Article,Wicaksono H.,,Universitas Kristen Petra,"Surabaya, East Java",Indonesia,,,,,2020-01-01,2020,International Journal of Electrical and Computer Engineering,20888708,21100373959,,Journal,10,2,,2200-2207,,,0,1,,,,"Like a human, a robot may benefit from being able to use a tool to solve
a complex task. When an appropriate tool is not available, a very useful ability for a robot is to create a novel one based on its experience.
With the advent of inexpensive 3D printing, it is now possible to give robots such an ability, at least to create simple tools. We proposed a method for learning how to use an object as a tool and, if needed, to design and construct a new tool. The robot began by learning an action model of tool use for
a PDDL planner by observing a trainer. It then refined the model by learning by trial and error. Tool creation consisted of generalising an existing tool model and generating a novel tool by instantiating the general model. Further learning by experimentation was performed. Reducing the search space of potentially useful tools could be achieved by providing a tool ontology.
We then used a constraint solver to obtain numerical parameters from abstract descriptions and use them for a ready-to-print design. We evaluated our system using a simulated and a real Baxter robot in two cases: hook and wedge. We found that our system performs tool creation successfully.",NO
2-s2.0-85076090666,10.1007/s11370-019-00302-w,,,Contribution to the path planning of a multi-robot system: centralized architecture,ar,Article,Matoui F.,,National School of Engineers of Gabes,Gabes,Tunisia,,,,,2020-01-01,1 January 2020,Intelligent Service Robotics,18612776,9500154152,18612784,Journal,13,1,,147-158,,,5,0,,,,"The current study is set to investigate the problem of planning trajectories for a multi-robot system in a dynamic environment. The planning study is conducted in a “barrier-free” and “with obstacle” environment, based on the artificial potential field (APF) technique. This study seeks to improve the APF method in order to have good trajectory planning of a multi-robot system. Also, for multi-robot mobile systems, one of the main technical considerations is the technique used to coordinate the movements of different robots. In this paper, we proposed a centralized architecture for the trajectory planning of a multi-robot system.",NO
2-s2.0-85075951428,10.1002/cae.22184,,,Robotic system education for young children by collaborative-project-based learning,ar,Article,Jawaid I.,,University of Central Punjab,Lahore,Pakistan,,,,,2020-01-01,1 January 2020,Computer Applications in Engineering Education,10613773,18156,10990542,Journal,28,1,,178-192,,,9,0,,,,"This paper presents the fusion of project-based learning (PBL) and collaborative learning (CL) cohesively, coordinated with sensors and Bluetooth advancements, open-source programming, and open-source equipment devices, in a specific microcontroller and installed frameworks designing apply autonomy course for the elementary learners. The major purpose of this study is to evaluate the significance of integrating PBL and CL. The course creates capacities and abilities in critical thinking, problem-solving, independent learning, collaboration, and specialized technical information. Since PBL alone does not guarantee profoundly talented cooperation, it was supplemented with CL. This structure coordinated course substance and understudy pragmatic accomplishment in a reenacted learning environment. The understudies built a line following and Bluetooth-controlled robots by actualizing control programming on the “Arduino” open-source platform, just as utilizing remote interchanges as Arduino offers an instinctive advancement condition and different equipment and programming resources that permit quick improvement of microcontroller-based ventures. The basic findings of this study work reveal that teaching, learning, and student assessment processes can be improved by using PBL when integrated with CL. The research successfully extends onto another group of learners for preparing similar gadgets under different timelines. In addition, this paper also discusses upon the problem identification, selection of the equipment, circuit design, hardware mounting, and critical analysis of the results acquired from the course through the personal learning experience of the teachers as well as in the form of feedback from the two groups of young learners.",SI
2-s2.0-85075852936,10.1016/j.compag.2019.105096,S0168169919309172,,A fast modeling and optimization scheme for greenhouse environmental system using proper orthogonal decomposition and multi-objective genetic algorithm,ar,Article,Li K.,,Jiangsu University,Zhenjiang,China,,,,,2020-01-01,January 2020,Computers and Electronics in Agriculture,01681699,30441,,Journal,168,,105096,,,,5,0,,,,"Highlights

•

Introduce a proper orthogonal decomposition (POD) method for greenhouse climate modeling.

•

Propose a fast POD - NSGA-II scheme for multi-objectives optimization with high spatial resolution.

•

CFD model validation of a real greenhouse using sensor matrix in East China is carried out.

•

Error analysis of POD and multi-dimensional interpolation method is presented.

•

Discussion on the obtained environmental Pareto frontier is conducted.
As a semi-closed ecosystem, environmental factors of greenhouses are mutual coupling, spacial distributed, and with high uncertainty. Considering the optimal environment for crop growth with energy efficiency, the optimization schemes of the greenhouse systems are studied in this paper. Different from current optimization methods, most of which are based on expert experience and parameter learning, we introduce Proper Orthogonal Decomposition (POD) technique for environmental parameters’ description. On this basis, a fast optimization scheme for greenhouse environmental system is proposed. In this method, several low-dimensional parameter subspaces of greenhouse environment are constructed using POD technique. They may be embedded into optimization loop for fast solving environment response. In our case study, NSGA-II algorithm is applied for the optimization of a real greenhouse’s environment. The multiple objectives include crop area’s temperature distribution, carbon dioxide concentration and related energy consumption. Results show that the proposed optimization strategy has low computation cost and high space resolution, which can effectively improve the crop growth’s environmental performances and save the energy consumption as well.",NO
2-s2.0-85074599166,10.1007/s10514-019-09891-y,,,Learning quasi-periodic robot motions from demonstration,ar,Article,Li X.,,Northeastern University,Shenyang,China,,,,,2020-01-01,1 January 2020,Autonomous Robots,09295593,18016,15737527,Journal,44,2,,251-266,,,1,0,,,,"The goal of Learning from Demonstration is to automatically transfer the skill knowledge from human to robot. Current researches focus on the problem of modeling aperiodic/periodic robot motions and extracting dynamic task parameters from the recorded sensory information. However, it is still not adequate for describing complex behaviors in an unstructured environment, such as searching for an unknown fitting position or painting/polishing an irregular surface. The quasi-periodic and stochastic properties cause a high demand for generalization ability of the modeling techniques. This paper proposes a systematic framework for learning quasi-periodic robot motions, which contains three steps: decomposition, modeling, and synthesization. Firstly FFT transform is performed to identify all the frequencies in the quasi-periodic motion. Then the motion is decomposed into an offset component, a series of harmonic and corresponding envelop components based on the concept of equivalent transformation. The offset component is extracted by Empirical Mode Decomposition, harmonic is separated by notch filter, and envelope component is extracted by Hilbert Transform. These components are either periodic or aperiodic. The aperiodic motions can be modeled by conventional techniques such as Gaussian Mixture Model and recovered by Gaussian Mixture Regression. The periodic motions are modeled in closed-form expressions. Finally, they are synthesized together to regenerate the robot motion. This modeling process captures both the aperiodicity and periodicity of a quasi-periodic motion. Simulation and experiment show that the proposed methods are feasible, effective and can predict robot motions beyond demonstrations. With this generalization ability, it is able to reduce the programming difficulty and demonstration complexity.",NO
2-s2.0-85072773298,10.1109/LRA.2019.2943818,,,A Cerebellar Internal Models Control Architecture for Online Sensorimotor Adaptation of a Humanoid Robot Acting in a Dynamic Environment,ar,Article,Capolei M.,,Technical University of Denmark,Lyngby,Denmark,,,,,2020-01-01,January 2020,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,5,1,8848431,80-87,,,8,0,,,,"-Humanoid robots are often supposed to operate in non-deterministic human environments, and as a consequence, the robust and gentle rejection of the external perturbations is extremely crucial. In this scenario, stable and accurate behavior is mostly solved through adaptive control mechanisms that learn an internal model to predict the consequences of the outgoing control signals. Evidences show that brain-based biological systems resolve this control issue by updating an appropriate internal model that is then used to direct the muscles activities. Inspired by the biological cerebellar internal models theory, that couples forward and inverse internal models into the biological motor control scheme, we propose a novel methodology to artificially replicate these learning and adaptive principles into a robotic feedback controller. The proposed cerebellar-like network combines machine learning, artificial neural network, and computational neuroscience techniques to deal with all the nonlinearities and complexities that modern robotic systems could present. Although the architecture is tested on the simulated humanoid iCub, it can be applied to different robotic systems without excessive customization, thanks to its neural network-based nature. During the experiments, the robot is requested to follow repeatedly a movement while it is interacting with two external systems. Four different internal model architectures are compared and tested under different conditions. The comparison of the performances confirmed the theories about internal models combinatory action. The combination of models together with the structural and learning features of the network, resulted in a benefit to the adaptation mechanism, but also the system response to nonlinearities, noise and external forces.",NO
2-s2.0-85064672169,10.1007/s12369-019-00548-5,,,Can Human-Inspired Learning Behaviour Facilitate Human–Robot Interaction?,ar,Article,Carfì A.,,"Dipartimento di Informatica, Bioingegneria, Robotica e Ingegneria dei Sistemi",Genoa,Italy,,,,,2020-01-01,1 January 2020,International Journal of Social Robotics,18754791,19500157063,18754805,Journal,12,1,,173-186,,,4,0,,,,"The evolution of production systems for smart factories foresees a tight relation between human operators and robots. Specifically, when robot task reconfiguration is needed, the operator must be provided with an easy and intuitive way to do it. A useful tool for robot task reconfiguration is Programming by Demonstration (PbD). PbD allows human operators to teach a robot new tasks by showing it a number of examples. The article presents two studies investigating the role of the robot in PbD. A preliminary study compares standard PbD with human–human teaching and suggests that a collaborative robot should actively participate in the teaching process as human practitioners typically do. The main study uses a wizard of oz approach to determine the effects of having a robot actively participating in the teaching process, specifically by controlling the end-effector. The results suggest that active behaviour inspired by humans can lead to a more intuitive PbD.",NO
2-s2.0-85028930977,10.1109/TETC.2017.2729585,,,Design and Evaluation of a Block-based Environment with a Data Science Context,ar,Article,Bart A.C.,,Virginia Polytechnic Institute and State University,Blacksburg,United States,,,,,2020-01-01,January-March 2020,IEEE Transactions on Emerging Topics in Computing,,21100338508,21686750,Journal,8,1,7987028,182-192,,,4,0,,,,"As computing becomes pervasive across fields, introductory computing curricula needs new tools to motivate and educate the influx of learners with little prior background and divergent goals. We seek to improve curricula by enriching it with authentic, real-world contexts and powerful scaffolds that can guide learners to success using automated tools, thereby reducing the strain on limited human instructional resources. To address these issues, we have created the BlockPy programming environment, a web-based, open-access, open-source platform for introductory computing students (https://www.blockpy.com). BlockPy has an embedded data science context that allows learners to connect the educational content with real-world scenarios through meaningful problems. The environment is block-based and gives guiding feedback to learners as they complete problems, but also mediates transfer to more sophisticated programming environments by supporting bidirectional, seamless transitions between block and text programming. Although it can be used as a stand-alone application, the environment has first-class support for the latest Learning Tools Interoperability standards, so that instructors can embed the environment directly within their Learning Management System. In this paper, we describe interesting design issues that we encountered during the development of BlockPy, an evaluation of the environment from fine-grained logs, and our future plans for the environment.",NO
2-s2.0-85116714540,10.1016/j.neunet.2021.09.011,S0893608021003610,,World model learning and inference,ar,Article,Friston K.,,UCL Queen Square Institute of Neurology,London,United Kingdom,,,,,2021-12-01,December 2021,Neural Networks,08936080,24804,18792782,Journal,144,,,573-590,,,0,1,,,,"Understanding information processing in the brain—and creating general-purpose artificial intelligence—are long-standing aspirations of scientists and engineers worldwide. The distinctive features of human intelligence are high-level cognition and control in various interactions with the world including the self, which are not defined in advance and are vary over time. The challenge of building human-like intelligent machines, as well as progress in brain science and behavioural analyses, robotics, and their associated theoretical formalisations, speaks to the importance of the world-model learning and inference. In this article, after briefly surveying the history and challenges of internal model learning and probabilistic learning, we introduce the free energy principle, which provides a useful framework within which to consider neuronal computation and probabilistic world models. Next, we showcase examples of human behaviour and cognition explained under that principle. We then describe symbol emergence in the context of probabilistic modelling, as a topic at the frontiers of cognitive robotics. Lastly, we review recent progress in creating human-like intelligence by using novel probabilistic programming languages. The striking consensus that emerges from these studies is that probabilistic descriptions of learning and inference are powerful and effective ways to create human-like artificial intelligent machines and to understand intelligence in the context of how humans interact with their world.",NO
2-s2.0-85109668903,10.1016/j.patcog.2021.108136,S003132032100323X,,Human trajectory prediction and generation using LSTM models and GANs,ar,Article,Rossi L.,,Università Politecnica delle Marche,Ancona,Italy,,,,,2021-12-01,December 2021,Pattern Recognition,00313203,24823,,Journal,120,,108136,,,,2,0,,,,"Highlights

•

New deep neural network models are proposed for trajectory prediction.

•

LSTM and GAN1 models are used for unimodal predictions, GAN3 model for multimodal.

•

Metrics are proposed for normalizing errors for more consistent comparisons.

•

New dataset are proposed with low linearity and a high diversity.
Human trajectory prediction is an important topic in several application domains, ranging from self-driving cars to environment design and planning, from socially-aware robots to intelligent tracking systems. This complex subject comes with different challenges, such as human-space interaction, human-human interaction, multimodality, and generalizability. Currently, these challenges, especially generalizability, have not been completely explored by state-of-the-art works. This work attempts to fill this gap by proposing and defining new methods and metrics to help understand trajectories. In particular, new deep learning models based on Long Short-Term Memory and Generative Adversarial Network architectures are used in both unimodal and multimodal contexts. These approaches are evaluated with new error metrics, which normalize some biases in standard metrics. Tests have been assessed using newly collected datasets characterized by a higher diversity and lower linearity than those used in state-of-the-art works. The results prove that the proposed models and datasets are comparable to and yield better generalizability than state-of-the-art works. Moreover, we also prove that our datasets better represent multimodal scenarios (allowing for multiple possible behaviors) and that human trajectories are moderately influenced by their spatial region and slightly influenced by their date and time.",NO
2-s2.0-85108369484,10.1007/s40692-021-00190-z,,,Effect of Scratch on computational thinking skills of Chinese primary school students,ar,Article,Jiang B.,,East China Normal University,Shanghai,China,,,,,2021-12-01,December 2021,Journal of Computers in Education,21979987,21100922758,21979995,Journal,8,4,,505-525,,,1,0,,,,"This study aimed to analyze the effects of Scratch language learning on the computational thinking skills (creativity, algorithmic thinking, cooperativity, critical thinking, and problem solving) of primary school students. We conducted an experiment with 336 Chinese primary students studying in fifth grade. At the beginning of the experiment, all students were required to complete the Computational Thinking Scale (CTS) to measure their CT skills. During the 5 weeks of lesson learning, all students were taught with the same instruction strategy and curriculum. Finally, they appeared for the CTS test again. The research findings indicate that there was a significant difference in the skills of creativity, cooperativity, and critical thinking. However, in this study, Scratch learning did not cause any significant differences in the problem-solving and algorithmic thinking skills of primary school students. Moreover, in both tests, while the girls scored lower than the boys in most skills, they were at the same significance level in most cases. Finally, we suggest providing students with more meaningful programming problems to practice and encourage teachers to combine Scratch with other subjects, such as mathematics and robotic programming.",NO
2-s2.0-85107923236,10.1016/j.rcim.2021.102199,S073658452100082X,,Impedance controlled human–robot collaborative tooling for edge chamfering and polishing applications,ar,Article,Kana S.,,School of Mechanical and Aerospace Engineering,Singapore City,Singapore,,,,,2021-12-01,December 2021,Robotics and Computer-Integrated Manufacturing,07365845,18080,,Journal,72,,102199,,,,1,0,,,,"Highlights

•

A curve tracing approach, where an impedance-controlled robot undergoes a constrained motion along a parametric-curve in response to an external force (from human–robot physical interaction for collaborative operation).

•

Application of the proposed framework to collaboratively carry out standard industrial tooling tasks such as edge-chamfering and edge-polishing to achieve improved surface quality.

•

The tool trajectory generation with minimal end-user programming/re-programming.
Surface finishing, as the final stage in the manufacturing pipeline, is a key process in determining the quality and life span of a product. Such a task is characterized by low contact forces and minimal material removal from the object surface. Despite the advancements in machine learning and artificial intelligence, human workforce is still irreplaceable in performing such tasks due to superior dexterity and adaptability, but this is often prone to risks such as hand-arm vibration syndrome due to hand-held tools. Therefore, we propose a collaborative approach to assist the human in carrying out such tasks with the help of two case studies: Human–Robot-Collaborative edge chamfering and polishing tasks, based on an impedance controlled collaborative curve tracing technique.

We propose a collaborative framework, where the robot assists an operator to guide the end-effector/tool along a pre-defined parametric curve. The algorithm is demonstrated in two scenarios. In the first case, we address a collaborative chamfering task whereas the second case focuses on a polishing application (for straight edges). For these kinds of tasks, the curve to be traced assumes the shape of a straight line along the edge. We make use of the compliant feature of a cobot, which allows the user to physically guide the robot in the task space, to generate a mathematical model for the tool path. From the end-user perspective, this is more intuitive than the classical programming-based path planning approaches. In the process of machining, to enhance the path tracking accuracy and to ensure constant tool-surface contact, we implement guidance virtual fixtures through impedance control. As a result, the machining error is reduced.",NO
2-s2.0-85098767474,10.1109/TIE.2020.3044776,,,Nonlinear Model Predictive Control for Mobile Medical Robot Using Neural Optimization,ar,Article,Hu Y.,,"Fakultät für Informatik, Technische Universität München",Garching bei Munchen,Germany,,,,,2021-12-01,December 2021,IEEE Transactions on Industrial Electronics,02780046,26053,15579948,Journal,68,12,9305985,12636-12645,,,1,0,,,,"Mobile medical robots have been widely used in various structured scenarios, such as hospital drug delivery, public area disinfection, and medical examinations. Considering the challenge of environment modeling and controller design, how to achieve the information from the human demonstration in a structured environment directly arouse our interests. Learning skills is a powerful way that can reduce the complexity of algorithm in searching space. This is especially true when naturally acquiring new skills, as mobile medical robot must learn from the interaction with a human being or the environment with limited programming effort. In this article, a learning scheme with nonlinear model predictive control (NMPC) is proposed for mobile robot path tracking. The learning-by-imitation system consists of two levels of hierarchy: in the first level, a multivirtual spring-dampers system is presented for imitation of the mobile robot's trajectories; and in the second level, the NMPC method is used in the motion control system. The NMPC strategy utilizes a varying-parameter one-layer projection neural network to solve an online quadratic programming optimization via iteration over a limited receding horizon. The proposed algorithm is evaluated on a mobile medical robot with an emulated trajectory in simulation and three scenarios used in the experiment.",NO
2-s2.0-85114032838,10.1061/(ASCE)CP.1943-5487.0000988,,,Interactive and Immersive Process-Level Digital Twin for Collaborative Human-Robot Construction Work,ar,Article,Wang X.,,"University of Michigan, Ann Arbor",Ann Arbor,United States,,,,,2021-11-01,1 November 2021,Journal of Computing in Civil Engineering,08873801,18643,19435487,Journal,35,6,04021023,,,,0,0,,,,"Human cognition plays a critical role in construction work, particularly in the context of high-level task planning and in-field improvisation. On the other hand, robots are adept at performing numerical computation and repetitive physical tasks with precise motion control. The unstructured and complex nature of construction environments and the inability to maintain tight tolerances in assembled workpieces pose several unique challenges to the wide application of robots in construction work. Thus, the robotization of field construction processes is best conceived as a collaborative human–robot endeavor that takes advantage of both human and robot intelligence as well as robots’ physical operation capabilities to overcome uncertainties and successfully perform useful construction work onsite. This paper proposes an interactive and immersive process-level digital twin (I2PL-DT) system in virtual reality (VR) that integrates visualization and supervision, task planning and execution, and bidirectional communication to enable collaborative human–robot construction work. In this work paradigm, the human worker is responsible for high-level task planning and work process supervision. The robot undertakes workspace sensing and monitoring, detailed motion planning, and physical execution of the work. A drywall installation case study involving imperfect rough carpentry (wall framing) is presented using a KUKA mobile industrial robotic arm emulator. A human-in-the-loop study involving 20 subjects was conducted for system verification and to collect feedback for future improvements. The experimental results show that users can use the system to specify work sequences, select optimal task plans, and perform robot trajectory guidance after simple training and felt positive about the system functions and user experience. The system demonstrates the potential of transitioning the role of construction workers from physical task performers to robot supervisors. In addition, the system establishes a promising framework for construction workers to remotely collaborate with onsite construction robots.",NO
2-s2.0-85111331392,10.1016/j.robot.2021.103845,S0921889021001305,,Designing user-centric programming aids for kinesthetic teaching of collaborative robots,ar,Article,Ajaykumar G.,,Johns Hopkins University,Baltimore,United States,,,,,2021-11-01,November 2021,Robotics and Autonomous Systems,09218890,18079,,Journal,145,,103845,,,,0,0,,,,"Just as end-user programming has helped make computer programming accessible for a variety of users and settings, end-user robot programming has helped empower end-users without specialized knowledge or technical skills to customize robotic assistance that meets diverse environmental constraints and task requirements. While end-user robot programming methods such as kinesthetic teaching have introduced direct approaches to task demonstration that allow users to avoid working with traditional programming constructs, our formative study revealed that everyday people still have difficulties in specifying effective robot programs using these methods due to challenges in understanding robot kinematics and programming without situated context and assistive system feedback. These findings informed our development of Demoshop, an interactive robot programming tool that includes user-centric programming aids to help end-users author and edit task demonstrations. To evaluate the effectiveness of Demoshop, we conducted a user study comparing task performance and user experience associated with using Demoshop relative to a widely used commercial baseline interface. Results of our study indicate that users have greater task efficiency while authoring robot programs and maintain stronger mental models of the system when using Demoshop compared to the baseline interface. Our system implementation and study have implications for the further development of assistance in end-user robot programming.",NO
2-s2.0-85106337348,10.1111/exsy.12734,,,A fixed structure learning automata-based optimization algorithm for structure learning of Bayesian networks,ar,Article,Asghari K.,,"Islamic Azad University, Urmia Branch",Urmia,Iran,,,,,2021-11-01,November 2021,Expert Systems,02664720,24185,14680394,Journal,38,7,e12734,,,,0,0,,,,"One of the useful knowledge representation tools, which can describe the joint probability distribution between some random variables with a graphical model and can be trained by a dataset, is the Bayesian network (BN). A BN is composed of a network structure and a conditional probability distribution table for each node. Discovering an optimal BN structure is an NP-hard optimization problem that various meta-heuristic algorithms are applied to solve this problem by researchers. The genetic algorithms, ant colony optimization, evolutionary programming, artificial bee colony, and bacterial foraging optimization are some of the meta-heuristic methods to solve this problem using a dataset. Most of these methods are applying a scoring metric to generate the best network structure from a set of candidates. A Fixed Structure Learning Automata-Based (FSLA-B) algorithm is presented in this paper to solve the structure learning problem of BNs. There is a fixed structure learning automaton for each pair of vertices in the BN's graph structure in the proposed algorithm. The action of this automaton determines the presence and direction of an edge between the vertices. The proposed algorithm performs a guided search procedure using the FSLA and escapes from local optimums. Several datasets are utilised in this paper to evaluate the performance of the proposed algorithm. By performing various experiments, multiple meta-heuristic algorithms are compared with the introduced new one. The obtained results represented that the proposed algorithm could produce competitive results and find the near-optimal solution for the BN structure learning problem.",NO
2-s2.0-85105588803,10.1016/j.eswa.2021.115128,S0957417421005698,,Multirobot coordination with deep reinforcement learning in complex environments,ar,Article,Wang D.,,Beijing Institute of Technology,Beijing,China,,,,,2021-10-15,15 October 2021,Expert Systems with Applications,09574174,24201,,Journal,180,,115128,,,,0,0,,,,"Highlights

•

In dynamic environment, starting tabula rasa, only image data are used as input.

•

Our approach can solve multirobot task assignment and path planning problems.

•

Results indicate that our method effectively applied to multi-robot coordination.
In the multiple autonomous robot system, it is very important to complete path planning coordinately and effectively in the processes of interference avoidance, resource allocation and information sharing. In traditional multirobot coordination algorithms, most of the solutions are in known environments, the target position that each robot needs to move to and the robot priority are set, which limits the autonomy of the robot. Only using visual information to solve the problem of multirobot coordination is still less. This paper proposes a multi-robot cooperative algorithm based on deep reinforcement learning to make the robot more autonomous in the process of selecting target positions and moving. We use the end-to-end approach, using only the top view, that is, a robot-centered top view, and the first-person view, that is, the image information collected from the first-person perspective of the robot, as input. The proposed algorithm, which includes a dueling neural network structure, can solve task allocation and path planning; we call the algorithm TFDueling. Through its perception and understanding of the environment, the robot can reach the target position without collision, and the robot can move to any target position. We compare the proposed algorithm, TFDueling, with different input structure algorithms, TDueling and FDueling, and with different neural network structures, TFDQN and TFDDQN. Experiments show that the proposed TFDueling algorithm has the highest accuracy and robustness.",NO
2-s2.0-85114776777,10.1016/j.compeleceng.2021.107412,S0045790621003773,,Fast path planning for underwater robots by combining goal-biased Gaussian sampling with focused optimal search,ar,Article,Shen J.,,Hohai University,Nanjing,China,,,,,2021-10-01,October 2021,Computers and Electrical Engineering,00457906,18159,,Journal,95,,107412,,,,0,0,,,,"Highlights

•

Path planning is a nondeterministic polynomial hard issue in classical path planning models.

•

Underwater path planning methods should be more efficient because many calculations performed using previous methods are unnecessary.

•

This method can regularize the sampling process and accelerate the convergence speed of path optimization for robot navigation.

•

A goal-biased Gaussian sampling strategy is used with variable standard deviations, which can quickly initialize the path to the goal.

•

The focused optimal search algorithm was applied to minimize the initial path.
Autonomous path planning plays an important role in the navigation of intelligent underwater robots. Path planning is a nondeterministic polynomial hard issue in classical path planning models. This problem can be solved using various sample-based strategies. However, the effectiveness of these sample-based strategies is significantly lower in underwater environments, owing to the special undulating terrain and obstacles that are sparser compared to those in the ground. In this study, a more efficient underwater path planning method is proposed for underwater robot navigation. The method employs a goal-biased Gaussian sampling algorithm to select searching nodes optimally, and a focused optimal search algorithm is proposed to accelerate the path optimization process. Combining these two algorithms results in high-efficiency and fast autonomous underwater path planning. Experimental results demonstrate that our method can generate a shorter path and is more efficient than a rapidly exploring random tree star in underwater robot navigation.

Graphical abstract

Download : Download high-res image (123KB)Download : Download full-size image",NO
2-s2.0-85114739614,10.1007/s10846-021-01477-0,,,Distributed Planning for Serving Cooperative Tasks with Time Windows: A Game Theoretic Approach,ar,Article,Yazıcıoğlu Y.,,University of Minnesota Twin Cities,Minneapolis,United States,,,,,2021-10-01,October 2021,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,103,2,27,,,,0,0,,,,"We study distributed planning for multi-robot systems to provide optimal service to cooperative tasks that are distributed over space and time. Each task requires service by sufficiently many robots at the specified location within the specified time window. Tasks arrive over episodes and the robots try to maximize the total value of service in each episode by planning their own trajectories based on the specifications of incoming tasks. Robots are required to start and end each episode at their assigned stations in the environment. We present a game theoretic solution to this problem by mapping it to a game, where the action of each robot is its trajectory in an episode, and using a suitable learning algorithm to obtain optimal joint plans in a distributed manner. We present a systematic way to design minimal action sets (subsets of feasible trajectories) for robots based on the specifications of incoming tasks to facilitate fast learning. We then provide the performance guarantees for the cases where all the robots follow a best response or noisy best response algorithm to iteratively plan their trajectories. While the best response algorithm leads to a Nash equilibrium, the noisy best response algorithm leads to globally optimal joint plans with high probability. We show that the proposed game can in general have arbitrarily poor Nash equilibria, which makes the noisy best response algorithm preferable unless the task specifications are known to have some special structure. We also describe a family of special cases where all the equilibria are guaranteed to have bounded suboptimality. Simulations and experimental results are provided to demonstrate the proposed approach.",NO
2-s2.0-85113925805,10.1109/LRA.2021.3103054,,,SABER: Data-driven motion planner for autonomously navigating heterogeneous robots,ar,Article,Schperberg A.,,"University of California, Los Angeles",Los Angeles,United States,,,,,2021-10-01,October 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,4,9511088,8086-8093,,,0,0,,,,"We present an end-to-end online motion planning framework that uses a data-driven approach to navigate a heterogeneous robot team towards a global goal while avoiding obstacles in uncertain environments. First, we use stochastic model predictive control (SMPC) to calculate control inputs that satisfy robot dynamics, and consider uncertainty during obstacle avoidance with chance constraints. Second, recurrent neural networks are used to provide a quick estimate of future state uncertainty considered in the SMPC finite-time horizon solution, which are trained on uncertainty outputs of various simultaneous localization and mapping algorithms. When two or more robots are in communication range, these uncertainties are then updated using a distributed Kalman filtering approach. Lastly, a Deep Q-learning agent is employed to serve as a high-level path planner, providing the SMPC with target positions that move the robots towards a desired global goal. Our complete methods are demonstrated on a ground and aerial robot simultaneously (code available at: https://github.com/AlexS28/SABER).",NO
2-s2.0-85112455774,10.1016/j.cie.2021.107603,S0360835221005076,,Deep learning-based optimization for motion planning of dual-arm assembly robots,ar,Article,Ying K.C.,,National Taipei University of Technology,Taipei,Taiwan,,,,,2021-10-01,October 2021,Computers and Industrial Engineering,03608352,18164,,Journal,160,,107603,,,,0,0,,,,"Highlights

•

An algorithm for planning collision-free trajectories of robots is developed.

•

The developed algorithm reduces the path length at a short computational time.

•

The approach outperforms in two- and three-dimensional operational environments.
With the rapid technological and economic development, a growing number of companies are employing robots for their production and service operations. Motion planning is a fundamental topic in robotics that has received wide attention due to its importance in the development of industry 4.0 and intelligent manufacturing systems. This study sought to develop a deep learning-based optimization algorithm for planning collision-free trajectories of dual-arm assembly robots in complex operational environments. Given the high dimensionality of the robotic motion patterns, a Bi-directional Rapidly-exploring Random Tree integrated with the Long Short-term Memory (LSTM-BiRRT) method is proposed to enhance the effectiveness and efficiency of the planning process. Numerical experiments demonstrated that the LSTM-BiRRT algorithm outperforms the state-of-the-art approaches developed for motion planning of dual-arm robots in both two- and three-dimensional environments. The developed algorithm reduces the path length of the robotic operations at a significantly shorter computational time. The LSTM-BiRRT algorithm can serve as a strong benchmark for future developments as well as applications in the process autonomy across intelligent supply chains.",NO
2-s2.0-85111573680,10.1016/j.ohx.2021.e00217,S2468067221000468,,Open source and open hardware mobile robot for developing applications in education and research,ar,Article,Betancur-Vásquez D.,,Instituto Tecnológico Metropolitano,Medellín,Colombia,,,,,2021-10-01,October 2021,HardwareX,,21100842867,24680672,Journal,10,,e00217,,,,0,1,,,,"Nowadays, additive manufacturing, rapid prototyping and assembly modules represent a
market that has invaded the entire world, especially in developing countries where traditional manufacturing is more restricted. In robotics, it is pertinent to think that modular
construction is essential, due to the complexity of geometry in each of the pieces and their
manufacture. Taking into account the globalization of information and the worldwide
reproduction of databases, facilitating access to CAD files to be reproduced in 3D printing
promotes the easy construction of archived mechanical designs. A robotic architecture
becomes a complex assembly by having multiple operating systems. The sensorics,
mechanics, electronics and programming that it requires for navigation, collaboration,
development, operation and even industrial manufacturing means that more and more
elaborate embedded systems are used. In this work, a mobile robotics architecture was
developed with a sensory system that allows free movement and navigation in closed loop
inverse kinematics. This kind of robot uses navigation algorithms to take a trajectory in collaborative closed environments, that is, closed industrial environments where obstacles are
normally immovable and corridors to move narrow, in addition to having mobile obstacles
like humans",NO
2-s2.0-85111156408,10.1109/LRA.2021.3092685,,,Learning Kinematic Feasibility for Mobile Manipulation through Deep Reinforcement Learning,ar,Article,Honerkamp D.,,Universität Freiburg,Freiburg im Breisgau,Germany,,,,,2021-10-01,October 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,4,9465645,6289-6296,,,0,0,,,,"Mobile manipulation tasks remain one of the critical challenges for the widespread adoption of autonomous robots in both service and industrial scenarios. While planning approaches are good at generating feasible whole-body robot trajectories, they struggle with dynamic environments as well as the incorporation of constraints given by the task and the environment. On the other hand, dynamic motion models in the action space struggle with generating kinematically feasible trajectories for mobile manipulation actions. We propose a deep reinforcement learning approach to learn feasible dynamic motions for a mobile base while the end-effector follows a trajectory in task space generated by an arbitrary system to fulfill the task at hand. This modular formulation has several benefits: it enables us to readily transform a broad range of end-effector motions into mobile applications, it allows us to use the kinematic feasibility of the end-effector trajectory as a dense reward signal and its modular formulation allows it to generalise to unseen end-effector motions at test time. We demonstrate the capabilities of our approach on multiple mobile robot platforms with different kinematic abilities and different types of wheeled platforms in extensive simulated as well as real-world experiments.",NO
2-s2.0-85110815172,10.1109/LRA.2021.3096758,,,Neural Tree Expansion for Multi-Robot Planning in Non-Cooperative Environments,ar,Article,Riviere B.,,California Institute of Technology,Pasadena,United States,,,,,2021-10-01,October 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,4,9484771,6868-6875,,,0,0,,,,"We present a self-improving, Neural Tree Expansion (NTE) method for multi-robot online planning in non-cooperative environments, where each robot attempts to maximize its cumulative reward while interacting with other self-interested robots. Our algorithm adapts the centralized, perfect information, discrete-action space method from AlphaZero to a decentralized, partial information, continuous action space setting for multi-robot applications. Our method has three interacting components: (i) a centralized, perfect-information “expert” Monte Carlo Tree Search (MCTS) with large computation resources that provides expert demonstrations, (ii) a decentralized, partial-information “learner” MCTS with small computation resources that runs in real-time and provides self-play examples, and (iii) policy & value neural networks that are trained with the expert demonstrations and bias both the expert and the learner tree growth. Our numerical experiments demonstrate Neural Tree Expansion's computational advantage by finding better solutions than a MCTS with 20 times more resources. The resulting policies are dynamically sophisticated, demonstrate coordination between robots, and play the Reach-Target-Avoid differential game significantly better than the state-of-the-art control-theoretic baseline for multi-robot, double-integrator systems. Our hardware experiments on an aerial swarm demonstrate the computational advantage of Neural Tree Expansion, enabling online planning at 20 Hz with effective policies in complex scenarios.",NO
2-s2.0-85104965813,10.1016/j.rcim.2021.102169,S0736584521000533,,Optimised Learning from Demonstrations for Collaborative Robots,ar,Article,Wang Y.Q.,,Wuhan University of Technology,Wuhan,China,,,,,2021-10-01,October 2021,Robotics and Computer-Integrated Manufacturing,07365845,18080,,Journal,71,,102169,,,,2,0,,,,"Highlight

•

A novel optimised approach is designed to improve Gaussian Mixture Model (GMM) and Gaussian Mixture Regression (GMR) in supporting Learning from Demonstrations (LfD) enabled cobots

•

A Gaussian noise strategy is devised to scatter demonstrations in order to better support GMM

•

A Simulated Annealing-Reinforcement Learning based optimisation algorithm is developed to refine Gaussian clusters to eliminate potential under-/over-fitting issues on GMM/GMR

•

A B-spline based cut-in algorithm is integrated with GMR to improve the adaptability of solutions for dynamic manufacturing tasks
The approach of Learning from Demonstrations (LfD) can support human operators especially those without much programming experience to control a collaborative robot (cobot) in an intuitive and convenient means. Gaussian Mixture Model and Gaussian Mixture Regression (GMM and GMR) are useful tools for implementing such a LfD approach. However, well-performed GMM/GMR require a series of demonstrations without trembling and jerky features, which are challenging to achieve in actual environments. To address this issue, this paper presents a novel optimised approach to improve Gaussian clusters then further GMM/GMR so that LfD enabled cobots can carry out a variety of complex manufacturing tasks effectively. This research has three distinguishing innovative characteristics: 1) a Gaussian noise strategy is designed to scatter demonstrations with trembling and jerky features to better support the optimisation of GMM/GMR; 2) a Simulated Annealing-Reinforcement Learning (SA-RL) based optimisation algorithm is developed to refine the number of Gaussian clusters in eliminating potential under-/over-fitting issues on GMM/GMR; 3) a B-spline based cut-in algorithm is integrated with GMR to improve the adaptability of reproduced solutions for dynamic manufacturing tasks. To verify the approach, cases studies of pick-and-place tasks with different complexities were conducted. Experimental results and comparative analyses showed that this developed approach exhibited good performances in terms of computational efficiency, solution quality and adaptability.",NO
2-s2.0-85103686253,10.1016/j.rcim.2021.102167,S073658452100051X,,Augmented reality-based robot teleoperation system using RGB-D imaging and attitude teaching device,ar,Article,Pan Y.,,Qingdao University,Qingdao,China,,,,,2021-10-01,October 2021,Robotics and Computer-Integrated Manufacturing,07365845,18080,,Journal,71,,102167,,,,0,0,,,,"Highlights

•

An effective and cheap human–robot interaction method using RGB-D imaging and an attitude teaching device is proposed. With the human–robot interaction method, a local operator can complete the trajectory planning (including the path planning and orientation planning of the end effector of the robot) of a remote robot effectively.

•

A tele-AR registration method, which makes the coordinate system of the virtual robot coincide with that of the physical robot, is proposed.
Augmented reality (AR)-based programming using the demonstration method has been widely studied. However, studies on AR-based programming for remote robots are lacking because of the limitation of human–computer interaction. This paper proposes an AR-based robot teleoperation system and method using RGB-D imaging and an attitude teaching device. By sending the color and depth images of the remote robot environment to the local side, the operators can complete the teleoperation of the robot at the local side. First, the operators select key positions on the motion path of the robot endpoint from color images via a mouse, and the computer calculates the 3D coordinates of these key points in the robot base coordinate system to complete the position teaching process. In the robot attitude teaching process, the AR technology is used to superimpose the virtual robot model onto the color images of the robot teleoperation environment, so as to make the virtual robot endpoint to move along the teaching path. An operator can use the portable attitude teaching device designed in this study to control the robot movement parameters, such as the attitude and motion speed, during the movement of the virtual robot. After the position and attitude teaching processes, the robot movement trajectory can be generated. To make the base coordinate system of the virtual model consistent with that of the physical robot, we propose an online AR registration method, which does not require manually placing the AR registration marker. The proposed AR-based robot teleoperation system can quickly and easily complete robot teleoperation at the local side.",NO
2-s2.0-85101613711,10.1016/j.rcim.2021.102130,S0736584521000156,,A visual path-following learning approach for industrial robots using DRL,ar,Article,Maldonado-Ramirez A.,,Centro de Investigacion y de Estudios Avanzados,Mexico City,Mexico,,,,,2021-10-01,October 2021,Robotics and Computer-Integrated Manufacturing,07365845,18080,,Journal,71,,102130,,,,1,0,,,,"Highlights

•

A robot is trained using domain randomisation and partial or full-state observation.

•

Policies work reliably in unexplored environments demonstrating the robot’s agility.

•

Short time for motion prediction (3.5 ms) is suitable for fast robot adaptation.

•

The method is applicable to control the tool’s position and orientation.

•

The method is applicable to industrial robots with external motion control enabled.
Manufacturing companies are in constant need for improved agility. An adequate combination of speed, responsiveness, and business agility to cope with fluctuating raw material costs is essential for today’s increasingly demanding markets. Agility in robots is key in operations requiring on-demand control of a robot’s tool position and orientation, reducing or eliminating extra programming efforts. Vision-based perception using full-state or partial-state observations and learning techniques are useful to create truly adaptive industrial robots. We propose using a Deep Reinforcement Learning (DRL) approach to solve path-following tasks using a simplified virtual environment with domain randomisation to provide the agent with enough exploration and observation variability during the training to generate useful policies to be transferred to an industrial robot. We validated our approach using a KUKA KR16HW robot equipped with a Fronius GMAW welding machine. The path was manually drawn on two workpieces so the robot was able to perceive, learn and follow it during welding experiments. It was also found that small processing times due to motion prediction (3.5 ms) did not slow down the process, which resulted in smooth robot operations. The novel approach can be implemented onto different industrial robots to carry out different tasks requiring material deposition.

Graphical abstract

Download : Download high-res image (281KB)Download : Download full-size image",NO
2-s2.0-85099772851,10.1177/0735633120988807,,,Visual Programming Environments and Computational Thinking Performance of Fifth- and Sixth-Grade Students,ar,Article,Wu S.Y.,,National Pingtung University,Pingtung,Taiwan,,,,,2021-10-01,October 2021,Journal of Educational Computing Research,07356331,18874,15414140,Journal,59,6,,1075-1092,,,3,0,,,,"Currently, many countries actively cultivate students to develop computational thinking ability. Many visual programming environments (VPEs) and physical robot courses have been integrated into computational thinking learning in the elementary education stage. This study explores the relationship between the programming learning environment (including VPE, physical robots, and no experience) and the computational thinking ability of higher-grade elementary school students of different genders. The results show that learning through VPE or physical robots can help students improve their computational thinking ability and that students learn better via physical robots. In addition, among the four dimensions of computational thinking ability, most students are weak in algorithm design. In terms of gender, no differences exist in computational thinking ability. Further analysis reveals that female students have better decomposition performance in VPE learning, while male students have better algorithm design performance.",SI
2-s2.0-85115231346,10.3390/s21186305,,,Modular robotic limbs for astronaut activities assistance,ar,Article,Zhao S.,,Harbin Institute of Technology,Harbin,China,,,,,2021-09-01,September 2021,Sensors,14248220,130124,,Journal,21,18,6305,,,,0,1,,,,"In order to meet the assist requirements of extravehicular activity (EVA) for astronauts, such as moving outside the international space station (ISS) or performing on-orbit tasks by a single astronaut, this paper proposes an astronaut robotic limbs system (AstroLimbs) for extravehicular activities assistance. This system has two robotic limbs that can be fixed on the backpack of the astronaut. Each limb is composed of several basic module units with identical structure and function, which makes it modularized and reconfigurable. The robotic limbs can work as extra arms of the astronaut to assist them outside the space station cabin. In this paper, the robotic limbs are designed and developed. The reinforcement learning method is introduced to achieve autonomous motion planning capacity for the robot, which makes the robot intelligent enough to assist the astronaut in unstructured environment. In the meantime, the movement of the robot is also planned to make it move smoothly. The structure scene of the ISS for extravehicular activities is modeled in a simulation environment, which verified the effectiveness of the proposed method. View Full-Text",NO
2-s2.0-85115046074,10.3390/s21186243,,,The data sensor hub (Dash): A physical computing system to support middle school inquiry science instruction,ar,Article,Gendreau Chakarov A.,,San Jose State University,San Jose,United States,,,,,2021-09-01,September 2021,Sensors,14248220,130124,,Journal,21,18,6243,,,,0,1,,,,"This article describes a sensor-based physical computing system, called the Data Sensor Hub (DaSH), which enables students to process, analyze, and display data streams collected using a variety of sensors. The system is built around the portable and affordable BBC micro:bit microcontroller (expanded with the gator:bit), which students program using a visual, cloud-based programming environment intended for novices. Students connect a variety of sensors (measuring temperature, humidity, carbon dioxide, sound, acceleration, magnetism, etc.) and write programs to analyze and visualize the collected sensor data streams. The article also describes two instructional units intended for middle grade science classes that use this sensor-based system. These inquiry-oriented units engage students in designing the system to collect data from the world around them to investigate scientific phenomena of interest. The units are designed to help students develop the ability to meaningfully integrate computing as they engage in place-based learning activities while using tools that more closely approximate the practices of contemporary scientists as well as other STEM workers. Finally, the article articulates how the DaSH and units have elicited different kinds of teacher practices using student drawn modeling activities, facilitating debugging practices, and developing place-based science practices. View Full-Text",SI
2-s2.0-85114844450,10.3390/educsci11090518,,,Fostering computational thinking skills: A didactic proposal for elementary school grades,ar,Article,Silva R.,,Centro de Investigação Didática e Tecnologia na Formação de Formadores (CIDTFF);Instituto Politcnico de Coimbra;University of Trás-os-Montes and Alto Douro,Aveiro;Coimbra;Vila Real,Portugal;Portugal;Portugal,,,,,2021-09-01,September 2021,Education Sciences,,21100897500,22277102,Journal,11,9,518,,,,0,1,,,,"There is a growing presence of technology in the daily lives of elementary school students, with a recent exponential rise due to the constraints of remote teaching during the COVID-19 pandemic. It is important to understand how the education system can contribute to helping students develop the required skills for technological careers, without neglecting its obligation to create conditions that allow them to acquire transversal skills and to enable them to exercise full citizenship. The integration of Educational Robotics and block programming activities in collaborative learning environments promotes the development of computational thinking and other ICT skills, as well as critical thinking, social skills, and problem solving. This paper presents a theoretical proposal of a didactic sequence for the introduction to educational robotics and programming with Scratch Jr. It is composed of three learning scenarios, designed for elementary school teaching. Its main goal is to create conditions that favour the development of computational thinking in a collaborative learning environment. With increasing complexity and degree of difficulty, all the tasks root from a common problem: How can we create an algorithm that programs the robot/sprite to reach a predetermined position? View Full-Text",SI
2-s2.0-85112016866,10.1007/s10846-021-01458-3,,,The State of Lifelong Learning in Service Robots:: Current Bottlenecks in Object Perception and Manipulation,ar,Article,Kasaei S.H.,,Rijksuniversiteit Groningen,Groningen,Netherlands,,,,,2021-09-01,September 2021,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,103,1,8,,,,0,1,,,,"Service robots are appearing more and more in our daily life. The development of service robots combines multiple fields of research, from object perception to object manipulation. The state-of-the-art continues to improve to make a proper coupling between object perception and manipulation. This coupling is necessary for service robots not only to perform various tasks in a reasonable amount of time but also to continually adapt to new environments and safely interact with non-expert human users. Nowadays, robots are able to recognize various objects, and quickly plan a collision-free trajectory to grasp a target object in predefined settings. Besides, in most of the cases, there is a reliance on large amounts of training data. Therefore, the knowledge of such robots is fixed after the training phase, and any changes in the environment require complicated, time-consuming, and expensive robot re-programming by human experts. Therefore, these approaches are still too rigid for real-life applications in unstructured environments, where a significant portion of the environment is unknown and cannot be directly sensed or controlled. In such environments, no matter how extensive the training data used for batch learning, a robot will always face new objects. Therefore, apart from batch learning, the robot should be able to continually learn about new object categories and grasp affordances from very few training examples on-site. Moreover, apart from robot self-learning, non-expert users could interactively guide the process of experience acquisition by teaching new concepts, or by correcting insufficient or erroneous concepts. In this way, the robot will constantly learn how to help humans in everyday tasks by gaining more and more experiences without the need for re-programming. In this paper, we review a set of previously published works and discuss advances in service robots from object perception to complex object manipulation and shed light on the current challenges and bottlenecks.",NO
2-s2.0-85111285188,10.1016/j.compag.2021.106350,S0168169921003677,,Collision-free path planning for a guava-harvesting robot based on recurrent deep reinforcement learning,ar,Article,Lin G.,,Zhongkai University of Agriculture and Engineering,Guangzhou,China,,,,,2021-09-01,September 2021,Computers and Electronics in Agriculture,01681699,30441,,Journal,188,,106350,,,,0,0,,,,"Highlights

•

An image process pipeline is introduced to locate guava fruits and obstacles.

•

A recurrent deep reinforcement learning algorithm is proposed to predict collision-free paths.

•

The robot is trained in a simulation environment and transferred to the real world directly.

•

The robot only needs 29 ms to plan a collision-free path with a success rate of 90.9%.
In unstructured orchard environments, picking a target fruit without colliding with neighboring branches is a significant challenge for guava-harvesting robots. This paper introduces a fast and robust collision-free path-planning method based on deep reinforcement learning. A recurrent neural network is first adopted to remember and exploit the past states observed by the robot, then a deep deterministic policy gradient algorithm (DDPG) predicts a collision-free path from the states. A simulation environment is developed and its parameters are randomized during the training phase to enable recurrent DDPG to generalize to real-world scenarios. We also introduce an image processing method that uses a deep neural network to detect obstacles and uses many three-dimensional line segments to approximate the obstacles. Simulations show that recurrent DDPG only needs 29 ms to plan a collision-free path with a success rate of 90.90%. Field tests show that recurrent DDPG can increase grasp, detachment, and harvest success rates by 19.43%, 9.11%, and 10.97%, respectively, compared to cases where no collision-free path-planning algorithm is implemented. Recurrent DDPG strikes a strong balance between efficiency and robustness and may be suitable for other fruits.",NO
2-s2.0-85111045874,10.1016/j.engappai.2021.104382,S095219762100230X,,Partially Observable Monte Carlo Planning with state variable constraints for mobile robot navigation,ar,Article,Castellini A.,,Università degli Studi di Verona,Verona,Italy,,,,,2021-09-01,September 2021,Engineering Applications of Artificial Intelligence,09521976,24182,,Journal,104,,104382,,,,0,0,,,,"Autonomous mobile robots employed in industrial applications often operate in complex and uncertain environments. In this paper we propose an approach based on an extension of Partially Observable Monte Carlo Planning (POMCP) for robot velocity regulation in industrial-like environments characterized by uncertain motion difficulties. The velocity selected by POMCP is used by a standard engine controller which deals with path planning. This two-layer approach allows POMCP to exploit prior knowledge on the relationships between task similarities to improve performance in terms of time spent to traverse a path with obstacles. We also propose three measures to support human-understanding of the strategy used by POMCP to improve the performance. The overall architecture is tested on a Turtlebot3 in two environments, a rectangular path and a realistic production line in a research lab. Tests performed on a C++ simulator confirm the capability of the proposed approach to profitably use prior knowledge, achieving a performance improvement from 0.7% to 3.1% depending on the complexity of the path. Experiments on a Unity simulator show that the proposed two-layer approach outperforms also single-layer approaches based only on the engine controller (i.e., without the POMCP layer). In this case the performance improvement is up to 37% comparing to a state-of-the-art deep reinforcement learning engine controller, and up to 51% comparing to the standard ROS engine controller. Finally, experiments in a real-world testing arena confirm the possibility to run the approach on real robots.",NO
2-s2.0-85108091980,10.1016/j.compchemeng.2021.107371,S0098135421001496,,An adaptive sampling surrogate model building framework for the optimization of reaction systems,ar,Article,Franzoi R.E.,,Universidade de São Paulo,Sao Paulo,Brazil,,,,,2021-09-01,September 2021,Computers and Chemical Engineering,00981354,24600,,Journal,152,,107371,,,,1,0,,,,"Highlights

•

A surrogate model building framework for reaction systems.

•

Surrogate models to accurately represent complex formulations.

•

An adaptive sampling algorithm iteratively explores the solution space.

•

Incorporate ideas from adaptive sampling, trust region methods, and successive linear programming approaches.

•

Highly accurate surrogates are successfully embedded in optimization problems.
Many industrial engineering problems involve complex formulations and are assisted by simulation tools. Although these tools provide highly accurate solutions, they may not be suitable for large scale problems and for optimization applications. Looking for alternatives to complex formulations that often lead to convergence issues and to time consuming solutions, the use of surrogate modeling for reaction systems is addressed herein. We propose a novel adaptive sampling algorithm that iteratively explores the solution space and incorporates ideas from adaptive sampling, trust region methods, and successive linear programming approaches. The surrogates are iteratively embedded into optimization problems to check feasibility and to collect insights to the following adaptive sampling iteration. The methodology is applied to a reaction system network and the surrogates are built to predict the reactor outputs. The adaptive sampling algorithm builds highly accurate surrogates that can be embedded into the reaction system optimization leading to near optimal solutions.",NO
2-s2.0-85103120175,10.1016/j.ijcci.2021.100277,S2212868921000209,,Envisioning Arduino Action: A collaborative tool for physical computing in educational settings,ar,Article,Roumen G.J.,,Umeå Universitet,Umea,Sweden,,,,,2021-09-01,September 2021,International Journal of Child-Computer Interaction,22128689,21100228541,,Journal,29,,100277,,,,1,0,,,,"Micro-controllers like Arduino are increasingly used in classroom settings to teach skills, attitudes and knowledge around technology. Education around these tools is often set in group contexts and collaboration is typically considered an important part of the learning process. However, much of the software tools currently available are still designed around a laptop programming paradigm that tends to restrict collaboration rather than encourage shifting of roles and sharing of experiences. This paper explores how to design tools that invite collaborative interactions, in particular how mobile software tools, with heavy usage of video as an interactive resource, could allow for collaborative sketching and understanding. Based on contextual inquiries with educators, observations and engagements with students in classroom settings, and a workshop with Arduino Education, this paper sketches out a vision for how the software tools used for learning physical computing can be re-designed to better work within the context of group work from the observations, for groups of students aged 14–16-years old.",SI
2-s2.0-85092675036,10.1002/cae.22353,,,Teaching concepts related to finite automata using ComVis,ar,Article,Jovanović N.,,University of Pristina - Kosovska Mitrovica,Sremska Mitrovica,Serbia,,,,,2021-09-01,September 2021,Computer Applications in Engineering Education,10613773,18156,10990542,Journal,29,5,,994-1006,,,2,0,,,,"This paper describes educational software for visualization and finite automata simulation. The system was developed in Java programming language, and its main purpose is learning process improvement. Using this software, finite automata can be defined in a graphical editor in the form of a state diagram, or by defining the transition function using the transition table. Upon defining an automaton, it is possible to run a visual simulation of the automaton operation for an arbitrary input string, whereby a textual description of the automaton simulation is also obtained. Furthermore, the system allows for conversion of regular expressions to deterministic finite automata and nondeterministic finite automata. The simulation of Thompson's construction algorithm is implemented, so that transformation of a regular expression to the corresponding NFA can be monitored in a step-by-step process. The quantitative analysis and evaluation of the effectiveness of the simulator are based on a survey of undergraduate students at two universities. The majority of students found the tool a useful means for better understanding and mastering of finite automata concepts.",NO
2-s2.0-85089006767,10.1177/0278364920940781,,,Fast deep swept volume estimator,ar,Article,Chiang H.T.L.,,The University of New Mexico;Google LLC,Albuquerque;Mountain View,United States;United States,,,,,2021-09-01,September 2021,International Journal of Robotics Research,02783649,18050,17413176,Journal,40,10-11,,1068-1086,,,0,1,,,,"Despite decades of research on efficient swept volume computation for robotics, computing the exact swept volume is intractable and approximate swept volume algorithms have been computationally prohibitive for applications such as motion and task planning. In this work, we employ deep neural networks (DNNs) for fast swept volume estimation. Since swept volume is a property of robot kinematics, a DNN can be trained off-line once in a supervised manner and deployed in any environment. The trained DNN is fast during on-line swept volume geometry or size inferences. Results show that DNNs can accurately and rapidly estimate swept volumes caused by rotational, translational, and prismatic joint motions. Sampling-based planners using the learned distance are up to five times more efficient and identify paths with smaller swept volumes on simulated and physical robots. Results also show that swept volume geometry estimation with a DNN is over 98.9% accurate and 1,200 times faster than an octree-based swept volume algorithm.",NO
2-s2.0-85104338782,10.1016/j.neucom.2021.03.117,S0925231221005099,,Effective method for detecting malicious PowerShell scripts based on hybrid features<sup>☆</sup>,ar,Article,Fang Y.,,Sichuan University,Chengdu,China,,,,,2021-08-11,11 August 2021,Neurocomputing,09252312,24807,18728286,Journal,448,,,30-39,,,0,0,,,,"Highlights

•

A new malicious PowerShell scripts detection method based on hybrid features.

•

A new dataset collected from open source repositories of malicious PowerShell scripts detection.

•

New discoveries of the gap between malicious scripts and benign scripts in different levels.

•

Our experiments has shown that detection model based hybrid features perform well in complex data set.
At present, network attacks are rampant in the Internet world, and the attack methods of hackers are changing steadily. PowerShell is a programming language based on the command line and.NET framework, with powerful functions and good compatibility. Therefore, hackers often use PowerShell malicious scripts to attack the victims in APT attacks. When these malicious PowerShell scripts are executed, hackers can control the victim’s computer or leave a backdoor on their computers. In this paper, a detection model of malicious PowerShell scripts based on hybrid features is proposed, we analyzed the differences between malicious and benign samples in text characters, functions, tokens and the nodes of the abstract syntax tree. Firstly, the script of PowerShell is embedded by FastText. Then the textual features, token features and the nodes features of PowerShell code extracted from the abstract syntax tree are added. Finally, the hybrid features of scrips will be classified by a Random Forest classifier. In the experiment, the malicious scripts are inserted into the benign scripts to weaken the features of the malicious samples in the level of abstract syntax tree nodes and tokens, which makes the scripts more complex. Even in such a complex data set, the proposed model which is based on hybrid features still achieves an accuracy of 97.76% in fivefold cross-validation. Moreover, the accuracy of this proposed model on the original scripts is 98.93%, which means that the proposed model has the ability to classify complex scripts.

Graphical abstract

Download : Download high-res image (130KB)Download : Download full-size image",NO
2-s2.0-85110771944,10.1016/j.aei.2021.101360,S1474034621001130,,Deep reinforcement learning-based safe interaction for industrial human-robot collaboration using intrinsic reward function,ar,Article,Liu Q.,,Wuhan University of Technology,Wuhan,China,,,,,2021-08-01,August 2021,Advanced Engineering Informatics,14740346,23640,,Journal,49,,101360,,,,0,0,,,,"Highlights

•

A method for safe interaction in industrial human-robot collaboration is proposed.

•

A specific reward function with intrinsic reward and extrinsic reward is designed.

•

Safety and task are considered simultaneously.

•

It contributes to safe human-robot collaboration and reward shaping.
Aiming at human-robot collaboration in manufacturing, the operator's safety is the primary issue during the manufacturing operations. This paper presents a deep reinforcement learning approach to realize the real-time collision-free motion planning of an industrial robot for human-robot collaboration. Firstly, the safe human-robot collaboration manufacturing problem is formulated into a Markov decision process, and the mathematical expression of the reward function design problem is given. The goal is that the robot can autonomously learn a policy to reduce the accumulated risk and assure the task completion time during human-robot collaboration. To transform our optimization object into a reward function to guide the robot to learn the expected behaviour, a reward function optimizing approach based on the deterministic policy gradient is proposed to learn a parameterized intrinsic reward function. The reward function for the agent to learn the policy is the sum of the intrinsic reward function and the extrinsic reward function. Then, a deep reinforcement learning algorithm intrinsic reward-deep deterministic policy gradient (IRDDPG), which is the combination of the DDPG algorithm and the reward function optimizing approach, is proposed to learn the expected collision avoidance policy. Finally, the proposed algorithm is tested in a simulation environment, and the results show that the industrial robot can learn the expected policy to achieve the safety assurance for industrial human-robot collaboration without missing the original target. Moreover, the reward function optimizing approach can help make up for the designed reward function and improve policy performance.",NO
2-s2.0-85107793442,10.1007/s00170-021-07265-2,,,Task-level decision-making for dynamic and stochastic human-robot collaboration based on dual agents deep reinforcement learning,ar,Article,Liu Z.,,Wuhan University of Technology;The Royal Institute of Technology (KTH),Wuhan;Stockholm,China;Sweden,,,,,2021-08-01,August 2021,International Journal of Advanced Manufacturing Technology,02683768,20428,14333015,Journal,115,11-12,,3533-3552,,,0,0,,,,"Human-robot collaboration as a multidisciplinary research topic is still pursuing the robots’ enhanced intelligence to be more human-compatible and fit the dynamic and stochastic characteristics of human. However, the uncertainties brought by the human partner challenge the task-planning and decision-making of the robot. When aiming at industrial tasks like collaborative assembly, dynamics on temporal dimension and stochasticities on the order of procedures need to be further considered. In this work, we bring a new perspective and solution based on reinforcement learning, where the problem is regarded as training an agent towards tasks in dynamic and stochastic environments. Concretely, an adapted training approach based on the deep Q learning method is proposed. This method regards both the robot and the human as the agents in the interactive training environment for deep reinforcement learning. With the consideration of task-level industrial human-robot collaboration, the training logic and the agent-environment interaction have been proposed. For the human-robot collaborative assembly tasks in the case study, it is illustrated that our method could drive the robot represented by one agent to collaborate with the human partner even the human performs randomly on the task procedures.",NO
2-s2.0-85104914388,10.1016/j.compedu.2021.104222,S0360131521000993,,Learning to code and the acquisition of computational thinking by young children,ar,Article,Relkin E.,,Tufts University,Medford,United States,,,,,2021-08-01,August 2021,Computers and Education,03601315,17645,,Journal,169,,104222,,,,3,0,,,,"Highlights

•

We examined the impact of the CAL-KIBO coding curriculum on children's computational thinking (CT).

•

An unplugged CT assessment (TechCheck) was used to compare coders to non-coding controls.

•

CT improved significantly in coders ages 5–9 compared to age-matched controls.

•

CT improvements after 7 weeks of coding equated to 6 months of normal development.

•

Algorithms, modularity, and representation probes showed improvements in children who coded.
This longitudinal study examined changes in Computational Thinking (CT) skills in first and second grade students exposed to a developmentally appropriate coding curriculum. The “Coding as Another Language” (CAL) curriculum spans seven weeks and uses the KIBO robot to engage students in learning that integrates programming and literacy concepts. We compared children receiving CAL (N = 667) to a control group (N = 181) who participated in typical classroom activities without coding (No-CAL). TechCheck, a validated “unplugged” CT assessment suitable for young children regardless of their coding experience, was used to measure CT. Over the course of the study, children who received CAL-KIBO improved on TechCheck (Mchange = 0.94, p < .001) whereas the No-CAL group did not change significantly (Mchange = 0.27, p = .07). Accounting for demographic factors, baseline performance and classroom (teacher) effects, CAL exposure was a significant predictor of post-test CT scores (p < .01). Improvements in CT measured by TechCheck over seven weeks of the CAL-KIBO curriculum were consistent with approximately six months of development without coding instruction. Secondary analysis stratified by grade revealed decisive evidence that CAL exposure improved scores in first grade and anecdotal evidence that second grade scores improved. The CT domains that showed improvement in children who received CAL-KIBO included algorithms, modularity, and representation. Young children who learned to code improved in solving unplugged problems that were not explicitly taught in the coding curriculum. This provides evidence that a developmentally appropriate curriculum for teaching young children to code can accelerate their acquisition of CT skills.",SI
2-s2.0-85091774621,10.1007/s12369-020-00697-y,,,Robotic System for Physical Training of Older Adults,ar,Article,Avioz-Sarig O.,,Ben-Gurion University of the Negev,Beer Sheba,Israel,,,,,2021-08-01,August 2021,International Journal of Social Robotics,18754791,19500157063,18754805,Journal,13,5,,1109-1124,,,1,1,,,,"Physical exercise has many physical, psychological and social health benefits leading to improved life quality. This paper presents a robotic system developed as a personal coach for older adults aiming to motivate older adults to participate in physical activities. The robot instructs the participants, demonstrates the exercises and provides real-time corrective and positive feedback according to the participant’s performance as monitored by an RGB-D camera. Two robotic systems based on two different humanoid robots (Nao, toy-like and Poppy, mechanical-like) were developed and implemented using the Python programming language. Experimental studies with 32 older adults were conducted, to determine the preferable mode and timing of the feedback provided to the user to accommodate user preferences, motivate the users and improve their interaction with the system. Additionally, user preferences with regards to the two different humanoid robots used were explored. The results revealed that the system motivated the older adults to engage more in physical exercises. The type and timing of feedback influenced this engagement. Most of these older adults also perceived the system as very useful, easy to use, had a positive attitude towards the system and noted their intention to use it. Most users preferred the more mechanical looking robot (Poppy) over the toy-like robot (Nao).",NO
2-s2.0-85098779684,10.1109/JSEN.2020.3038143,,,Hybrid Embedded-Systems-Based Approach to in-Driver Drunk Status Detection Using Image Processing and Sensor Networks,ar,Article,Rosero-Montalvo P.D.,,Universidad Técnica del Norte;Universidad de Salamanca,Ibarra;Salamanca,Ecuador;Spain,,,,,2021-07-15,15 July 2021,IEEE Sensors Journal,1530437X,15047,15581748,Journal,21,14,9258992,15729-15740,,,1,0,,,,"Car drivers under the influence of alcohol is one of the most common causes of road traffic accidents. To tackle this issue, an emerging, suitable alternative is the use of intelligent systems -traditionally based on either sensor networks or artificial vision- that are aimed to prevent starting the car when drunk status on the car driver is detected. In such vein, this paper introduces a system whose main objective is identifying a person having alcohol in the blood through supervised classification of sensor-generated and computer-vision-based data. To do so, some drunk-status criteria are considered, namely: the concentration of alcohol in the car environment, the facial temperature of the driver and the pupil width. Specifically, for data acquisition purposes, the proposed system incorporates a gas sensor, temperature sensor and a digital camera. Acquired data are analyzed into a two-stages machine learning system consisting of feature selection and supervised classification algorithms. Both acquisition and analysis stages are to be performed into a embedded system, and therefore all procedures and algorithms are designed to work at low-computational resources. As a remarkable outcome, due mainly to the incorporation of feature selection and relevance analysis stages, proposed approach reaches a classification performance of 98% while ensures adequate operation conditions for the embedded system.",NO
2-s2.0-85113509455,10.16383/j.aas.c180855,,,Robot Path Planning Based on Improved Bat Algorithm and Cubic Spline Interpolation,ar,Article,Liu J.S.,,Henan University,Kaifeng,China,,,,,2021-07-01,July 2021,Zidonghua Xuebao/Acta Automatica Sinica,02544156,25566,,Journal,47,7,,1710-1719,,,1,0,,,,,NO
2-s2.0-85109866672,10.3390/educsci11070329,,,Using robots with storytelling and drama activities in science education,ar,Article,Bravo F.A.,,Pontificia Universidad Javeriana,Bogota,Colombia,,,,,2021-07-01,July 2021,Education Sciences,,21100897500,22277102,Journal,11,7,329,,,,0,1,,,,"Storytelling and drama are well-known teaching tools that can be used throughout the curriculum for the active participation of students in their own learning process. The introduction of robots in storytelling and drama activities provides students with a meaningful, multisensory, hands-on learning experience. This paper explores the potential and challenges of using storytelling and drama activities with robot actors in science teaching. We present the lessons learned from two experiences of storytelling and drama activities with robots in science education. Observations revealed that this approach facilitates the development of science concepts, creates a rich context to foster skills in students, creates a positive classroom environment, and improves the students’ attention and motivation. Finally, it was identified that there is a need to design low-cost expressive actor robots that are easily customizable. Additionally, the need to develop multi-robot programming interfaces that facilitate the creation of scripts for robots and their programming is also shown. View Full-Text",SI
2-s2.0-85109808487,10.1016/j.jmsy.2021.07.015,S0278612521001527,,Optimizing task scheduling in human-robot collaboration with deep multi-agent reinforcement learning,ar,Article,Yu T.,,University of Virginia,Charlottesville,United States,,,,,2021-07-01,July 2021,Journal of Manufacturing Systems,02786125,14966,,Journal,60,,,487-499,,,1,0,,,,"Highlights

•

Format the HRC assembly process into a chessboard game.

•

Develop a DQN-based multi-agent reinforcement learning method to optimize the task scheduling policy.

•

Verify the effectiveness of the DQN-MARL method in optimizing the completion time with various task spaces and agents.
Human-Robot Collaboration (HRC) presents an opportunity to improve the efficiency of manufacturing processes. However, the existing task planning approaches for HRC are still limited in many ways, e.g., co-robot encoding must rely on experts’ knowledge and the real-time task scheduling is applicable within small state-action spaces or simplified problem settings. In this paper, the HRC assembly working process is formatted into a novel chessboard setting, in which the selection of chess piece move is used to analogize to the decision making by both humans and robots in the HRC assembly working process. To optimize the completion time, a Markov game model is considered, which takes the task structure and the agent status as the state input and the overall completion time as the reward. Without experts’ knowledge, this game model is capable of seeking for correlated equilibrium policy among agents with convergency in making real-time decisions facing a dynamic environment. To improve the efficiency in finding an optimal policy of the task scheduling, a deep-Q-network (DQN) based multi-agent reinforcement learning (MARL) method is applied and compared with the Nash-Q learning, dynamic programming and the DQN-based single-agent reinforcement learning method. A height-adjustable desk assembly is used as a case study to demonstrate the effectiveness of the proposed algorithm with different number of tasks and agents.",NO
2-s2.0-85108855960,10.3390/electronics10131562,,,Design of a laboratory scale solar microgrid cyber-physical system for education,ar,Article,Guo L.,,Northern Illinois University,DeKalb,United States,,,,,2021-07-01,1 July 2021,Electronics (Switzerland),,21100829272,20799292,Journal,10,13,1562,,,,0,1,,,,"Renewable energy sources such as solar and wind provide an effective solution for reducing dependency on conventional power generation and increasing the reliability and quality of power systems. Presented in this paper are design and implementation of a laboratory scale solar microgrid cyber-physical system (CPS) with wireless data monitoring as a teaching tool in the engineering technology curriculum. In the system, the solar panel, battery, charge controller, and loads form the physical layer, while the sensors, communication networks, supervisory control and data acquisition systems (SCADA) and control systems form the cyber layer. The physical layer was seamlessly integrated with the cyber layer consisting of control and communication. The objective was to create a robust CPS platform and to use the system to promote interest in and knowledge of renewable energy among university students. Experimental results showed that the maximum power point tracking (MPPT) charge controller provided the loads with power from the solar panel and used additional power to charge the rechargeable battery. Through the system, students learned and mastered key concepts and knowledge of multi-disciplinary areas including data sampling and acquisition, analog to digital conversion, solar power, battery charging, control, embedded systems and software programing. It is a valuable teaching resource for students to study renewable energy in CPS. View Full-Text",NO
2-s2.0-85108314630,10.1109/TASE.2020.2996018,,,Optimal Feedback Control of Pedestrian Flow in Heterogeneous Corridors,ar,Article,Zhu Y.,,Institute of Automation Chinese Academy of Sciences,Beijing,China,,,,,2021-07-01,July 2021,IEEE Transactions on Automation Science and Engineering,15455955,17340,15583783,Journal,18,3,9108557,1097-1108,,,2,0,,,,"Maintaining the orderliness and efficiency of pedestrian flow through an architectural area is critical for the evacuation process. Especially, clogs and jams are easily triggered in width-changing areas. In this article, we consider pedestrian movement in heterogeneous corridors and design an optimal feedback control to regulate pedestrian flow. Flow characteristics are first studied based on microscopic social-force simulations. A Gaussian process describes the relationship between flow variables with the observation data. The macroscopic model for flow in heterogeneous corridors is developed. To avoid jams, discharges among these corridors are balanced with the narrowest corridor as the primary concern. At the equilibrium, a continuous-time nonlinear control system is formulated, and the adaptive dynamic programming learns the optimal feedback controller. Policy iteration (PI) and neural networks are combined together, and the convergence of neural-network-based PI is demonstrated by analyzing its equivalence to the Gauss–Newton method. Batch normalization is introduced to stabilize the learning process. Simulated experiments demonstrate that the control design can effectively regulate pedestrian flow for both macroscopic and microscopic models. Note to Practitioners —The development of video-processing techniques provides a powerful tool to detect human behavior in real time. In crowd events, the pedestrian movement must be regulated; otherwise, it is easy to fall into the faster-is-slower effect. It is especially important for evacuation routes with different widths. In this article, the optimal feedback control is studied to regulate pedestrian flow in heterogeneous corridors. It takes flow densities as state and produces commands that are composed of entrance influx and free-flow velocities. These commands can be executed with the support of speakers, displays, or the recently developed interactive robots. To avoid congestion, discharges of different corrido...
(Show More)",NO
2-s2.0-85103784977,10.1109/LRA.2021.3070308,,,Volumetric occupancy mapping with probabilistic depth completion for robotic navigation,ar,Article,Popovic M.,,Imperial College London;Universität Bonn,London;Bonn,United Kingdom;Germany,,,,,2021-07-01,July 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,3,9392300,5072-5079,,,0,0,,,,"In robotic applications, a key requirement for safe and efficient motion planning is the ability to map obstacle-free space in unknown, cluttered 3D environments. However, commodity-grade RGB-D cameras commonly used for sensing fail to register valid depth values on shiny, glossy, bright, or distant surfaces, leading to missing data in the map. To address this issue, we propose a framework leveraging probabilistic depth completion as an additional input for spatial mapping. We introduce a deep learning architecture providing uncertainty estimates for the depth completion of RGB-D images. Our pipeline exploits the inferred missing depth values and depth uncertainty to complement raw depth images and improve the speed and quality of free space mapping. Evaluations on synthetic data show that our approach maps significantly more correct free space with relatively low error when compared against using raw data alone in different indoor environments; thereby producing more complete maps that can be directly used for robotic navigation tasks. The performance of our framework is validated using real-world data.",NO
2-s2.0-85103766402,10.1109/LRA.2021.3070250,,,Learning Barrier Functions with Memory for Robust Safe Navigation,ar,Article,Long K.,,Contextual Robotics Institute,San Diego,United States,,,,,2021-07-01,July 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,3,9392327,4931-4938,,,0,0,,,,"Control barrier functions are widely used to enforce safety properties in robot motion planning and control. However, the problem of constructing barrier functions online and synthesizing safe controllers that can deal with the associated uncertainty has received little attention. This letter investigates safe navigation in unknown environments, using on-board range sensing to construct control barrier functions online. To represent different objects in the environment, we use the distance measurements to train neural network approximations of the signed distance functions incrementally with replay memory. This allows us to formulate a novel robust control barrier safety constraint which takes into account the error in the estimated distance fields and its gradient. Our formulation leads to a second-order cone program, enabling safe and stable control synthesis in a prior unknown environments.",NO
2-s2.0-85103280432,10.1109/LRA.2021.3067285,,,Visual Servoing of a Cable-Driven Soft Robot Manipulator with Shape Feature,ar,Article,Xu F.,,Shanghai Jiao Tong University,Shanghai,China,,,,,2021-07-01,July 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,3,9381634,4281-4288,,,2,0,,,,"Soft continuum robot is of superiority in the applications in unstructured environments due to its high flexibility and safe interaction ability. Accurate shape control is regarded as one of the prerequisites to improve its practicability. Considering the situation where the 3D position signals are not available, this letter investigates the vision-based shape control scheme of a soft robot manipulator. The curvature features used to depict the reference image shape of the robot backbone curve are solved through nonlinear optimization with given constraints of two endpoints in pixel coordinates. Thereafter, an adaptive image-based visual servoing controller is designed to track the reference image shape features with an uncalibrated monocular camera. The proposed algorithm was tested on an eight-cable driving soft robot prototype and proved its validity in convergence to the desired image shape.",NO
2-s2.0-85103265467,10.1109/LRA.2021.3067594,,,Planning for a Tight Squeeze: Navigation of Morphing Soft Robots in Congested Environments,ar,Article,Gough E.,,Bristol Robotics Laboratory,Bristol,United Kingdom,,,,,2021-07-01,July 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,3,9382069,4752-4757,,,1,0,,,,"Autonomous navigation methods can prevent robots becoming trapped between obstacles and ensure that they take the most efficient route. As mobile robots have a limited power supply, selecting the most efficient route is crucial. This letter presents a path-planning method for morphing soft robots in congested environments. The proposed method is suitable for all scales of robots and environments, from intra-organ biomedical navigation to search-and-rescue operations in cave networks. The method utilizes 3D Voronoi diagrams and Dijkstra's algorithm to calculate an optimal path that balances cost between the size and shape change of the robot and the length of the path. The Voronoi method is particularly suitable for circumferentially expanding robots because the waypoints generated lay where a device with a circular cross-section would naturally sit. The method is demonstrated by simulation in procedurally generated environments with either spherical or continuous obstacles to illustrate the effectiveness of the method for in-situ planning and as an aid to design. This letter provides a generic approach that has the potential to be easily adapted for many applications across healthcare, industry and space exploration.",NO
2-s2.0-85089353609,10.1109/LCSYS.2020.3007663,,,Integral Reinforcement Learning-Based Multi-Robot Minimum Time-Energy Path Planning Subject to Collision Avoidance and Unknown Environmental Disturbances,ar,Article,He C.,,The University of Texas at Arlington,Arlington,United States,,,,,2021-07-01,July 2021,IEEE Control Systems Letters,,21100885366,24751456,Journal,5,3,9134394,983-988,,,4,0,,,,"In this letter, we study the online multi-robot minimum time-energy path planning problem subject to collision avoidance and input constraints in an unknown environment. We develop an online adaptive solution for the problem using integral reinforcement learning (IRL). This is achieved through transforming the finite-horizon minimum time-energy problem with input constraints to an approximate infinite-horizon optimal control problem. To achieve collision avoidance, we incorporate artificial potential fields into the approximate cost function. We develop an IRL-based optimal control strategy and prove its convergence. The theoretical results are verified through simulation studies.",NO
2-s2.0-85079457281,10.1007/s11280-020-00778-y,,,OpenCL-Darknet: implementation and optimization of OpenCL-based deep learning object detection framework,ar,Article,Koo Y.,,Electronics and Telecommunications Research Institute,Daejeon,South Korea,,,,,2021-07-01,July 2021,World Wide Web,1386145X,14965,15731413,Journal,24,4,,1299-1319,,,2,0,,,,"Object detection is a technology that deals with recognizing classes of objects and their location. It is used in many different areas, such as in face-detecting systems [16, 34, 37], surveillance tools [9], human-machine interfaces [17], and self-driving cars [18, 23, 25, 26, 30]. These days, deep learning object detection approaches have achieved significantly better performance than the classical feature-based algorithms. Darknet [31] is a deep learning object detection framework, which is well known for its fast speed and simple structure. Unfortunately, Darknet can only work with Nvidia CUDA [6] for accelerating its deep learning calculations. For this reason, users have only limited options of selecting appropriate graphic cards. Open computing language (OpenCL) [35], an open standard for cross-platform, parallel programming of heterogeneous systems, is available for the general hardware accelerators. However, many deep learning frameworks including Darknet have no support for OpenCL.

In our previous paper, we presented OpenCL-Darknet [19], which transformed the CUDA-based Darknet into an open standard OpenCL backend. The original OpenCL-Darknet successfully showed its ability for the general graphics processing unit (GPU) hardware. However, it could not achieve competitive performance compared with the CUDA version, and it only supported a limited platform. In this study, we improved the performance of OpenCL-Darknet with several optimization techniques and added support for various architectures. We also evaluated OpenCL-Darknet not only in AMD R7 accelerated processing unit (APU) with OpenCL 2.0, but also in Nvidia GPU and ARM Mali embedded GPU with OpenCL 1.2 Profile. The evaluation using the standard object detection datasets showed that our advanced OpenCL-Darknet reduced the processing time by at most 50% on average for various deep learning object detection networks compared with our original implementation. We also showed that our OpenCL deep learning framework has competitiveness compared with the CUDA-based one.",NO
2-s2.0-85112487785,10.3901/JME.2021.11.128,,,Flexible Needle Path Planning Based on the Iterative Learning Algorithm,ar,Article,Li M.,,State Key Laboratory of Fluid Power and Mechatronic System,Hangzhou,China,,,,,2021-06-05,5 June 2021,Jixie Gongcheng Xuebao/Journal of Mechanical Engineering,05776686,20948,,Journal,57,11,,128-137,,,0,0,,,,,NO
2-s2.0-85109034702,10.3390/app11125699,,,Seamless human–robot collaborative assembly using artificial intelligence and wearable devices,ar,Article,Dimitropoulos N.,,University of Patras,Rio,Greece,,,,,2021-06-02,2 June 2021,Applied Sciences (Switzerland),,21100829268,20763417,Journal,11,12,5699,,,,0,1,,,,"Seamless human–robot collaboration requires the equipping of robots with cognitive capabilities that enable their awareness of the environment, as well as the actions that take place inside the assembly cell. This paper proposes an AI-based system comprised of three modules that can capture the operator and environment status and process status, identify the tasks that are being executed by the operator using vision-based machine learning, and provide customized operator support from the robot side for shared tasks, automatically adapting to the operator’s needs and preferences. Moreover, the proposed system is able to assess the ergonomics in human–robot shared tasks and adapt the robot pose to improve ergonomics using a heuristics-based search algorithm. An industrial case study derived from the elevator manufacturing sector using a high payload collaborative robot is presented to demonstrate that collaboration efficiency can be enhanced through the use of the discussed system. View Full-Text",NO
2-s2.0-85113850291,10.1007/s13218-021-00735-5,,,Early Introduction of AI in Spanish Middle Schools. A Motivational Study,ar,Article,Fernández-Martínez C.,,Universidad Rey Juan Carlos,Madrid,Spain,,,,,2021-06-01,June 2021,KI - Kunstliche Intelligenz,09331875,21101017166,16101987,Journal,35,2,,163-170,,,0,1,,,,"This paper describes the practical initiative to include Artificial Intelligence (AI) in the Spanish educational system’s curriculum at an early age. This proposal is in line with the current trend of introducing AI in school curricula all over the world. To this end, we propose an Artificial Intelligence workshop for middle schools within the existing subject, Technology, Programming and Robotics. In order to test the suitability of introducing AI at an early age, we conducted the activities at a bilingual middle school in Madrid. As evaluation tools, a quiz and motivational study of the students concerning AI was carried out using Situational Motivational Scale (SIMS) before and after introducing the activities. Responses of 84 students were analysed and the conclusion was reached that it is slightly better to introduce AI at an early age.",NO
2-s2.0-85107181147,10.3390/s21113916,,34204095,Development of an onboard robotic platform for embedded programming education,ar,Article,Lee H.J.,,Keyon System,Daegu,South Korea,,,,,2021-06-01,1 June 2021,Sensors,14248220,130124,,Journal,21,11,3916,,,,0,1,,,,"Robotics has been used as an attractive tool in diverse educational fields. A variety of robotic platforms have contributed to teaching practical embedded programming to engineering students at universities. However, most platforms only support content with a low level of programming skills and are unlikely to support a high level of embedded programming. This low association negatively affects students, such as incomprehension, decreased participation, dissatisfaction with course quality, etc. Therefore, this paper proposed a new robotic platform with relevant curricula to improve their effectiveness. The developed platform provided practical content used in mechatronics classes and the capability to operate a robot with a high level of embedded programming. To verify the effectiveness of the proposed platform, participants (undergraduates) examined course evaluations for educational programs based on the developed platform compared with the previous year’s class evaluation. The results showed that the proposed platform positively affects students’ intellectual ability (performance) and satisfaction in programming education. View Full-Text",SI
2-s2.0-85106435124,10.3390/s21113709,,34073565,Collaborative complete coverage and path planning for multi-robot exploration,ar,Article,Lin H.Y.,,National Chung Cheng University,Min-Hsiung,Taiwan,,,,,2021-06-01,1 June 2021,Sensors,14248220,130124,,Journal,21,11,3709,,,,1,1,,,,"In mobile robotics research, the exploration of unknown environments has always been an important topic due to its practical uses in consumer and military applications. One specific interest of recent investigation is the field of complete coverage and path planning (CCPP) techniques for mobile robot navigation. In this paper, we present a collaborative CCPP algorithms for single robot and multi-robot systems. The incremental coverage from the robot movement is maximized by evaluating a new cost function. A goal selection function is then designed to facilitate the collaborative exploration for a multi-robot system. By considering the local gains from the individual robots as well as the global gain by the goal selection, the proposed method is able to optimize the overall coverage efficiency. In the experiments, our CCPP algorithms are carried out on various unknown and complex environment maps. The simulation results and performance evaluation demonstrate the effectiveness of the proposed collaborative CCPP technique. View Full-Text",NO
2-s2.0-85106263070,10.1007/s10846-021-01400-7,,,A Methodological Approach to the Learning of Robotics with EDUROSC-Kids,ar,Article,Patiño-Escarcina R.E.,,Universidad Católica San Pablo,Arequipa,Peru,,,,,2021-06-01,June 2021,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,102,2,34,,,,0,1,,,,"With advances in science and technology, several innovative researches have been developed trying to figure out the main problems related to children’s learning. It is known that issues such as frustration and inattention, between others, affect student learning. In this fashion, robotics is an important resource that can be used towards helping to solve these issues, empowering our students in order to push their learning up. In this case, robotic tools are generally used considering two different paradigms: as the main focus and as a secondary focus. Actually, these paradigms define the way that Educational Robotics is implemented in schools. Most of the approaches have implemented it as the main focus, which is teaching Robotics. Nevertheless, there are quite a few works that implement robotics as a secondary focus, which is currently assisting the learning process in several disciplines. The main contribution of this work is a complete three steps methodology for Robotics in Education to guide projects in order to either use it alone or to teach robotics with others topics. Our experiments show the importance of devising a study plan and evaluation method because the process is iterative and could improve the final results. As a novelty, here we have joined and extended our previous works by proposing a new set of methods with guidelines and strategies for applying the educational robotics standard curriculum for kids, named EDUROSC-Kids. We propose several tools that have been developed to organize the learning topics of Robotics for children, including the desired outcomes during the learning process. As said our current approach is divided in three steps (or phases): setting up the environment, defining the project, and performing evaluation. The proposed curriculum organizes robotics contents into five disciplines: Robotics and Society, Mechanics, Electronics, Programming, and Control Theory. Also, it considers a set of topics for each discipline and defines the level of knowledge that is recommended to achieve each group of children based on Bloom’s Nomenclature. The contribution on this paper is a crucial step towards linking the general learning process with Educational Robotics approaches. Our methodology is validated by presenting practical experiences with application of EDUROSC-kids and the proposed method with a rubric guidelines into groups of children.",SI
2-s2.0-85104291317,10.1016/j.sysarc.2021.102116,S1383762121000886,,Learning based compilation of embedded applications targeting minimal energy consumption,ar,Article,Sachan A.,,Council of Indian Institutes of Information Technology,Gwalior,India,,,,,2021-06-01,June 2021,Journal of Systems Architecture,13837621,12398,,Journal,116,,102116,,,,0,0,,,,"The choice of correct optimization passes during compilation is one of the major factors that determines the performance and energy consumption of an application when executed on a target hardware. However, making such a choice is challenging since it requires knowledge of target architecture, code features and compiler pass interdependence. Software developers mostly rely on heuristic approaches while choosing the optimization passes. However, such heuristic solutions and random choices often yield sub-optimal results. In this work, we propose an automated technique of determining the optimal compiler optimization setting for minimum energy consumption utilizing power profile results and performance characteristics from real hardware and machine learning models. The proposed approach on one hand brings about reduction in energy consumption and on the other releases embedded software developers from making the complicated compiler optimization choices for each application. Our proposed five phase strategy when implemented on multi-core ARM based ODROID-XU4 experimental platform using the Clang Compiler shows a maximum of 8.43% improvement in power dissipation and a maximum of 27.27% in energy consumption for MiBench and Polybench representative benchmarks in comparison to state-of-art energy aware compilation strategies.",NO
2-s2.0-85100203716,10.1016/j.micpro.2021.103992,S0141933121001654,,Design of english video learning platform based on FPGA system and sobel algorithm,ar,Article,Liu T.,,Ludong University,Yantai,China,,,,,2021-06-01,June 2021,Microprocessors and Microsystems,01419331,15552,,Journal,83,,103992,,,,2,0,,,,"In order to improve the system performance of image processing and improve the efficiency of image processing, we can use some hardware running image processing algorithms. in practice, we introduce some reconfigurable devices and more advanced programming languages to use FPGA for image processing. following will briefly introduce the design of FPGA in the edge detection system.The design has integrated a 32-bit soft RISC processor as dedicated hardware peripheral micro development and EDK embedded system developed by the system generator. Input is detected from a real-time image obtained from the CMOS camera displayed on the DVI display on the screen.",NO
2-s2.0-85069899151,10.1109/TCDS.2019.2925890,,,Autonomous Identification and Goal-Directed Invocation of Event-Predictive Behavioral Primitives,ar,Article,Gumbsch C.,,Max Planck Institute for Intelligent Systems;Eberhard Karls Universität Tübingen,Tubingen;Tubingen,Germany;Germany,,,,,2021-06-01,June 2021,IEEE Transactions on Cognitive and Developmental Systems,23798920,21100784665,23798939,Journal,13,2,8753716,298-311,,,4,0,,,,"Voluntary behavior of humans appears to be composed of small, elementary building blocks, or behavioral primitives. While this modular organization seems crucial for the learning of complex motor skills and the flexible adaption of behavior to new circumstances, the problem of learning meaningful, compositional abstractions from sensorimotor experiences remains an open challenge. Here, we introduce a computational learning architecture, termed as surprise-based behavioral modularization into event-predictive structures (SUBMODES) that explores behavior and identifies the underlying behavioral units completely from scratch. The SUBMODES architecture bootstraps sensorimotor exploration using a self-organizing neural controller. While exploring the behavioral capabilities of its own body, the system learns modular structures that predict the sensorimotor dynamics and generate the associated behavior. In line with recent theories of event perception, the system uses unexpected prediction error signals, i.e., surprise, to detect transitions between successive behavioral primitives. We show that, when applied to two robotic systems with completely different body kinematics, the system manages to learn a variety of complex behavioral primitives. Moreover, after initial self exploration the system can use its learned predictive models progressively more effectively for invoking model predictive planning and goal-directed control in different tasks and environments.",NO
2-s2.0-85114006903,10.11975/j.issn.1002-6819.2021.10.015,,,Recognition of grape leaf diseases and mobile application based on transfer learning,ar,Article,Su S.,,Anhui Agricultural University,Hefei,China,,,,,2021-05-15,15 May 2021,Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering,10026819,62499,,Journal,37,10,,127-134,,,0,0,,,,,NO
2-s2.0-85112682853,10.1109/RITA.2021.3089919,,,Robotics as a Tool to Awaken Interest in Engineering and Computing among Children and Young People,ar,Article,Carro G.,,Universidad Nacional de Educacion a Distancia,Madrid,Spain,,,,,2021-05-01,May 2021,Revista Iberoamericana de Tecnologias del Aprendizaje,,19700201532,19328540,Journal,16,2,9459195,204-212,,,0,0,,,,"Training is critical on engineering and technology disciplines, and it must be used to encourage today's children and youngsters to become the engineers and scientists of the future. For this reason, the Techno Museum Project carried out a series of workshops that used robotics as a motivational item to bring electronics and programming closer to children from 6 to 18 years. These topics are, a priori, commonly considered complex. The effects of these experiences on engineering and science understanding were analyzed. This work presents those analyses, which prove that learning scenarios based on the use of robotic equipment increases the motivation and curiosity of children and young people towards the use of new technologies. Motivation promotes their will to understand engineering and science. The paper shows the processes carried out by the Techno Museum Project. As for the results, a set of questions was asked to each of the participants in the experience. We will conclude that the use of mechatronics and robotics on education is a powerful motivational tool to enhance the interests of children and young people with minimal training on science and engineering.",SI
2-s2.0-85104866400,10.1007/s42452-021-04567-8,,,Promotion of active ageing through interactive artificial agents in a smart environment,ar,Article,Menezes P.,,"University of Coimbra, Institute of Systems and Robotics",Coimbra,Portugal,,,,,2021-05-01,May 2021,SN Applied Sciences,,21101037132,25233971,Journal,3,5,583,,,,0,1,,,,"Societies in the most developed countries have witnessed a significant ageing of the population in recent decades, which increases the demand for healthcare services and caregivers. The development of technologies to help the elderly, so that they can remain active and independent for a longer time, helps to mitigate the sustainability problem posed in care services. This article follows this new trend, proposing a multi-agent system composed of a smart camera network, centralised planning agent, a virtual coach, and robotic exercise buddy, designed to promote regular physical activity habits among the elderly. The proposed system not only persuades the users to perform exercise routines, but also guides and accompanies them during exercises in order to provide effective training and engagement to the user. The different agents are combined in the system to exploit their complementary features in the quest for an effective and engaging training system. Three variants of the system, involving either a partial set of those agents or the full proposed system, were evaluated and compared through a pilot study conducted with 12 elderly users. The results demonstrate that all variants are able to guide the user in an exercise routine, but the most complete system that includes a robotic exercise buddy was the best scored by the participants.

Article Highlights

Proposal of a multi-agent system to help elderly adopting regular physical activity habits.

A virtual coach and a robotic exercise buddy provide both guidance and companionship during the exercise.

A pilot study conducted with 12 elderly users demonstrated an effective and engaging training system.",NO
2-s2.0-85104389093,10.1007/s10846-021-01328-y,,,Analysis of Methods for Incremental Policy Refinement by Kinesthetic Guidance,ar,Article,Simonič M.,,Jozef Stefan Institute,Ljubljana,Slovenia,,,,,2021-05-01,May 2021,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,102,1,5,,,,0,1,,,,"Traditional robot programming is often not feasible in small-batch production, as it is time-consuming, inefficient, and expensive. To shorten the time necessary to deploy robot tasks, we need appropriate tools to enable efficient reuse of existing robot control policies. Incremental Learning from Demonstration (iLfD) and reversible Dynamic Movement Primitives (DMP) provide a framework for efficient policy demonstration and adaptation. In this paper, we extend our previously proposed framework with improvements that provide better performance and lower the algorithm’s computational burden. Further, we analyse the learning stability and evaluate the proposed framework with a comprehensive user study. The proposed methods have been evaluated on two popular collaborative robots, Franka Emika Panda and Universal Robot UR10.",NO
2-s2.0-85104097471,10.1007/s10846-021-01383-5,,,"The MRS UAV System: Pushing the Frontiers of Reproducible Research, Real-world Deployment, and Education with Autonomous Unmanned Aerial Vehicles",ar,Article,Baca T.,,Czech Technical University in Prague,Prague,Czech Republic,,,,,2021-05-01,May 2021,Journal of Intelligent and Robotic Systems: Theory and Applications,09210296,24360,15730409,Journal,102,1,26,,,,7,0,,,,"We present a multirotor Unmanned Aerial Vehicle (UAV) control and estimation system for supporting replicable research through realistic simulations and real-world experiments. We propose a unique multi-frame localization paradigm for estimating the states of a UAV in various frames of reference using multiple sensors simultaneously. The system enables complex missions in GNSS and GNSS-denied environments, including outdoor-indoor transitions and the execution of redundant estimators for backing up unreliable localization sources. Two feedback control designs are presented: one for precise and aggressive maneuvers, and the other for stable and smooth flight with a noisy state estimate. The proposed control and estimation pipeline are constructed without using the Euler/Tait-Bryan angle representation of orientation in 3D. Instead, we rely on rotation matrices and a novel heading-based convention to represent the one free rotational degree-of-freedom in 3D of a standard multirotor helicopter. We provide an actively maintained and well-documented open-source implementation, including realistic simulation of UAV, sensors, and localization systems. The proposed system is the product of years of applied research on multi-robot systems, aerial swarms, aerial manipulation, motion planning, and remote sensing. All our results have been supported by real-world system deployment that subsequently shaped the system into the form presented here. In addition, the system was utilized during the participation of our team from the Czech Technical University in Prague in the prestigious MBZIRC 2017 and 2020 robotics competitions, and also in the DARPA Subterranean challenge. Each time, our team was able to secure top places among the best competitors from all over the world.",NO
2-s2.0-85101350856,10.1016/j.cie.2021.107173,S0360835221000772,,A fast robot path planning algorithm based on bidirectional associative learning,ar,Article,Zhao M.,,Beihang University,Beijing,China,,,,,2021-05-01,May 2021,Computers and Industrial Engineering,03608352,18164,,Journal,155,,107173,,,,0,0,,,,"Highlights

•

A robot fast path planning algorithm used in unknown environment is proposed.

•

The episode is defined to satisfy the continuity of robot position in application.

•

Reducing planning time by locking search scope in the early stage of planning.

•

Some action selection strategies are proposed to improve the planning efficiency.
Fast path planning in unknown environment is important to reduce the loss of human and material resources. To reduce planning time while obtaining a short path, this paper proposes a Bidirectional Associative Learning Algorithm (BALA). In the proposed algorithm, an episode is defined as a bidirectional movement between the start point and the target point. The planning process in the BALA is divided into three stages: early stage, medium stage and end stage. In the early stage, the attraction of the target point is adopted to instruct the robot to select action. This strategy not only helps the robot avoid blind search, but also provides the search scope that may contain the global shortest path for the subsequent episodes. In the medium stage, we propose an action selection strategy based on the experience guidance, where the experience obtained in the obverse and reverse movements is used alternately to improve the learning efficiency of the robot. In the end stage, a strong connectivity relationship between nodes is defined. Planning by this relationship, the length of the final planned path will be the shortest based on the experience the robot obtains. The comparison results with Q-Learning and its improved algorithm reveal that the BALA demonstrates desirable and stable performance in planning efficiency in any environment, and it can well balance the planning time and path length. Additionally, the practicability of the proposed algorithm is validated on Turtlebot3 burger robot.",NO
2-s2.0-85098942830,10.1016/j.future.2020.12.012,S0167739X20330740,,Multi-robot path planning in wireless sensor networks based on jump mechanism PSO and safety gap obstacle avoidance,ar,Article,Tian S.,,South-Central University for Nationalities;Wuhan University,Wuhan;Wuhan,China;China,,,,,2021-05-01,May 2021,Future Generation Computer Systems,0167739X,12264,,Journal,118,,,37-47,,,7,0,,,,"Highlights

•

In this paper, JPSO algorithm and SGOA algorithm were proposed.

•

The JPSO algorithm updates the particles with poor comprehensive quality by jumping and adjusts the inertia weight adaptively according to fitness value evaluation function.

•

With the cooperation of new learning samples in JPSO algorithm, the global searching ability and precision of the algorithm can be improved.

•

By implementing the SGOA algorithm, a new collision-free safety path can be optimized for the robot with low priority.
In order to meet the real-time and accurate requirements of multi-robot path planning in dynamic environment, this paper adopted wireless sensor network to locate robots and obstacles and used an improved artificial intelligent algorithm to plan path. In this paper, a jumping mechanism particle swarm optimization (JPSO) algorithm and a safety gap obstacle avoidance algorithm (SGOA) algorithm were proposed. Compared with canonical PSO algorithm, JPSO algorithm has three improvement strategies: Fitness value evaluation function, new learning sample and jumping strategy. The JPSO algorithm updates the particles with poor comprehensive quality by jumping and adjusts the inertia weight adaptively according to fitness value evaluation function. With the cooperation of new learning samples, the global searching ability and precision of the algorithm can be improved. SGOA algorithm is mainly aimed at the problem that robots with low priority are stuck in a long wait and cannot continue to walk when avoiding obstacles. By implementing the SGOA algorithm, a new collision-free safety path can be optimized for the robot with low priority. In order to verify JPSO and SGOA algorithm, a lot of experiments were done. JPSO algorithm was compared with two other improved PSO algorithms with 6 standard test functions. The path planning and obstacle avoidance experiments of six robots were realized using the JPSO and SGOA algorithm. The experimental results show that JPSO algorithm has higher accuracy and faster convergence speed than the other two improved PSO algorithms, and SGOA algorithm can solve the dynamic obstacle avoidance problem in the path planning of multiple robots well.",NO
2-s2.0-85098708110,10.1142/S021812662150105X,,,Performance Analysis of Deterministic Finite Automata and Turing Machine Using JFLAP Tool,ar,Article,Devi B.P.,,M. Kumarasamy College of Engineering,Karur,India,,,,,2021-05-01,May 2021,"Journal of Circuits, Systems and Computers",02181266,26046,,Journal,30,6,2150105X,,,,0,0,,,,"In real life, the increased data accessing speed and data storage ability is required by most of the machinery fields. However, the real-world problems can be studied effectively with the combination of scientific computational techniques with the mathematical models. Automata theory is known to be the popular mathematical model. Towards most of the software and hardware related applications, the computational methods are analyzed and designed using significant automata theory concepts (likely, pushdown automata (PDA), Turing machines (TMs) and finite automata (FA)). Hence, the conventional lecture-driven style has attracted the reflective preferences of learners using these abstract natured concepts. But the lecture-driven teaching style has less motivated the computer engineering learners. In order to learn automata theory and computational models, we introduce the PDA and TM in a virtual platform. However, this work has motivated the improvement of longitudinal experimental validation and learning using the modern technology. Java Formal Languages and Automata Package (JFLAP) tool is used to write our simulators in JAVA language and the results are obtained from each machine through simulating the input strings.",NO
2-s2.0-85103558380,10.3390/s21082577,,33916995,Coverage path planning using reinforcement learning-based tsp for htetran — A polyabolo-inspired self-reconfigurable tiling robot,ar,Article,Le A.V.,,Singapore University of Technology and Design;Ton-Duc-Thang University,;Ho Chi Minh City,Singapore;Viet Nam,,,,,2021-04-02,2 April 2021,Sensors,14248220,130124,,Journal,21,8,2577,,,,3,1,,,,"One of the critical challenges in deploying the cleaning robots is the completion of covering the entire area. Current tiling robots for area coverage have fixed forms and are limited to cleaning only certain areas. The reconfigurable system is the creative answer to such an optimal coverage problem. The tiling robot’s goal enables the complete coverage of the entire area by reconfiguring to different shapes according to the area’s needs. In the particular sequencing of navigation, it is essential to have a structure that allows the robot to extend the coverage range while saving energy usage during navigation. This implies that the robot is able to cover larger areas entirely with the least required actions. This paper presents a complete path planning (CPP) for hTetran, a polyabolo tiled robot, based on a TSP-based reinforcement learning optimization. This structure simultaneously produces robot shapes and sequential trajectories whilst maximizing the reward of the trained reinforcement learning (RL) model within the predefined polyabolo-based tileset. To this end, a reinforcement learning-based travel sales problem (TSP) with proximal policy optimization (PPO) algorithm was trained using the complementary learning computation of the TSP sequencing. The reconstructive results of the proposed RL-TSP-based CPP for hTetran were compared in terms of energy and time spent with the conventional tiled hypothetical models that incorporate TSP solved through an evolutionary based ant colony optimization (ACO) approach. The CPP demonstrates an ability to generate an ideal Pareto optima trajectory that enhances the robot’s navigation inside the real environment with the least energy and time spent in the company of conventional techniques. View Full-Text",NO
2-s2.0-85103511499,10.3390/s21072534,,33916624,Deep reinforcement learning for end-to-end local motion planning of autonomous aerial robots in unknown outdoor environments: Real-time flight experiments,ar,Article,Doukhi O.,,Kunsan National University,Gunsan,South Korea,,,,,2021-04-01,1 April 2021,Sensors,14248220,130124,,Journal,21,7,2534,,,,1,1,,,,"Autonomous navigation and collision avoidance missions represent a significant challenge for robotics systems as they generally operate in dynamic environments that require a high level of autonomy and flexible decision-making capabilities. This challenge becomes more applicable in micro aerial vehicles (MAVs) due to their limited size and computational power. This paper presents a novel approach for enabling a micro aerial vehicle system equipped with a laser range finder to autonomously navigate among obstacles and achieve a user-specified goal location in a GPS-denied environment, without the need for mapping or path planning. The proposed system uses an actor–critic-based reinforcement learning technique to train the aerial robot in a Gazebo simulator to perform a point-goal navigation task by directly mapping the noisy MAV’s state and laser scan measurements to continuous motion control. The obtained policy can perform collision-free flight in the real world while being trained entirely on a 3D simulator. Intensive simulations and real-time experiments were conducted and compared with a nonlinear model predictive control technique to show the generalization capabilities to new unseen environments, and robustness against localization noise. The obtained results demonstrate our system’s effectiveness in flying safely and reaching the desired points by planning smooth forward linear velocity and heading rates. View Full-Text",NO
2-s2.0-85103394440,10.1007/s11370-021-00363-w,,,Coordination of multi-robot path planning for warehouse application using smart approach for identifying destinations,ar,Article,Sharma K.,,National Institute of Technology Raipur,Raipur,India,,,,,2021-04-01,April 2021,Intelligent Service Robotics,18612776,9500154152,18612784,Journal,14,2,,313-325,,,1,0,,,,"Path planning and coordination in a multi-robot system are important and complex tasks in any environment. In a multi-robot system, there can be multiple objectives to be achieved by multiple robots simultaneously. Nowadays, many mobile service robots are being used in warehouses to reduce running costs and overheads. In a large warehouse, there can be multiple robots to handle the number of operations. Planning a path means to find out the optimal route, and coordinating them means a collision-free route. To get both the parameters to reach their optimal level becomes a tedious task to achieve. The efficiency of overall warehouse operation can be improved by adequately addressing the coordination and path planning issues among the robots. In warehouses, each robot has to navigate to its destination by finding a collision-free optimal route in coordination with other robots. In this paper, a comparative study with the acclaimed path planning and coordination has been presented. The proposed smart approach has been presented for a multi-robot system to find a collision-free optimal path in a warehouse to handle storage pods. This paper proposes a smart distance metric-based approach for a multi-robot system to identify their goals smartly and traverse only a minimal path to reach their goal without getting being collided. It uses a smart distance metric-based approach to find the intended path. The proposed work performs better when compared with other works like A* and ILP. It is strictly monitored that there is no collision occurred during execution. Three different instances of a warehouse have been considered to carry out the experiments with parameters such as path length, average path and elapsed time. The experiments with 800 pods and 16 robots report the improvement in performance up to 2.5% and 13% in average path length and elapsed time.",NO
2-s2.0-85103333065,10.1109/JPROC.2021.3063154,,,Learning-Based Automation of Robotic Assembly for Smart Manufacturing,ar,Article,Ji S.,,Korea Institute of Industrial Technology,Cheonan,South Korea,,,,,2021-04-01,April 2021,Proceedings of the IEEE,00189219,17915,15582256,Journal,109,4,9383829,423-440,,,4,1,,,,"For smart manufacturing, an automated robotic assembly system built upon an autoprogramming environment is necessary to reduce setup time and cost for robots that are engaged in frequent task reassignment. This article presents an approach to the autoprogramming of robotic assembly tasks with minimal human assistance. The approach integrates “robotic learning of assembly tasks from observation” and “robotic embodiment of learned assembly tasks in the form of skills.” In the former, robots observe human assembly operations to learn a sequence of assembly tasks, which is formalized into a human assembly script. The latter transforms the human assembly script into a robot assembly script in which a sequence of robot-executable assembly tasks are defined based on action planning supported by workspace modeling and simulated retargeting. The assembly tasks, in the form of the robot assembly script, are then implemented via pretrained robot skills. These skills aim to enable robots to execute difficult tasks that involve inherent uncertainties and variations. We validate the proposed approach by building a prototype of the automated robotic assembly system for a power breaker and an electronic set-top box. The results verify that the proposed automated robotic assembly system is not only feasible but also viable, as it is associated with a dramatic reduction in the human effort required for automating robotic assembly.",NO
2-s2.0-85103005407,10.1109/TVT.2021.3066482,,,Real-Time Path Planning and following of a Gliding Robotic Dolphin within a Hierarchical Framework,ar,Article,Wang J.,,University of Chinese Academy of Sciences;Institute of Automation Chinese Academy of Sciences,Beijing;Beijing,China;China,,,,,2021-04-01,April 2021,IEEE Transactions on Vehicular Technology,00189545,17393,19399359,Journal,70,4,9380299,3243-3255,,,0,0,,,,"This paper proposes a novel hierarchical framework to achieve real-time path planning and following for a gliding robotic dolphin, including a learning-based path planner and an adaptive following controller. Subsequent to considering higher intelligence in unknown ocean environment, we present a novel hierarchical deep Q-network method to separately plan the collision avoidance path and the approach path, and also design different continuous-states under the kinematic constraints. Next, we adopt an improved line-of-sight method to obtain the desired points from planned path. More importantly, we derive a nonlinear control law based on backstepping technique, and specially avoid singularities in the law derivation using barrier Lyapunov function. In particular, the unknown model parameters are adaptively calculated to make the controller more robust. Finally, extensive simulation and experimental results verify the effectiveness of the proposed methods, providing a new idea to further ocean exploration.",NO
2-s2.0-85102305776,10.1109/LRA.2021.3063989,,,Reachability-Based Trajectory Safeguard (RTS): A Safe and Fast Reinforcement Learning Safety Layer for Continuous Control,ar,Article,Shao Y.S.,,"University of Michigan, Ann Arbor",Ann Arbor,United States,,,,,2021-04-01,April 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,2,9369910,3663-3670,,,0,0,,,,"Reinforcement Learning (RL) algorithms have achieved remarkable performance in decision making and control tasks by reasoning about long-term, cumulative reward using trial and error. However, during RL training, applying this trial-and-error approach to real-world robots operating in safety critical environment may lead to collisions. To address this challenge, this letter proposes a Reachability-based Trajectory Safeguard (RTS), which leverages reachability analysis to ensure safety during training and operation. Given a known (but uncertain) model of a robot, RTS precomputes a Forward Reachable Set of the robot tracking a continuum of parameterized trajectories. At runtime, the RL agent selects from this continuum in a receding-horizon way to control the robot; the FRS is used to identify if the agent's choice is safe or not, and to adjust unsafe choices. The efficacy of this method is illustrated in static environments on three nonlinear robot models, including a 12-D quadrotor drone, in simulation and in comparison with state-of-the-art safe motion planning methods.",NO
2-s2.0-85102285081,10.1109/LRA.2021.3062805,,,Learning-Based Predictive Path following Control for Nonlinear Systems under Uncertain Disturbances,ar,Article,Yang R.,,Sun Yat-Sen University,Guangzhou,China,,,,,2021-04-01,April 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,2,9366351,2854-2861,,,1,0,,,,"Accurate path following is challenging for autonomous robots operating in uncertain environments. Adaptive and predictive control strategies are crucial for a nonlinear robotic system to achieve high-performance path following control. In this letter, we propose a novel learning-based predictive control scheme that couples a high-level model predictive path following controller (MPFC) with a low-level learning-based feedback linearization controller (LB-FBLC) for nonlinear systems under uncertain disturbances. The low-level LB-FBLC utilizes Gaussian Processes to learn the uncertain environmental disturbances online and tracks the reference state accurately with a probabilistic stability guarantee. Meanwhile, the high-level MPFC exploits the linearized system model augmented with a virtual linear path dynamics model to optimize the evolution of path reference targets, and provides the reference states and controls for the low-level LB-FBLC. Simulation results illustrate the effectiveness of the proposed control strategy on a quadrotor path following task under unknown wind disturbances.",NO
2-s2.0-85102261113,10.1109/LRA.2021.3062798,,,Exploiting Natural Language for Efficient Risk-Aware Multi-Robot SaR Planning,ar,Article,Shree V.,,Cornell University College of Engineering,Ithaca,United States,,,,,2021-04-01,April 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,2,9366368,3152-3159,,,0,0,,,,"The ability to develop a high-level understanding of a scene, such as perceiving danger levels, can prove valuable in planning multi-robot search and rescue (SaR) missions. In this work, we propose to uniquely leverage natural language descriptions from the mission commander in chief and image data captured by robots to estimate scene danger. Given a description and an image, a state-of-the-art deep neural network is used to assess a corresponding similarity score, which is then converted into a probabilistic distribution of danger levels. Because commonly used visio-linguistic datasets do not represent SaR missions well, we collect a large-scale image-description dataset from synthetic images taken from realistic disaster scenes and use it to train our machine learning model. A risk-aware variant of the Multi-robot Efficient Search Path Planning (MESPP) problem is then formulated to use the danger estimates in order to account for high-risk locations in the environment when planning the searchers' paths. The problem is solved via a distributed approach based on Mixed-Integer Linear Programming. Our experiments demonstrate that our framework allows to plan safer yet highly successful search missions, abiding to the two most important aspects of SaR missions: to ensure both searchers' and victim safety.",NO
2-s2.0-85101856603,10.1088/1361-6501/abcc15,,,A robust visual odometry based on RGB-D camera in dynamic indoor environments,ar,Article,Zhang F.,,Zhengzhou University,Zhengzhou,China,,,,,2021-04-01,April 2021,Measurement Science and Technology,09570233,15526,13616501,Journal,32,4,044003,,,,1,0,,,,"To solve the accurate positioning problem of mobile robots, simultaneous localization and mapping (SLAM) or visual odometry (VO) based on visual information are widely used. However, most visual SLAM or VO cannot meet the accuracy requirements in dynamic indoor environments. This paper proposes a robust visual odometry based on deep learning to eliminate feature points matching error. However, when a camera and dynamic objects are in relative motion, the frames of camera will produce ghosting, especially in high-dynamic environments, which bring additional positioning error; in view of this problem, a novel method based on the average optical flow value of the dynamic region is proposed to identify feature points of the ghosting, and then the feature points of the ghosting and dynamic region are removed. After the remaining feature points are matched, we use a non-linear optimization method to calculate the pose. The proposed algorithm is tested on TUM RGB-D dataset, and the results show that our VO improves the positioning accuracy than other robust SLAM or VO and is strongly robust especially in high-dynamic environments.",NO
2-s2.0-85101751105,10.1109/LRA.2021.3061372,,,A Coach-Based Bayesian Reinforcement Learning Method for Snake Robot Control,ar,Article,Jia Y.,,Ritsumeikan University Biwako-Kusatsu Campus,Kusatsu,Japan,,,,,2021-04-01,April 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,2,9361111,2319-2326,,,1,0,,,,"Reinforcement Learning (RL) usually needs thousands of episodes, leading its applications on physical robots expensive and challenging. Little research has been reported about snake robot control using RL due to additional difficulty of high redundancy of freedom. We propose a coach-based deep learning method for snake robot control, which can effectively save convergence time with much less episodes. The main contributions include: 1) a unified graph-based Bayesian framework integrating a coach module to guide the RL agent; 2) an explicit stochastic formulation of robot-environment interaction with uncertainty; 3) an efficient and robust training process for snake robot control to achieve both path planning and obstacle avoidance simultaneously. The performance has been demonstrated on both simulation and real-world data in comparison with state-of-the-art, showing promising results.",NO
2-s2.0-85101732865,10.1109/LRA.2021.3060649,,,Learning Composable Behavior Embeddings for Long-Horizon Visual Navigation,ar,Article,Meng X.,,University of Washington,Seattle,United States,,,,,2021-04-01,April 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,2,9359335,3128-3135,,,0,0,,,,"Learning high-level navigation behaviors has important implications: it enables robots to build compact visual memory for repeating demonstrations and to build sparse topological maps for planning in novel environments. Existing approaches only learn discrete, short-horizon behaviors. These standalone behaviors usually assume a discrete action space with simple robot dynamics, thus they cannot capture the intricacy and complexity of real-world trajectories. To this end, we propose Composable Behavior Embedding (CBE), a continuous behavior representation for long-horizon visual navigation. CBE is learned in an end-to-end fashion; it effectively captures path geometry and is robust to unseen obstacles. We show that CBE can be used to performing memory-efficient path following and topological mapping, saving more than an order of magnitude of memory than behavior-less approaches.",NO
2-s2.0-85101732326,10.1109/LRA.2021.3061073,,,Learning Interaction-Aware Trajectory Predictions for Decentralized Multi-Robot Motion Planning in Dynamic Environments,ar,Article,Zhu H.,,"Department of Cognitive Robotics, TU Delft",Delft,Netherlands,,,,,2021-04-01,April 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,2,9360433,2256-2263,,,1,0,,,,"This letter presents a data-driven decentralized trajectory optimization approach for multi-robot motion planning in dynamic environments. When navigating in a shared space, each robot needs accurate motion predictions of neighboring robots to achieve predictive collision avoidance. These motion predictions can be obtained among robots by sharing their future planned trajectories with each other via communication. However, such communication may not be available nor reliable in practice. In this letter, we introduce a novel trajectory prediction model based on recurrent neural networks (RNN) that can learn multi-robot motion behaviors from demonstrated trajectories generated using a centralized sequential planner. The learned model can run efficiently online for each robot and provide interaction-aware trajectory predictions of its neighbors based on observations of their history states. We then incorporate the trajectory prediction model into a decentralized model predictive control (MPC) framework for multi-robot collision avoidance. Simulation results show that our decentralized approach can achieve a comparable level of performance to a centralized planner while being communication-free and scalable to a large number of robots. We also validate our approach with a team of quadrotors in real-world experiments.",NO
2-s2.0-85101731353,10.1109/LRA.2021.3060408,,,Robust Policy Search for Robot Navigation,ar,Article,Garcia-Barcos J.,,Universidad de Zaragoza,Zaragoza,Spain,,,,,2021-04-01,April 2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,6,2,9357906,2389-2396,,,0,0,,,,"Complex robot navigation and control problems can be framed as policy search problems. However, interactive learning in uncertain environments can be expensive, requiring the use of data-efficient methods. Bayesian optimization is an efficient nonlinear optimization method where queries are carefully selected to gather information about the optimum location. This is achieved by a surrogate model, which encodes past information, and the acquisition function for query selection. Bayesian optimization can be very sensitive to uncertainty in the input data or prior assumptions. In this letter, we incorporate both robust optimization and statistical robustness, showing that both types of robustness are synergistic. For robust optimization we use an improved version of unscented Bayesian optimization which provides safe and repeatable policies in the presence of policy uncertainty. We also provide new theoretical insights. For statistical robustness, we use an adaptive surrogate model and we introduce the Boltzmann selection as a stochastic acquisition method to have convergence guarantees and improved performance even with surrogate modeling errors. We present results in several optimization benchmarks and robot tasks.",NO
2-s2.0-85100996629,10.1177/0278364921992793,,,A model predictive approach for online mobile manipulation of non-holonomic objects using learned dynamics,ar,Article,Sabbagh Novin R.,,The University of Utah,Salt Lake City,United States,,,,,2021-04-01,April 2021,International Journal of Robotics Research,02783649,18050,17413176,Journal,40,4-5,,815-831,,,0,0,,,,"Assistive robots designed for physical interaction with objects will play an important role in assisting with mobility and fall prevention in healthcare facilities. Autonomous mobile manipulation presents a hurdle prior to safely using robots in real-life applications. In this article, we introduce a mobile manipulation framework based on model predictive control using learned dynamics models of objects. We focus on the specific problem of manipulating legged objects such as those commonly found in healthcare environments and personal dwellings (e.g., walkers, tables, chairs). We describe a probabilistic method for autonomous learning of an approximate dynamics model for these objects. In this method, we learn dynamic parameters using a small dataset consisting of force and motion data from interactions between the robot and object. Moreover, we account for multiple manipulation strategies by formulating manipulation planning as a mixed-integer convex optimization. The proposed framework considers the hybrid control system composed of (i) choosing which leg to grasp and (ii) control of continuous applied forces for manipulation. We formalize our algorithm based on model predictive control to compensate for modeling errors and find an optimal path to manipulate the object from one configuration to another. We present results for several objects with various wheel configurations. Simulation and physical experiments show that the obtained dynamics models are sufficiently accurate for safe and collision-free manipulation. When combined with the proposed manipulation planning algorithm, the robot successfully moves the object to the desired pose while avoiding any collision.",NO
2-s2.0-85100995523,10.1007/s10994-020-05934-z,,,Learning programs by learning from failures,ar,Article,Cropper A.,,University of Oxford,Oxford,United Kingdom,,,,,2021-04-01,April 2021,Machine Learning,08856125,24775,15730565,Journal,110,4,,801-856,,,0,1,,,,"We describe an inductive logic programming (ILP) approach called learning from failures. In this approach, an ILP system (the learner) decomposes the learning problem into three separate stages: generate, test, and constrain. In the generate stage, the learner generates a hypothesis (a logic program) that satisfies a set of hypothesis constraints (constraints on the syntactic form of hypotheses). In the test stage, the learner tests the hypothesis against training examples. A hypothesis fails when it does not entail all the positive examples or entails a negative example. If a hypothesis fails, then, in the constrain stage, the learner learns constraints from the failed hypothesis to prune the hypothesis space, i.e. to constrain subsequent hypothesis generation. For instance, if a hypothesis is too general (entails a negative example), the constraints prune generalisations of the hypothesis. If a hypothesis is too specific (does not entail all the positive examples), the constraints prune specialisations of the hypothesis. This loop repeats until either (i) the learner finds a hypothesis that entails all the positive and none of the negative examples, or (ii) there are no more hypotheses to test. We introduce Popper, an ILP system that implements this approach by combining answer set programming and Prolog. Popper supports infinite problem domains, reasoning about lists and numbers, learning textually minimal programs, and learning recursive programs. Our experimental results on three domains (toy game problems, robot strategies, and list transformations) show that (i) constraints drastically improve learning performance, and (ii) Popper can outperform existing ILP systems, both in terms of predictive accuracies and learning times.",NO
2-s2.0-85095428813,10.1016/j.rcim.2020.102085,S0736584520302957,,MEGURU: a gesture-based robot program builder for Meta-Collaborative workstations,ar,Article,Nuzzi C.,,Università degli Studi di Brescia,Brescia,Italy,,,,,2021-04-01,April 2021,Robotics and Computer-Integrated Manufacturing,07365845,18080,,Journal,68,,102085,,,,5,0,,,,"Highlights

•

Definition and presentation of the novel idea of Meta-Collaborative workstations.

•

The developed ROS-based software called MEGURU (MEta-collaborative GestUre-based Robot program bUilder) is described in detail.

•

MEGURU GitHub repository page is supplied.

•

Experimental evaluation of a demo MEGURU interface to assess the behavior of users of different age, sex and professional background using the developed prototype.

•

Experimental evaluation of the MEGURU interface in the task of assembling a moka coffee maker, comparing the prototype performances to the Teach Pendant traditional programming method.
This paper presents the Meta-Collaborative Workstation concept and a gesture-based robot program builder software named MEGURU. The software is ROS-based, and it is publicly available on GitHub. A hand-gestures language has been developed to create a fast and easy to use communication method, where single-hand gestures are combined to create composed Commands, allowing the user to create a customized, powerful, and flexible Gestures Dictionary. Gestures are recognized using an R-FCN Object Detector model fine-tuned on a custom dataset developed for this work.

The system has been tested in two experiments. The first one was aimed at evaluating the user experience of people of different age, sex, and professional background concerning the proposed communication method. The second one was aimed at comparing the traditional teach pendant programming method and MEGURU in the task of assembling a small Moka coffee maker. The results of both experiments highlight that MEGURU is a promising robot programming method, especially for non-expert users.",NO
2-s2.0-85093972789,10.1109/LCSYS.2020.3002852,,,Self-Configuring Robot Path Planning with Obstacle Avoidance via Deep Reinforcement Learning,ar,Article,Sangiovanni B.,,Università degli Studi di Pavia,Pavia,Italy,,,,,2021-04-01,April 2021,IEEE Control Systems Letters,,21100885366,24751456,Journal,5,2,9119090,397-402,,,7,0,,,,"This letter proposes a hybrid control methodology to achieve full body collision avoidance in anthropomorphic robot manipulators. The proposal improves classical motion planning algorithms by introducing a Deep Reinforcement Learning (DRL) approach trained ad hoc for performing obstacle avoidance, while achieving a reaching task in the operative space. More specifically, a switching mechanism is enabled whenever a condition of proximity to the obstacles is met, thus conferring to the dual-mode architecture a self-configuring capability in order to cope with objects unexpectedly invading the workspace. The proposal has been finally tested relying on a realistic robot manipulator simulated in a V-REP environment.",NO
2-s2.0-85092146703,10.1002/rnc.5122,,,Integral reinforcement learning-based approximate minimum time-energy path planning in an unknown environment,ar,Article,He C.,,The University of Texas at Arlington,Arlington,United States,,,,,2021-04-01,April 2021,International Journal of Robust and Nonlinear Control,10498923,17987,10991239,Journal,31,6,,1905-1922,,,2,1,,,,"Summary

Path planning is a fundamental and critical task in many robotic applications. For energy-constrained robot platforms, path planning solutions are desired with minimum time arrivals and minimal energy consumption. Uncertain environments, such as wind conditions, pose challenges to the design of effective minimum time-energy path planning solutions. In this article, we develop a minimum time-energy path planning solution in continuous state and control input spaces using integral reinforcement learning (IRL). To provide a baseline solution for the performance evaluation of the proposed solution, we first develop a theoretical analysis for the minimum time-energy path planning problem in a known environment using the Pontryagin's minimum principle. We then provide an online adaptive solution in an unknown environment using IRL. This is done through transforming the minimum time-energy problem to an approximate minimum time-energy problem and then developing an IRL-based optimal control strategy. Convergence of the IRL-based optimal control strategy is proven. Simulation studies are developed to compare the theoretical analysis and the proposed IRL-based algorithm.",NO
2-s2.0-85089185917,10.1007/s00521-020-05224-8,,,A neural integrator model for planning and value-based decision making of a robotics assistant,ar,Article,Wojtak W.,,Universidade do Minho,Braga,Portugal,,,,,2021-04-01,April 2021,Neural Computing and Applications,09410643,24800,14333058,Journal,33,8,,3737-3756,,,2,0,,,,"Modern manufacturing and assembly environments are characterized by a high variability in the built process which challenges human–robot cooperation. To reduce the cognitive workload of the operator, the robot should not only be able to learn from experience but also to plan and decide autonomously. Here, we present an approach based on Dynamic Neural Fields that apply brain-like computations to endow a robot with these cognitive functions. A neural integrator is used to model the gradual accumulation of sensory and other evidence as time-varying persistent activity of neural populations. The decision to act is modeled by a competitive dynamics between neural populations linked to different motor behaviors. They receive the persistent activation pattern of the integrators as input. In the first experiment, a robot learns rapidly by observation the sequential order of object transfers between an assistant and an operator to subsequently substitute the assistant in the joint task. The results show that the robot is able to proactively plan the series of handovers in the correct order. In the second experiment, a mobile robot searches at two different workbenches for a specific object to deliver it to an operator. The object may appear at the two locations in a certain time period with independent probabilities unknown to the robot. The trial-by-trial decision under uncertainty is biased by the accumulated evidence of past successes and choices. The choice behavior over a longer period reveals that the robot achieves a high search efficiency in stationary as well as dynamic environments.",NO
2-s2.0-85097294284,10.1108/IR-01-2020-0010,,,Effectiveness of multi-gated sequence model for the learning of kinematics and dynamics of an industrial robot,ar,Article,Singh A.,,"Indian Institute of Information Technology, Allahabad",Allahabad,India,,,,,2021-03-19,19 Mar 2021,Industrial Robot,0143991X,18047,,Journal,48,1,,62-70,,,0,0,,,,"Purpose

For efficient trajectory control of industrial robots, a cumbersome computation for inverse kinematics and inverse dynamics is needed, which is usually developed using spatial transformation using Denavit–Hartenberg principle and Lagrangian or Newton–Euler methods, respectively. The model is highly non-linear and needs to deal with uncertainties because of lack of accurate measurement of mechanical parameters, noise and non-inclusion of joint friction, which results in some inaccuracies in predicting accurate torque trajectories. To get a guaranteed closed form solution, the robot designers normally follow Pieper’s recommendation and compromise with the mechanical design. While this may be acceptable for the industrial robots where the aesthetic look is not that important, it is not for humanoid and social robots. To help solve this problem, this study aims to propose an alternative machine learning-based computational approach based on a multi-gated sequence model for finding appropriate mapping between Cartesian space to joint space and motion space to joint torque space.

Design/methodology/approach

First, the authors generate sufficient data required for the sequence model, using forward kinematics and forward dynamics by running N number of nested loops, where N is the number of joints of the robot. Subsequently, to develop a learning-based model based on sequence analysis, the authors propose to use long short-term memory (LSTM) and hence, train an LSTM model, the architecture details of which have been discussed in the paper. To make LSTM learning algorithms perform efficiently, the authors need to detect and eliminate redundant features from the data set, which the authors propose to do using an elegant statistical tool called Pearson coefficient.

Findings

To validate the proposed model, the authors have performed rigorous experiments using both hardware and simulation robots (Baxter/Anukul robot) available in their laboratory and KUKA simulation robot data set made available from Neural Learning for Robotics Laboratory. Through several characteristic plots, it has been shown that a sequence-based LSTM model of deep learning architecture with non-redundant features could help the robots to learn smooth and accurate trajectories more quickly compared to data sets having redundancy. Such data-driven modeling techniques can change the future course of direction of robotics research for solving the classical problems such as trajectory planning and motion planning for manipulating industrial as well as social humanoid robots.

Originality/value

The present investigation involves development of deep learning-based computation model, statistical analyses to eliminate redundant features, data creation from one hardware robot (Anukul) and one simulation robot model (KUKA), rigorously training and testing separately two computational models (specially configured two LSTM models) – one for learning inverse kinematics and one for learning inverse dynamics problem – and comparison of the inverse dynamics model with the state-of-the-art model. Hence, the authors strongly believe that the present paper is compact and complete to get published in a reputed journal so that dissemination of new ideas can benefit the researchers in the area of robotics.",NO
2-s2.0-85102776629,10.1142/S0219686721500116,,,Optimizing OCTG Thread Manufacturing Operation Using Automation,ar,Article,Nair P.U.,,The University of North Carolina at Chapel Hill,Chapel Hill,United States,,,,,2021-03-01,March 2021,Journal of Advanced Manufacturing Systems,02196867,27676,,Journal,20,1,,205-225,,,0,0,,,,"The paper discusses a unique technique developed initially at Nation Institute of Technology, Surat that is remodeled in real-world applications. The concept consists primarily of a user-friendly software facilitating direct communication with any intelligent or learning system/robot operating under known parameters of motor specifications. Any software base permitting high level PC interface without ASCII interrupt can be used for easy programming. This allows for a learning operation mode where a prevention of time lag is enabled by stored machine data, captured through movements such movements can be physically made or taught via programs to the device and such learning aspects make the machine more efficient where the robot can either perform individual actions as needed or learn new methods for the same results and can perform a series of actions continuously. Using the stored data, the machine is also capable of autonomous movements based on the path of least resistance as calculated by the time it takes to perform an act.

Interfacing Technique Tool Machining Robot (ITTMR) was developed as robotic tool holder that can determine the shape and size of different OCTG pipes utilized in the downhole industry and enable it to machine appropriate threads on the pipe with no manual intervention.

The process thereby completely negates any possibility of human error which can otherwise cause heavy loss on finished equipment that are rendered unusable because of threading errors on almost nearly finished complex milled parts or assemblies that are pending threads as the final operation. The purpose of the software codes is to provide a user-friendly GUI that can communicate with any machine by pulling in appropriate ACNC programs and performing the required tasks associated with the operating system and specifications of the motors/mobilization equipment’s used. For the purpose of this paper, the software code is not provided.

Any firmware base that permits the usage of an ASCII interrupt can be used and for the purpose of this operation, an RS323 equivalent board will also suffice for basic operations, however a complex ITTMR system has been utilized. This paper solely addresses the technique of how the threading operation is performed and does not address the process of how the pipe is bought to the machine or other associated aspects of the software to retain any possible patent applications on the same.",NO
2-s2.0-85102768405,10.1109/TCDS.2020.2968056,,,A Framework of Hybrid Force/Motion Skills Learning for Robots,ar,Article,Wang N.,,University of the West of England,Bristol,United Kingdom,,,,,2021-03-01,March 2021,IEEE Transactions on Cognitive and Developmental Systems,23798920,21100784665,23798939,Journal,13,1,8964480,162-170,,,5,0,,,,"Human factors and human-centered design philosophy are highly desired in today's robotics applications such as human-robot interaction (HRI). Several studies showed that endowing robots of human-like interaction skills can not only make them more likeable but also improve their performance. In particular, skill transfer by imitation learning can increase the usability and acceptability of robots by users without computer programming skills. In fact, besides positional information, muscle stiffness of the human arm and contact force with the environment also play important roles in understanding and generating human-like manipulation behaviors for robots, e.g., in physical HRI and teleoperation. To this end, we present a novel robot learning framework based on dynamic movement primitives (DMPs), taking into consideration both the positional and contact force profiles for human-robot skills transferring. Distinguished from the conventional method involving only the motion information, the proposed framework combines two sets of DMPs, which are built to model the motion trajectory and the force variation of the robot manipulator, respectively. Thus, a hybrid force/motion control approach is taken to ensure the accurate tracking and reproduction of the desired positional and force motor skills. Meanwhile, in order to simplify the control system, a momentum-based force observer is applied to estimate the contact force instead of employing force sensors. To deploy the learned motion-force robot manipulation skills to a broader variety of tasks, the generalization of these DMP models in actual situations is also considered. Comparative experiments have been conducted using a Baxter robot to verify the effectiveness of the proposed learning framework on real-world scenarios like cleaning a table.",NO
2-s2.0-85101053697,10.1088/1361-665X/abdc04,,,Smart wearable monitoring system based on multi-type sensors for motion recognition,ar,Article,Yang J.,,Donghua University,Shanghai,China,,,,,2021-03-01,March 2021,Smart Materials and Structures,09641726,29859,1361665X,Journal,30,3,035017,,,,0,0,,,,"Motion monitoring systems are often designed and researched to detect the movement of human lower limbs, and play an important role in the field of exoskeleton control. However, current wearable devices can still be improved to be more convenient or accurate in motion recognition. In this work, a comfortable smart wearable gait monitoring system was designed and tested. Inertial measurement units (IMUs) and flexible membrane compression sensors were implemented, integrated to a comfortable sport pant and insoles of both feet, respectively. Data acquisition module was designed, while software with user interface for data collection and storage was realized based on LABVIEW. Experiments were conducted to evaluate the recognition performance of the smart wearable gait monitoring system among nine common actions. Results show that the combined data set of IMUs and compression sensor provided by the system can highly improve classification performance. Based on the self-designed sensing network and the K-nearest neighbor machine learning algorithm, the recognition rate of nine motion patterns can reach as high as 99.96%, showing that the multi-channel wearable gait monitoring system is more effective for motion detection and prediction compared to that with single-type sensors.",NO
2-s2.0-85100779547,10.3390/s21041322,,33668412,Emotion detection for social robots based on nlp transformers and an emotion ontology,ar,Article,Graterol W.,,Universidad Simón Bolívar,Caracas,Venezuela,,,,,2021-02-02,2 February 2021,Sensors (Switzerland),14248220,130124,,Journal,21,4,1322,1-19,,,2,1,,,,"For social robots, knowledge regarding human emotional states is an essential part of adapting their behavior or associating emotions to other entities. Robots gather the information from which emotion detection is processed via different media, such as text, speech, images, or videos. The multimedia content is then properly processed to recognize emotions/sentiments, for example, by analyzing faces and postures in images/videos based on machine learning techniques or by converting speech into text to perform emotion detection with natural language processing (NLP) techniques. Keeping this information in semantic repositories offers a wide range of possibilities for implementing smart applications. We propose a framework to allow social robots to detect emotions and to store this information in a semantic repository, based on EMONTO (an EMotion ONTOlogy), and in the first figure or table caption. Please define if appropriate. an ontology to represent emotions. As a proof-of-concept, we develop a first version of this framework focused on emotion detection in text, which can be obtained directly as text or by converting speech to text. We tested the implementation with a case study of tour-guide robots for museums that rely on a speech-to-text converter based on the Google Application Programming Interface (API) and a Python library, a neural network to label the emotions in texts based on NLP transformers, and EMONTO integrated with an ontology for museums; thus, it is possible to register the emotions that artworks produce in visitors. We evaluate the classification model, obtaining equivalent results compared with a state-of-the-art transformer-based model and with a clear roadmap for improvement. View Full-Text",NO
2-s2.0-85101491068,10.1109/TLT.2021.3058060,,,Introducing Algorithmic Thinking and Sequencing Using Tangible Robots,ar,Article,Evripidou S.,,Neapolis University Pafos,Paphos,Cyprus,,,,,2021-02-01,February 2021,IEEE Transactions on Learning Technologies,,19700167026,19391382,Journal,14,1,9351683,93-105,,,1,0,,,,"Today, in the era of robotics, different types of educational robots have been used extensively in school classrooms to facilitate teaching activities related to a variety of computer science concepts. Numerous studies have been performed that attempt to examine the effects of using tangible interfaces to enhance collaborative learning experiences. In most of these studies, feedback, which is a vital function for a successful game activity, is mainly provided by the trainers. However, this kind of feedback can be considered as static and general, while each trainee seeks clear, consistent, and even personalized feedback. This article proposes an interactive learning tool for introducing algorithmic thinking and sequencing using educational robots suitable for elementary and intermediate students. In more detail, in this article, we leverage a fuzzy-rule-based system and computer vision techniques to provide immediate, personalized feedback and recommendations to young students while they perform a series of activities using tangible robots. These activities relate to teaching programming skills and improve the algorithmic thinking of students. Experimental results revealed that participants were able to increase their algorithmic/programming thinking skills while developing a positive attitude toward programming. The interactive gaming factor that is embedded in the use of tangible robots, while participating in the activities, was proved to be a compelling and a rewarding experience. The article concludes that the use of the proposed feedback mechanism, when placed in a robot game environment, can lead to a positive and more effective learning process.",SI
2-s2.0-85100980709,10.1109/TRO.2020.3006716,,,Motion Planning Networks: Bridging the Gap between Learning-Based and Classical Motion Planners,ar,Article,Qureshi A.H.,,"University of California, San Diego",San Diego,United States,,,,,2021-02-01,February 2021,IEEE Transactions on Robotics,15523098,95101,19410468,Journal,37,1,9154607,48-66,,,7,0,,,,"This article describes motion planning networks (MPNet), a computationally efficient, learning-based neural planner for solving motion planning problems.MPNet uses neural networks to learn general near-optimal heuristics for path planning in seen and unseen environments. It takes environment information such as raw point cloud from depth sensors, as well as a robot's initial and desired goal configurations and recursively calls itself to bidirectionally generate connectable paths. In addition to finding directly connectable and near-optimal paths in a single pass, we show that worst-case theoretical guarantees can be proven if we merge this neural network strategy with classical sample-based planners in a hybrid approach while still retaining significant computational and optimality improvements. To train the MPNet models, we present an active continual learning approach that enables MPNet to learn from streaming data and actively ask for expert demonstrations when needed, drastically reducing data for training. We validate MPNet against gold-standard and state-of-the-art planning methods in a variety of problems from two-dimensional to seven-dimensional robot configuration spaces in challenging and cluttered environments, with results showing significant and consistently stronger performance metrics, and motivating neural planning in general as a modern strategy for solving motion planning problems efficiently.",NO
2-s2.0-85096720522,10.1016/j.robot.2020.103693,S0921889020305339,,LOOP: Iterative learning for optimistic planning on robots,ar,Article,Riccio F.,,Sapienza Università di Roma,Rome,Italy,,,,,2021-02-01,February 2021,Robotics and Autonomous Systems,09218890,18079,,Journal,136,,103693,,,,0,0,,,,"Highlights

•

Novel approach to take advantage of both Robot learning and planning techniques.

•

Improve sample efficiency for tackling robotic tasks with large state-spaces.

•

Action policy generalization via Monte Carlo tree search and function approximation.

•

Extensive experimental evaluation of the proposed method in robotic scenarios.
Efficient robotic behaviors require robustness and adaptation to dynamic changes of the environment, whose characteristics rapidly vary during robot operation. To generate effective robot action policies, planning and learning techniques have shown the most promising results. However, if considered individually, they present different limitations. Planning techniques lack generalization among similar states and require experts to define behavioral routines at different levels of abstraction. Conversely, learning methods usually require a considerable number of training samples and iterations of the algorithm. To overcome these issues, and to efficiently generate robot behaviors, we introduce LoOP, an iterative learning algorithm for optimistic planning that combines state-of-the-art planning and learning techniques to generate action policies. The main contribution of LoOP is the combination of Monte-Carlo Search Planning and Q-learning, which enables focused exploration during policy refinement in different robotic applications. We demonstrate the robustness and flexibility of LoOP in various domains and multiple robotic platforms, by validating the proposed approach with an extensive experimental evaluation.",NO
2-s2.0-85096564433,10.1016/j.aej.2020.11.003,S1110016820305858,,A lightweight cryptography (LWC) framework to secure memory heap in Internet of Things,ar,Article,Khalifa M.,,University of Bisha,Bisha,Saudi Arabia,,,,,2021-02-01,February 2021,Alexandria Engineering Journal,11100168,13907,,Journal,60,1,,1489-1497,,,1,1,,,,"The extensive networking of devices and the large amount of data generated from the Internet of Things (IoT) has brought security issues to the attention of the researcher. Java is the most common platform for embedded applications such as IoT, Wireless Sensors Networks (WSN), Near Field Communications (NFC) and Radio Frequency Identification (RFID). The object programming languages such as Java, SWIFT, PHP and C++ use garbage collection after any object run which creates security loophole for attacks such as Next Memory Address Occupation (NMAO), memory replay, Learning Tasks Behaviors (LTB). The security risk increases in IoT when attacks exceeds the target device to the surrounding connected devices. Inappropriate or wrong operations causes energy loss and increased costs. In this paper, a security method to protect IoT system operation from memory heap penetration and address modification attack is proposed. The proposed method prevents directed attack by encrypting the object Garbage Collection at run time. To form a unique signature mechanism, the Cryptographic Hash Function (CHF) which employs a specific one-way hash algorithm. The proposed framework uses L-function based ECC and one-time Key (OTK) to secure the memory heap. Our method is used with open system where the effect on the operating system is not considered. The proposed method proved to be powerful and efficient which can help in achieving higher levels of security across several IoT applications, by enabling better detection of malicious attacks.",NO
2-s2.0-85100081388,10.3389/fnbot.2020.600885,,,Gait Optimization Method for Humanoid Robots Based on Parallel Comprehensive Learning Particle Swarm Optimizer Algorithm,ar,Article,Tao C.,,University of Science and Technology of Suzhou;Tsinghua University,Suzhou;Beijing,China;China,,,,,2021-01-15,15 January 2021,Frontiers in Neurorobotics,,21100199837,16625218,Journal,14,,600885,,,,0,1,,,,"To improve the fast and stable walking ability of a humanoid robot, this paper proposes a gait optimization method based on a parallel comprehensive learning particle swarm optimizer (PCLPSO). Firstly, the key parameters affecting the walking gait of the humanoid robot are selected based on the natural zero-moment point trajectory planning method. Secondly, by changing the slave group structure of the PCLPSO algorithm, the gait training task is decomposed, and a parallel distributed multi-robot gait training environment based on RoboCup3D is built to automatically optimize the speed and stability of bipedal robot walking. Finally, a layered learning approach is used to optimize the turning ability of the humanoid robot. The experimental results show that the PCLPSO algorithm achieves a quickly optimal solution, and the humanoid robot optimized possesses a fast and steady gait and flexible steering ability.",NO
2-s2.0-85117341134,10.1155/2021/5810371,,,Vision-Based Intelligent Perceiving and Planning System of a 7-DoF Collaborative Robot,ar,Article,Xu L.,,University of Florida,Gainesville,United States,,,,,2021-01-01,2021,Computational Intelligence and Neuroscience,16875265,7000153240,16875273,Journal,2021,,5810371,,,,0,1,,,,"In this paper, an intelligent perceiving and planning system based on deep learning is proposed for a collaborative robot consisting of a 7-DoF (7-degree-of-freedom) manipulator, a three-finger robot hand, and a vision system, known as IPPS (intelligent perceiving and planning system). The lack of intelligence has been limiting the application of collaborative robots for a long time. A system to realize “eye-brain-hand” process is crucial for the true intelligence of robots. In this research, a more stable and accurate perceiving process was proposed. A well-designed camera system as the vision system and a new hand tracking method were proposed for operation perceiving and recording set establishment to improve the applicability. A visual process was designed to improve the accuracy of environment perceiving. Besides, a faster and more precise planning process was proposed. Deep learning based on a new CNN (convolution neural network) was designed to realize intelligent grasping planning for robot hand. A new trajectory planning method of the manipulator was proposed to improve efficiency. The performance of the IPPS was tested with simulations and experiments in a real environment. The results show that IPPS could effectively realize intelligent perceiving and planning for the robot, which could realize higher intelligence and great applicability for collaborative robots.",NO
2-s2.0-85117278393,10.1109/TNNLS.2021.3117878,,,Policy Gradient-Based Core Placement Optimization for Multichip Many-Core Systems,ar,Article,Myung W.,,Tsinghua University,Beijing,China,,,,,2021-01-01,2021,IEEE Transactions on Neural Networks and Learning Systems,2162237X,21100235616,21622388,Journal,,,,,,,0,0,,,,"As many deep neural network models become deeper and more complex, processing devices with stronger computing performance and communication capability are required. Following this trend, the dependence on multichip many-core systems that have high parallelism and reasonable transmission costs is on the rise. In this work, in order to improve routing performance of the system, such as routing runtime and power consumption, we propose a reinforcement learning (RL)based core placement optimization approach, considering application constraints, such as deadlock caused by multicast paths. We leverage the capability of deep RL from indirect supervision as a direct nonlinear optimizer, and the parameters of the policy network are updated by proximal policy optimization. We treat the routing topology as a network graph, so we utilize a graph convolutional network to embed the features into the policy network. One step size environment is designed, so all cores are placed simultaneously. To handle large dimensional action space, we use continuous values matching with the number of cores as the output of the policy network and discretize them again for obtaining the new placement. For multichip system mapping, we developed a community detection algorithm. We use several datasets of multilayer perceptron and convolutional neural networks to evaluate our agent. We compare the optimal results obtained by our agent with other baselines under different multicast conditions. Our approach achieves a significant reduction of routing runtime, communication cost, and average traffic load, along with deadlock-free performance for inner chip data transmission. The traffic of interchip routing is also significantly reduced after integrating the community detection algorithm to our agent.",NO
2-s2.0-85116877007,10.1109/LRA.2021.3116700,,,Sim2Real Learning of Obstacle Avoidance for Robotic Manipulators in Uncertain Environments,ar,Article,Zhang T.,,Shenzhen Technology University,Shenzhen,China,,,,,2021-01-01,2021,IEEE Robotics and Automation Letters,,21100900379,23773766,Journal,,,,,,,0,0,,,,"Obstacle avoidance for robotic manipulators can be challenging when they operate in unstructured environments. This problem is probed with the sim-to-real (sim2real) deep reinforcement learning, such that a moving policy of the robotic arm is learnt in a simulator and then adapted to the real world. However, the problem of sim2real adaptation is notoriously difficult. To this end, this work proposes (1) a unified representation of obstacles and targets to capture the underlying dynamics of the environment while allowing generalization to unseen goals and (2) a flexible end-to-end model combining the unified representation with the deep reinforcement learning control module that can be trained by interacting with the environment. Such a representation is agnostic to the shape and appearance of the underlying objects, which simplifies and unifies the scene representation in both simulated and real worlds. We implement this idea with a vision-based actor-critic framework by devising a bounding box predictor module. The predictor estimates the 3D bounding boxes of obstacles and targets from the RGB-D input. The features extracted by the predictor are fed into the policy network, and all the modules are jointly trained. This makes the policy learn object-aware scene representation, which leads to a data-efficient learning of the obstacle avoidance policy. Our experiments in simulated environment and the real-world show that the end-to-end model of the unified representation achieves better sim2real adaption and scene generalization than state-of-the-art techniques.",NO
2-s2.0-85116403571,10.1007/s11370-021-00387-2,,,Reinforcement learning-based dynamic obstacle avoidance and integration of path planning,ar,Article,Choi J.,,Seoul National University of Science and Technology (SNUST);Hyundai-Rotem Co.,Seoul;Uiwang-si,South Korea;South Korea,,,,,2021-01-01,2021,Intelligent Service Robotics,18612776,9500154152,18612784,Journal,,,,,,,0,1,,,,"Deep reinforcement learning has the advantage of being able to encode fairly complex behaviors by collecting and learning empirical information. In the current study, we have proposed a framework for reinforcement learning in decentralized collision avoidance where each agent independently makes its decision without communication with others. In an environment exposed to various kinds of dynamic obstacles with irregular movements, mobile robot agents could learn how to avoid obstacles and reach a target point efficiently. Moreover, a path planner was integrated with the reinforcement learning-based obstacle avoidance to solve the problem of not finding a path in a specific situation, thereby imposing path efficiency. The robots were trained about the policy of obstacle avoidance in environments where dynamic characteristics were considered with soft actor critic algorithm. The trained policy was implemented in the robot operating system (ROS), tested in virtual and real environments for the differential drive wheel robot to prove the effectiveness of the proposed method. Videos are available at https://youtu.be/xxzoh1XbAl0.",NO
2-s2.0-85116382507,10.1002/cae.22464,,,Model-based automatic grading of object-oriented programming assignments,ar,Article,Le D.M.,,FPT University,Hanoi,Viet Nam,,,,,2021-01-01,2021,Computer Applications in Engineering Education,10613773,18156,10990542,Journal,,,,,,,0,0,,,,"Automatic grading of object-oriented programming (OOP) assignments is an important problem from practical, theoretical, and educational viewpoints. Apart from computing a specific grade, an effective grading method needs to provide systematic feedback comments to both the design and code elements. Existing works have proposed grading methods that make various assumptions about the design. However, none of these methods have considered using a design language for the program model. A challenge here is to use a language that eases learning and application in program design. In this paper, we propose a novel grading method, named OOPGRADER, which automatically grades OOP assignments constructed based on an essentially detailed program model. This model is defined in an embedded design language, which directly uses the annotation feature of OOP language to express the essential design rules. We explain how programming assignments can be designed with this language and propose a program checker and a grader for both student and teacher to use in working on the assignments and in grading them. We implement these components in a tool and develop an Eclipse plugin for this tool. We evaluate our method using a combination of qualitative and quantitative techniques. The main result is that our method helps students effectively learn to program through detailed feedback comments based on a program model. The tool is adaptable, has a good performance, and helps enhance the productivity of both students and teachers through IDE integration.",NO
2-s2.0-85115665181,10.1109/TRO.2021.3109414,,,LAMP: Learning a Motion Policy to Repeatedly Navigate in an Uncertain Environment,ar,Article,Tsang F.,,University of Waterloo,Waterloo,Canada,,,,,2021-01-01,2021,IEEE Transactions on Robotics,15523098,95101,19410468,Journal,,,,,,,0,0,,,,"Mobile robots are often tasked with repeatedly navigating through an environment whose traversability changes over time. These changes may exhibit some hidden structure, which can be learned. Many studies consider reactive algorithms for online planning, however, these algorithms do not take advantage of the past executions of the navigation task for future tasks. In this article, we formalize the problem of minimizing the total expected cost to perform multiple start-to-goal navigation tasks on a roadmap by introducing the learned reactive planning problem. We propose a method that captures information from past executions to learn a motion policy to handle obstacles that the robot has seen before. We propose the LAMP framework, which integrates the generated motion policy with an existing navigation stack. Finally, an extensive set of experiments in simulated and real-world environments show that the proposed method outperforms the state-of-the-art algorithms by 10% to 40% in terms of expected time to travel from start to goal. We also evaluate the robustness of the proposed method in the presence of localization and mapping errors on a real robot.",NO
2-s2.0-85115615061,10.15388/infedu.2021.22,,,Designing Informatics Curriculum for K-12 Education: From Concepts to Implementations,ar,Article,Dagienė V.,,Vilniaus Universitetas,Vilnius,Lithuania,,,,,2021-01-01,2021,Informatics in Education,16485831,4100151705,,Journal,20,3,,333-360,,,0,1,,,,"Computing as a discipline has common roots with mathematics and written languages, and computing as a way of thinking and handling has been integral to human culture since ever. This is not only a reasonable argument for convincing society to consider informatics as one of the very fundamental pillars of education, but it also puts the potential contributions of teaching informatics in schools into the correct perspective in the context of science and humanities. Many European countries are switching from teaching information technologies to informatics education during the current second decade of this century. Informatics curriculum is becoming a central part of school education. We explain and design a way of developing informatics curriculum that offer the critical competences new generations need to survive and thrive in todays’ knowledge society and will allow them to contribute to the future development of society. These competences also strongly support the development of their intellectual potential and creativity. Our design of informatics curriculum takes into account the interaction with other scientific disciplines as well with the subject didactics, pedagogy and psychology. The starting point is merging constructionism and critical thinking. Constructionism with its “learning by doing” and “learning by getting things to work” enables designing a teaching process in which students acquire knowledge by creating products, analysing the properties and the functionality of their own products, and finally derive motivation to improve these products. Critical thinking asks us not to teach products of science and technology and their application, but to teach the creative process of their development. To implement this approach, we use the historical method allowing the students to learn by productive failures in the process of searching for a solution. To organize the process of learning and make the different steps available to the appropriate age groups we take into account the cognitive dimensions of the revised taxonomy of Bloom. To illustrate how the combination of all these concepts works we present a detailed curriculum for algorithm design, programming, robotics, and communication in networks.",SI
2-s2.0-85115099809,10.3991/ijet.v16i17.22889,,,The Use of The High-Performance Computing in The Learning Process,ar,Article,Serik M.,,L.N. Gumilyov Eurasian National University,Nur-Sultan,Kazakhstan,,,,,2021-01-01,2021,International Journal of Emerging Technologies in Learning,18688799,21100197967,18630383,Journal,16,17,,240-254,,,0,1,,,,"The need for specialists with high-performance computing skills is growing day by day. This is due to the fact that the high-performance process of processing big data is one of the most pressing problems today. This is especially important in science, economics, physical modeling, medicine, bioinformatics, weather forecasting, etc.
This article analyzes the conditions for teaching high-performance computing, the experience of leading universities in the world, and it is established that teaching high-performance computing requires study. High performance computing training was carried out on 3 different hardware equipment (a personal computer, a supercomputer “Param-Bilim” India – Kazakhstan Centre of Excellence in ICT [IKCOEICT] at L.N. Gumilyov Eurasian National University and a quantum computer in the cloud IBM Quantum Experience) using different algorithms in the C ++ and Phyton programming languages. The effectiveness of the calculation results in the educational process was determined as a result of the completed questionnaire.",NO
2-s2.0-85114805973,10.1007/s13042-021-01405-6,,,An improved neural dynamics based approach with territorial mechanism to online path planning of multi-robot systems,ar,Article,Yi X.,,Shenzhen University,Shenzhen,China,,,,,2021-01-01,2021,International Journal of Machine Learning and Cybernetics,18688071,19700177336,1868808X,Journal,,,,,,,0,0,,,,"The coordination of multi-robot system (MRS) are applied commonly to various fields of the automotive industry. In a variety of cooperative modes, online path planning with obstacles avoidance is a fundamentally important hotspot, especially in a 3-D, complex, or dynamic environment. In the paper, an improved neural dynamics based approach with territorial mechanism is proposed to online path planning of MRS, which can be used as the online path planner for multi-AUVs and multi-UAVs in complex and dynamic environments. This approach integrates biological neural network, computational fluid dynamics, and territorial mechanism of animals, which has the characteristics and advantages of the biological nervous system, namely self-regulation, self-adaptation, self-organization, etc. It can cope with a variety of accidents during path planning, such as the disappearance of targets, the breakdown of robots, the change of environments, and so forth. Meanwhile, the proposed approach has better time performance and is insensitive to the number of robots in MRS. During the path planning of MRS, it can also guarantee to balance workload and to reduce entire workload and total time, which enhance robustness and fairness. The effectiveness and efficiency of the proposed approach are demonstrated by simulations and comparative studies.",NO
2-s2.0-85114673783,10.1016/j.ijcci.2021.100388,S2212868921000854,,Exploring the development of mental rotation and computational skills in elementary students through educational robotics,ar,Article,Diago P.D.,,Universitat de València,Valencia,Spain,,,,,2021-01-01,2021,International Journal of Child-Computer Interaction,22128689,21100228541,,Journal,,,100388,,,,0,0,,,,"Highlights

•

Robotic map-reading tasks promote significant gains in CT in 8-year-old students

•

Bee-bot produces significant improvements in CT compared to traditional instruction

•

Bee-bot enhances CT for the 3rd grade students through map-reading task
Interest in educational robotics has increased over the last decade. Through various approaches, robots are being used in the teaching and learning of different subjects at distinct education levels. The present study investigates the effects of an educational robotic intervention on the mental rotation and computational thinking assessment in a 3rd grade classroom. To this end, we carried out a quasi-experimental study involving 24 third-grade students. From an embodied approach, we have designed a two-hour intervention providing students with a physical environment to perform tangible programming on Bee-bot. The results revealed that this educational robotic proposal aimed at map-reading tasks leads to statistically significant gains in computational thinking. Moreover, students who followed the Bee-bot-based intervention achieved greater CT level compared to students following a traditional instruction approach, after controlling student’s prior level. No conclusive results were found in relation to mental rotation.",SI
2-s2.0-85114652119,10.1109/TIE.2021.3105977,,,Towards Proactive Human Robot Collaborative Assembly: A Multimodal Transfer Learning-Enabled Action Prediction Approach,ar,Article,Li S.,,Hong Kong Polytechnic University,Kowloon,Hong Kong,,,,,2021-01-01,2021,IEEE Transactions on Industrial Electronics,02780046,26053,15579948,Journal,,,,,,,0,0,,,,"Human-robot collaborative assembly (HRCA) is vital for achieving high-level flexible automation for mass personalization in todays smart factories. However, existing works in both industry and academia mainly focus on adaptive robot planning, while seldom consider human operators intentions in advance. Hence, it hinders the HRCA transition towards a proactive manner. To overcome the bottleneck, this research proposes a multimodal transfer learning-enabled action prediction approach, serving as the prerequisite to ensure the Proactive HRCA. Firstly, a multimodal intelligence-based action recognition approach is proposed to predict ongoing human actions by leveraging the visual stream and skeleton stream with short-time input frames. Secondly, a transfer learning-enabled model is adapted to transfer learned knowledge from daily activities to industrial assembly operations rapidly for online operator intention analysis. Thirdly, a dynamic decision-making mechanism including the robotic decision and motion control is described to allow mobile robots to assist operators in a proactive manner. Lastly, an aircraft bracket assembly task is demonstrated in the lab environment, and the comparative study result shows that the proposed approach outperforms other state-of-the-art ones for efficient action prediction.",NO
2-s2.0-85114097466,10.1002/oca.2781,,,Path planning of mobile robot in unknown dynamic continuous environment using reward-modified deep Q-network,ar,Article,Huang R.,,Guangzhou University,Guangzhou,China,,,,,2021-01-01,2021,Optimal Control Applications and Methods,01432087,25529,10991514,Journal,,,,,,,0,0,,,,"The path planning problem of mobile robot in unknown dynamic environment (UDE) is discussed in this article by building a continuous dynamic simulation environment. To achieve a collision-free path in UDE, the reinforcement learning theory with deep Q-network (DQN) is applied for the mobile robot to learn optimal decisions. A reward function is designed with weight to balance the obstacle avoidance and the approach to the goal. Moreover, it is found that the relative motion between moving obstacles and robots may cause abnormal rewards and further lead to a collision between robot and obstacle. To address this problem, two reward thresholds are set to modify the abnormal rewards, and the experiments shows that the robot can avoid all obstacles and reach the goal successfully. Finally, double DQN (DDQN) and dueling DQN are applied in this article. This article compares the results of reward-modified DQN (RMDQN), reward-modified DDQN (RMDDQN), dueling RMDQN, and dueling RMDDQN and concludes that the result of RMDDQN is the best.",NO
2-s2.0-85114090768,10.1155/2021/5532210,,,Soccer-assisted training robot based on image recognition omnidirectional movement,ar,Article,Tan B.,,Hunan Institute of Science and Technology,Yueyang,China,,,,,2021-01-01,2021,Wireless Communications and Mobile Computing,15308669,17543,15308677,Journal,2021,,5532210,,,,0,1,,,,"With the continuous emergence and innovation of computer technology, mobile robots are a relatively hot topic in the field of artificial intelligence. It is an important research area of more and more scholars. The core of mobile robots is to be able to realize real-time perception of the surrounding environment and self-positioning and to conduct self-navigation through this information. It is the key to the robot’s autonomous movement and has strategic research significance. Among them, the goal recognition ability of the soccer robot vision system is the basis of robot path planning, motion control, and collaborative task completion. The main recognition task in the vision system is the omnidirectional vision system. Therefore, how to improve the accuracy of target recognition and the light adaptive ability of the robot omnidirectional vision system is the key issue of this paper. Completed the system construction and program debugging of the omnidirectional mobile robot platform, and tested its omnidirectional mobile function, positioning and map construction capabilities in the corridor and indoor environment, global navigation function in the indoor environment, and local obstacle avoidance function. How to use the local visual information of the robot more perfectly to obtain more available information, so that the “eyes” of the robot can be greatly improved by relying on image recognition technology, so that the robot can obtain more accurate environmental information by itself has always been domestic and foreign one of the goals of the joint efforts of scholars. Research shows that the standard error of the experimental group’s shooting and dribbling test scores before and the experimental group’s shooting and dribbling test results after the standard error level is 0.004, which is less than 0.05, which proves the use of soccer-assisted robot-assisted training. On the one hand, we tested the positioning and navigation functions of the omnidirectional mobile robot, and on the other hand, we verified the feasibility of positioning and navigation algorithms and multisensor fusion algorithms.",NO
2-s2.0-85113864073,10.1109/TEVC.2021.3106672,,,Genetic Programming for Manifold Learning: Preserving Local Topology,ar,Article,Lensen A.,,Victoria University of Wellington,Wellington,New Zealand,,,,,2021-01-01,2021,IEEE Transactions on Evolutionary Computation,1089778X,25037,19410026,Journal,,,,,,,0,0,,,,"Manifold learning methods are an invaluable tool in today’s world of increasingly huge datasets. Manifold learning algorithms can discover a much lower-dimensional representation (embedding) of a high-dimensional dataset through non-linear transformations that preserve the most important structure of the original data. State-of-the-art manifold learning methods directly optimise an embedding without mapping between the original space and the discovered embedded space. This makes interpretability — a key requirement in exploratory data analysis — nearly impossible. Recently, genetic programming has emerged as a very promising approach to manifold learning by evolving functional mappings from the original space to an embedding. However, genetic programming-based manifold learning has struggled to match the performance of other approaches. In this work, we propose a new approach to using genetic programming for manifold learning, which preserves local topology. This is expected to significantly improve performance on tasks where local neighbourhood structure (topology) is paramount. We compare our proposed approach with various baseline manifold learning methods and find that it often outperforms other methods, including a clear improvement over previous genetic programming approaches. These results are particularly promising, given the potential interpretability and reusability of the evolved mappings.",NO
2-s2.0-85113255459,10.1080/0305215X.2021.1958210,,,Continuous trajectory planning based on learning optimization in high dimensional input space for serial manipulators,ar,Article,Zhang S.,,Beihang University,Beijing,China,,,,,2021-01-01,2021,Engineering Optimization,0305215X,29114,10290273,Journal,,,,,,,0,0,,,,"In order to generate trajectories continuously for serial manipulators with high dimensional degrees of freedom (DOFs) in a dynamic environment, a real-time trajectory planning method based on optimization and machine learning aimed at high dimensional inputs is presented. A learning optimization (LO) framework is established. Multiple criteria are defined to evaluate the performance quantitatively, and implementations with different sub-methods are discussed. In particular, a database generation method based on input space mapping is proposed for generating valid and representative samples. The methods presented are applied on a practical application—haptic interaction in virtual reality systems. The results show that the input space mapping method significantly elevates the efficiency and quality of database generation and consequently improves the performance of the LO. With the LO method, real-time trajectory generation with high dimensional inputs is achieved, which lays the foundation for robots with high dimensional DOFs to execute complex tasks in dynamic environments.",NO
2-s2.0-85112656163,10.1109/TRO.2021.3096069,,,A Hierarchical Coordination Framework for Joint Perception-Action Tasks in Composite Robot Teams,ar,Article,Seraj E.,,Georgia Institute of Technology,Atlanta,United States,,,,,2021-01-01,2021,IEEE Transactions on Robotics,15523098,95101,19410468,Journal,,,,,,,0,0,,,,"We propose a collaborative planning and control algorithm to enhance cooperation for composite teams of autonomous robots in dynamic environments. Composite robot teams are groups of agents that perform different tasks according to their respective capabilities in order to accomplish an overarching mission. Examples of such teams include groups of perception agents (can only sense) and action agents (can only manipulate) working together to perform disaster response tasks. Coordinating robots in a composite team is a challenging problem due to the heterogeneity in the robots’ characteristics and their tasks. Here, we propose a coordination framework for composite robot teams. The proposed framework consists of two hierarchical modules: First, A multiagent state-action-reward-time-state-action algorithm in multiagent partially observable semi-Markov decision process as the high-level decision-making module to enable perception agents to learn to surveil in an environment with an unknown number of dynamic targets and second, a low-level coordinated control and planning module that ensures probabilistically guaranteed support for action agents. Simulation and physical robot implementations of our algorithms on a multiagent robot testbed demonstrated the efficacy and feasibility of our coordination framework by reducing the overall operation times in a benchmark wildfire-fighting case study.",NO
2-s2.0-85112623879,10.1109/TSMC.2021.3096935,,,An Improved Dyna-Q Algorithm for Mobile Robot Path Planning in Unknown Dynamic Environment,ar,Article,Pei M.,,Harbin Institute of Technology,Harbin,China,,,,,2021-01-01,2021,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",21682216,12952,21682232,Journal,,,,,,,0,0,,,,"This article deals with the problem of mobile robot path planning in an unknown environment that contains both static and dynamic obstacles, utilizing a reinforcement learning approach. We propose an improved Dyna-Q algorithm, which incorporates heuristic search strategies, simulated annealing mechanism, and reactive navigation principle into Q-learning based on the Dyna architecture. A novel action-selection strategy combining ϵ-greedy policy with the cooling schedule control is presented, which, together with the heuristic reward function and heuristic actions, can tackle the exploration-exploitation dilemma and enhance the performance of global searching, convergence property, and learning efficiency for path planning. The proposed method is superior to the classical Q-learning and Dyna-Q algorithms in an unknown static environment, and it is successfully applied to an uncertain environment with multiple dynamic obstacles in simulations. Further, practical experiments are conducted by integrating MATLAB and robot operating system (ROS) on a physical robot platform, and the mobile robot manages to find a collision-free path, thus fulfilling autonomous navigation tasks in the real world.",NO
2-s2.0-85112623797,10.1109/TSE.2021.3101818,,,Combining Genetic Programming and Model Checking to Generate Environment Assumptions,ar,Article,Gaaloul K.,,University of Luxembourg,Esch-sur-Alzette,Luxembourg,,,,,2021-01-01,2021,IEEE Transactions on Software Engineering,00985589,18711,19393520,Journal,,,,,,,0,0,,,,"Software verification may yield spurious failures when environment assumptions are not accounted for. Environment assumptions are the expectations that a system or a component makes about its operational environment and are often specified in terms of conditions over the inputs of that system or component. In this article, we propose an approach to automatically infer environment assumptions for Cyber-Physical Systems (CPS). Our approach improves the state-of-the-art in three different ways: First, we learn assumptions for complex CPS models involving signal and numeric variables; second, the learned assumptions include arithmetic expressions defined over multiple variables; third, we identify the trade-off between soundness and coverage of environment assumptions and demonstrate the flexibility of our approach in prioritizing either of these criteria. We evaluate our approach using a public domain benchmark of CPS models from Lockheed Martin and a component of a satellite control system from LuxSpace, a satellite system provider. The results show that our approach outperforms state-of-the-art techniques on learning assumptions for CPS models, and further, when applied to our industrial CPS model, our approach is able to learn assumptions that are sufficiently close to the assumptions manually developed by engineers to be of practical value.",NO
2-s2.0-85112113296,10.1109/ACCESS.2021.3093233,,,Assessment of a Robotic Assistant for Supporting Homework Activities of Children with ADHD,ar,Article,Berrezueta-Guzman J.,,Universidad Politécnica de Madrid;CEDIA,Madrid;Cuenca,Spain;Ecuador,,,,,2021-01-01,2021,IEEE Access,,21100374601,21693536,Journal,9,,9466828,93450-93465,,,0,1,,,,"Robotics, Artificial Intelligence (AI), and the Internet of Things (IoT) support various processes in many scenarios of modern life such as e-health and psychological treatments. This article presents the design, development, implementation, and assessment of a Robotic Assistant (RA), named “Atent@”, as a support tool in the homework activities of children with Attention Deficit Hyperactivity Disorder (ADHD). Interacting with the children the RA helps them correct their bad habits and misbehavior caused by the disorder. Its features and functionalities were designed by therapists, implementing AI algorithms to process information and make decisions in real-time to help children to be focused on their homework. This RA interacts with smart objects deployed at home, which are associated with the activity under observation (desk and chair). This solution allows therapists to receive more accurate information about the homework sessions inside the home. At the same time, remote interaction with the child is made possible (through the RA) to provide new instructions and support him/her along with the sessions. This RA is a significant evolution of an earlier version. All the improvements brought to the project by the modifications in technical and qualitative features are explained. Furthermore, the experiment and its results are presented to illustrate the clinical potential. This project shows that the RA can not only make observations with a high degree of precision like an expert (teacher/therapist) but also positively influences the homework performance of children with and without ADHD.",NO
2-s2.0-85111817143,10.1007/s13198-021-01219-3,,,Research on manipulator motion planning for complex systems based on deep learning,ar,Article,Ding W.,,Tangshan Normal University,Tangshan,China,,,,,2021-01-01,2021,International Journal of Systems Assurance Engineering and Management,09756809,19700177002,09764348,Journal,,,,,,,0,0,,,,"Manipulator control and planning for complex systems has become a fantasizing concept for the current age robotics bases technological era. The manipulator motion control and planning deals with various challenges of obstacle avoidance and complex environmental conditions which are dealt in this article. This paper addresses the crucial challenges of the current manipulator planning approaches by utilizing the concept of deep learning. A dynamic deep neural network enabled iterative manipulator motion planning framework for complex systems is proposed in this article to deal with the task specific manipulators. The proposed methodology includes three basic modules: a dynamic deep neural network module for input modelling, an iterative trajectory planning and propagation module and a manipulator control and planning module for complex systems. The presented model learns from training and predicts the robot configuration path by generating the feasible task-specific trajectories. The model testing is done on a large dataset including multiple working environments and different manipulator planning problems. The results of the proposed framework are evaluated for different performance indicators and a success rate of 95.19% is achieved consistently with respective minimized error rate of 0.213. The proposed deep learning-based methodology not only make the manipulator learning task specific, but it generalizes the manipulator planning for complex systems, making it more optimal and efficient. The proposed framework when tested over different environments while upholding the computational gains.",NO
2-s2.0-85111611942,10.1109/TRO.2021.3096070,,,Constrained Motion Planning Networks X,ar,Article,Qureshi A.H.,,"University of California, San Diego",San Diego,United States,,,,,2021-01-01,2021,IEEE Transactions on Robotics,15523098,95101,19410468,Journal,,,,,,,0,0,,,,"Constrained motion planning is a challenging field of research, aiming for computationally efficient methods that can find a collision-free path on the constraint manifolds between a given start and goal configuration. These planning problems come up surprisingly frequently, such as in robot manipulation for performing daily life assistive tasks. However, few solutions to constrained motion planning are available, and those that exist struggle with high computational time complexity in finding a path solution on the manifolds. To address this challenge, we present Constrained Motion Planning Networks X (CoMPNetX). It is a neural planning approach, comprising a conditional deep neural generator and discriminator with neural gradients-based fast projection operator. We also introduce neural task and scene representations conditioned on which the CoMPNetX generates implicit manifold configurations to turbo-charge any underlying classical planner such as sampling-based motion planning methods for quickly solving complex constrained planning tasks. We show that our method finds path solutions with high success rates and lower computation times than state-of-the-art traditional path-finding tools on various challenging scenarios.",NO
2-s2.0-85111396087,10.1108/ITSE-04-2021-0074,,,The effect of self-regulated programming learning on undergraduate students’ academic performance and motivation,ar,Article,Öztürk M.,,Aksaray Üniversitesi,Aksaray,Turkey,,,,,2021-01-01,2021,Interactive Technology and Smart Education,17415659,21100385802,17588510,Journal,,,,,,,0,0,,,,"Purpose

The purpose of this study was to investigate the effect of self-regulated programming learning on undergraduate students’ academic performance and motivation compared to traditional methods.

Design/methodology/approach

This study was conducted with an explanatory sequential mixed method. Participants consist of 31 undergraduate students studying in the department of computer and instructional technologies education. The students were separated into two groups as experimental (n = 15) and control (n = 16) in the robotic programming course. Academic performance tests, programming motivation scale and interview form were used as data collection tools. After collecting quantitative data, interviews were conducted with the students regarding their academic performance and motivation.

Findings

The results indicated that the self-regulated programming learning process can contribute positively to students’ academic performance and motivation compared to traditional methods. Students stated that self-regulated learning strategies can positively affect their academic performance and motivation.

Originality/value

In this study, a self-regulated learning support system was designed to encourage students to use self-regulated learning strategies. This study has the potential to contribute to the gap in the literature, especially as a study of adapting the phased model of self-regulated learning to programming teaching. Instructors can use the self-regulating programming learning framework by adapting it to different disciplines.",SI
2-s2.0-85111071624,10.1109/TPAMI.2021.3088063,,,Batch Reinforcement Learning with a Nonparametric Off-Policy Policy Gradient,ar,Article,Tosatto S.,,University of Alberta,Edmonton,Canada,,,,,2021-01-01,2021,IEEE Transactions on Pattern Analysis and Machine Intelligence,01628828,24254,19393539,Journal,,,,,,,0,0,,,,"Off-policy Reinforcement Learning (RL) holds the promise of better data efficiency as it allows sample reuse and potentially enables safe interaction with the environment. Current off-policy policy gradient methods either suffer from high bias or high variance, delivering often unreliable estimates. The price of inefficiency becomes evident in real-world scenarios such as interaction-driven robot learning, where the success of RL has been rather limited, and a very high sample cost hinders straightforward application. In this paper, we propose a nonparametric Bellman equation, which can be solved in closed form. The solution is differentiable w.r.t the policy parameters and gives access to an estimation of the policy gradient. In this way, we avoid the high variance of importance sampling approaches, and the high bias of semi-gradient methods. We empirically analyze the quality of our gradient estimate against state-of-the-art methods, and we show that it outperforms the baselines in terms of sample efficiency on classical control tasks.",NO
2-s2.0-85111043036,10.1109/ACCESS.2021.3098706,,,Mobile Robot Dynamic Path Planning Based on Self-Adaptive Harmony Search Algorithm and Morphin Algorithm,ar,Article,Quan Y.,,Guangzhou University,Guangzhou,China,,,,,2021-01-01,2021,IEEE Access,,21100374601,21693536,Journal,9,,9491151,102758-102769,,,0,1,,,,"As a vital part of autonomous navigation of mobile robot, path planning is a hot research direction which aims at searching a shortest collision-free path from the starting position to the goal position in a complex environment. In this paper, a method for global dynamic path planning is designed based on improved self-adaptive harmony search algorithm (ISAHS) and Morphin algorithm. Firstly, to improve the quality of new solution vector, a neighbors and optimal learning strategy is introduced. Secondly, two key parameters are adjusted adaptively and a probability disturbance strategy is designed for renewing harmony memory, and then an improved self-adaptive harmony search algorithm is proposed to obtain an initial optimal path in the static environment. Finally, the Morphin algorithm is introduced to avoid the moving obstacles in real time. Simulation results indicate that the proposed method performs well in planning an initial static optimal path and it can avoid all preset moving obstacles effectively.",NO
2-s2.0-85110923610,10.1109/TCNS.2021.3097306,,,Adaptive Online Distributed Optimal Control of Very-Large-Scale Robotic Systems,ar,Article,Zhu P.,,Marshall University,Huntingdon,United States,,,,,2021-01-01,2021,IEEE Transactions on Control of Network Systems,,21100358105,23255870,Journal,,,,,,,0,0,,,,"Autonomous systems comprised of many cooperative agents have the potential for enabling long-duration tasks and data collection critical to the understanding of a wide range of phenomena in spatially and temporally variable environments. The adaptive distributed optimal control approach presented in this article extends online approximate dynamic programming to very-large-scale robotics (VLSR) systems that must operate and adapt to highly uncertain and variable environments. Optimal mass transport theory is used to show that, in the Wasserstein–Gaussian mixture model space, the VLSR system's cost to go can be represented by a value functional of the robot distribution and dynamic environmental maps. The approach is demonstrated on a cooperative path planning problem in which knowledge of the obstacles in the environment changes incrementally over time based on in situ measurements. Numerical simulations show that the proposed approach significantly outperforms existing methods by finding an approximately optimal solution that avoids obstacles and meets a desired final robot distribution using minimum energy.",NO
2-s2.0-85107792880,10.1007/s10798-021-09677-3,,,Cultivating students’ computational thinking through student–robot interactions in robotics education,ar,Article,Qu J.R.,,The Education University of Hong Kong,Hong Kong,China,,,,,2021-01-01,2021,International Journal of Technology and Design Education,09577572,21389,15731804,Journal,,,,,,,0,1,,,,"This research focuses on student–robot interaction in the learning environment of robotics education (RE) and attempts to explore how it cultivates students’ computational thinking (CT). Different from child–robot interactions as investigated in the social robot field, student–robot (S–R) interactions focus mainly on the process of interaction between learners and programmable robot kits in RE settings. At a four-week robotics summer camp in China, mixed-methods research was conducted. Forty primary school students and one dedicated robotics teacher participated in this research, while 32 students and the teacher completed all the lessons and data collection procedures of the summer camp. Results indicated that students’ CT skill increased during the summer camp and that the change in their CT skill was positively correlated to the time spent on S–R interaction. Additionally, how three kinds of S–R interaction—programming-computing, observational investigation, and participatory investigation—cultivated students’ CT were found. Moreover, the hierarchy of three S–R interactions and students’ role-shifting in the hierarchy were discussed. Previous studies rarely discussed S–R interaction; however, this kind of interaction should be explored because it provides more information about students’ natural learning process, which might be meaningful to RE practice.",SI
2-s2.0-85106358112,10.46328/IJEMST.1205,,,Discovering concepts of geometry through robotics coding activities,ar,Article,Kim Y.R.,,Texas A&amp;M University-San Antonio,San Antonio,United States,,,,,2021-01-01,2021,"International Journal of Education in Mathematics, Science and Technology",,21100896316,2147611X,Journal,9,3,,406-425,,,0,1,,,,"In recent years, mathematics classrooms in the U.S. and around the world have seen an increasing integration of educational robotics with interest from both students and teachers. Through their robotics coding activities, students in the present study discovered the concepts of special angle pairs in geometry—namely, complementary and supplementary angles—as they learned to navigate the immediate feedback from the robot Sphero SPRK+ into a trial-and-error mathematics problem-solving process. Students’ experiences in these three coding activities revealed, to a certain extent, that engaging in reflective play could be shaped into meaningful teachable moments where students could participate in a “doing with learning” pedagogical method using educational robotics. These activities had transferability implications that might afford STEM learning access and opportunities for students to develop not only mathematical reasoning skills, but also problem solving and critical thinking skills operable to a coding environment. This paper presents students’ use of educational robotics in a school geometry curriculum setting to demonstrate the possibility that mathematics concepts could be gathered and mastered in a playful and informal manner, and that robotics games and computer coding could be performed and framed in a thoughtful and challenging manner.",SI
2-s2.0-85106067286,10.1108/AA-11-2020-0161,,,Human-robot skills transfer interface for UAV-based precision pesticide in dynamic environments,ar,Article,Zhou X.,,Zhejiang University of Technology;Central South University,Hangzhou;Changsha,China;China,,,,,2021-01-01,2021,Assembly Automation,01445154,24904,,Journal,41,3,,345-357,,,1,0,,,,"Purpose

Nowadays, the global agricultural system is highly dependent on the widespread use of synthetic pesticides to control diseases, weeds and insects. The unmanned aerial vehicle (UAV) is deployed as a major part of integrated pest management in a precision agriculture system for accurately and cost-effectively distributing pesticides to resist crop diseases and insect pests.

Design/methodology/approach

With multimodal sensor fusion applying adaptive cubature Kalman filter, the position and velocity are enhanced for the correction and accuracy. A dynamic movement primitive is combined with the Gaussian mixture model to obtain numerous trajectories through the teaching of a demonstration. Further, to enhance the trajectory tracking accuracy under an uncertain environment of the spraying, a novel model reference adaptive sliding mode control approach is proposed for motion control.

Findings

Experimental studies have been carried out to test the ability of the proposed interface for the pesticides in the crop fields. The effectiveness of the proposed interface has been demonstrated by the experimental results.

Originality/value

To solve the path planning problem of a complex unstructured environment, a human-robot skills transfer interface is introduced for the UAV that is instructed to follow a trajectory demonstrated by a human teacher.",NO
2-s2.0-85105851507,10.1109/ACCESS.2021.3079351,,,Neural-Guided Inductive Synthesis of Functional Programs on List Manipulation by Offline Supervised Learning,ar,Article,Wang Y.,,East China Normal University,Shanghai,China,,,,,2021-01-01,2021,IEEE Access,,21100374601,21693536,Journal,9,,9427519,71521-71534,,,0,1,,,,"Synthesizing intended programs from user-specified input-output examples, also known as Programming by Examples (PBE), is a challenging problem in program synthesis, and has been applied to a wide range of domains. A key challenge in PBE is to efficiently discover a user-intended program in the search space that can be exponentially large. In this work, we propose a method for automatic synthesis of functional programs on list manipulation, by using offline-trained Recurrent Neural Network (RNN) models to guide the program search. We adopt miniKanren, an embedded domain-specific language for flexible relational programming, as an underlying top-down deductive search engine of candidate programs that are consistent with input-output examples. Our approach targets an easy and effective integration of deep learning techniques in making better PBE systems and combines two technical ideas on generating diverse training dataset and designing rich feature embeddings of probable subproblems for synthesis generated by deductive search. The offline-learned model is then used in PBE to guide the top-down deductive search with specific strategies. To practically manipulate data structures of lists, our method synthesizes functional programs with popular higher-order combinators including map, foldl and foldr. We have implemented our method and evaluated it with challenging program synthesis tasks on list manipulation. The experiments show promising results on the performance of our method compared to related state-of-the-art inductive synthesizers.",NO
2-s2.0-85105790327,10.29333/ejmste/10842,,,"A Study of the Impact of Arduino and Visual Programming In Self-Efficacy, Motivation, Computational Thinking and 5th Grade Students’ Perceptions on Electricity",ar,Article,Ntourou V.,,,,,,,,,2021-01-01,2021,"Eurasia Journal of Mathematics, Science and Technology Education",13058215,4400151729,13058223,Journal,17,5,,1-11,,,1,1,,,,"This article presents a quasi-experiment which, with the use of Arduino and Scratch for Arduino (S4A), attempts to study their effect on self-efficacy and motivation towards Science Education, Computational Thinking (CT) and the views of 5th Grade students about concepts of electricity. It was conducted on the 5th Grade of a Primary School in Greece. The research team chose the quantitative method, which was conducted through the delivery of four questionnaires that were mainly consisted of close-ended questions. In order to achieve triangulation and a deeper understanding of the topic, it was considered important to include individual open interviews. The data processing failed to prove the effect on motivation, while in self-efficacy it was proved only partially. However, the effect was explicit in view of the conceptual understanding of electricity and CT. The specific project could spur the prosecution of an extended research, aiming at the probe on the one hand of how the existing outcome is confirmed and on the other hand how they are preserved through time, for the purpose of insinuating computational methods and tools into primary education.",SI
2-s2.0-85104775712,10.1007/s00521-021-05972-1,,,Fully neural object detection solutions for robot soccer,ar,Article,Szemenyei M.,,Budapest University of Technology and Economics,Budapest,Hungary,,,,,2021-01-01,2021,Neural Computing and Applications,09410643,24800,14333058,Journal,,,,,,,0,1,,,,"RoboCup is one of the major global AI events, gathering hundreds of teams from the world’s best universities to compete in various tasks ranging from soccer to home assistance and rescue. The commonality of these three seemingly dissimilar tasks is that in order to perform well, the robot needs to excel at the all major AI tasks: perception, control, navigation, strategy and planning. In this work, we focus on the first of these by presenting what is—to our knowledge—the first fully neural vision system for the Nao robot soccer. This is a challenging task, mainly due to the limited computational capabilities of the Nao robot. In this paper, we propose two novel neural network architectures for semantic segmentation and object detection that ensure low-cost inference, while improving accuracy by exploiting the properties of the environment. These models use synthetic transfer learning to be able to learn from a low number of hand-labeled images. The experiments show that our models outperform state-of-the-art methods such as Tiny YOLO at a fraction of the cost.",NO
2-s2.0-85103980055,10.1016/j.isatra.2021.03.046,S0019057821001956,,A Hybrid MPC for Constrained Deep Reinforcement Learning applied for Planar Robotic Arm,ar,Article,Al-Gabalawy M.,,Future University in Egypt,Cairo,Egypt,,,,,2021-01-01,2021,ISA Transactions,00190578,29805,,Journal,,,,,,,2,0,,,,"This article has been withdrawn at the request of the author(s). The authors apologize for any inconvenience this may cause.

The full Elsevier Policy on Article Withdrawal can be found at https://www.elsevier.com/about/our-business/policies/article-withdrawal.",NO
2-s2.0-85103769146,10.1109/ACCESS.2021.3065956,,,Intelligent Guidance Programming of Welding Robot for 3D Curved Welding Seam,ar,Article,Zhou B.,,Southeast University,Nanjing,China,,,,,2021-01-01,2021,IEEE Access,,21100374601,21693536,Journal,9,,9380906,42345-42357,,,0,1,,,,"Due to the limitations of welding complexity and machining error, traditional manual teaching and offline programming are not intelligent enough and have weak adaptability to workpiece. At present, the 2D perception visual welding guidance programming method is commonly used which cannot accurately locate and model the complicated 3D spatial curve welding seam. The 2D perception method can hardly meet the requirements of welding process. In this paper, a welding seam perception method based on a line structure-light sensor was proposed, which optimizes the generation of the weld seam trajectory, and builds a highly adaptable intelligent guidance programming system for welding robots. Firstly, 3D modeling perception of welding parts is realized through eye-in-hand system of robot, which solves the problem that offline programming system cannot be applied when the welding model is not precise enough or partly miss. Secondly, aiming at solving extraction problem of common types of 3D space curve welding seam, corresponding types of weld extraction algorithms are proposed according to the characteristics of different types of welds under the general process of weld extraction. These methods not only can directly extract the weld from the ordered point cloud with high precision and resolution, but also are less affected by the welding environment, which solve the problem of low perception accuracy of complex curved welds in 3D space. Then, on the basis of welding seam extraction, NURBS curves are used to realize the optimal generation of weld trajectory. Finally, the feasibility and effectiveness of all the methods proposed in this paper are verified by a large number of experiments.",NO
2-s2.0-85103759359,10.1109/TE.2021.3066891,,,Halloween Educational Robotics,ar,Article,Menacho A.,,Universidad Nacional de Educacion a Distancia,Madrid,Spain,,,,,2021-01-01,2021,IEEE Transactions on Education,00189359,17344,15579638,Journal,,,,,,,0,0,,,,"Today’s society is facing new challenges and opportunities that demand professional profiles specialized in problem solving, with the ability to innovate and exploit the possibilities offered by information and communication technologies (ICTs). Far from being a novelty, the term STEM was coined in the mid-1990s. From then until now, there are a multitude of initiatives focusing on working STEM education with students. In recent years, the use of the arts as an enhancer of the educational experience has been incorporated into STEM education. There has also been a focus on involving the student in the educational process. Despite this, few experiences have been detected in which parents are involved in the educational process. Throughout this work, it is shown the pilot experience which has been developed to motivate parents to be part of the learning process in science, technology, engineering, art, and mathematics (STEAM) subjects.",SI
2-s2.0-85103041796,10.1007/s10758-021-09508-3,,,Learning Newtonian Physics through Programming Robot Experiments,ar,Article,Ferrarelli P.,,Sapienza Università di Roma,Rome,Italy,,,,,2021-01-01,2021,"Technology, Knowledge and Learning",22111662,19700200832,22111670,Journal,,,,,,,0,1,,,,"Novel technology has been applied to improve students’ learning abilities in different disciplines. The research in this field is still finding suitable methodologies, tools, and evaluation mechanisms to devise learning frameworks with high impact on students’ performance. This article describes an instructional method to perform Newtonian physics experiments by programming a mobile robot. Such experiments allow the learners to design, implement and visualize physics concepts, thus using the robot as a cognitive tool or mindtool. An accurate assessment of the students learning gain, involving 29 high-school students, shows that the proposed method provided significant improvements in the students understanding of the first Newton’s law, the second Newton law and the superposition principle. The learning gain has been measured through the Force Concept Inventory questionnaire. From this study, we can state that programming a mobile robot to perform physics experiments can improve knowledge about Newtonian physics, even without giving specific lectures in the subject and with a much shorter lecture plan with respect to traditional lectures.",SI
2-s2.0-85102259324,10.1109/TCDS.2021.3063273,,,Conditional Generative Adversarial Networks for Optimal Path Planning,ar,Article,Ma N.,,Southern University of Science and Technology,Shenzhen,China,,,,,2021-01-01,2021,IEEE Transactions on Cognitive and Developmental Systems,23798920,21100784665,23798939,Journal,,,,,,,0,0,,,,"Path planning plays an important role in autonomous robot systems. Effective understanding of the surrounding environment and efficient generation of an optimal collision-free path are both critical parts for solving path planning problems. Although conventional sampling-based algorithms, such as the rapidly-exploring random tree (RRT) and its improved optimal version (RRT*), have been widely used in path planning problems because of their ability to find a feasible path in even complex environments, they fail to find an optimal path efficiently. To solve this problem and satisfy the two aforementioned requirements, we propose a novel learning-based path planning algorithm which consists of a novel generative model based on the conditional generative adversarial networks (CGAN) and a modified RRT* algorithm (denoted by CGAN-RRT*). Given the map information, our CGAN model can generate an efficient probability distribution of feasible paths, which can be utilized by the CGAN-RRT* algorithm to find an optimal path with a non-uniform sampling strategy. The CGAN model is trained by learning from ground truth maps, each of which is generated by putting all the results of executing the RRT algorithm 50 times on one raw map. We demonstrate the efficient performance of this CGAN model by testing it on two groups of maps and comparing the CGAN-RRT* algorithm with the Informed-RRT* algorithm and conventional RRT* algorithm.",NO
2-s2.0-85101805922,10.1109/TCYB.2020.2981480,,,Bioinspired Scene Classification by Deep Active Learning With Remote Sensing Applications,ar,Article,Zhang L.,,Wenzhou University,Wenzhou,China,,,,,2021-01-01,2021,IEEE Transactions on Cybernetics,21682267,21100274221,21682275,Journal,,,,,,,0,0,,,,"Accurately classifying sceneries with different spatial configurations is an indispensable technique in computer vision and intelligent systems, for example, scene parsing, robot motion planning, and autonomous driving. Remarkable performance has been achieved by the deep recognition models in the past decade. As far as we know, however, these deep architectures are incapable of explicitly encoding the human visual perception, that is, the sequence of gaze movements and the subsequent cognitive processes. In this article, a biologically inspired deep model is proposed for scene classification, where the human gaze behaviors are robustly discovered and represented by a unified deep active learning (UDAL) framework. More specifically, to characterize objects' components with varied sizes, an objectness measure is employed to decompose each scenery into a set of semantically aware object patches. To represent each region at a low level, a local-global feature fusion scheme is developed which optimally integrates multimodal features by automatically calculating each feature's weight. To mimic the human visual perception of various sceneries, we develop the UDAL that hierarchically represents the human gaze behavior by recognizing semantically important regions within the scenery. Importantly, UDAL combines the semantically salient region detection and the deep gaze shifting path (GSP) representation learning into a principled framework, where only the partial semantic tags are required. Meanwhile, by incorporating the sparsity penalty, the contaminated/redundant low-level regional features can be intelligently avoided. Finally, the learned deep GSP features from the entire scene images are integrated to form an image kernel machine, which is subsequently fed into a kernel SVM to classify different sceneries. Experimental evaluations on six well-known scenery sets (including remote sensing images) have shown the competitiveness of our approach.
(Show More)",NO
2-s2.0-85101287945,10.1080/01691864.2021.1890212,,,Autonomous planning based on spatial concepts to tidy up home environments with service robots,ar,Article,Taniguchi A.,,Ritsumeikan University Biwako-Kusatsu Campus,Kusatsu,Japan,,,,,2021-01-01,2021,Advanced Robotics,01691864,18003,15685535,Journal,35,8,,471-489,,,2,0,,,,"Tidy-up tasks by service robots in home environments are challenging in robotics applications because they involve various interactions with the environment. In particular, robots are required not only to grasp, move, and release various home objects but also to plan the order and positions for placing the objects. In this paper, we propose a novel planning method that can efficiently estimate the order and positions of the objects to be tidied up by learning the parameters of a probabilistic generative model. The model allows a robot to learn the distributions of the co-occurrence probability of the objects and places to tidy up using the multimodal sensor information collected in a tidied environment. Additionally, we develop an autonomous robotic system to perform the tidy-up operation. We evaluate the effectiveness of the proposed method by an experimental simulation that reproduces the conditions of the Tidy Up Here task of the World Robot Summit 2018 international robotics competition. The simulation results show that the proposed method enables the robot to successively tidy up several objects and achieves the best task score among the considered baseline tidy-up methods.",NO
2-s2.0-85101206574,10.1515/itit-2018-0016,,,The Berlin Big Data Center (BBDC),ar,Article,Boden C.,,Technical University of Berlin,Berlin,Germany,,,,,2021-01-01,2021,IT - Information Technology,16112776,21100929583,21967032,Journal,60,5,,321-326,,,0,0,,,,"The last decade has been characterized by the collection and availability of unprecedented amounts of data due to rapidly decreasing storage costs and the omnipresence of sensors and data-producing global online-services. In order to process and analyze this data deluge, novel distributed data processing systems resting on the paradigm of data flow such as Apache Hadoop, Apache Spark, or Apache Flink were built and have been scaled to tens of thousands of machines. However, writing efficient implementations of data analysis programs on these systems requires a deep understanding of systems programming, prohibiting large groups of data scientists and analysts from efficiently using this technology. In this article, we present some of the main achievements of the research carried out by the Berlin Big Data Cente (BBDC). We introduce the two domain-specific languages Emma and LARA, which are deeply embedded in Scala and enable declarative specification and the automatic parallelization of data analysis programs, the PEEL Framework for transparent and reproducible benchmark experiments of distributed data processing systems, approaches to foster the interpretability of machine learning models and finally provide an overview of the challenges to be addressed in the second phase of the BBDC.",NO
2-s2.0-85100784455,10.1109/ACCESS.2021.3056903,,,Motion planning for dual-arm robot based on soft actor-critic,ar,Article,Wong C.C.,,Tamkang University,New Taipei City,Taiwan,,,,,2021-01-01,2021,IEEE Access,,21100374601,21693536,Journal,9,,9345768,26871-26885,,,4,1,,,,"In this paper, a motion planning method based on the Soft Actor-Critic (SAC) is designed for a dual-arm robot with two 7-Degree-of-Freedom (7-DOF) arms so that the robot can effectively avoid self-collision and at the same time can avoid the joint limits and singularities of the arm. The left-arm and right-arm of the dual-arm robot each have a neural network to control its position and orientation. Dual-agent training, distributed training structure, and progressive training environment are used to train neural networks. During the training process, the motion of one arm is regarded as the environment of the other arm, and the two agents are trained at the same time. In the input part of the neural network of the proposed method, all parameters come from the angle of each axis and kinematic calculation, no additional sensors are needed, so the method is easier to transplant to different dual-arm robots. With some appropriate neural network inputs and reward functions design, the robot can perform the expected self-collision avoidance and effectively avoid the joint limits and singularities of the arm. Finally, some experiments of the simulation tests in the Gazebo simulator and actual tests in a laboratory-made dual-arm robot are presented to illustrate the proposed SAC-based motion planning method is feasible and practicable in the avoidance of self-collision, joint limits, and singularities.",NO
2-s2.0-85100318273,10.3233/THC-202527,,33074204,Robot-assisted feeding: A technical application that combines learning from demonstration and visual interaction,ar,Article,Liu F.,,University of Shanghai for Science and Technology;Shanghai Engineering Research Center of Assistive Devices,Shanghai;Shanghai,China;China,,,,,2021-01-01,2021,Technology and Health Care,09287329,19644,,Journal,29,1,,187-192,,,0,0,,,,"BACKGROUND: The traditional meal assistance robots use human-computer interaction such as buttons, voice, and EEG. However, most of them rely on excellent programming technology for development, in parallelism with exhibiting inconvenient interaction or unsatisfactory recognition rates in most cases. OBJECTIVE: To develop a convenient human-computer interaction mode with a high recognition rate, which allows users to make the robot show excellent adaptability in the new environment without programming ability. METHODS: A visual interaction method based on deep learning was used to develop the feeding robot: when the camera detects that the user’s mouth is open for 2 seconds, the feeding command is turned on, and the feeding is temporarily conducted when the eyes are closed for 2 seconds. A programming method of learning from the demonstration, which is simple and has strong adaptability to different environments, was employed to generate a feeding trajectory. RESULTS: The user is able to eat independently through convenient visual interaction, and it only requires the caregiver to drag and teach the robotic arm once in the face of a new eating environment.",NO
2-s2.0-85099580197,10.1109/ACCESS.2021.3051043,,,Characterizing Visual Programming Approaches for End-User Developers: A Systematic Review,ar,Article,Kuhail M.A.,,Zayed University,Dubai,United Arab Emirates,,,,,2021-01-01,2021,IEEE Access,,21100374601,21693536,Journal,9,,9320477,14181-14202,,,2,1,,,,"Recently many researches have explored the potential of visual programming in robotics, the Internet of Things (IoT), and education. However, there is a lack of studies that analyze the recent evidence-based visual programming approaches that are applied in several domains. This study presents a systematic review to understand, compare, and reflect on recent visual programming approaches using twelve dimensions: visual programming classification, interaction style, target users, domain, platform, empirical evaluation type, test participants' type, number of test participants, test participants' programming skills, evaluation methods, evaluation measures, and accessibility of visual programming tools. The results show that most of the selected articles discussed tools that target IoT and education, while other fields such as data science, robotics are emerging. Further, most tools use abstractions to hide implementation details and use similar interaction styles. The predominant platforms for the tools are web and mobile, while desktop-based tools are on the decline. Only a few tools were evaluated with a formal experiment, whilst the remaining ones were evaluated with evaluation studies or informal feedback. Most tools were evaluated with students with little to no programming skills. There is a lack of emphasis on usability principles in the design stage of the tools. Additionally, only one of the tools was evaluated for expressiveness. Other areas for exploration include supporting end users throughout the life cycle of applications created with the tools, studying the impact of tutorials on improving learnability, and exploring the potential of machine learning to improve debugging solutions developed with visual programming.",SI
2-s2.0-85099317604,10.3390/robotics10010003,,,Leveraging graphical user interface automation for generic robot programming,ar,Article,Ionescu T.B.,,Technische Universität Wien,Vienna,Austria,,,,,2021-01-01,2021,Robotics,,21100833833,22186581,Journal,10,1,3,1-23,,,4,1,,,,"A novel approach to generic (or generalized) robot programming and a novel simplified, block-based programming environment, called “Assembly”, are introduced. The approach leverages the newest graphical user interface automation tools and techniques to generate programs in various proprietary robot programming environments by emulating user interactions in those environments. The “Assembly” tool is used to generate robot-independent intermediary program models, which are translated into robot-specific programs using a graphical user interface automation toolchain. The generalizability of the approach to list, tree, and block-based programming is assessed using three different robot programming environments, two of which are proprietary. The results of this evaluation suggest that the proposed approach is feasible for an entire range of programming models and thus enables the generation of programs in various proprietary robot programming environments. In educational settings, the automated generation of programs fosters learning different robot programming models by example. For experts, the proposed approach provides a means for generating program (or task) templates, which can be adjusted to the needs of the application at hand on the shop floor. View Full-Text",SI
2-s2.0-85094140525,10.1109/TASE.2020.2984739,,,A Method Integrating Q-Learning with Approximate Dynamic Programming for Gantry Work Cell Scheduling,ar,Article,Ou X.,,Stony Brook University,Stony Brook,United States,,,,,2021-01-01,January 2021,IEEE Transactions on Automation Science and Engineering,15455955,17340,15583783,Journal,18,1,9069276,85-93,,,6,0,,,,"This article formulates gantry real-time scheduling in a gantry work cell, where the material transfer is driven by gantries, as a Markov decision process (MDP). Classical learning methods and planning methods for solving the optimization problems in MDP are discussed. An innovative method, called “Q-ADP,” is proposed to integrate reinforcement learning (RL) with approximate dynamic programming (ADP). Q-ADP uses model-free Q-learning algorithm to learn state values through interactions with the environment, meanwhile, planning steps during the learning process opt for ADP to keep updating state values through several sample paths. A model of one-step transition probabilities is built based on the machines' reliability model, and serves the ADP algorithm. To demonstrate the effectiveness of this method, a numerical study is performed to show the production performance, compared to a standard Q-learning algorithm. The simulation results show that Q-ADP outperforms standard Q-learning under the same length of training process. It is also shown that with the benefit of repeated updating state values through sample paths, Q-ADP requires less data for gantry policy to converge, which makes the method promising when real data are limited.",NO
2-s2.0-85091727135,10.1007/s10514-020-09947-4,,,Reinforcement based mobile robot path planning with improved dynamic window approach in unknown environment,ar,Article,Chang L.,,Nanjing University of Science and Technology,Nanjing,China,,,,,2021-01-01,January 2021,Autonomous Robots,09295593,18016,15737527,Journal,45,1,,51-76,,,8,0,,,,"Mobile robot path planning in an unknown environment is a fundamental and challenging problem in the field of robotics. Dynamic window approach (DWA) is an effective method of local path planning, however some of its evaluation functions are inadequate and the algorithm for choosing the weights of these functions is lacking, which makes it highly dependent on the global reference and prone to fail in an unknown environment. In this paper, an improved DWA based on Q-learning is proposed. First, the original evaluation functions are modified and extended by adding two new evaluation functions to enhance the performance of global navigation. Then, considering the balance of effectiveness and speed, we define the state space, action space and reward function of the adopted Q-learning algorithm for the robot motion planning. After that, the parameters of the proposed DWA are adaptively learned by Q-learning and a trained agent is obtained to adapt to the unknown environment. At last, by a series of comparative simulations, the proposed method shows higher navigation efficiency and successful rate in the complex unknown environment. The proposed method is also validated in experiments based on XQ-4 Pro robot to verify its navigation capability in both static and dynamic environment.",NO
2-s2.0-85083969396,10.1002/cae.22245,,,Development of an augmented reality-based scaffold to improve the learning experience of engineering students in embedded system course,ar,Article,Kumar A.,,"Chitkara University, Punjab",Rajpura,India,,,,,2021-01-01,January 2021,Computer Applications in Engineering Education,10613773,18156,10990542,Journal,29,1,,244-257,,,4,0,,,,"The Embedded system is the core unit of every digital device. The design and development of a new digital device or system require a good understanding of the embedded system embed in it. In the context of engineering education, learning embedded systems remains a challenge for the millennial. As, it involves the implementation of mathematics, programming, and working knowledge of electronic and electrical components rooted in it. Traditional teaching pedagogy has become less useful for new-gen learners to satisfy their demand for knowledge of embedded systems. So, the teaching techniques have to be modified and equipped with the latest technological tools and practices. Augmented reality (AR) is emerging as a new technology in the field of engineering education. With the help of computer-generated 3D data, animation, visual effects, and immersion, this technology has become more prevalent in the education domain to make complex concepts easier to understand. In this paper, an augmented reality-based framework designed to teach embedded systems to engineering students. The proposed framework utilizes a tangible user interface comprising of AR markers, a USB camera, a display device, and the processing unit to give AR learning experience to the students. The system so developed tested for its usability with the faculty members of engineering education. Twenty faculty members, as participants, share their system usability experience and feedback using google form. The overall system usability score is 79.5%, which makes it suitable for further deployment on students forexploratory work.

KEYWORDSAR marker, augmented reality, embedded systems, engineering education, usability",NO
2-s2.0-85068542094,10.1080/07370024.2019.1621175,,,Physical Programming for Blind and Low Vision Children at Scale,ar,Article,Morrison C.,,Microsoft Research,Redmond,United States,,,,,2021-01-01,2021,Human-Computer Interaction,07370024,25019,,Journal,36,5-6,,535-569,,,3,0,,,,"There is a dearth of appropriate tools for young learners with mixed visual abilities to engage with computational learning. Addressing this gap, Torino is a physical programming language for teaching computational learning to children ages 7–11 regardless of level of vision. To create code, children connect physical instruction pods and tune their parameter dials to create music, audio stories, or poetry. Currently, the uptake of novel educational technologies to support inclusive education of children with disabilities continues to be limited at scale. We consider how the Torino Learning Environment supports non-specialist teachers to teach computational learning to children with mixed visual abilities in a UK-wide evaluation with 75 children and 30 teachers over a period of three months. We demonstrate how children can successfully learn with a novel physical programming language. We articulate how key design constructs such as persistent program overview and liveness supported non-specialist teachers to co-produce learning for children of different ages, visual and cognitive abilities. We conclude with reflective guidance on evaluating inclusive educational technologies at scale.

CCS CONCEPTS

Human-centered computing → Accessibility → Empirical studies in accessibility",NO
2-s2.0-85063399432,10.1080/10494820.2019.1593862,,,Algotaurus: an educational computer programming game for beginners,ar,Article,Krajcsi A.,,Eötvös Loránd Tudományegyetem,Budapest,Hungary,,,,,2021-01-01,2021,Interactive Learning Environments,10494820,145681,17445191,Journal,29,4,,634-647,,,0,1,,,,"An educational computer game is presented, used for beginner students to introduce some basic concepts of code execution and code writing. In this mini-language microworld game, a code should be written with which a robot can escape from a procedurally generated labyrinth. The game uses a simple language and utilizes a virtual environment, where code execution could be tracked easily. One essential advantage of the software is that after a very short training, students can start experimenting, and they can understand many basic properties of code writing and execution. Based on several pilot teaching classes in both primary schools and universities, the game is an efficient tool to introduce the bases of computer programming, which bases might be harder to demonstrate with other educational tools.",NO
